{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1002\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.4.min.js\"];\n",
       "  var css_urls = [];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1002\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.4.min.js\"];\n  var css_urls = [];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from src.CCLE_postp_function import *\n",
    "from JKBio import Datanalytics as da \n",
    "from JKBio import TerraFunction as terra\n",
    "from JKBio import Helper as h\n",
    "from gsheets import Sheets\n",
    "from taigapy import TaigaClient\n",
    "import dalmatian as dm\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from bokeh.plotting import *\n",
    "from bokeh.models import HoverTool\n",
    "from collections import OrderedDict\n",
    "from IPython.display import Image,display\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext rpy2.ipython\n",
    "tc = TaigaClient()\n",
    "output_notebook()\n",
    "sheets = Sheets.from_files('~/.client_secret.json', '~/.storage.json')\n",
    "replace = {'T': 'Tumor', 'N': 'Normal', 'm': 'Unknown', 'L': 'Unknown'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boot up\n",
    "\n",
    "we are instanciating all the parameters needed for this pipeline to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesetname = \"20Q3\"\n",
    "prevname=\"20Q2\"\n",
    "prevversion = 22\n",
    "prevprevname ='20Q1'\n",
    "prevprevversion= 20\n",
    "virtual_public='public-20q3-3d35'\n",
    "virtual_dmc='dmc-20q3-033d'\n",
    "virtual_internal='internal-20q3-00d0'\n",
    "\n",
    "workspace1=\"broad-genomics-delivery/Getz_IBM_CellLines_Exomes\"\n",
    "workspace2=\"broad-firecloud-ccle/CCLE_DepMap_WES\"\n",
    "workspace3=\"broad-genomics-delivery/CCLE_DepMap_WES\"\n",
    "\n",
    "workspace6=\"terra-broad-cancer-prod/CCLE_DepMap_WES\"\n",
    "\n",
    "refworkspace=\"broad-firecloud-ccle/DepMap_Mutation_Calling_CGA_pipeline\"\n",
    "\n",
    "rnaworkspace=\"broad-firecloud-ccle/DepMap_hg38_RNAseq\"\n",
    "\n",
    "source1=\"ibm\"\n",
    "source2=\"ccle\"\n",
    "source3=\"ccle\"\n",
    "source6=\"ccle\"\n",
    "source7=\"ibm\"\n",
    "\n",
    "refsheet_url = \"https://docs.google.com/spreadsheets/d/1XkZypRuOEXzNLxVk9EOHeWRE98Z8_DBvL4PovyM01FE\"\n",
    "sheeturl = \"https://docs.google.com/spreadsheets/d/115TUgA1t_mD32SnWAGpW9OKmJ2W5WYAOs3SuSdedpX4\"\n",
    "\n",
    "release = samplesetname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "release <- '20Q3'\n",
    "prevname <- '20Q2'\n",
    "genome_version <- 'hg19'\n",
    "taiga_version <- 10\n",
    "prevversion <-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm1 = dm.WorkspaceManager(workspace1)\n",
    "wm2 = dm.WorkspaceManager(workspace2)\n",
    "wm3 = dm.WorkspaceManager(workspace3)\n",
    "\n",
    "wm6 = dm.WorkspaceManager(workspace6)\n",
    "\n",
    "refwm = dm.WorkspaceManager(refworkspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_to_change = {'from_arxspan_id': 'participant'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new data\n",
    "\n",
    "We are looking for new samples in a range of workspaces.\n",
    "\n",
    "They are quite messy and might contains duplicates, contain broken file paths...\n",
    "\n",
    "- We are thus looking at the bam files one by one and comparing them with our own bams. \n",
    "- We remove broken files, duplicates and add new version of a cell line's bam if we find some."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be missing \"primary disease\",\"sm_id\", \"cellosaurus_id\", \"gender, \"age\", \"primary_site\", \"primary_disease\", \"subtype\", \"subsubtype\", \"origin\", \"comments\"\n",
    "#when SMid: match== \n",
    "samples, pairs, noarxspan = GetNewCellLinesFromWorkspaces(refworkspace, stype='wes', refurl=refsheet_url, wmfroms = [workspace1, workspace2, workspace3, workspace6], sources=[source1, source2, source3, source6], match=['ACH-','CDS-'], participantslicepos=10, accept_unknowntypes=True, extract=extract_to_change, recomputedate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am trying to remove duplicates from samples without arxspan ids to then look more into them and see if I have to get data for them or if I should just throw them out\n",
    "toremov=set()\n",
    "for k, val in noarxspan.iterrows():\n",
    "    withsamesize = noarxspan[noarxspan[\"sample_id\"] == val[\"sample_id\"]]\n",
    "    if len(withsamesize) > 1:\n",
    "        for l, v in withsamesize.iloc[1:].iterrows():\n",
    "            toremov.add(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in toremov:\n",
    "    noarxspan = noarxspan.drop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noarxspan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noarxspan.sample_id = [i.split('_Exom')[0] for i in noarxspan.sample_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(noarxspan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noarxspan['ccle_name'] = [''.join(i.split('_')[1:-1]).split('_v')[0] for i in noarxspan.sample_id]\n",
    "noarxspan['readgroup'] = [i.split('_')[0] for i in noarxspan.sample_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in noarxspan.iterrows():\n",
    "    if not gcp.exists(v['cram_or_bam_path']):\n",
    "        print(v.ccle_name)\n",
    "        noarxspan = noarxspan.drop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noarxspan['ccle_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(noarxspan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toupdate = {\"gender\":[],\n",
    "\"primary_disease\":[],\n",
    "\"sm_id\":[],\n",
    "\"cellosaurus_id\":[],\n",
    "\"age\":[],\n",
    "\"primary_site\":[],\n",
    "\"subtype\":[],\n",
    "\"subsubtype\":[],\n",
    "\"origin\":[],\n",
    "\"comments\":[],\n",
    "\"patient_id\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If I have a previous samples I can update unknown data directly\n",
    "index=[]\n",
    "notfound=[]\n",
    "for k, val in samples.iterrows():\n",
    "    dat = ccle_refsamples[ccle_refsamples['arxspan_id']==val['arxspan_id']]\n",
    "    if len(dat)>0:\n",
    "        index.append(k)\n",
    "        for k, v in toupdate.items():\n",
    "            toupdate[k].append(dat[k].tolist()[0])\n",
    "    else:\n",
    "        notfound.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing so..\n",
    "for k, v in toupdate.items():\n",
    "    samples.loc[index,k] =v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples.loc[notfound].patient_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.loc[notfound].patient_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for these samples I will need to check and manually add the data in the list \n",
    "samples.loc[notfound]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# found same patient\n",
    "a = [\"ACH-000635\",\"ACH-000717\", \"ACH-000864\", \"ACH-001042\", \"ACH-001547\"]\n",
    "b = [\"ACH-002291\",\"ACH-001672\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples[ccle_refsamples.arxspan_id.isin(a)].patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate ach-id\n",
    "dup = {\"ACH-001620\": \"ACH-001605\",\n",
    "\"ACH-001621\": \"ACH-001606\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = changeCellLineNameInNewSet(new = samples, ref=ccle_refsamples, datatype=\"rna\", dupdict=dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename ccle_name TODO: ask becky what to do\n",
    "rename = {\"PEDS117\": \"CCLFPEDS0009T\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(notfound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting the addtional data and writing it here in the right order 'as shown above'\n",
    "- use the stripped_cell_line_name to find the samples on https://docs.google.com/spreadsheets/d/1uqCOos-T9EMQU7y2ZUw4Nm84opU5fIT1y7jet1vnScE/edit#gid=356471436. \n",
    "- Make sure that we don't have duplicate cell lines in there. Otherwise, use the duplicate renaming function\n",
    "- copy Primary Site, Primary Disease, Subtype, Comments, Disease Sub-subtype, if they exist. (sometimes subtype and subsubtype are the same.. don't use subsubtype then.\n",
    "- look for the cell line in cellosaurus, you might need to use one of the aliases given in master depmap pv..\n",
    "- copy  cellosaurus_id gender age info or write 'U' if they don't exist. 'can be a number or {Embryonic, Children, Adult, Fetus, U} \n",
    "- check that it does not say this cell line is not a duplicate from another cell line\n",
    "- check that if it says this cell line is derived/children/father/samepatient from other cell lines, and that if we have any of the other cell lines, that the patient id is changed to be the same one for all (be sure that you are updating everywhere these patient ids are used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toupdate = {\"gender\":[\"Female\",\"Female\",\"Female\"],\n",
    "\"primary_disease\":[\"Breast Cancer\",\"Breast Cancer\",\"Breast Cancer\"],\n",
    "\"cellosaurus_id\":[\"CVCL_7932\",\"CVCL_7931\",\"CVCL_7933\"],\n",
    "\"age\":[37,37,37],\n",
    "\"primary_site\":[\"pleural_effusion\",\"pleural_effusion\",\"breast\"],\n",
    "\"subtype\":[\"Carcinoma\",\"Carcinoma\",\"Carcinoma\"],\n",
    "\"subsubtype\":[\"\",\"\",\"\"],\n",
    "\"comments\":[\"HER2+; Received from Academic lab (Polyak, DFCI)\",\"HER2+; Received from Academic lab (Polyak, DFCI)\",\"HER2+; Received from Academic lab (Polyak, DFCI)\"],\n",
    "\"stripped_cell_line_name\":[\"21MT2\",\"21MT1\", \"21NT\"],\n",
    "\"patient_id\":['PT-y3RbI7uD', 'PT-y3RbI7uD', 'PT-y3RbI7uD']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = pd.DataFrame(toupdate)\n",
    "a['name'] = samples.loc[notfound,\"stripped_cell_line_name\"].tolist()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating..\n",
    "for k, v in toupdate.items():\n",
    "    samples.loc[notfound,k] =v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploading to our bucket (now a new function)\n",
    "samples = h.changeToBucket(samples,'gs://cclebams/wes/', values=['internal_bam_filepath','internal_bai_filepath'], catchdup=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving and updating the spreadsheet with these\n",
    "print(\"YOU NOW NEED TO UPDATE THE GOOGLE SHEET!\")\n",
    "samples.to_csv('temp/new_ccle_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples['arxspan_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = samples.rename(columns={'patient_id':'participant_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairs.rename(columns={'patient_id':'participant_id'}).set_index('pair_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.participant_id = samples.participant_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = cnwm.get_samples()\n",
    "sam[sam['baits']==\"AGILENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uploading new samples to mut\n",
    "refwm = refwm.disable_hound()\n",
    "refwm.upload_samples(samples)\n",
    "refwm.upload_entities('pairs', pairs)\n",
    "refwm.update_pair_set(pair_set_id=samplesetname,pair_ids=pairs.index)\n",
    "sam = refwm.get_samples()\n",
    "\n",
    "pair = refwm.get_pairs()\n",
    "refwm.update_pair_set(pair_set_id='all',pair_ids=pair.index)\n",
    "refwm.update_pair_set(pair_set_id='all_agilent',pair_ids=pair[pair[\"case_sample\"].isin(sam[sam['baits']==\"AGILENT\"].index.tolist())].index)\n",
    "refwm.update_pair_set(pair_set_id='all_ice',pair_ids=pair[pair[\"case_sample\"].isin([i for i in sam[(sam['baits'] == \"ICE\") |(sam['baits'].isna())].index.tolist() if i != 'nan'])].index)\n",
    "#creating a sample set\n",
    "refwm.update_sample_set(sample_set_id=samplesetname, sample_ids=samples.index)\n",
    "refwm.update_sample_set(sample_set_id='all', sample_ids=[i for i in sam.index.tolist() if i!='nan'])\n",
    "refwm.update_sample_set(sample_set_id='all_agilent', sample_ids = sam[sam['baits'] == \"AGILENT\"].index.tolist())\n",
    "refwm.update_sample_set(sample_set_id='all_ice', sample_ids=[i for i in sam[(sam['baits'] == \"ICE\") |(sam['baits'].isna())].index.tolist() if i != 'nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and CN\n",
    "cnwm = dm.WorkspaceManager('broad-firecloud-ccle/DepMap_WES_CN_hg38')\n",
    "cnwm = cnwm.disable_hound()\n",
    "cnwm.upload_samples(samples)\n",
    "cnwm.upload_entities('pairs', pairs)\n",
    "cnwm.update_pair_set(pair_set_id=samplesetname,pair_ids=pairs.index)\n",
    "sam = cnwm.get_samples()\n",
    "\n",
    "pair = cnwm.get_pairs()\n",
    "cnwm.update_pair_set(pair_set_id='all',pair_ids=pair.index)\n",
    "cnwm.update_pair_set(pair_set_id='all_agilent',pair_ids=pair[pair[\"case_sample\"].isin(sam[sam['baits']==\"AGILENT\"].index.tolist())].index)\n",
    "cnwm.update_pair_set(pair_set_id='all_ice',pair_ids=pair[pair[\"case_sample\"].isin([i for i in sam[(sam['baits'] == \"ICE\") |(sam['baits'].isna())].index.tolist() if i != 'nan'])].index)\n",
    "#creating a sample set\n",
    "#cnwm.update_sample_set(sample_set_id=samplesetname, sample_ids=samples.index)\n",
    "#cnwm.update_sample_set(sample_set_id='all', sample_ids=[i for i in sam.index.tolist() if i!='nan'])\n",
    "#cnwm.update_sample_set(sample_set_id='all_agilent', sample_ids = sam[sam['baits'] == \"AGILENT\"].index.tolist())\n",
    "cnwm.update_sample_set(sample_set_id='all_ice', sample_ids=[i for i in sam[(sam['baits'] == \"ICE\") |(sam['baits'].isna())].index.tolist() if i != 'nan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that we have all the cell lines we expect for this release\n",
    "\n",
    "This involves comparing to the list in the Google sheet \"Cell Line Profiling Status.\"\n",
    "\n",
    "_As the list cannot be parsed, we are not comparing it for now_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function may not work - it hasn't been tested\n",
    "url = 'https://docs.google.com/spreadsheets/d/1qus-9TKzqzwUMNWp8S1QP4s4-3SsMo2vuQRZrNXf7ag/edit?ts=5db85e27#gid=0&fvid=1627883727'\n",
    "\n",
    "compareToCuratedGS(url, sample = newsample[0], samplesetname = samplesetname, colname = 'CN New to internal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the pipeline\n",
    "\n",
    "We are using Dalmatian to send request to Terra, we are running a set of 5 functions To generate the mutation dataset:\n",
    "\n",
    "*   For new samples in DepMap, run the ICE version of this task. CCLE2 samples used Agilent targets, so this pipeline should be used instead. The pipelines are identical in terms of their outputs, but the proper targets, baits, and pseudo normal should be used based on how the samples were sequenced.\n",
    "\n",
    "    **ICE_CGA_Production_Analysis_Pipeline_Cell_Lines_copy** (cclf/CGA_Production_Analysis_Pipeline_Cell_Lines_debuggingSnapshot ID: 22) OR\n",
    "\n",
    "\n",
    "    **AGILENT_CGA_Production_Analysis_Pipeline_Cell_Lines** (cclf/CGA_Production_Anablysis_Pipeline_Cell_Lines_debuggingSnapshot ID: 22)\n",
    "\n",
    "*   **common_variant_filter** (breardon/common_variant_filterSnapshot ID: 3)\n",
    "*   **filterMAF_on_CGA_pipeline** (gkugener/filterMAF_on_CGA_pipelineSnapshot ID: 8)\n",
    "*   **aggregateMAFs_selectFields** (ccle_mg/aggregateMAFs_selectFieldsSnapshot ID: 1)\n",
    "\n",
    "This outputs to be downloaded will be saved in the sample set that was run. The output we use for the release is:\n",
    "\n",
    "\n",
    "*   **passedCGA_filteredMAF_aggregated** \n",
    "\n",
    "There are several other tasks in this workspace. In brief:\n",
    "\n",
    "\n",
    "\n",
    "*   **CGA_Production_Analysis_Pipeline_Cell_Lines** (lelagina/CGA_Production_Analysis_Pipeline_Cell_LinesSnapshot ID: 12). This task is the same as the ICE and AGILENT prefixed version above, except that it relied on pulling the baits and targets to use from the metadata stored for the samples. Having AGILENT and ICE versions specified made the uploading and running process easier.\n",
    "*   **SANGER_CGA_Production_Analysis_Pipeline_Cell_Lines** (cclf/CGA_Production_Analysis_Pipeline_Cell_Lines_debuggingSnapshot ID: 22). This task was trying to run the CGA pipeline on the Sanger WES data, using a Sanger pseudo normal. In its current implementation, this task fails to complete for the samples.\n",
    "*   **UNFILTERED_aggregateMAFs_selectFields** (ccle_mg/aggregateMAFs_selectFieldsSnapshot ID: 1). Aggregates the MAF outputted by the CGA cell line pipeline prior to the common variant filter and germline filtering tasks. This can give us insight to which mutations are getting filtered out when. We may want to potentially include this MAF in the release so people can see why certain mutations of interest may be getting filtered out.\n",
    "*   WES_DM_Mutation_Calling_Pipeline_(standard |expensive) (gkugener/WES_DM_Mutation_Calling_PipelineSnapshot ID: 2). This was a previous mutation calling pipeline implemented for CCLE. We do not use this pipeline any more as the CGA pipeline looks better.\n",
    "*   aggregate_filterMAF_CGA (CCLE/aggregate_filterMAF_CGASnapshot ID: 1). An aggregation MAF task that we used in the past. We do not use this task anymore.\n",
    "*   calculate_mutational_burden (breardon/calculate_mutational_burdenSnapshot ID: 21). This task can be used to calculate the mutational rate of the samples. We do not make use of this data in the release although it could be of interest.\n",
    "*   summarizeWigFile (breardon/summarizeWigFileSnapshot ID: 5). CCLF ran this task (might be necessary for the mutational burden task). For our workflow, we do not run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Terra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id1 = refwm.create_submission(\"CGA_WES_CCLE_ICE\", samplesetname,'pair_set',expression='this.pairs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy pairs data to sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = refwm.get_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairs[pairs.index.isin(tokeep)]\n",
    "pairs = pairs[~pairs['mutation_validator_validated_maf'].isna()]\n",
    "pairs = pairs.drop(columns=['case_sample','control_sample','participant_id'])\n",
    "pairs.index = [i.split('_')[0] for i in pairs.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refwm.update_sample_attributes(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Germline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-1cbc8561191b>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-1cbc8561191b>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    terra.waitForSubmission(refworkspace, submission_id)\"cnn-variant-filter\"\u001b[0m\n\u001b[0m                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "submission_id2 = refwm.create_submission(\"cnn-variant-filter\", samplesetname, 'sample_set', expression='this.samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.waitForSubmission(refworkspace, submission_id1)\n",
    "submission_id1 = refwm.create_submission(\"common_variant_filter\", samplesetname, 'sample_set', expression='this.samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.waitForSubmission(refworkspace, submission_id2)\n",
    "submission_id2 = refwm.create_submission(\"aggregate_vcfs\", samplesetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.waitForSubmission(refworkspace, submission_id1)\n",
    "submission_id1 = refwm.create_submission(\"filterMAF_on_CGA_pipeline\", samplesetname,'sample_set',expression='this.samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.waitForSubmission(refworkspace, submission_id1)\n",
    "submission_id1 = refwm.create_submission(\"aggregateMAFs_selectFields_copy\", samplesetname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id3 = refwm.create_submission(\"aggregateMAFs_selectFields_unfiltered\", samplesetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.waitForSubmission(refworkspace, [submission_id1,submission_id2, submission_id3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the workflow configurations used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.saveConfigs(refworkspace,'./data/'+samplesetname+'/Mutconfig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On local\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove some datafile to save money¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = refwm.get_samples()\n",
    "toremove = [\"fixedmate_bam\"]\n",
    "for val in toremove:\n",
    "    refwm.disable_hound().delete_entity_attributes('sample', res[val], delete_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil -m rm \"gs://fc-secure-012d088c-f039-4d36-bde5-ee9b1b76b912/9e3cc501-3f08-47fb-87a5-0359febb833c/**/call-tumorMM_Task/*.cleaned.bam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes it does not work so better check again\n",
    "a = res.fixedmate_bam\n",
    "a = [i for i in a if i is not np.nan]\n",
    "gcp.rmFiles(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### downloading from terra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = refwm.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nowes = set(mutations.DepMap_ID)-set(sam.arxspan_id)\n",
    "nowes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nothing = nows -set(ccle_refsamples.arxspan_id)\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(mutations[mutations.DepMap_ID.isin(nothing) & ~mutations.SangerWES_AC.isna()].DepMap_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = refwm.get_sample_sets().loc[\"all\"]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = res['filtered_CGA_MAF_aggregated']\n",
    "! gsutil cp $filtered \"temp/mutation_filtered_terra_merged.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get QC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMut = getWESQC(workspace=refworkspace ,only=[], qcname=[\"gatk_cnv_all_plots\", \"lego_plotter_pngs\", \"copy_number_qc_report\", \"ffpe_OBF_figures\", \"mut_legos_html\", \"oxoG_OBF_figures\", \"tumor_bam_base_distribution_by_cycle_metrics\", \"tumor_bam_converted_oxog_metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataBam = getWESQC(workspace=refworkspace ,only=[], qcname=[ \"tumor_bam_alignment_summary_metrics\", \"tumor_bam_bait_bias_summary_metrics\", \"tumor_bam_gc_bias_summary_metrics\", \"tumor_bam_hybrid_selection_metrics\", \"tumor_bam_insert_size_histogram\", \"tumor_bam_insert_size_metrics\", \"tumor_bam_pre_adapter_summary_metrics\", \"tumor_bam_quality_by_cycle_metrics\", \"tumor_bam_quality_distribution_metrics\", \"tumor_bam_quality_yield_metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_refsamples = pd.read_csv('temp/newrefCN.csv',index_col=\"cds_sample_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dataMut.items():\n",
    "    if k =='nan':\n",
    "        continue\n",
    "    new_refsamples.loc[k,'processing_qc'] = str(v) + ',' + new_refsamples.loc[k,'processing_qc']\n",
    "for k,v in dataBam.items():\n",
    "    if k =='nan':\n",
    "        continue\n",
    "    new_refsamples.loc[k,'bam_qc'] = str(v) + ',' + new_refsamples.loc[k,'bam_qc']\n",
    "new_refsamples.to_csv('temp/newrefWES.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieving unfiltered mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered = res['unfiltered_CGA_MAF_aggregated']\n",
    "! gsutil cp $unfiltered \"temp/mutation_unfiltered_terra_merged.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered = pd.read_csv('temp/mutation_unfiltered_terra_merged.txt', sep='\\t', encoding='L6',na_values=[\"__UNKNOWN__\",'.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toremove = []\n",
    "for val in unfiltered.columns:\n",
    "    if len(unfiltered[unfiltered[val]=='nan'])>len(unfiltered)*0.99:\n",
    "        toremove.append(val)\n",
    "    elif len(set(unfiltered[val])-set(['nan']))==1:\n",
    "        toremove.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered = unfiltered.drop(columns=[\"UniProt_Site\",\"alt_allele_seen\",\"CCLE_ONCOMAP_overlapping_mutations\",\"failure_reasons\",\"ESP_CA\",\"SVTYPE\",\"id\",\"gnomADg_GT\",\"ESP_GWAS_PUBMED\", 'dbSNP_Val_Status', 'qual', 'iHpol', 'QSI_ref', 'BCNoise', 'score', 'Familial_Cancer_Genes_Reference', 'NT']+toremove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered['somatic'] = unfiltered['somatic'].replace('nan','False')\n",
    "unfiltered['HGNC_Status'] = unfiltered['HGNC_Status'].replace('nan','Unapproved')\n",
    "unfiltered['judgement'] = unfiltered['judgement'].replace('nan','REMOVE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toint =  [\"Start_position\", \"End_position\"]\n",
    "for val in toint:\n",
    "    unfiltered[val]  = unfiltered[val].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieving RNAseq vcfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnamutations = dm.WorkspaceManager(rnaworkspace).get_sample_sets().loc['All_samples']['merged_vcf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnamutations = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations[mutations.DepMap_ID==\"ACH-000045\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieving germline mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### postprocessing\n",
    "\n",
    "\n",
    "Here, rather than rerunning the entire analysis, because we know we are adding only WES samples, we can download the previous release's MAF, add the samples, update any annotations, and perform any global filters at the end.\n",
    "\n",
    "First we need to do an additional step of filtering on coverage and number \n",
    "\n",
    "- readMutations\n",
    "- createSNPs\n",
    "- addToMainMutation\n",
    "- filterAllelicFraction\n",
    "- filterMinCoverage\n",
    "- mergeAnnotations\n",
    "- addAnnotation\n",
    "- maf_add_variant_annotations\n",
    "- mutation_maf_to_binary_matrix (x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('temp/mutation_filtered_terra_merged.txt',sep='\\t') \n",
    "print(file.columns[:10])\n",
    "renaming = removeOlderVersions(names = set(file['Tumor_Sample_Barcode']), refsamples = refwm.get_samples(), arxspan_id = \"arxspan_id\", version=\"version\")\n",
    "print(file[file['Chromosome']=='0'])\n",
    "file[file['Tumor_Sample_Barcode'].isin(renaming.keys())].replace({'Tumor_Sample_Barcode':renaming}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered[unfiltered.DepMap_ID.isin(renaming.keys())].replace(renaming).rename(columns={'Tumor_Sample_Barcode':'DepMap_ID'}).to_csv('temp/mutation_unfiltered_terra_merged.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saving samples used for 20Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples.loc[renaming.keys(),version]=1\n",
    "new_refsamples.to_csv('temp/newrefWES.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "newly_merged_maf <- readMutations('temp/mutation_filtered_terra_merged.txt')\n",
    "new_release <- createSNPs(newly_merged_maf)\n",
    "names(new_release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "previous.release.maf <- load.from.taiga(data.name='depmap-mutations-maf-35fe', data.file=paste0('mutations.',prevname),data.version=prevversion)\n",
    "if (colnames(previous.release.maf)[1] == 'X1' || colnames(previous.release.maf)[1] == \"\") {\n",
    " previous.release.maf[,1] <- NULL \n",
    "}\n",
    "prevnames <- names(previous.release.maf)\n",
    "prevnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "merged <- addToMainMutation(previous.release.maf, new_release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "## Adding more\n",
    "newly_merged_maf <- readMutations('temp/mutation_filtered_terra_merged.txt')\n",
    "new_release <- createSNPs(newly_merged_maf)\n",
    "print(names(new_release))\n",
    "merged <- addToMainMutation(merged, new_release)\n",
    "nrow(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "filtered <- filterAllelicFraction(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "filtered <- filterMinCoverage(filtered$merged, filtered$removed_from_maf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "clean_annotations <- mergeAnnotations(merged,previous.release.maf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Guillaume's version\n",
    "new_release <- addAnnotation(filtered$merged, clean_annotations, colnames(previous.release.maf))\n",
    "# Allie's version\n",
    "new_release <- maf_add_variant_annotations(new_release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterCoverage(maf, loc=['CGA_WES_AC'], sep=':',cov=4):\n",
    "    muts=np.zeroes((len(maf),2))\n",
    "    for val in loc:\n",
    "        muts+= np.array([[v[0],0] if 'NA' in v else v for v in mutations_20Q2_all[val].fillna('0'+sep+'0').astype(str).str.split(sep).tolist()]).astype(int)\n",
    "    return maf[muts[:,1]>=cov]\n",
    "\n",
    "def filterAllelicFraction(maf, loc=['CGA_WES_AC'], sep=':',frac=0.3):\n",
    "    muts=np.zeroes((len(maf),2))\n",
    "    for val in loc:\n",
    "        muts+= np.array([[v[0],0] if 'NA' in v else v for v in mutations_20Q2_all[val].fillna('0'+sep+'0').astype(str).str.split(sep).tolist()]).astype(int)\n",
    "    muts = muts[:,0]/muts[:,1]\n",
    "    return maf[muts>=frac]\n",
    "\n",
    "def mergeAnnotations(newmaf, additionalmaf, additionalonmerge=[]):\n",
    "    on = ['Chromosome', 'Start_position', 'End_position', 'Reference_Allele', 'Tumor_Seq_Allele1']\n",
    "    on.extend(additionalonmerge)\n",
    "    \n",
    "    newmaf = newmaf.join(additionalmaf, on = on)\n",
    "    if \n",
    "    solve issues with Hugo_Symbol, Entrez_Gene_Id\n",
    "    \n",
    "    \n",
    "    \n",
    "    return newmad\n",
    "    \n",
    "def mergeXY():\n",
    "    dbSNP_RS.x, dbSNP_RS.y\n",
    "\n",
    "\n",
    "def addAnnotation(maf, NCBI_Build='37', Strand=\"+\"):\n",
    "    maf['NCBI_Build'] = NCBI_Build\n",
    "    maf['Strand'] = Strand\n",
    "    maf = maf[['current', 'SangerWES_AC', 'SangerRecalibWES_AC', 'RNAseq_AC', 'HC_AC', 'RD_AC', 'WGS_AC']\n",
    "\n",
    "def mafToMat(maf, col, boolify = False, samplesCol = \"DepMap_ID\", mutNameCol=\"Hugo_Symbol\"):\n",
    "    maf = maf.sort_values(by = mutNameCol)\n",
    "    samples = set(maf[samplesCol])\n",
    "    mut = pd.DataFrame(data = np.zeros((len(set(maf[mutNameCol])), 1)), columns=['fake'], index=set(maf[mutNameCol])).astype(float)\n",
    "    for i,val in enumerate(samples):\n",
    "        h.showcount(i,len(samples))\n",
    "        mut = mut.join(maf[maf[samplesCol]==val].drop_duplicates(mutNameCol).set_index(mutNameCol)[col].rename(val))\n",
    "    return mut.nan_to_num(0).astype(bool if boolify else float).drop(columns=['fake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_mutations = filterCoverage(mutations)\n",
    "filtered_mutations = filterAllelicFraction(filtered_mutations)\n",
    "\n",
    "merged_mutations = addAnnotation(mutations)\n",
    "\n",
    "mafToMat(filtered_mutations[filtered_mutations.damaging]).to_csv('.csv')\n",
    "mafToMat(filtered_mutations[filtered_mutations.other]).to_csv('.csv')\n",
    "mafToMat(filtered_mutations[filtered_mutations.hotspot]).to_csv('.csv')\n",
    "\n",
    "\n",
    "CCLE2othermutations = \n",
    "\n",
    "mutations = mergeAnnotations(filtered_mutations, CCLE2othermutations)\n",
    "\n",
    "#making \n",
    "for muttype in ['']:\n",
    "    mafToMat(CCLE2othermutations[CCLE2othermutations.damaging & CCLE2othermutations[muttype]]).to_csv(''+muttype+\".csv\")\n",
    "    mafToMat(CCLE2othermutations[CCLE2othermutations.other & CCLE2othermutations[muttype]]).to_csv(''+muttype+\".csv\")\n",
    "    mafToMat(CCLE2othermutations[CCLE2othermutations.hotspot & CCLE2othermutations[muttype]]).to_csv(''+muttype+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to previous release\n",
    "\n",
    "I would run some checks here comparing the results to the previous releases MAF. Namely:\n",
    "\n",
    "- Count the total number of mutations per cell line, split by type (SNP, INS, DEL)\n",
    "- Count the total number of mutations observed by position (group by chromosome, start position, end position and count the number of mutations)\n",
    "- Look at specific differences between the two MAFs (join on DepMap_ID, Chromosome, Start position, End position, Variant_Type). I would do this for WES only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremie/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "mutations = pd.read_csv('temp/mutations.'+release+'.all.csv')\n",
    "damaging_mutation = pd.read_csv('temp/damaging_mutation.'+release+'.all.csv')\n",
    "print(len(damaging_mutation))\n",
    "other_mutation = pd.read_csv('temp/other_mutation.'+release+'.all.csv')\n",
    "print(len(other_mutation))\n",
    "hotspot_mutation = pd.read_csv('temp/hotspot_mutation.'+release+'.all.csv')\n",
    "print(len(hotspot_mutation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(mutations.DepMap_ID) - set(mutations[~(mutations['CGA_WES_AC'].isna() & mutations['SangerWES_AC'].isna() & mutations['WGS_AC'].isna() & mutations['SangerRecalibWES_AC'].isna())].DepMap_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations[mutations.DepMap_ID==\"ACH-000458\"].sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations[mutations[\"Hugo_Symbol\"]==\"ACOT4\"][mutations['Start_position']==74058831]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_data = mutations[[val for val in mutations.columns.values if '_AC' in val]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_names = ac_data.columns.values\n",
    "ac_data = ac_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do some checks and manual rescuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations[mutations.DepMap_ID==\"ACH-003000\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check important mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check MOLM13, MV411 cell lines- The well known mutation status of FLT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check TP53 mutation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toofew = 0\n",
    "allnan = 0\n",
    "for pos, val in enumerate(ac_data):\n",
    "    i = 0\n",
    "    print(str(100*pos/ac_data.shape[0]),end='\\r')\n",
    "    for p, v in enumerate(val):\n",
    "        if v is np.nan:\n",
    "            i+=1\n",
    "    if i==7:\n",
    "        mutations = mutations.drop[pos]\n",
    "        allnan+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allnan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the total number of mutations per cell line, split by type (SNP, INS, DEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of mutations observed by position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are mutation consistent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to check this, if you group all the mutations in the mutations table by Chromosome, Start_position, End_position, Reference_Allele, Tumor_Seq_Allele1 columns, they should all have the same annotation for the other columns (protein change, exac_af, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QC mutations, for a known dependency, check if it matches mutation of this gene. (if P53 is mutated, cannot have dependency on P53 or MDM2 MDM4/ inverse fir BRAF and KRAF to themselves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevprevname,prevprevversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations[mutations.DepMap_ID==\"ACH-001546\"][mutations.columns[-17:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevprev= set(tc.get(name='depmap-mutation-calls-9be3', file= \"depmap_\"+prevprevname+\"_mutation_calls\", version = prevprevversion).DepMap_ID.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# uploading on taiga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsheets = sheets.get(sheeturl).sheets[6].to_frame()\n",
    "wes_dmc_embargo = [i for i in gsheets['WES_DMC_embargo'].values.tolist() if str(i) != \"nan\"]\n",
    "wes_embargo = [i for i in gsheets['WES_embargo'].values.tolist() if str(i) != \"nan\"]\n",
    "blacklist = [i for i in gsheets['blacklist'].values.tolist() if str(i) != \"nan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wes_embargo, wes_dmc_embargo, blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "scrolled": true
    }
   },
   "outputs": [],
   "source": [
    "! cd .. && git clone https://github.com/broadinstitute/depmap-release-readmes.git && cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd ../depmap-release-readmes && git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../depmap-release-readmes/ && python3 make_new_release.py $release && git add . && git commit -m $release && git push "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('cd ../depmap-release-readmes && git pull && mv release-'+release+'/internal-'+release+'.txt ../ccle_processing/temp/README && cd -')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.update_dataset(dataset_permaname=\"depmap-mutations-maf-35fe\",\n",
    "                 upload_file_path_dict={'temp/mutations.'+release+'.all.csv': 'TableCSV'}, \n",
    "                 dataset_description=\"\"\"\n",
    "# Mutations\n",
    "\n",
    "filtered and unfiltered mutation files from Broad WES and Sanger WES data mapped to hg19\n",
    "The MAF file for DepMap that includes all of the latest WES samples. This MAF is generated by merging CCLE (WGS, RNAseq, RD, HC) and Sanger (WES) data.\n",
    "\n",
    "PORTAL TEAM SHOULD NOT USE THIS: There are lines here that should not make it even to internal. Must use subsetted dataset instead. These data will not make it on the portal starting 19Q1. With the DMC portal, there is new cell line release prioritization as to which lines can be included, so a new taiga dataset will be created containing CN for the portal.\n",
    "\n",
    "version 1:  In 19Q1 the WES_AC column has been replaced by two columns, VA_WES_AC and CGA_WES_AC. We are currently using the Van Allen and CGA based pipeline to generate mutation calls. The CGA pipeline includes more filtering on the MAFs than VA and has a better INDEL caller. However, some of these filters may be removing some variants of interest that are still capture by the VA pipeline, which is why both a retained for now. DEPRECATED:  Missing the VA_WES_AC, CGA_WES_AC columns\n",
    "version 2: 19Q1 data\n",
    "version 3: 19Q2 data. We are no longer using the CCLE_WES_AC column. We are only using the CGA pipeline for mutation calls.\n",
    "version 4: Updating to 19Q3interim DEPRECATED\n",
    "version 5: Updating to 19Q3interim DEPRECATED\n",
    "version 6: Updating to 19Q3interim\n",
    "version 7: Updating to 19Q3 DEPRECATED\n",
    "version 8: reparing the missing mutation problem DEPRECATED\n",
    "version 9: reparing the missing column problem\n",
    "\n",
    "\n",
    "version10:\n",
    "Adding 52 new cell lines. \n",
    "Some cells lines have been flagged as:\n",
    "\n",
    "version11:\n",
    "adding missing cell lines\n",
    "\n",
    "Adding 52 new cell lines. \n",
    "Some cells lines have been flagged as:\n",
    "\n",
    " - having bad looking copy ration plots = \n",
    " - Genes having a similar CN value accross all []\n",
    "\n",
    "version 12:\n",
    "\n",
    "adding 8 new cell lines\n",
    "\n",
    "version 13:\n",
    "\n",
    "removing a wrong column\n",
    "\n",
    "version 14:\n",
    "\n",
    "adding 8 new cell lines. Adding .all. since we are soon going to release a restricted set of mutations. this one contains everything which is not necessarily what we want\n",
    "\n",
    "\n",
    "genes (gene rpkm):\n",
    "__Rows__:\n",
    "__Columns__:\n",
    "Counts (gene counts):\n",
    "__Rows__:\n",
    "__Columns__:\n",
    "Gene level CN data:\n",
    "__Rows__:\n",
    "__Columns__:\n",
    " DepMap cell line IDs\n",
    " gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "DepMap\\_ID, Chromosome, Start, End, Num\\_Probes, Segment\\_Mean\n",
    " \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotspot_mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevmut = tc.get(name='depmap-mutation-calls-9be3', version=24, file='depmap_'+prevname+'_mutation_calls.all')\n",
    "print('shoud be None')\n",
    "print(set(prevmut.DepMap_ID) - set(mutations.DepMap_ID))\n",
    "print(\"new lines\")\n",
    "newlines = set(mutations.DepMap_ID) - set(prevmut.DepMap_ID) \n",
    "newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.update_dataset(dataset_permaname=\"depmap-mutation-calls-9be3\",\n",
    "                 upload_file_path_dict={'temp/depmap_'+release+'_mutation_calls.all': 'TableCSV',\n",
    "                                        'temp/damaging_mutation.all': 'NumericMatrixCSV',\n",
    "                                        'temp/other_mutation.all': 'NumericMatrixCSV',\n",
    "                                        'temp/hotspot_mutation.all': 'NumericMatrixCSV',\n",
    "                                       },#'temp/README': 'Raw'},\n",
    "                 dataset_description=\"\"\"\n",
    "# Internal Mutations\n",
    "\n",
    "Mutation calls for Internal DepMap data\n",
    "\n",
    "* Version 1 Internal 18Q1*\n",
    "\n",
    "original source: `/xchip/ccle_dist/broad_only/CMAG/mutations/CCLE_depMap_18Q1_maf_20180202.txt`\n",
    "* Version 2-4 Internal 18Q2*\n",
    "\n",
    "merged mutations and indels file (1,606 cell lines, including CCLE and Sanger WES reanalysis)\n",
    "original source: \n",
    "`/xchip/ccle_dist/broad_only/CMAG/mutations/CCLE_depMap_18q2_maf_20180502.txt`\n",
    "Binary matrices:\n",
    "- damaging: if isDeleterious is true\n",
    "- missense: if isDeleterious is false\n",
    "- hotspot: if missense and either TCGA or COSMIC hotspot\n",
    "Version 2 contains the MAF file\n",
    "* Version 5-6 Internal 18Q3*\n",
    "\n",
    "version 5 deprecated\n",
    "\n",
    "original source: `/xchip/ccle_dist/broad_only/CMAG/mutations/CCLE_depMap_18q3_maf_20180716.txt`\n",
    "\n",
    "Binary matrices:\n",
    "- damaging: if isDeleterious is true\n",
    "- missense: if isDeleterious is false\n",
    "- hotspot: if missense and either TCGA or COSMIC hotspot\n",
    "- Rows: cell line, Broad (arxspan) IDs\n",
    "\n",
    "Columns: Gene, HGNC symbol (Entrez ID)\n",
    "\n",
    "MAF file\n",
    "\n",
    "* Version 7-8 Internal 18Q4*\n",
    "\n",
    "version 8 just changes a column name in the MAF file from Broad_ID to DepMap_ID\n",
    "\n",
    "original source: `/xchip/ccle_dist/broad_only/CMAG/mutations/CCLE_DepMap_18Q4_maf_20181028.txt`\n",
    "\n",
    "* Version 9-12 Internal 19Q1*\n",
    "\n",
    "version 12 updates the column name from VA_WES_AC to CCLE_WES_AC\n",
    "\n",
    "version 11+ uses an updated definition for hotspot mutations\n",
    "\n",
    "version 12 contains the correct data for 19Q1\n",
    "\n",
    "* Version 13 Internal 19Q2*\n",
    "\n",
    "* Version 14-15 Internal 19Q3*\n",
    "\n",
    "version 15 fixed entrez ids\n",
    "\n",
    "* Version 16 Internal 19Q4*\n",
    "\n",
    "adding 35 new cell lines.\n",
    "\n",
    "* Version 16 Internal 19Q4*\n",
    "uploading as matrices\n",
    "\n",
    "* Version 17 Internal 19Q4*\n",
    "removing unauthorized lines and setting as matrices\n",
    "\n",
    "* Version 18 Internal 19Q4*\n",
    "removing unauthorized lines and setting as matrices\n",
    "\n",
    "* Version 19 Internal 20Q1*\n",
    "uploading 8 new lines\n",
    "\n",
    "* Version 20 Internal 20Q1*\n",
    "removing unauthorized cl\n",
    "\n",
    "* Version 21 Internal 20Q2*\n",
    "uploading 8 new lines and adding .all to express the fact that this data is the aggregate of all different sequencing methods.\n",
    "\n",
    "* Version 22 Internal 20Q2*\n",
    "removing 2 cell lines\n",
    "\n",
    "* Version 23 Internal 20Q3*\n",
    "nothing different from 20Q2. no new cell lines\n",
    "\n",
    "* Version 24 Internal 20Q2*\n",
    "updating the blacklists\n",
    "\n",
    "*** Variant annotation column ***\n",
    "\n",
    "MAF file, added column (Variant_annotation) classifying each variant as either silent, damaging, other conserving, or other non-conserving, based on this mapping (old annotation from Variant_Classification column - new annotation):\n",
    "\n",
    "Silent - silent\n",
    "Splice_Site - damaging\n",
    "Missense_Mutation - other non-conserving\n",
    "Nonsense_Mutation - damaging\n",
    "De_novo_Start_OutOfFrame - damaging\n",
    "Nonstop_Mutation - other non-conserving\n",
    "Frame_Shift_Del - damaging\n",
    "Frame_Shift_Ins - damaging\n",
    "In_Frame_Del - other non-conserving\n",
    "In_Frame_Ins - other non-conserving\n",
    "Stop_Codon_Del - other non-conserving\n",
    "Stop_Codon_Ins - other non-conserving\n",
    "Start_Codon_SNP - damaging\n",
    "Start_Codon_Del - damaging\n",
    "Start_Codon_Ins - damaging\n",
    "5'Flank - other conserving\n",
    "Intron - other conserving\n",
    "IGR - other conserving\n",
    "3'UTR - other conserving\n",
    "5'UTR - other conserving\n",
    "Binary matrices:\n",
    "\n",
    "- damaging: if damaging\n",
    "- other: if other conserving or other non-conserving\n",
    "- hotspot: if it is not a silent mutation and is either TCGA or COSMIC hotspot\n",
    "- Rows: cell line, DepMap (arxspan) IDs\n",
    "\n",
    "Columns: Gene, HGNC symbol (Entrez ID)\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+newlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add to a virtual dataset\n",
    "AddToVirtual(virtual_internal, 'depmap-mutation-calls-9be3', [('CCLE_mutations', 'depmap_'+release+'_mutation_calls'),])#('README','README')])\n",
    "# To add to a eternal dataset\n",
    "AddToVirtual('depmap-a0ab', 'depmap-mutation-calls-9be3', [('CCLE_mutations', 'depmap_'+release+'_mutation_calls')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('cd ../depmap-release-readmes && git pull && mv release-'+releAse+'/dmc-'+releAse+'.txt ../ccle_processing/temp/README && cd -')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1301656\n",
      "1297418\n",
      "1757\n",
      "1744\n",
      "1758\n",
      "1745\n",
      "1725\n",
      "1712\n"
     ]
    }
   ],
   "source": [
    "print(len(mutations))\n",
    "mutations = mutations[~mutations.DepMap_ID.isin(wes_embargo)]\n",
    "print(len(mutations))\n",
    "mutations.to_csv('temp/depmap_'+release+'_mutation_calls.all', index=False)\n",
    "print(len(damaging_mutation))\n",
    "damaging_mutation = damaging_mutation[~damaging_mutation.index.isin(wes_embargo)]\n",
    "print(len(damaging_mutation))\n",
    "damaging_mutation.to_csv('temp/damaging_mutation.all')\n",
    "print(len(other_mutation))\n",
    "other_mutation = other_mutation[~other_mutation.index.isin(wes_embargo)]\n",
    "print(len(other_mutation))\n",
    "other_mutation.to_csv('temp/other_mutation.all',)\n",
    "print(len(hotspot_mutation))\n",
    "hotspot_mutation = hotspot_mutation[~hotspot_mutation.index.isin(wes_embargo)]\n",
    "print(len(hotspot_mutation))\n",
    "hotspot_mutation.to_csv('temp/hotspot_mutation.all',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##################]100% |  40.4 MiB/s | 277.3 MiB / 277.3 MiB | Time:  0:00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoud be None\n",
      "set()\n",
      "new lines\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ACH-001533', 'ACH-001574', 'ACH-002021', 'ACH-002065'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevmut = tc.get(name='depmap-mutation-calls-dfce', version=15, file='depmap_'+prevname+'_mutation_calls')\n",
    "print('shoud be None')\n",
    "print(set(prevmut.DepMap_ID) - set(mutations.DepMap_ID))\n",
    "print(\"new lines\")\n",
    "newlines = set(mutations.DepMap_ID) - set(prevmut.DepMap_ID) \n",
    "newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.update_dataset(dataset_permaname=\"depmap-mutation-calls-dfce\",\n",
    "                 upload_file_path_dict={'temp/depmap_'+release+'_mutation_calls.all': 'TableCSV',\n",
    "                                        'temp/damaging_mutation.all': 'NumericMatrixCSV',\n",
    "                                        'temp/other_mutation.all': 'NumericMatrixCSV',\n",
    "                                        'temp/hotspot_mutation.all': 'NumericMatrixCSV',\n",
    "                                       },#'temp/README': 'Raw'},\n",
    "                 dataset_description=\"\"\"\n",
    "# DMC Mutations\n",
    "\n",
    "* Version 1-5 DMC 19Q1*\n",
    "\n",
    "version 5 is a one-off portal thing because dmc wanted to be able to plot if a gene has any mutation as one-hot encoded value in the x/y axes of the data explorer It adds the any_mutation matrix, but does not change the others. Code used to generate:\n",
    "\n",
    "```\n",
    "from taigapy import TaigaClient\n",
    "\n",
    "c = TaigaClient()\n",
    "\n",
    "dmc_19q1_mutation_taiga_root = \"depmap-mutation-calls-dfce.3/\"\n",
    "other_matrix = c.get(dmc_19q1_mutation_taiga_root + \"other_mutation\")\n",
    "damaging_matrix = c.get(dmc_19q1_mutation_taiga_root + \"damaging_mutation\")\n",
    "hotspot_matrix = c.get(dmc_19q1_mutation_taiga_root + \"hotspot_mutation\")\n",
    "\n",
    "df = other_matrix.append(damaging_matrix)\n",
    "df = df.groupby(level=0).sum()\n",
    "\n",
    "df = df.append(hotspot_matrix)\n",
    "df = df.groupby(level=0).sum()\n",
    "\n",
    "df[df > 1] = 1\n",
    "\n",
    "df.to_csv('any_mutation.csv')\n",
    "```\n",
    "The code uses version 3 because the dmc portal was using version 3\n",
    "\n",
    "version 4 updates the column name from VA_WES_AC to CCLE_WES_AC\n",
    "\n",
    "version 3 has an updated definition for hotspot mutations\n",
    "\n",
    "version 2+ contains the correct data for 19Q1\n",
    "\n",
    "* Version 6 DMC 19Q2*\n",
    "\n",
    "* Version 7-8 DMC 19Q3*\n",
    "version 8 fixed entrez ids\n",
    "\n",
    "* Version 9 DMC 19Q4*\n",
    "adding 52 new cell lines.\n",
    "\n",
    "* Version 10 DMC 19Q4*\n",
    "removing unauthorized lines and setting as matrices\n",
    "\n",
    "* Version 11 DMC 19Q4*\n",
    "removing unauthorized lines and setting as matrices\n",
    "\n",
    "* Version 12 Internal 20Q1*\n",
    "uploading 8 new lines\n",
    "\n",
    "* Version 13 Internal 20Q1*\n",
    "removing unauthorized cl\n",
    "\n",
    "* Version 14 Internal 20Q2*\n",
    "uploading 8 new lines and adding .all to express the fact that this data is the aggregate of all different sequencing methods.\n",
    "\n",
    "* Version 15 Internal 20Q2*\n",
    "removing 2 lines\n",
    "\n",
    "* Version 15 Internal 20Q3*\n",
    "nothing different from 20Q2. no new cell lines\n",
    "\n",
    "* Version 15 Internal 20Q3*\n",
    "updating the blacklists\n",
    "\n",
    "\n",
    "MAF file, added column (Variant_annotation) classifying each variant as either silent, damaging, other conserving, or other non-conserving, based on this mapping (old annotation from Variant_Classification column - new annotation):\n",
    "\n",
    "Silent - silent\n",
    "Splice_Site - damaging\n",
    "Missense_Mutation - other non-conserving\n",
    "Nonsense_Mutation - damaging\n",
    "De_novo_Start_OutOfFrame - damaging\n",
    "Nonstop_Mutation - other non-conserving\n",
    "Frame_Shift_Del - damaging\n",
    "Frame_Shift_Ins - damaging\n",
    "In_Frame_Del - other non-conserving\n",
    "In_Frame_Ins - other non-conserving\n",
    "Stop_Codon_Del - other non-conserving\n",
    "Stop_Codon_Ins - other non-conserving\n",
    "Start_Codon_SNP - damaging\n",
    "Start_Codon_Del - damaging\n",
    "Start_Codon_Ins - damaging\n",
    "5'Flank - other conserving\n",
    "Intron - other conserving\n",
    "IGR - other conserving\n",
    "3'UTR - other conserving\n",
    "5'UTR - other conserving\n",
    "Binary matrices:\n",
    "- damaging: if damaging\n",
    "- other: if other conserving or other non-conserving\n",
    "- hotspot: if it is not a silent mutation and is either TCGA or COSMIC hotspot\n",
    "- Rows: cell line, DepMap (arxspan) IDs\n",
    "\n",
    "Columns: Gene, HGNC symbol (Entrez ID)\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+newlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add to a virtual dataset\n",
    "AddToVirtual(virtual_dmc, 'depmap-mutation-calls-dfce', [('CCLE_mutations', 'depmap_'+release+'_mutation_calls'),])#('README','README')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('cd ../depmap-release-readmes && git pull && mv release-'+releAse+'/public-'+releAse+'.txt README && cd -')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#damaging_mutation\n",
    "mutations=depmap_20Q3_mutation_calls\n",
    "#hotspot_mutation\n",
    "#other_mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1297418\n",
      "1297418\n",
      "1744\n",
      "1744\n",
      "1745\n",
      "1745\n",
      "1712\n",
      "1712\n"
     ]
    }
   ],
   "source": [
    "print(len(mutations))\n",
    "mutations = mutations[mutations.DepMap_ID.isin(prevprev)]\n",
    "mutations = mutations[~mutations.DepMap_ID.isin(wes_dmc_embargo)]\n",
    "print(len(mutations))\n",
    "mutations.to_csv('temp/depmap_'+release+'_mutation_calls.all', index=False)\n",
    "print(len(damaging_mutation))\n",
    "damaging_mutation = damaging_mutation[damaging_mutation.index.isin(prevprev)]\n",
    "damaging_mutation = damaging_mutation[~damaging_mutation.index.isin(wes_dmc_embargo)]\n",
    "print(len(damaging_mutation))\n",
    "damaging_mutation.to_csv('temp/damaging_mutation.all')\n",
    "print(len(other_mutation))\n",
    "other_mutation = other_mutation[other_mutation.index.isin(prevprev)]\n",
    "other_mutation = other_mutation[~other_mutation.index.isin(wes_dmc_embargo)]\n",
    "print(len(other_mutation))\n",
    "other_mutation.to_csv('temp/other_mutation.all')\n",
    "print(len(hotspot_mutation))\n",
    "hotspot_mutation = hotspot_mutation[hotspot_mutation.index.isin(prevprev)]\n",
    "hotspot_mutation = hotspot_mutation[~hotspot_mutation.index.isin(wes_dmc_embargo)]\n",
    "print(len(hotspot_mutation))\n",
    "hotspot_mutation.to_csv('temp/hotspot_mutation.all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoud be None\n",
      "set()\n",
      "new lines\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ACH-001533', 'ACH-001574', 'ACH-002021', 'ACH-002065'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevmut = tc.get(name='depmap-mutation-calls-9a1a', version=18, file='depmap_'+prevname+'_mutation_calls')\n",
    "print('shoud be None')\n",
    "ermgency_removed = set(prevmut.DepMap_ID) - set(mutations.DepMap_ID)\n",
    "print(ermgency_removed) \n",
    "print(\"new lines\")\n",
    "newlines = set(mutations.DepMap_ID) - set(prevmut.DepMap_ID) \n",
    "newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading depmap_20Q3_mutation_calls...\n",
      "hitting https://cds.team/taiga/api/datafile/00b151ca35a14f6d9f1be95ef24ea368\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: depmap_20Q3_mutation_calls properly converted and uploaded\n",
      "Uploading damaging_mutation...\n",
      "hitting https://cds.team/taiga/api/datafile/00b151ca35a14f6d9f1be95ef24ea368\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: damaging_mutation properly converted and uploaded\n",
      "Uploading other_mutation...\n",
      "hitting https://cds.team/taiga/api/datafile/00b151ca35a14f6d9f1be95ef24ea368\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: other_mutation properly converted and uploaded\n",
      "Uploading hotspot_mutation...\n",
      "hitting https://cds.team/taiga/api/datafile/00b151ca35a14f6d9f1be95ef24ea368\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1500\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: hotspot_mutation properly converted and uploaded\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 8cc4900a50874d8593b0bfc591001360 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/8cc4900a50874d8593b0bfc591001360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'8cc4900a50874d8593b0bfc591001360'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description=\"\"\"\n",
    "# Public Mutations\n",
    "\n",
    "Mutation calls for Public DepMap data\n",
    "\n",
    "* Version 1 Public 18Q1*\n",
    "\n",
    "original source: CCLE data portal\n",
    "* Version 2 Public 18Q2*\n",
    "\n",
    "merged mutations and indels file (1,549 cell lines total, including data for 63 newly released cell lines)\n",
    "original source: `/xchip/ccle_dist/public/DepMap_18Q2/CCLE_DepMap_18Q2_maf_20180502.txt`\n",
    "* Version 3-4 Public 18Q3*\n",
    "\n",
    "version 3 deprecated\n",
    "\n",
    "original source: `/xchip/ccle_dist/public/DepMap_18Q3/CCLE_DepMap_18q3_maf_20180718.txt`\n",
    "\n",
    "Binary matrices:\n",
    "damaging: if isDeleterious is true\n",
    "missense: if isDeleterious is false\n",
    "hotspot: if missense and either TCGA or COSMIC hotspot\n",
    "Rows: cell line, Broad (arxspan) IDs\n",
    "\n",
    "Columns: Gene, HGNC symbol (Entrez ID)\n",
    "\n",
    "MAF file\n",
    "\n",
    "* Version 5 Public 18Q4*\n",
    "\n",
    "original source: `/xchip/ccle_dist/public/DepMap_18Q4/CCLE_DepMap_18q4_maf_20181029.txt`\n",
    "\n",
    "* Version 6-9 Public 19Q1*\n",
    "\n",
    "version 9 updates the column name from VA_WES_AC to CCLE_WES_AC\n",
    "\n",
    "version 8 uses an updated definition for hotspot mutations\n",
    "\n",
    "version 9 contains the correct data for 19Q1\n",
    "\n",
    "* Version 10 Public 19Q2*\n",
    "\n",
    "* Version 11-12 Public 19Q3*\n",
    "\n",
    "version 12 fixed entrez ids\n",
    "\n",
    "* Version 13 Public 19Q4*\n",
    "\n",
    "adding 52 new cell lines\n",
    "\n",
    "* Version 14 Public 19Q4*\n",
    "removing unauthorized lines and setting matrices\n",
    "\n",
    "* Version 15 Public 20Q1*\n",
    "adding 8 new lines \n",
    "\n",
    "* Version 16 Public 20Q1*\n",
    "removing an unauthorized line\n",
    "\n",
    "* Version 17 Internal 20Q2*\n",
    "uploading 8 new lines and adding .all to express the fact that this data is the aggregate of all different sequencing methods.\n",
    "\n",
    "* Version 18 Internal 20Q2*\n",
    "removing 2 lines\n",
    "\n",
    "* Version 19 Internal 20Q3*\n",
    "nothing different from 20Q2. no new cell lines\n",
    "\n",
    "* Version 20 Internal 20Q3*\n",
    "updating the blacklists\n",
    "\n",
    "* Version 21 Internal 20Q3*\n",
    "updating the dmc\n",
    "\n",
    "* Version 22 Internal 20Q3*\n",
    "readding two already released samples to the public list\n",
    "\n",
    "MAF file, added column (Variant_annotation) classifying each variant as either silent, damaging, other conserving, or other non-conserving, based on this mapping (old annotation from Variant_Classification column - new annotation):\n",
    "\n",
    "Silent - silent\n",
    "Splice_Site - damaging\n",
    "Missense_Mutation - other non-conserving\n",
    "Nonsense_Mutation - damaging\n",
    "De_novo_Start_OutOfFrame - damaging\n",
    "Nonstop_Mutation - other non-conserving\n",
    "Frame_Shift_Del - damaging\n",
    "Frame_Shift_Ins - damaging\n",
    "In_Frame_Del - other non-conserving\n",
    "In_Frame_Ins - other non-conserving\n",
    "Stop_Codon_Del - other non-conserving\n",
    "Stop_Codon_Ins - other non-conserving\n",
    "Start_Codon_SNP - damaging\n",
    "Start_Codon_Del - damaging\n",
    "Start_Codon_Ins - damaging\n",
    "5'Flank - other conserving\n",
    "Intron - other conserving\n",
    "IGR - other conserving\n",
    "3'UTR - other conserving\n",
    "5'UTR - other conserving\n",
    "Binary matrices:\n",
    "\n",
    "- damaging: if damaging\n",
    "- other: if other conserving or other non-conserving\n",
    "- hotspot: if it is not a silent mutation and is either TCGA or COSMIC hotspot\n",
    "- Rows: cell line, DepMap (arxspan) IDs\n",
    "\n",
    "Columns: Gene, HGNC symbol (Entrez ID)\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)\n",
    "\n",
    "if len(ermgency_removed):\n",
    "    description+=\"\"\"\n",
    "    \n",
    "    !! WE REMOVED!!:\n",
    "    \"\"\"+str(ermgency_removed)\n",
    "\n",
    "tc.update_dataset(dataset_permaname=\"depmap-mutation-calls-9a1a\",\n",
    "                 upload_file_path_dict={'temp/depmap_'+release+'_mutation_calls.all': 'TableCSV',\n",
    "                                        'temp/damaging_mutation.all': 'NumericMatrixCSV',\n",
    "                                        'temp/other_mutation.all': 'NumericMatrixCSV',\n",
    "                                        'temp/hotspot_mutation.all': 'NumericMatrixCSV',\n",
    "                                       },#'temp/README': 'Raw'},\n",
    "                 dataset_description=description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CCLE_mutations', 'depmap-mutation-calls-9a1a.22/depmap_20Q3_mutation_calls'), ('CCLE_gene_cn', 'depmap-wes-cn-data-97cc.34/public_20Q3_gene_cn'), ('Achilles_gene_effect_unscaled', 'avana-public-tentative-20q3-3e73.5/gene_effect_unscaled'), ('Achilles_high_variance_genes', 'avana-public-tentative-20q3-3e73.5/high_variance_genes'), ('Achilles_guide_efficacy', 'avana-public-tentative-20q3-3e73.5/guide_efficacy'), ('CCLE_fusions_unfiltered', 'gene-fusions-6212.14/unfiltered_fusions_20Q3'), ('common_essentials', 'avana-public-tentative-20q3-3e73.5/essential_genes'), ('Achilles_logfold_change_failures', 'avana-public-tentative-20q3-3e73.5/logfold_change_failures'), ('CCLE_expression', 'depmap-rnaseq-expression-data-ccd0.25/public_20Q3_proteincoding_tpm'), ('Achilles_raw_readcounts', 'avana-public-tentative-20q3-3e73.5/raw_readcounts'), ('Achilles_raw_readcounts_failures', 'avana-public-tentative-20q3-3e73.5/raw_readcounts_failing'), ('README', 'public-20q3-3d35.22/README'), ('CCLE_segment_cn', 'depmap-wes-cn-data-97cc.34/public_20Q3_segs_cn'), ('CCLE_RNAseq_transcripts', 'depmap-rnaseq-expression-data-ccd0.25/public_20Q3_transcripts_tpm'), ('nonessentials', 'avana-public-tentative-20q3-3e73.5/nonessential_genes'), ('Achilles_guide_map', 'avana-public-tentative-20q3-3e73.5/guide_gene_map'), ('Achilles_dropped_guides', 'avana-public-tentative-20q3-3e73.5/dropped_guides'), ('CCLE_fusions', 'gene-fusions-6212.14/filtered_fusions_20Q3'), ('CCLE_RNAseq_reads', 'depmap-rnaseq-expression-data-ccd0.25/public_20Q3_counts'), ('CCLE_expression_full', 'depmap-rnaseq-expression-data-ccd0.25/public_20Q3_tpm'), ('Achilles_replicate_map', 'avana-public-tentative-20q3-3e73.5/replicate_map'), ('Achilles_gene_dependency', 'avana-public-tentative-20q3-3e73.5/gene_dependency'), ('Achilles_common_essentials', 'avana-public-tentative-20q3-3e73.5/pan_dependent_genes'), ('Achilles_logfold_change', 'avana-public-tentative-20q3-3e73.5/logfold_change'), ('Achilles_gene_effect', 'avana-public-tentative-20q3-3e73.5/gene_effect')]\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datafile/ad76ca2f1c2f43c1b57c7f84a1adaafe\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id f803fe38cdb04895b6285533dcc8b00b created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/f803fe38cdb04895b6285533dcc8b00b\n"
     ]
    }
   ],
   "source": [
    "# To add to a virtual dataset\n",
    "AddToVirtual(virtual_public, 'depmap-mutation-calls-9a1a', [('CCLE_mutations', 'depmap_'+release+'_mutation_calls'),])#('README','README')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "277px",
    "width": "375px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "198.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "617.8px",
    "left": "1232.4px",
    "right": "20px",
    "top": "120px",
    "width": "262.8px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
