{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T18:54:06.392207Z",
     "start_time": "2021-03-01T18:54:06.352063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1002\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.4.min.js\"];\n",
       "  var css_urls = [];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1002\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.4.min.js\"];\n  var css_urls = [];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.CCLE_postp_function import *\n",
    "from genepy import terra\n",
    "from genepy.utils import helper as h\n",
    "from genepy.google import gcp\n",
    "from gsheets import Sheets\n",
    "from taigapy import TaigaClient\n",
    "import dalmatian as dm\n",
    "from genepy.google.google_sheet import dfToSheet\n",
    "\n",
    "\n",
    "from IPython.display import Image,display\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext rpy2.ipython\n",
    "tc = TaigaClient()\n",
    "output_notebook()\n",
    "\n",
    "my_id = '~/.client_secret.json'\n",
    "mystorage_id = \"~/.storage.json\"\n",
    "# do the first steps of https://medium.com/craftsmenltd/from-csv-to-google-sheet-using-python-ef097cb014f9\n",
    "creds = '../.credentials.json'\n",
    "\n",
    "sheets = Sheets.from_files(my_id, mystorage_id)\n",
    "replace = {'T': 'Tumor', 'N': 'Normal', 'm': 'Unknown', 'L': 'Unknown'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boot up\n",
    "\n",
    "we are instanciating all the parameters needed for this pipeline to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesetname = \"21Q1\"\n",
    "\n",
    "workspace1=\"broad-genomics-delivery/Getz_IBM_CellLines_Exomes\"\n",
    "workspace2=\"broad-firecloud-ccle/CCLE_DepMap_WES\"\n",
    "workspace3=\"broad-genomics-delivery/CCLE_DepMap_WES\"\n",
    "\n",
    "workspace6=\"terra-broad-cancer-prod/CCLE_DepMap_WES\"\n",
    "workspace7=\"terra-broad-cancer-prod/Getz_IBM_CellLines_Exomes\"\n",
    "refworkspace=\"broad-firecloud-ccle/DepMap_Mutation_Calling_CGA_pipeline\"\n",
    "\n",
    "rnaworkspace=\"broad-firecloud-ccle/DepMap_hg38_RNAseq\"\n",
    "\n",
    "source1=\"ibm\"\n",
    "source2=\"ccle\"\n",
    "source3=\"ccle\"\n",
    "source6=\"ccle\"\n",
    "source7=\"ibm\"\n",
    "\n",
    "refsheet_url = \"https://docs.google.com/spreadsheets/d/1Pgb5fIClGnErEqzxpU7qqX6ULpGTDjvzWwDN8XUJKIY\"\n",
    "refsheet_id = \"555466897\"\n",
    "sheeturl = \"https://docs.google.com/spreadsheets/d/115TUgA1t_mD32SnWAGpW9OKmJ2W5WYAOs3SuSdedpX4\"\n",
    "extract_to_change = {'from_arxspan_id': 'participant'}\n",
    "\n",
    "MutationWESmethods=[\n",
    "    \"broadinstitute_gtex/samtofastq_v1-0_BETA/6\",\n",
    "    \"broadinstitute_gtex/star_v1-0_BETA/7\",\n",
    "    \"broadinstitute_gtex/rsem_v1-0_BETA/6\",\n",
    "    \"jkobject/rsem_aggregate_results/5\",\n",
    "    \"jkobject/rnaseq-germline-snps-indels/7\",\n",
    "    \"broadinstitute_gtex/rnaseqc2_v1-0_BETA/2\",\n",
    "    \"gkugener/STAR_fusion/17\",\n",
    "    \"jkobject/aggregate_vcfs/22\",\n",
    "    \"gkugener/Aggregate_files_set/2\",\n",
    "]\n",
    "\n",
    "maxage='2020-09-10'\n",
    "\n",
    "# version 102\n",
    "ensemblserver = \"http://nov2020.archive.ensembl.org/biomart\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "release = samplesetname\n",
    "\n",
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame(index_col=0)\n",
    "#wm1 = dm.WorkspaceManager(workspace1)\n",
    "#wm2 = dm.WorkspaceManager(workspace2)\n",
    "#wm3 = dm.WorkspaceManager(workspace3)\n",
    "\n",
    "wm6 = dm.WorkspaceManager(workspace6)\n",
    "wm7 = dm.WorkspaceManager(workspace6)\n",
    "\n",
    "refwm = dm.WorkspaceManager(refworkspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new data\n",
    "\n",
    "We are looking for new samples in a range of workspaces.\n",
    "\n",
    "They are quite messy and might contains duplicates, contain broken file paths...\n",
    "\n",
    "- We are thus looking at the bam files one by one and comparing them with our own bams. \n",
    "- We remove broken files, duplicates and add new version of a cell line's bam if we find some."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be missing \"primary disease\",\"sm_id\", \"cellosaurus_id\", \"gender, \"age\", \"primary_site\", \"primary_disease\", \"subtype\", \"subsubtype\", \"origin\", \"comments\"\n",
    "#when SMid: match== \n",
    "samples, pairs, noarxspan = GetNewCellLinesFromWorkspaces(refworkspace, stype='wes', maxage=maxage, refurl=refsheet_url, wmfroms = [workspace6, workspace7], sources=[source6,source7], match=['ACH-','CDS-'], participantslicepos=10, accept_unknowntypes=True, extract=extract_to_change, recomputedate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noarxspan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding back arxspan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noarxspan = retrieveFromCellLineName(noarxspan, ccle_refsamples, datatype='wes', depmappvlink = \"https://docs.google.com/spreadsheets/d/1uqCOos-T9EMQU7y2ZUw4Nm84opU5fIT1y7jet1vnScE\", extract=extract_to_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assess any potential issues\n",
    "set(noarxspan.arxspan_id) & set(samples.arxspan_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noarxspan.arxspan_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.concat([samples, noarxspan[noarxspan.arxspan_id!='0']], sort=False)\n",
    "\n",
    "noarxspan = noarxspan[noarxspan.arxspan_id=='0']\n",
    "\n",
    "samples = assessAllSamples(samples, ccle_refsamples, stype='wes', rename={}, extract={})\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: manage the match normals in noarxspan samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting the addtional data and writing it here in the right order 'as shown above'\n",
    "- use the stripped_cell_line_name to find the samples on https://docs.google.com/spreadsheets/d/1uqCOos-T9EMQU7y2ZUw4Nm84opU5fIT1y7jet1vnScE/edit#gid=356471436. \n",
    "- Make sure that we don't have duplicate cell lines in there. Otherwise, use the duplicate renaming function\n",
    "- copy Primary Site, Primary Disease, Subtype, Comments, Disease Sub-subtype, if they exist. (sometimes subtype and subsubtype are the same.. don't use subsubtype then.\n",
    "- look for the cell line in cellosaurus, you might need to use one of the aliases given in master depmap pv..\n",
    "- copy  cellosaurus_id gender age info or write 'U' if they don't exist. 'can be a number or {Embryonic, Children, Adult, Fetus, U} \n",
    "- check that it does not say this cell line is not a duplicate from another cell line\n",
    "- check that if it says this cell line is derived/children/father/samepatient from other cell lines, and that if we have any of the other cell lines, that the patient id is changed to be the same one for all (be sure that you are updating everywhere these patient ids are used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If I have a previous samples I can update unknown data directly\n",
    "samples, notfound = updateFromTracker(samples, ccle_refsamples)\n",
    "noarxspan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noarxspan.sort_values(by = 'stripped_cell_line_name').to_csv('temp/noarxspan_wes_' + release + '.csv')\n",
    "samples.loc[notfound].to_csv('temp/notfound_wes_'+release+'.csv')\n",
    "samples.to_csv('temp/new_wes_'+release+'.csv')\n",
    "samples.loc[notfound]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toupdate = {\n",
    "\"primary_disease\":['Bone Cancer'],\n",
    "\"cellosaurus_id\":[''],\n",
    "\"age\":['C'],\n",
    "\"primary_site\":['bone'],\n",
    "\"subtype\":[\"Ewings Sarcoma\"],\n",
    "\"subsubtype\":[\"\"],\n",
    "\"origin\":[\"bone\"],\n",
    "\"parent_cell_line\":[\"\"],\n",
    "\"matched_normal\":[\"\"],\n",
    "\"comments\":[\"(PCR) EWS/FLI\"],\n",
    "\"sex\":[\"U\"],\n",
    "\"mediatype\":[\"Adherent, CM2:051117: 100.0 %\"],\n",
    "\"condition\":[\"\"],\n",
    "'stripped_cell_line_name':['CCLFPEDS0010T'],\n",
    "\"participant_id\":['PT-hrwIWtZC']\n",
    "}\n",
    "pd.DataFrame(toupdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating..\n",
    "for k, v in toupdate.items():\n",
    "    samples.loc[notfound,k] =v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples['baits'] = 'ice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploading to our bucket (now a new function)\n",
    "terra.changeToBucket(samples,'gs://cclebams/wes/', name_col= \"index\" , values=['internal_bam_filepath','internal_bai_filepath'], filetypes=['bam', 'bai'], catchdup=True, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame(index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the right version TODO: func\n",
    "names=[]\n",
    "subccle_refsamples = ccle_refsamples[ccle_refsamples['datatype'] == \"wes\"]\n",
    "for k, val in samples.iterrows():\n",
    "    val = val[\"arxspan_id\"]\n",
    "    names.append(val)\n",
    "    samples.loc[k, 'version'] = len(subccle_refsamples[subccle_refsamples['arxspan_id'] == val]) + names.count(val)\n",
    "samples['version'] = samples['version'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = ccle_refsamples.append(samples, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToSheet(ccle_refsamples,'ccle sample tracker', secret=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = setupPairsFromSamples(samples, subccle_refsamples, extract={'patient_id':'participant_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uploading new samples to mut\n",
    "refwm = refwm.disable_hound()\n",
    "refwm.upload_samples(samples)\n",
    "refwm.upload_entities('pairs', pairs)\n",
    "refwm.update_pair_set(pair_set_id=samplesetname,pair_ids=pairs.index)\n",
    "sam = refwm.get_samples()\n",
    "\n",
    "pair = refwm.get_pairs()\n",
    "refwm.update_pair_set(pair_set_id='all',pair_ids=pair.index)\n",
    "refwm.update_pair_set(pair_set_id='all_agilent',pair_ids=pair[pair[\"case_sample\"].isin(sam[sam['baits']==\"AGILENT\"].index.tolist())].index)\n",
    "refwm.update_pair_set(pair_set_id='all_ice',pair_ids=pair[pair[\"case_sample\"].isin([i for i in sam[(sam['baits'] == \"ICE\") |(sam['baits'].isna())].index.tolist() if i != 'nan'])].index)\n",
    "#creating a sample set\n",
    "refwm.update_sample_set(sample_set_id=samplesetname, sample_ids=samples.index)\n",
    "refwm.update_sample_set(sample_set_id='all', sample_ids=[i for i in sam.index.tolist() if i!='nan'])\n",
    "refwm.update_sample_set(sample_set_id='all_agilent', sample_ids = sam[sam['baits'] == \"AGILENT\"].index.tolist())\n",
    "refwm.update_sample_set(sample_set_id='all_ice', sample_ids=[i for i in sam[(sam['baits'] == \"ICE\") |(sam['baits'].isna())].index.tolist() if i != 'nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and CN\n",
    "cnwm = dm.WorkspaceManager('broad-firecloud-ccle/DepMap_WES_CN_hg38')\n",
    "cnwm = cnwm.disable_hound()\n",
    "cnwm.upload_samples(samples)\n",
    "cnwm.upload_entities('pairs', pairs)\n",
    "cnwm.update_pair_set(pair_set_id=samplesetname,pair_ids=pairs.index)\n",
    "sam = cnwm.get_samples()\n",
    "\n",
    "pair = cnwm.get_pairs()\n",
    "cnwm.update_pair_set(pair_set_id='all',pair_ids=pair.index)\n",
    "cnwm.update_pair_set(pair_set_id='all_agilent',pair_ids=pair[pair[\"case_sample\"].isin(sam[sam['baits']==\"AGILENT\"].index.tolist())].index)\n",
    "cnwm.update_pair_set(pair_set_id='all_ice',pair_ids=pair[pair[\"case_sample\"].isin([i for i in sam[(sam['baits'] == \"ICE\") |(sam['baits'].isna())].index.tolist() if i != 'nan'])].index)\n",
    "#creating a sample set\n",
    "cnwm.update_sample_set(sample_set_id=samplesetname, sample_ids=samples.index)\n",
    "cnwm.update_sample_set(sample_set_id='all', sample_ids=[i for i in sam.index.tolist() if i!='nan'])\n",
    "cnwm.update_sample_set(sample_set_id='all_agilent', sample_ids = sam[sam['baits'] == \"AGILENT\"].index.tolist())\n",
    "cnwm.update_sample_set(sample_set_id='all_ice', sample_ids=[i for i in sam[(sam['baits'] == \"ICE\") |(sam['baits'].isna())].index.tolist() if i != 'nan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the pipeline\n",
    "\n",
    "We are using Dalmatian to send request to Terra, we are running a set of 5 functions To generate the mutation dataset:\n",
    "\n",
    "*   For new samples in DepMap, run the ICE version of this task. CCLE2 samples used Agilent targets, so this pipeline should be used instead. The pipelines are identical in terms of their outputs, but the proper targets, baits, and pseudo normal should be used based on how the samples were sequenced.\n",
    "\n",
    "    **ICE_CGA_Production_Analysis_Pipeline_Cell_Lines_copy** (cclf/CGA_Production_Analysis_Pipeline_Cell_Lines_debuggingSnapshot ID: 22) OR\n",
    "\n",
    "\n",
    "    **AGILENT_CGA_Production_Analysis_Pipeline_Cell_Lines** (cclf/CGA_Production_Anablysis_Pipeline_Cell_Lines_debuggingSnapshot ID: 22)\n",
    "\n",
    "*   **common_variant_filter** (breardon/common_variant_filterSnapshot ID: 3)\n",
    "*   **filterMAF_on_CGA_pipeline** (gkugener/filterMAF_on_CGA_pipelineSnapshot ID: 8)\n",
    "*   **aggregateMAFs_selectFields** (ccle_mg/aggregateMAFs_selectFieldsSnapshot ID: 1)\n",
    "\n",
    "This outputs to be downloaded will be saved in the sample set that was run. The output we use for the release is:\n",
    "\n",
    "\n",
    "*   **passedCGA_filteredMAF_aggregated** \n",
    "\n",
    "There are several other tasks in this workspace. In brief:\n",
    "\n",
    "\n",
    "\n",
    "*   **CGA_Production_Analysis_Pipeline_Cell_Lines** (lelagina/CGA_Production_Analysis_Pipeline_Cell_LinesSnapshot ID: 12). This task is the same as the ICE and AGILENT prefixed version above, except that it relied on pulling the baits and targets to use from the metadata stored for the samples. Having AGILENT and ICE versions specified made the uploading and running process easier.\n",
    "*   **SANGER_CGA_Production_Analysis_Pipeline_Cell_Lines** (cclf/CGA_Production_Analysis_Pipeline_Cell_Lines_debuggingSnapshot ID: 22). This task was trying to run the CGA pipeline on the Sanger WES data, using a Sanger pseudo normal. In its current implementation, this task fails to complete for the samples.\n",
    "*   **UNFILTERED_aggregateMAFs_selectFields** (ccle_mg/aggregateMAFs_selectFieldsSnapshot ID: 1). Aggregates the MAF outputted by the CGA cell line pipeline prior to the common variant filter and germline filtering tasks. This can give us insight to which mutations are getting filtered out when. We may want to potentially include this MAF in the release so people can see why certain mutations of interest may be getting filtered out.\n",
    "*   WES_DM_Mutation_Calling_Pipeline_(standard |expensive) (gkugener/WES_DM_Mutation_Calling_PipelineSnapshot ID: 2). This was a previous mutation calling pipeline implemented for CCLE. We do not use this pipeline any more as the CGA pipeline looks better.\n",
    "*   aggregate_filterMAF_CGA (CCLE/aggregate_filterMAF_CGASnapshot ID: 1). An aggregation MAF task that we used in the past. We do not use this task anymore.\n",
    "*   calculate_mutational_burden (breardon/calculate_mutational_burdenSnapshot ID: 21). This task can be used to calculate the mutational rate of the samples. We do not make use of this data in the release although it could be of interest.\n",
    "*   summarizeWigFile (breardon/summarizeWigFileSnapshot ID: 5). CCLF ran this task (might be necessary for the mutational burden task). For our workflow, we do not run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torm = terra.listHeavyFiles(refworkspace)\n",
    "h.parrun(['gsutil rm '+i for i in torm], cores=8)\n",
    "terra.removeFromFailedWorkflows(refworkspace, dryrun=False, everythingFor=['Realign_WES_GATK4','Generate_uBAM_File_List','BamToUnmappedRGBams_MC','CGA_WES_CCLE_ICE','CGA_WES_CCLE_AGILENT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Terra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesetname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id1 = refwm.create_submission(\"CGA_WES_CCLE_ICE\", samplesetname, 'sample_set', expression='this.samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Germline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id2 = refwm.create_submission(\"cnn_variant_filter_ice\", samplesetname, 'sample_set', expression='this.samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy pairs data to sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.waitForSubmission(refworkspace, submission_id1)\n",
    "pairs = refwm.get_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairs[pairs.index.isin(tokeep)]\n",
    "pairs = pairs[~pairs['mutation_validator_validated_maf'].isna()]\n",
    "pairs = pairs.drop(columns=['case_sample','control_sample','participant_id'])\n",
    "pairs.index = [i.split('_')[0] for i in pairs.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refwm.update_sample_attributes(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id1 = refwm.create_submission(\"common_variant_filter\", samplesetname, 'sample_set', expression='this.samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#terra.waitForSubmission(refworkspace, submission_id2)\n",
    "#submission_id2 = refwm.create_submission(\"aggregate_vcfs\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.waitForSubmission(refworkspace, submission_id1)\n",
    "submission_id1 = refwm.create_submission(\"filterMAF_on_CGA_pipeline\", samplesetname,'sample_set',expression='this.samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.waitForSubmission(refworkspace, submission_id1)\n",
    "submission_id1 = refwm.create_submission(\"aggregateMAFs_selectFields_filtered\", \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id3 = refwm.create_submission(\"aggregateMAFs_selectFields_unfiltered\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.waitForSubmission(refworkspace, [submission_id1,submission_id2, submission_id3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the workflow configurations used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.saveConfigs(refworkspace,'./data/'+samplesetname+'/Mutconfig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On local\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove some datafile to save moneyÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = refwm.get_samples()\n",
    "toremove = [\"fixedmate_bam\"]\n",
    "for val in toremove:\n",
    "    refwm.disable_hound().delete_entity_attributes('sample', res[val], delete_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes it does not work; so better check again\n",
    "a = res.fixedmate_bam\n",
    "a = [i for i in a if i is not np.nan]\n",
    "gcp.rmFiles(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### downloading from terra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = refwm.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nowes = set(mutations.DepMap_ID)-set(sam.arxspan_id)\n",
    "nowes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nothing = nows -set(ccle_refsamples.arxspan_id)\n",
    "nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get QC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only = samples.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMut = getQC(workspace=refworkspace ,only=only, qcname=[\"gatk_cnv_all_plots\", \"lego_plotter_pngs\", \"copy_number_qc_report\", \"ffpe_OBF_figures\", \"mut_legos_html\", \"oxoG_OBF_figures\", \"tumor_bam_base_distribution_by_cycle_metrics\", \"tumor_bam_converted_oxog_metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataBam = getQC(workspace=refworkspace ,only=only, qcname=[ \"tumor_bam_alignment_summary_metrics\", \"tumor_bam_bait_bias_summary_metrics\", \"tumor_bam_gc_bias_summary_metrics\", \"tumor_bam_hybrid_selection_metrics\", \"tumor_bam_insert_size_histogram\", \"tumor_bam_insert_size_metrics\", \"tumor_bam_pre_adapter_summary_metrics\", \"tumor_bam_quality_by_cycle_metrics\", \"tumor_bam_quality_distribution_metrics\", \"tumor_bam_quality_yield_metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame(index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dataMut.items():\n",
    "    if k =='nan':\n",
    "        continue\n",
    "    curr = ccle_refsamples.loc[k,'processing_qc']\n",
    "    if curr is np.nan or curr==\"\":\n",
    "        curr=set(v)\n",
    "    else:\n",
    "        curr = set(curr[1:-1].replace(\"'\",\"\").split(', '))\n",
    "        curr = set(v) | curr\n",
    "    ccle_refsamples.loc[k,'processing_qc'] = str(list(curr))\n",
    "for k,v in dataBam.items():\n",
    "    if k =='nan':\n",
    "        continue\n",
    "    curr = ccle_refsamples.loc[k,'bam_qc']\n",
    "    if curr is np.nan or curr==\"\":\n",
    "        curr=set(v)\n",
    "    else:\n",
    "        curr = set(curr[1:-1].replace(\"'\",\"\").split(', '))\n",
    "        curr = set(v) | curr\n",
    "    ccle_refsamples.loc[k,'bam_qc'] = str(list(curr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToSheet(ccle_refsamples,'ccle sample tracker', secret=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = refwm.get_sample_sets().loc[\"all\"]\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieving RNAseq vcfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnamutations = dm.WorkspaceManager(rnaworkspace).get_sample_sets().loc['All_samples']['merged_vcf']\n",
    "! gsutil cp $rnamutations \"temp/rna_mutation_unfiltered_terra_merged.vcf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieving germline mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snps = res['merged_vcf']\n",
    "! gsutil cp $snps gs://cclebams/germline_data/wes.all.called.vcf\n",
    "! gsutil -m acl ch -ru taiga-892@cds-logging.iam.gserviceaccount.com:R gs://cclebams/germline_data/wes.all.called.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieving filtered mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = res['filtered_CGA_MAF_aggregated']\n",
    "! gsutil cp $filtered \"temp/mutation_filtered_terra_merged.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:41:25.983349Z",
     "start_time": "2021-01-22T20:40:54.467319Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremie/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (27) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Hugo_Symbol', 'Entrez_Gene_Id', 'Center', 'NCBI_Build', 'Chromosome',\n",
      "       'Start_position', 'End_position', 'Strand', 'Variant_Classification',\n",
      "       'Variant_Type'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremie/miniconda3/lib/python3.7/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/jeremie/ccle_processing/src/CCLE_postp_function.py\u001b[0m(1157)\u001b[0;36mremoveOlderVersions\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1156 \u001b[0;31m    \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1157 \u001b[0;31m    \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'we had some ids in our dataset not registered in this refsample dataframe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1158 \u001b[0;31m  \u001b[0;32mfor\u001b[0m \u001b[0marxspan\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefsamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marxspan_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-a15a6dbf5246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmutations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'temp/mutation_filtered_terra_merged.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmutations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrenaming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremoveOlderVersions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmutations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tumor_Sample_Barcode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefsamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefwm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marxspan_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"arxspan_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"version\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmutations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmutations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Chromosome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ccle_processing/src/CCLE_postp_function.py\u001b[0m in \u001b[0;36mremoveOlderVersions\u001b[0;34m(names, refsamples, arxspan_id, version)\u001b[0m\n\u001b[1;32m   1155\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlennames\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'we had some ids in our dataset not registered in this refsample dataframe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0marxspan\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefsamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marxspan_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0mallv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefsamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrefsamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marxspan_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0marxspan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ccle_processing/src/CCLE_postp_function.py\u001b[0m in \u001b[0;36mremoveOlderVersions\u001b[0;34m(names, refsamples, arxspan_id, version)\u001b[0m\n\u001b[1;32m   1155\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlennames\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'we had some ids in our dataset not registered in this refsample dataframe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0marxspan\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefsamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marxspan_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0mallv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefsamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrefsamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marxspan_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0marxspan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mutations = pd.read_csv('temp/mutation_filtered_terra_merged.txt',sep='\\t') \n",
    "print(mutations.columns[:10])\n",
    "renaming = removeOlderVersions(names = set(mutations['Tumor_Sample_Barcode']), refsamples = refwm.get_samples(), arxspan_id = \"arxspan_id\", version=\"version\")\n",
    "print(len(mutations[mutations['Chromosome']=='0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# postprocessing\n",
    "\n",
    "\n",
    "Here, rather than rerunning the entire analysis, because we know we are adding only WES samples, we can download the previous release's MAF, add the samples, update any annotations, and perform any global filters at the end.\n",
    "\n",
    "First we need to do an additional step of filtering on coverage and number \n",
    "\n",
    "- readMutations\n",
    "- createSNPs\n",
    "- addToMainMutation\n",
    "- filterAllelicFraction\n",
    "- filterMinCoverage\n",
    "- mergeAnnotations\n",
    "- addAnnotation\n",
    "- maf_add_variant_annotations\n",
    "- mutation_maf_to_binary_matrix (x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:41:34.056936Z",
     "start_time": "2021-01-22T20:41:32.235159Z"
    }
   },
   "outputs": [],
   "source": [
    "mutations = mutations.rename(columns={\"i_ExAC_AF\":\"ExAC_AF\",\"Tumor_Sample_Barcode\":'DepMap_ID',\"Tumor_Seq_Allele2\":\"Tumor_Allele\"}).drop(columns=['Center','Tumor_Seq_Allele1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = annotate_likely_immortalized(mutations, TCGAlocs = ['TCGAhsCnt',\n",
    "'COSMIChsCnt'], max_recurrence=0.05 ,min_tcga_true_cancer=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T20:41:40.985472Z",
     "start_time": "2021-01-22T20:41:38.057669Z"
    }
   },
   "outputs": [],
   "source": [
    "mutations['CGA_WES_AC'] = [str(i[0]) + ':' + str(i[1]) for i in np.nan_to_num(mutations[['t_alt_count','t_ref_count']].values,0).astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = filterCoverage(mutations, loc=['CGA_WES_AC'], sep=':',cov=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = filterAllelicFraction(mutations, loc=['CGA_WES_AC'], sep=':',frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the total number of mutations per cell line, split by type (SNP, INS, DEL)\n",
    "#Count the total number of mutations observed by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = addAnnotation(mutations, NCBI_Build='37', Strand=\"+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations.to_csv('temp/wes_somatic_mutations_withduplicates_'+samplesetname+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations= pd.read_csv('temp/wes_somatic_mutations_withduplicates_'+samplesetname+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeep = {\"CDS-mys9Dm\":\"ACH-001955\",\"CDS-Rl87Z1\":\"ACH-001956\",\"CDS-TzQAjG\":\"ACH-001957\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on QC from the CN pipeline: can't be done in mut because not a quantitativ pipeline\n",
    "%store -r wesfailed\n",
    "%store -r wesdup\n",
    "%store -r renaming\n",
    "%store -r issues\n",
    "#removing dups from replicates\n",
    "mutations = mutations[~mutations.DepMap_ID.isin((set(wesdup[:,1])|set(wesfailed)) - set(tokeep.keys()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming.update(tokeep)\n",
    "renaming.update({\"CDS-Ckptje\": \"ACH-001672\",\n",
    "\"CDS-pgDmZb\": \"ACH-002291\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priomutations = mutations[mutations.DepMap_ID.isin(renaming.keys())].replace(renaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding WGS's exonic mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgsmutations = pd.read_csv('temp/wgs_somatic_mutations_'+samplesetname+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for now we keep WES if we have them\n",
    "toadd = set(wgsmutations.DepMap_ID) - set(mutations.DepMap_ID)\n",
    "toadd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priomutations = priomutations.append(wgsmutations[wgsemutations.DepMap_ID.isin(toadd)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame(index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normals = set(ccle_refsamples[ccle_refsamples.primary_disease==\"normal\"].arxspan_id)\n",
    "wrong = set(['ACH-001189', 'ACH-002303', 'ACH-002315', 'ACH-002341', 'ACH-001011', 'ACH-001108', 'ACH-001187','ACH-003000', 'ACH-002875', 'ACH-002874'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priomutations = priomutations[~priomutations.DepMap_ID.isin(wrong)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mutations = mutations[mutations.DepMap_ID.isin(normals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priomutations.to_csv('temp/wes_somatic_mutations_all_'+samplesetname+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priomutations = pd.read_csv('temp/wes_somatic_mutations_all_'+samplesetname+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priomutations = priomutations.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mafToMat(priomutations[(priomutations.isDeleterious) & (priomutations['tumor_f']>0.25)]).T.to_csv('temp/wes_somatic_mutations_deleterious_matrix.csv')\n",
    "mafToMat(priomutations[~(priomutations.isDeleterious | priomutations.isCOSMIChotspot | priomutations.isTCGAhotspot | priomutations['Variant_Classification']=='Silent') & (priomutations['tumor_f']>0.25)]).T.to_csv('temp/wes_somatic_mutations_other_matrix.csv')\n",
    "mafToMat(priomutations[(priomutations.isCOSMIChotspot | priomutations.isTCGAhotspot) &(priomutations['tumor_f']>0.25)]).T.to_csv('temp/wes_somatic_mutations_hotspot_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mafToMat(priomutations[(priomutations.isDeleterious) & (priomutations['tumor_f']>0.25)], boolify=True).astype(int).T.to_csv('temp/wes_somatic_mutations_deleterious_boolmatrix.csv')\n",
    "mafToMat(priomutations[~(priomutations.isDeleterious | priomutations.isCOSMIChotspot | priomutations.isTCGAhotspot | priomutations['Variant_Classification']=='Silent') & (priomutations['tumor_f']>0.25)], boolify=True).astype(int).T.to_csv('temp/wes_somatic_mutations_other_boolmatrix.csv')\n",
    "mafToMat(priomutations[(priomutations.isCOSMIChotspot | priomutations.isTCGAhotspot) & (priomutations['tumor_f']>0.25)], boolify=True).astype(int).T.to_csv('temp/wes_somatic_mutations_hotspot_boolmatrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_hybridcapture = tc.get(name='mutations-da6a', file='legacy_hybridcapture_somatic_mutations').drop(columns=['Unnamed: 0',\"Tumor_Sample_Barcode\"]).rename(columns={'Tumor_Seq_Allele1':'Tumor_Allele'})\n",
    "legacy_raindance = tc.get(name='mutations-da6a', file='legacy_raindance_somatic_mutations').drop(columns=['Unnamed: 0',\"Tumor_Sample_Barcode\"]).rename(columns={'Tumor_Seq_Allele1':'Tumor_Allele'})\n",
    "legacy_rna = tc.get(name='mutations-da6a', file='legacy_rna_somatic_mutations').drop(columns=['Unnamed: 0',\"Tumor_Sample_Barcode\"]).rename(columns={'Tumor_Seq_Allele1':'Tumor_Allele'})\n",
    "legacy_wes_sanger = tc.get(name='mutations-da6a', file='legacy_wes_sanger_somatic_mutations').drop(columns=['Unnamed: 0',\"Tumor_Sample_Barcode\"]).rename(columns={'Tumor_Seq_Allele1':'Tumor_Allele'})\n",
    "legacy_wgs_exoniconly = tc.get(name='mutations-da6a', file='legacy_wgs_exoniconly_somatic_mutations').drop(columns=['Unnamed: 0',\"Tumor_Sample_Barcode\"]).rename(columns={'Tumor_Seq_Allele1':'Tumor_Allele'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solving issues with the legacy datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_hybridcapture.loc[legacy_hybridcapture[legacy_hybridcapture['Variant_Classification'].isna()].index,'Variant_Classification']='Missense_Mutation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_wgs_exoniconly.loc[legacy_wgs_exoniconly[legacy_wgs_exoniconly['Genome_Change'].isna()].index, 'Genome_Change'] = ['g.chr'+str(i.Chromosome)+\":\"+str(i.Start_position)+i.Reference_Allele+\">\"+i.Tumor_Allele for _, i in legacy_wgs_exoniconly[legacy_wgs_exoniconly['Genome_Change'].isna()].iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_wes_sanger.loc[legacy_wes_sanger[legacy_wes_sanger['Genome_Change'].isna()].index, 'Genome_Change'] = ['g.chr'+str(i.Chromosome)+\":\"+str(i.Start_position)+i.Reference_Allele+\">\"+i.Tumor_Allele for _, i in legacy_wes_sanger[legacy_wes_sanger['Genome_Change'].isna()].iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_wes_sanger[legacy_wes_sanger.DepMap_ID==\"ACH-002378\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_raindance.loc[legacy_raindance[legacy_raindance['Genome_Change'].isna()].index, 'Genome_Change'] = ['g.chr'+str(i.Chromosome)+\":\"+str(i.Start_position)+i.Reference_Allele+\">\"+i.Tumor_Allele for _, i in legacy_raindance[legacy_raindance['Genome_Change'].isna()].iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_hybridcapture.loc[legacy_hybridcapture[legacy_hybridcapture['Genome_Change'].isna()].index, 'Genome_Change'] = ['g.chr'+str(i.Chromosome)+\":\"+str(i.Start_position)+i.Reference_Allele+\">\"+i.Tumor_Allele for _, i in legacy_hybridcapture[legacy_hybridcapture['Genome_Change'].isna()].iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_rna.loc[legacy_rna[legacy_rna['Genome_Change'].isna()].index, 'Genome_Change'] = ['g.chr'+str(i.Chromosome)+\":\"+str(i.Start_position)+i.Reference_Allele+\">\"+i.Tumor_Allele for _, i in legacy_rna[legacy_rna['Genome_Change'].isna()].iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todrop = []\n",
    "legacy_rna['loci'] = legacy_rna['DepMap_ID']+\"_\"+legacy_rna['Chromosome']+\"_\"+legacy_rna['Start_position'].astype(str)\n",
    "for val in h.dups(legacy_rna.loci):\n",
    "    todrop.append(legacy_rna[legacy_rna.loci==val].index[0])\n",
    "legacy_rna = legacy_rna.drop(todrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#legacy_hybridcapture = legacy_hybridcapture[~legacy_hybridcapture.DepMap_ID.isin(normals)]\n",
    "#legacy_raindance = legacy_raindance[~legacy_raindance.DepMap_ID.isin(normals)]\n",
    "#legacy_wes_sanger = legacy_wes_sanger[~legacy_wes_sanger.DepMap_ID.isin(normals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_wgs_exoniconly = legacy_wgs_exoniconly[~legacy_wgs_exoniconly.DepMap_ID.isin(wrong)]\n",
    "legacy_wes_sanger = legacy_wes_sanger[~legacy_wes_sanger.DepMap_ID.isin(wrong)]\n",
    "legacy_raindance = legacy_raindance[~legacy_raindance.DepMap_ID.isin(wrong)]\n",
    "legacy_rna = legacy_rna[~legacy_rna.DepMap_ID.isin(wrong)]\n",
    "legacy_hybridcapture = legacy_hybridcapture[~legacy_hybridcapture.DepMap_ID.isin(set(wrong)-set([\"ACH-001187\", \"ACH-001011\", \"ACH-001108\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = mergeAnnotations(priomutations, legacy_hybridcapture, useSecondForConflict=True, dry_run=False)\n",
    "merged = mergeAnnotations(merged, legacy_raindance, useSecondForConflict=True, dry_run=False)\n",
    "merged = mergeAnnotations(merged, legacy_wgs_exoniconly, useSecondForConflict=False, dry_run=False)\n",
    "merged = mergeAnnotations(merged, legacy_wes_sanger, useSecondForConflict=False, dry_run=False)\n",
    "merged = mergeAnnotations(merged, legacy_rna, useSecondForConflict=False, dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_groups={\n",
    "\"other conserving\": [\"5'Flank\", \"Intron\", \"IGR\", \"3'UTR\", \"5'UTR\"],\n",
    "\"other non-conserving\":[\"In_Frame_Del\", \"In_Frame_Ins\", \"Stop_Codon_Del\", \"Stop_Codon_Ins\", \"Missense_Mutation\", \"Nonstop_Mutation\"],\n",
    "'silent': ['Silent'],\n",
    "\"damaging\":['De_novo_Start_OutOfFrame','Frame_Shift_Del','Frame_Shift_Ins', 'Splice_Site', 'Start_Codon_Del', 'Start_Codon_Ins', 'Start_Codon_SNP','Nonsense_Mutation']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {}\n",
    "for k,v in mutation_groups.items():\n",
    "    for e in v:\n",
    "        rename[e] = k\n",
    "merged['Variant_annotation'] = [rename[i] for i in merged['Variant_Classification'].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to previous release\n",
    "\n",
    "I would run some checks here comparing the results to the previous releases MAF. Namely:\n",
    "\n",
    "- Count the total number of mutations per cell line, split by type (SNP, INS, DEL)\n",
    "- Count the total number of mutations observed by position (group by chromosome, start position, end position and count the number of mutations)\n",
    "- Look at specific differences between the two MAFs (join on DepMap_ID, Chromosome, Start position, End position, Variant_Type). I would do this for WES only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check important mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check MOLM13, MV411 cell lines- The well known mutation status of FLT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check TP53 mutation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are mutation consistent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QC mutations, for a known dependency, check if it matches mutation of this gene. (if P53 is mutated, cannot have dependency on P53 or MDM2 MDM4/ inverse fir BRAF and KRAF to themselves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving this version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(merged.DepMap_ID) \n",
    "b = set(tc.get(name='depmap-a0ab', file='CCLE_mutations').DepMap_ID)\n",
    "print(\"new lines:\")\n",
    "print(a-b)\n",
    "print('lost lines:')\n",
    "print(b-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[merged.DepMap_ID==\"ACH-001194\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('temp/wes_somatic_mutations_withlegacy_'+samplesetname+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv('temp/wes_somatic_mutations_withlegacy_'+samplesetname+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mafToMat(merged[merged.Variant_annotation==\"damaging\"], boolify=True).astype(int).T.to_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_damaging.csv')\n",
    "mafToMat(merged[merged.Variant_annotation==\"other conserving\"], boolify=True).astype(int).T.to_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_othercons.csv')\n",
    "mafToMat(merged[merged.Variant_annotation==\"other non-conserving\"], boolify=True).astype(int).T.to_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_othernoncons.csv')\n",
    "mafToMat(merged[(merged.isCOSMIChotspot | merged.isTCGAhotspot)], boolify=True).astype(int).T.to_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_hotspot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving samples used for this release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should be the same as in CN otherwise need to do something more complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ccle_refsamples.loc[renaming.keys(),samplesetname]=1\n",
    "#ccle_refsamples.loc[ccle_refsamples[ccle_refsamples.arxspan_id.isin(toadd) & ccle_refsamples.datatype==\"wgs\"].index,samplesetname]=1\n",
    "#ccle_refsamples.to_csv('temp/newrefWES.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retrieving unfiltered mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered = res['unfiltered_CGA_MAF_aggregated']\n",
    "! gsutil cp $unfiltered \"temp/wes_mutation_unfiltered_terra_merged.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered = pd.read_csv('temp/wes_mutation_unfiltered_terra_merged.txt', sep='\\t', encoding='L6',na_values=[\"__UNKNOWN__\",'.'], engine='c', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered['somatic'] = unfiltered['somatic'].replace('nan','False')\n",
    "unfiltered['HGNC_Status'] = unfiltered['HGNC_Status'].replace('nan','Unapproved')\n",
    "unfiltered['judgement'] = unfiltered['judgement'].replace('nan','REMOVE')\n",
    "unfiltered = unfiltered.rename(columns={\"i_ExAC_AF\":\"ExAC_AF\",\"Tumor_Sample_Barcode\":'DepMap_ID',\"Tumor_Seq_Allele2\":\"Tumor_Allele\"}).drop(columns=['Tumor_Seq_Allele1'])\n",
    "unfiltered['CGA_WES_AC'] = [str(i[0]) + ':' + str(i[1]) for i in np.nan_to_num(unfiltered[['t_alt_count','t_ref_count']].values.astype(float),0).astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toremove = []\n",
    "subunfilt = unfiltered.iloc[:10000]\n",
    "for i, val in enumerate(unfiltered.columns):\n",
    "    h.showcount(i,len(unfiltered.columns))\n",
    "    if len(set(subunfilt[val])-set(['nan']))==1:\n",
    "        if len(set(unfiltered[val])-set(['nan']))==1:\n",
    "            toremove.append(val)\n",
    "unfiltered = unfiltered.drop(columns=set(toremove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toint =  [\"Start_position\", \"End_position\"]\n",
    "for val in toint:\n",
    "    unfiltered[val]  = unfiltered[val].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered.to_csv('temp/mutation_somatic_unfiltered_withreplicates.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered = unfiltered[unfiltered.DepMap_ID.isin(renaming.keys())]\n",
    "unfiltered['DepMap_ID'] = unfiltered['DepMap_ID'].replace(renaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered.to_csv('temp/mutation_somatic_unfiltered_all.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del unfiltered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# uploading on taiga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gunzip temp/wes_mutation_somatic_unfiltered_withreplicates.csv.gz\n",
    "!gunzip temp/wes_mutation_somatic_unfiltered_all.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.update_dataset(dataset_permaname=\"mutations-latest-ed72\",\n",
    "                 upload_file_path_dict={\n",
    "        'temp/wes_somatic_mutations_withduplicates_'+samplesetname+'.csv': 'TableCSV',\n",
    "        'temp/wgs_somatic_mutations_'+samplesetname+'.csv': 'TableCSV',\n",
    "        'temp/wes_somatic_mutations_deleterious_matrix.csv': 'NumericMatrixCSV',\n",
    "        'temp/wes_somatic_mutations_other_matrix.csv': 'NumericMatrixCSV',\n",
    "        'temp/wes_somatic_mutations_hotspot_matrix.csv': 'NumericMatrixCSV',\n",
    "        'temp/wes_somatic_mutations_all_'+samplesetname+'.csv': 'TableCSV',\n",
    "        'temp/wes_somatic_mutations_deleterious_boolmatrix.csv': 'NumericMatrixCSV',\n",
    "        'temp/wes_somatic_mutations_other_boolmatrix.csv': 'NumericMatrixCSV',\n",
    "        'temp/wes_somatic_mutations_hotspot_boolmatrix.csv': 'NumericMatrixCSV',\n",
    "        'temp/wes_mutation_somatic_unfiltered_all.csv': 'TableCSV',\n",
    "        'temp/all_somatic_mutations_boolmatrix_fordepmap_damaging.csv': 'NumericMatrixCSV',\n",
    "        'temp/all_somatic_mutations_boolmatrix_fordepmap_othercons.csv': 'NumericMatrixCSV',\n",
    "        'temp/all_somatic_mutations_boolmatrix_fordepmap_othernoncons.csv': 'NumericMatrixCSV',\n",
    "        'temp/all_somatic_mutations_boolmatrix_fordepmap_hotspot.csv': 'NumericMatrixCSV',\n",
    "        #'temp/wes_mutation_somatic_unfiltered_withreplicates.csv': 'TableCSV',\n",
    "        }, \n",
    "                 dataset_description=\"\"\"\n",
    "# Mutations\n",
    "\n",
    "PORTAL TEAM SHOULD NOT USE THIS: There are lines here that should not make it even to internal.\n",
    "\n",
    "/!\\ This is the most up to date version of the CCLE Mutatios data.\n",
    "The data is most likely of a better quality that what is on other folder. It is however in beta version as not all changes have either been confirmed or accepted by the DepMap Ops and the DepMap Portal Team.\n",
    "\n",
    "# Notations:\n",
    "\n",
    "all: every cell lines we have\n",
    "\n",
    "WES: all data comes from the WExomeS samples we posses\n",
    "\n",
    "WGS: all data comes from the WGenomeS samples we posses\n",
    "\n",
    "withreplicates: if we have two different sequencing from a sample, we kept both, see the depmap sample tracker for annotations [https://docs.google.com/spreadsheets/d/1XkZypRuOEXzNLxVk9EOHeWRE98Z8_DBvL4PovyM01FE](https://docs.google.com/spreadsheets/d/1XkZypRuOEXzNLxVk9EOHeWRE98Z8_DBvL4PovyM01FE). this dataset is more geared toward QC or in-depth analysis of a particular cell line.\n",
    "\n",
    "merged: everything from both WGS and WES\n",
    "\n",
    "latest: only the latest sequencing versions of the samples were kept\n",
    "\n",
    "genes (gene rpkm):\n",
    "__Rows__:\n",
    "__Columns__:\n",
    "Counts (gene counts):\n",
    "__Rows__:\n",
    "__Columns__:\n",
    "Gene level CN data:\n",
    "__Rows__:\n",
    "__Columns__:\n",
    " DepMap cell line IDs\n",
    " gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "DepMap\\_ID, Chromosome, Start, End, Num\\_Probes, Segment\\_Mean\n",
    " \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "277px",
    "width": "375px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "198.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "607.8px",
    "left": "1269.4px",
    "right": "20px",
    "top": "96px",
    "width": "248.8px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
