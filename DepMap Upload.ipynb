{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro & Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "\n",
    "import os \n",
    "\n",
    "from genepy.utils import helper as h\n",
    "from depmapomics import terra as myterra\n",
    "from gsheets import Sheets\n",
    "from taigapy import TaigaClient\n",
    "from bokeh.plotting import output_notebook\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext rpy2.ipython\n",
    "tc = TaigaClient()\n",
    "output_notebook()\n",
    "\n",
    "my_id = '~/.client_secret.json'\n",
    "mystorage_id = \"~/.storage.json\"\n",
    "sheets = Sheets.from_files(my_id, mystorage_id)\n",
    "replace = {'T': 'Tumor', 'N': 'Normal', 'm': 'Unknown', 'L': 'Unknown'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesetname = \"21Q2\"\n",
    "\n",
    "prev_virtual = {}\n",
    "\n",
    "#20Q3\n",
    "#prev_virtual['public'] = 'public-20q3-3d35'\n",
    "#prev_virtual['dmc'] = 'dmc-20q3-deprecated-never-released--5f55'\n",
    "#prev_virtual['internal'] = 'internal-20q3-00d0'\n",
    "\n",
    "#20Q4\n",
    "# prev_virtual['public'] = 'public-20q4-a4b3'\n",
    "# prev_virtual['dmc'] = 'dmc-20q4-fcf4'\n",
    "# prev_virtual['ibm'] = 'ibm-20q4-269f'\n",
    "# prev_virtual['internal'] = 'internal-20q4-2540'\n",
    "\n",
    "#21Q1\n",
    "prev_virtual['public'] = 'public-21q1-4b39'\n",
    "prev_virtual['ibm'] = 'ibm-21q1-abd9'\n",
    "prev_virtual['dmc'] = 'dmc-21q1-0e11'\n",
    "prev_virtual['internal'] = 'internal-21q1-4fc4'\n",
    "\n",
    "potential_list_url = \"https://docs.google.com/spreadsheets/d/1YuKEgZ1pFKRYzydvncQt9Y_BKToPlHP-oDB-0CAv3gE\"\n",
    "\n",
    "virtual_folder = \"8d9c4c0691154a1f86b1b6e67c3fb683\"\n",
    "\n",
    "eternal_dataset = \"depmap-a0ab\"\n",
    "\n",
    "release = samplesetname.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making a tentative virtual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making the virtuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = {}\n",
    "gsheets = sheets.get(potential_list_url).sheets[0].to_frame()\n",
    "new['internal'] = set([i for i in gsheets['Internal'].values.tolist() if str(i) != \"nan\"])\n",
    "new['dmc'] = set([i for i in gsheets['DMC'].values.tolist() if str(i) != \"nan\"])\n",
    "new['ibm'] = set([i for i in gsheets['IBM'].values.tolist() if str(i) != \"nan\"])\n",
    "new['public'] = set([i for i in gsheets['Public'].values.tolist() if str(i) != \"nan\"])\n",
    "\n",
    "\n",
    "new[\"internal\"] = new[\"internal\"] | new[\"ibm\"] | new[\"dmc\"] | new[\"public\"]\n",
    "new[\"ibm\"] = new[\"ibm\"] | new[\"dmc\"] | new[\"public\"]\n",
    "new[\"dmc\"] = new[\"dmc\"] | new[\"public\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting what was released before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevmut = {}\n",
    "prevrna = {}\n",
    "prevcn = {}\n",
    "prevwes = {}\n",
    "prev = {}\n",
    "for val in ['internal', 'dmc', 'ibm', 'public']:\n",
    "    print(val)\n",
    "    prevmut[val] = set(tc.get(name=prev_virtual[val], file='CCLE_mutations').DepMap_ID)\n",
    "    prevrna[val] = set(tc.get(name=prev_virtual[val], file='CCLE_expression').index)\n",
    "    prevcn[val] = set(tc.get(name=prev_virtual[val], file='CCLE_segment_cn').DepMap_ID)\n",
    "    prev[val] = prevmut[val] | prevrna[val] | prevcn[val]\n",
    "    prevwes[val] = prevmut[val] | prevcn[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevmut[\"dmc\"] = prevmut[\"dmc\"] | prevmut[\"public\"]\n",
    "prevrna[\"dmc\"] = prevrna[\"dmc\"] | prevrna[\"public\"]\n",
    "prevcn[\"dmc\"] = prevcn[\"dmc\"] | prevcn[\"public\"]\n",
    "prev[\"dmc\"] = prev[\"dmc\"] | prev[\"public\"]\n",
    "prevwes[\"dmc\"] = prevwes[\"dmc\"] | prevwes[\"public\"]\n",
    "\n",
    "prevmut[\"ibm\"] = prevmut[\"ibm\"] | prevmut[\"dmc\"]\n",
    "prevrna[\"ibm\"] = prevrna[\"ibm\"] | prevrna[\"dmc\"]\n",
    "prevcn[\"ibm\"] = prevcn[\"ibm\"] | prevcn[\"dmc\"]\n",
    "prev[\"ibm\"] = prev[\"ibm\"] | prev[\"dmc\"]\n",
    "prevwes[\"ibm\"] = prevwes[\"ibm\"] | prevwes[\"dmc\"]\n",
    "\n",
    "prevmut[\"internal\"] = prevmut[\"internal\"] | prevmut[\"ibm\"]\n",
    "prevrna[\"internal\"] = prevrna[\"internal\"] | prevrna[\"ibm\"]\n",
    "prevcn[\"internal\"] = prevcn[\"internal\"] | prevcn[\"ibm\"]\n",
    "prev[\"internal\"] = prev[\"internal\"] | prev[\"ibm\"]\n",
    "prevwes[\"internal\"] = prevwes[\"internal\"] | prevwes[\"ibm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('in cn but not mut')\n",
    "print(prevwes[\"internal\"] - prevmut[\"internal\"])\n",
    "print('in mut but not cn')\n",
    "print(prevwes[\"internal\"] - prevcn[\"internal\"])\n",
    "print('in rna but no wes/wgs')\n",
    "print(prev[\"internal\"] - prevwes[\"internal\"])\n",
    "print('in wes/wgs but not rna')\n",
    "print(prev[\"internal\"] - prevrna[\"internal\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## managing the readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! cd .. && git clone https://github.com/broadinstitute/depmap-release-readmes.git && cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd ../depmap-release-readmes && git pull --no-commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../depmap-release-readmes/ && python3 make_new_release.py $release  && git add . && git commit -m $release && git push "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW UPDATE THE READMEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "folder = \"../depmap-release-readmes/release-\"+release+\"/\" \n",
    "a = ! ls $folder\n",
    "print(a)\n",
    "for val in a:\n",
    "    with open(folder+val,'r+') as file:\n",
    "        # The FullLoader parameter handles the conversion from YAML\n",
    "        # scalar values to Python the dictionary format\n",
    "        dict_file = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "        dict_file['extra_sections'][0]['description'] = changes\n",
    "        yaml.dump(dict_file, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and save them\n",
    "! cd ../depmap-release-readmes && cp release-$release/* ../ccle_processing/readmes/ && git add . && git commit -m \"Omics: updating readmes to new release\" && git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genecn= pd.read_csv('temp/all_'+samplesetname+'_gene_cn.csv',index_col=0)\n",
    "segmentcn = pd.read_csv('temp/all_'+samplesetname+'_segment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genecn = genecn.apply(lambda x: (x**2)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#virtual= {}\n",
    "INFO = {}\n",
    "\n",
    "for val in ['internal','ibm', 'dmc', 'public']:\n",
    "    print('_________________________________________________')\n",
    "    print(val)\n",
    "    print('removed')\n",
    "    removed = set(prevcn[val]) - set(segmentcn.DepMap_ID)\n",
    "    print(removed)\n",
    "    missing = set(new[val]) - set(segmentcn.DepMap_ID)\n",
    "    blacklist = (set(segmentcn.DepMap_ID) - (prevcn[val] | set(new[val])))\n",
    "    print('missing')\n",
    "    print(missing)\n",
    "    newlines = set(new[val]) \n",
    "    print('blacklist')\n",
    "    print(len(blacklist), blacklist)\n",
    "    ## for segment removing first blacklisted, then embargoed, to create two datasets\n",
    "    print(len(segmentcn))\n",
    "    a = segmentcn[~segmentcn.DepMap_ID.isin(blacklist)]\n",
    "    print(len(segmentcn) - len(a))\n",
    "    a.to_csv('temp/all_merged_segments.csv', index=False)\n",
    "    print(len(genecn))\n",
    "    a = genecn[~genecn.index.isin(blacklist)]\n",
    "    print(len(genecn) - len(a))\n",
    "    a.to_csv('temp/all_merged_genes_cn.csv')\n",
    "    \n",
    "    INFO[val] = \"# \" + val + \"\"\" dataset:\n",
    "                \n",
    "## DNAseq Omics:\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "BLACKLIST:\n",
    "\"\"\"+str(blacklist)+\"\"\"\n",
    "\n",
    "MISSING:\n",
    "\"\"\"+str(missing)+\"\"\"\n",
    "\n",
    "REMOVED:\n",
    "\"\"\"+str(removed)\n",
    "    \n",
    "    # Add to Taiga \n",
    "    # 1.(replace create_dataset() by update_dataset() if the dataset already exists)\n",
    "    # 2.remove folder_id=virtual_folder\n",
    "    # 3.add a changes_description=\"something\",\n",
    "    # 4.add add_all_existing_files=True,\n",
    "    # 5.replace val+\"_\"+samplesetname by the virtual dataset id\n",
    "    virtual[val] = tc.update_dataset(virtual[val],#val+\"_\"+samplesetname, \n",
    "                    dataset_description = samplesetname + \" relese of the DepMap dataset for the DepMap Portal. Please look at the README file for additional information about this dataset. \",\n",
    "                    upload_files=[\n",
    "                        {\n",
    "                            \"path\": \"temp/all_merged_genes_cn.csv\",\n",
    "                            \"name\": \"CCLE_gene_cn\",\n",
    "                            \"format\": \"NumericMatrixCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"path\": \"temp/all_merged_segments.csv\",\n",
    "                            \"name\": \"CCLE_segment_cn\",\n",
    "                            \"format\": \"TableCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        },\n",
    "                        #{\n",
    "                        #    \"path\": 'readmes/'+val+'-'+release+'.yaml',\n",
    "                        #    \"name\": \"README\",\n",
    "                        #    \"format\": \"Raw\",\n",
    "                        #    \"encoding\": \"utf-8\"\n",
    "                        #}\n",
    "                    ],\n",
    "                    add_all_existing_files=True,\n",
    "                    changes_description=\"rerunning the CN upload script\",\n",
    "                                    )#folder_id=virtual_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## current dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Somatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations[mutations.DepMap_ID==\"ACH-002021\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = pd.read_csv(\"temp/all_somatic_mutations_withlegacy_\"+samplesetname+\"_depmapversion.csv\")\n",
    "damaging = pd.read_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_damaging.csv', index_col=0)\n",
    "othercons = pd.read_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_othercons.csv', index_col=0)\n",
    "othernoncons = pd.read_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_othernoncons.csv', index_col=0)\n",
    "hotspot = pd.read_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_hotspot.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = mutations.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = set()\n",
    "for val in ['internal', \"ibm\", \"dmc\", \"public\"]:\n",
    "    print('_________________________________________________')\n",
    "    print(val)\n",
    "    missing = set(new[val]) - set(mutations.DepMap_ID)\n",
    "    print('not present')\n",
    "    removed = set(prev[val]) - set(mutations.DepMap_ID)\n",
    "    print(removed)\n",
    "    print('removed')\n",
    "    removed = set(prevmut[val]) - set(mutations.DepMap_ID)\n",
    "    print(removed)\n",
    "    blacklist = (set(mutations.DepMap_ID) - (prevmut[val] | set(new[val]))) | blacklist\n",
    "    print('missing')\n",
    "    print(missing)\n",
    "    newlines = set(new[val]) \n",
    "    print('blacklist')\n",
    "    print(blacklist)\n",
    "    # adding files\n",
    "    a = mutations[~mutations.DepMap_ID.isin(blacklist)]\n",
    "    print(len(mutations)- len(a))\n",
    "    a.to_csv('temp/all_somatic_mutations_withlegacy.csv', index=False)\n",
    "    a = damaging[~damaging.index.isin(blacklist)]\n",
    "    print(len(damaging) - len(a))\n",
    "    a.to_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_damaging.csv')\n",
    "    a = othercons[~othercons.index.isin(blacklist)]\n",
    "    print(len(othercons) - len(a))\n",
    "    a.to_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_othercons.csv')\n",
    "    a = othernoncons[~othernoncons.index.isin(blacklist)]\n",
    "    print(len(othernoncons) - len(a))\n",
    "    a.to_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_othernoncons.csv')\n",
    "    a = hotspot[~hotspot.index.isin(blacklist)]\n",
    "    print(len(hotspot) - len(a))\n",
    "    a.to_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_hotspot.csv')\n",
    "    os.popen('cp readmes/'+val+'-'+release+'.txt temp/README').read()\n",
    "    \n",
    "    # updating on taiga\n",
    "    tc.update_dataset(dataset_id=virtual[val],\n",
    "                      changes_description='adding mutations',\n",
    "                      upload_files=[\n",
    "                        {\n",
    "                            \"path\": \"temp/all_somatic_mutations_withlegacy.csv\",\n",
    "                            \"name\": \"CCLE_mutations\",\n",
    "                            \"format\": \"TableCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"path\": \"temp/all_somatic_mutations_boolmatrix_fordepmap_damaging.csv\",\n",
    "                            \"name\": \"CCLE_mutations_bool_damaging\",\n",
    "                            \"format\": \"NumericMatrixCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"path\": \"temp/all_somatic_mutations_boolmatrix_fordepmap_othernoncons.csv\",\n",
    "                            \"name\": \"CCLE_mutations_bool_nonconserving\",\n",
    "                            \"format\": \"NumericMatrixCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"path\": \"temp/all_somatic_mutations_boolmatrix_fordepmap_othercons.csv\",\n",
    "                            \"name\": \"CCLE_mutations_bool_otherconserving\",\n",
    "                            \"format\": \"NumericMatrixCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"path\": \"temp/all_somatic_mutations_boolmatrix_fordepmap_hotspot.csv\",\n",
    "                            \"name\": \"CCLE_mutations_bool_hotspot\",\n",
    "                            \"format\": \"NumericMatrixCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        }\n",
    "                      ],\n",
    "                      add_all_existing_files=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_tpm = pd.read_csv('temp/expression_' + samplesetname + '_transcripts_tpm_logp1.csv',index_col=0)\n",
    "genes_tpm = pd.read_csv('temp/expression_' + samplesetname + '_genes_tpm_logp1.csv',index_col=0)\n",
    "genes_expected_count = pd.read_csv('temp/expression_' + samplesetname + '_genes_expected_count.csv',index_col=0)\n",
    "proteincoding_genes_expected_count = pd.read_csv('temp/expression_' + samplesetname + '_proteincoding_genes_expected_count.csv',index_col=0)\n",
    "proteincoding_genes_tpm = pd.read_csv('temp/expression_' + samplesetname + '_proteincoding_genes_tpm_logp1.csv',index_col=0)\n",
    "transcripts_expected_count = pd.read_csv('temp/expression_' + samplesetname + '_transcripts_expected_count.csv',index_col=0)\n",
    "enrichments = pd.read_csv('temp/gene_sets_'+samplesetname+'_all.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r rnafailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blacklist = set()\n",
    "for val in ['dmc','public']:\n",
    "    print('_________________________________________________')\n",
    "    print(val)\n",
    "    print('not present')\n",
    "    removed = set(prev[val]) - set(genes_tpm.index)\n",
    "    print(removed)\n",
    "    print('removed for QC reasons')\n",
    "    print(failed)\n",
    "    print('removed')\n",
    "    removed = set(prevrna[val]) - set(genes_tpm.index)\n",
    "    #print(removed - set(rename.keys()))\n",
    "    missing = set(new[val]) - set(genes_tpm.index)\n",
    "    blacklist = (set(genes_tpm.index) - (prevrna[val] | set(new[val]))) | blacklist\n",
    "    print('missing')\n",
    "    print(missing)\n",
    "    newlines = set(new[val]) \n",
    "    print('blacklist')\n",
    "    print(len(blacklist), blacklist)\n",
    "\n",
    "    ## removing first blacklisted, then embargoed, to create two datasets\n",
    "    print(len(genes_expected_count))\n",
    "    a = genes_expected_count[~genes_expected_count.index.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/expression_genes_expected_count.csv')\n",
    "    print(len(genes_tpm))\n",
    "    a = genes_tpm[~genes_tpm.index.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/expression_genes_tpm.csv')\n",
    "    print(len(proteincoding_genes_tpm))\n",
    "    a = proteincoding_genes_tpm[~proteincoding_genes_tpm.index.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/expression_proteincoding_genes_tpm.csv')\n",
    "    print(len(transcripts_tpm))\n",
    "    a = transcripts_tpm[~transcripts_tpm.index.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/expression_transcripts_tpm.csv')\n",
    "    print(len(proteincoding_genes_expected_count))\n",
    "    a = proteincoding_genes_expected_count[~proteincoding_genes_expected_count.index.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/expression_proteincoding_genes_expected_count.csv')\n",
    "    print(len(transcripts_expected_count))\n",
    "    a = transcripts_expected_count[~transcripts_expected_count.index.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/expression_transcripts_expected_count.csv')\n",
    "    print(len(enrichments))\n",
    "    a = enrichments[~enrichments.index.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/enrichments_ssGSEA.csv')\n",
    "    \n",
    "    INFO[val] += \"\"\"\n",
    "\n",
    "\n",
    "## RNAseq Omics:\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "BLACKLIST:\n",
    "\"\"\"+str(blacklist)+\"\"\"\n",
    "\n",
    "MISSING:\n",
    "\"\"\"+str(missing)+\"\"\"\n",
    "\n",
    "REMOVED:\n",
    "\"\"\"+str(removed)+\"\"\"\n",
    "                \n",
    "REMOVED FOR QC REASONS:\n",
    "\"\"\"+str(rnafailed)\n",
    "    \n",
    "    # adding to taiga\n",
    "    tc.update_dataset(virtual[val],\n",
    "                      changes_description='adding expression',\n",
    "                      upload_files=[\n",
    "                        {\n",
    "                            \"path\": \"temp/expression_genes_expected_count.csv\",\n",
    "                            \"name\": \"CCLE_RNAseq_reads\",\n",
    "                            \"format\": \"NumericMatrixCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"path\": \"temp/expression_transcripts_tpm.csv\",\n",
    "                            \"name\": \"CCLE_RNAseq_transcripts\",\n",
    "                            \"format\": \"NumericMatrixCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"path\": \"temp/expression_genes_tpm.csv\",\n",
    "                            \"name\": \"CCLE_expression_full\",\n",
    "                            \"format\": \"NumericMatrixCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"path\": \"temp/expression_proteincoding_genes_tpm.csv\",\n",
    "                            \"name\": \"CCLE_expression\",\n",
    "                            \"format\": \"NumericMatrixCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"path\": \"temp/expression_proteincoding_genes_expected_count.csv\",\n",
    "                            \"name\": \"CCLE_expression_proteincoding_genes_expected_count\",\n",
    "                            \"format\": \"NumericMatrixCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"path\": \"temp/expression_transcripts_expected_count.csv\",\n",
    "                            \"name\": \"CCLE_expression_transcripts_expected_count\",\n",
    "                            \"format\": \"NumericMatrixCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"path\": \"temp/enrichments_ssGSEA.csv\",\n",
    "                            \"name\": \"CCLE_ssGSEA\",\n",
    "                            \"format\": \"NumericMatrixCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        },\n",
    "                    ],\n",
    "                    upload_async=False,\n",
    "                    add_all_existing_files=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions = pd.read_csv('temp/fusions_'+samplesetname+'.csv')\n",
    "filtered = pd.read_csv('temp/filtered_fusions_'+samplesetname+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = set()\n",
    "for val in ['internal', 'ibm', 'dmc', 'public']:\n",
    "    print('_________________________________________________')\n",
    "    print(val)\n",
    "    print('not present')\n",
    "    removed = set(prev[val]) - set(fusions.DepMap_ID)\n",
    "    print(removed)\n",
    "    print('removed for QC reasons')\n",
    "    print(failed)\n",
    "    print('removed')\n",
    "    removed = set(prevrna[val]) - set(fusions.DepMap_ID)\n",
    "    print(removed)\n",
    "    missing = set(new[val]) - set(fusions.DepMap_ID)\n",
    "    blacklist = (set(fusions.DepMap_ID) - (prevrna[val] | set(new[val]))) | blacklist\n",
    "    print('missing')\n",
    "    print(missing)\n",
    "    newlines = set(new[val]) \n",
    "    print('blacklist')\n",
    "    print(len(blacklist), blacklist)\n",
    "    ## removing first blacklisted, then embargoed, to create two datasets\n",
    "    print(len(fusions))\n",
    "    a = fusions[~fusions.DepMap_ID.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/fusions.csv', index=False)\n",
    "    print(len(filtered))\n",
    "    a= filtered[~filtered.DepMap_ID.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/filtered_fusions.csv', index=False)\n",
    "\n",
    "    # uploading to taiga\n",
    "    tc.update_dataset(virtual[val],\n",
    "                      changes_description='adding fusions',\n",
    "                      upload_files=[\n",
    "                        {\n",
    "                            \"path\": \"temp/fusions.csv\",\n",
    "                            \"name\": \"CCLE_fusions_unfiltered\",\n",
    "                            \"format\": \"TableCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"path\": \"temp/filtered_fusions.csv\",\n",
    "                            \"name\": \"CCLE_fusions\",\n",
    "                            \"format\": \"TableCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        },\n",
    "                      ],\n",
    "                      dataset_description=INFO[val],\n",
    "                      add_all_existing_files=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating eternal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLatestVersion(dataset, approved_only=True):\n",
    "    highest = 0\n",
    "    latest_version = 0\n",
    "    data = tc.get_dataset_metadata(dataset)\n",
    "    for val in data['versions']:\n",
    "        if val['state']==\"approved\" or not approved_only:\n",
    "            if int(val['name'])>highest:\n",
    "                highest = int(val['name'])\n",
    "                latest_version = highest\n",
    "    if latest_version==0:\n",
    "        raise ValueError('could not find a version')\n",
    "    return data['permanames'][0]+'.'+str(latest_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add to a eternal dataset\n",
    "latest_version = findLatestVersion(virtual['internal'])\n",
    "\n",
    "files = [\"CCLE_gene_cn\", \"CCLE_segment_cn\", \n",
    "         \n",
    "         \"CCLE_mutations\", \"CCLE_mutations_bool_damaging\", \"CCLE_mutations_bool_nonconserving\", \"CCLE_mutations_bool_otherconserving\", \"CCLE_mutations_bool_hotspot\", \n",
    "         \n",
    "         \"CCLE_expression_full\", \"CCLE_RNAseq_transcripts\", \"CCLE_RNAseq_reads\", \"CCLE_expression\", \"CCLE_expression_proteincoding_genes_expected_count\", \"CCLE_expression_transcripts_expected_count\",\n",
    "\n",
    "         \"CCLE_fusions_unfiltered\", \"CCLE_fusions\"]\n",
    "\n",
    "tc.update_dataset(eternal_dataset,\n",
    "                changes_description='new '+samplesetname+\" omics dataset.\",\n",
    "                add_taiga_ids=[{\"taiga_id\": latest_version +\"/\"+ file, \"name\": file} for file in files],\n",
    "                add_all_existing_files=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving the current release version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd ../ccle_processing && git add . && git commit -m \"depmap omics $samplesetname final\" && git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! jupyter nbconvert --to html \\\"DepMap Upload.ipynb\n",
    "\\\"DepMap Upload.html\\\".replace('ipynb','html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir release_notebooks/$samplesetname\n",
    "for val in ['DepMap Upload.ipynb', 'preprocessing_Achilles.ipynb', \"RNA_CCLE.ipynb\", \"WGS_CCLE.ipynb\"]:\n",
    "    name = val.replace('.ipynb','.html')\n",
    "    ! jupyter nbconvert --to html $val && mv $name release_notebooks/$samplesetname\n",
    "\n",
    "cmd = \"cd ../ccle_processing && git add . && git commit -m 'depmap omics \" + samplesetname + \" final' && git push\"\n",
    "! $cmd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "206px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
