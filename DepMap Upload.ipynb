{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro & Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you need to have JKBio in your path:\n",
      "e.g. have installed JKBio in the same folder as ccle_processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremie/miniconda3/lib/python3.7/site-packages/rpy2/robjects/pandas2ri.py:14: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import Index as PandasIndex\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.4.min.js\"];\n",
       "  var css_urls = [];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.4.min.js\"];\n  var css_urls = [];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from src.CCLE_postp_function import *\n",
    "from JKBio import Datanalytics as da \n",
    "from JKBio import TerraFunction as terra\n",
    "from JKBio import Helper as h\n",
    "from gsheets import Sheets\n",
    "from taigapy import TaigaClient\n",
    "import dalmatian as dm\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from bokeh.plotting import *\n",
    "from bokeh.models import HoverTool\n",
    "from collections import OrderedDict\n",
    "from IPython.display import Image,display\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext rpy2.ipython\n",
    "tc = TaigaClient()\n",
    "output_notebook()\n",
    "\n",
    "my_id = '~/.client_secret.json'\n",
    "mystorage_id = \"~/.storage.json\"\n",
    "sheets = Sheets.from_files(my_id, mystorage_id)\n",
    "replace = {'T': 'Tumor', 'N': 'Normal', 'm': 'Unknown', 'L': 'Unknown'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesetname = \"20Q4\"\n",
    "prevname=\"20Q3\"\n",
    "\n",
    "prevprevname ='20Q2'\n",
    "\n",
    "virtual_public='public-20q4-a4b3'\n",
    "virtual_dmc='dmc-20q4-fcf4'\n",
    "virtual_ibm='ibm-20q4-269f'\n",
    "virtual_internal='internal-20q4-2540'\n",
    "\n",
    "prev_virtual_public='public-20q3-3d35'\n",
    "prev_virtual_dmc='dmc-20q3-deprecated-never-released--5f55'\n",
    "prev_virtual_internal='internal-20q3-00d0'\n",
    "\n",
    "\n",
    "prevprev_virtual_internal='internal-20q2-7f46'\n",
    "\n",
    "\n",
    "workspace1=\"terra-broad-cancer-prod/DepMap_WGS\"\n",
    "workspace2=\"terra-broad-cancer-prod/Getz_IBM_CellLines_WGS\"\n",
    "\n",
    "\n",
    "refworkspace=\"broad-firecloud-ccle/DepMap_WGS_CN\"\n",
    "cgaworkspace=\"broad-firecloud-ccle/DepMap_Mutation_Calling_CGA_pipeline-wgs\"\n",
    "\n",
    "source1=\"ccle\"\n",
    "source2=\"ibm\"\n",
    "\n",
    "refsheet_url = \"https://docs.google.com/spreadsheets/d/1XkZypRuOEXzNLxVk9EOHeWRE98Z8_DBvL4PovyM01FE\"\n",
    "sheeturl = \"https://docs.google.com/spreadsheets/d/115TUgA1t_mD32SnWAGpW9OKmJ2W5WYAOs3SuSdedpX4\"\n",
    "potential_list_url = \"https://docs.google.com/spreadsheets/d/1YuKEgZ1pFKRYzydvncQt9Y_BKToPlHP-oDB-0CAv3gE\"\n",
    "release = samplesetname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsheets = sheets.get(sheeturl).sheets[6].to_frame()\n",
    "wes_dmc_embargo = [i for i in gsheets['WES_DMC_embargo'].values.tolist() if str(i) != \"nan\"]\n",
    "wes_embargo = [i for i in gsheets['WES_embargo'].values.tolist() if str(i) != \"nan\"]\n",
    "blacklist = [i for i in gsheets['blacklist'].values.tolist() if str(i) != \"nan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsheets = sheets.get(potential_list_url).sheets[0].to_frame()\n",
    "internal = [i for i in gsheets['Internal'].values.tolist() if str(i) != \"nan\"]\n",
    "dmc = [i for i in gsheets['DMC'].values.tolist() if str(i) != \"nan\"]\n",
    "ibm = [i for i in gsheets['IBM'].values.tolist() if str(i) != \"nan\"]\n",
    "public = [i for i in gsheets['Public'].values.tolist() if str(i) != \"nan\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting what was released before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "internal\n",
      "mismatch cn/mut\n",
      "{'ACH-001037', 'ACH-002396', 'ACH-000629', 'ACH-001045', 'ACH-001018', 'ACH-001678', 'ACH-001098', 'ACH-001101', 'ACH-001225', 'ACH-001017', 'ACH-001224', 'ACH-001108', 'ACH-001087', 'ACH-001071', 'ACH-001171', 'ACH-001198', 'ACH-001121', 'ACH-001079', 'ACH-000010', 'ACH-001175', 'ACH-000084', 'ACH-001194', 'ACH-002204', 'ACH-002395', 'ACH-001187', 'ACH-002394', 'ACH-002048', 'ACH-002391', 'ACH-001011', 'ACH-001109', 'ACH-001078', 'ACH-002392', 'ACH-001847', 'ACH-000033', 'ACH-001000', 'ACH-001131', 'ACH-002393', 'ACH-001061', 'ACH-001210', 'ACH-001015', 'ACH-002390', 'ACH-000712', 'ACH-002335', 'ACH-001088', 'ACH-001249'}\n",
      "mismatch rna+cn/mut\n",
      "{'ACH-001249', 'ACH-001079', 'ACH-002709', 'ACH-002335', 'ACH-001088', 'ACH-001000', 'ACH-001101', 'ACH-001045', 'ACH-001493', 'ACH-001017', 'ACH-001449', 'ACH-001712', 'ACH-001087', 'ACH-001224', 'ACH-001171', 'ACH-002010', 'ACH-001037', 'ACH-001071', 'ACH-001502', 'ACH-001662', 'ACH-001669', 'ACH-001708', 'ACH-001672', 'ACH-001743', 'ACH-001225', 'ACH-001693', 'ACH-001293', 'ACH-001847', 'ACH-001971', 'ACH-002014', 'ACH-001316', 'ACH-001854', 'ACH-001349', 'ACH-001696', 'ACH-001061', 'ACH-001741', 'ACH-001018', 'ACH-001194', 'ACH-001437', 'ACH-002204', 'ACH-002048', 'ACH-001678', 'ACH-001175', 'ACH-001676', 'ACH-001537', 'ACH-001393', 'ACH-001855', 'ACH-001198', 'ACH-001098', 'ACH-002512', 'ACH-001438', 'ACH-001015', 'ACH-001121', 'ACH-001512', 'ACH-001429'}\n",
      "mismatch mut+cn/rna\n",
      "{'ACH-002196', 'ACH-002205', 'ACH-002289', 'ACH-001064', 'ACH-001641', 'ACH-002127', 'ACH-002344', 'ACH-002384', 'ACH-002383', 'ACH-002157', 'ACH-001037', 'ACH-002216', 'ACH-001680', 'ACH-002351', 'ACH-002207', 'ACH-002114', 'ACH-002300', 'ACH-002377', 'ACH-002204', 'ACH-002360', 'ACH-002292', 'ACH-002058', 'ACH-002104', 'ACH-002314', 'ACH-002183', 'ACH-002213', 'ACH-002168', 'ACH-002382', 'ACH-002260', 'ACH-001208', 'ACH-002095', 'ACH-002200', 'ACH-002269', 'ACH-002387', 'ACH-002375', 'ACH-002129', 'ACH-001199', 'ACH-002312', 'ACH-002282', 'ACH-002395', 'ACH-001338', 'ACH-002232', 'ACH-002267', 'ACH-002190', 'ACH-001093', 'ACH-002336', 'ACH-002281', 'ACH-001137', 'ACH-002199', 'ACH-002185', 'ACH-002208', 'ACH-002276', 'ACH-002374', 'ACH-002396', 'ACH-001383', 'ACH-002237', 'ACH-001151', 'ACH-002119', 'ACH-002136', 'ACH-002359', 'ACH-001182', 'ACH-002399', 'ACH-002106', 'ACH-001187', 'ACH-002394', 'ACH-002180', 'ACH-001045', 'ACH-002291', 'ACH-002230', 'ACH-002193', 'ACH-001089', 'ACH-001331', 'ACH-002401', 'ACH-002147', 'ACH-002242', 'ACH-002361', 'ACH-002201', 'ACH-002191', 'ACH-002143', 'ACH-001203', 'ACH-002290', 'ACH-002188', 'ACH-001018', 'ACH-002294', 'ACH-001388', 'ACH-002247', 'ACH-002167', 'ACH-002391', 'ACH-001125', 'ACH-001591', 'ACH-001118', 'ACH-002159', 'ACH-002197', 'ACH-002253', 'ACH-002102', 'ACH-001023', 'ACH-002238', 'ACH-002182', 'ACH-002198', 'ACH-002175', 'ACH-001599', 'ACH-002250', 'ACH-002284', 'ACH-002091', 'ACH-001233', 'ACH-002299', 'ACH-001092', 'ACH-002369', 'ACH-002123', 'ACH-002305', 'ACH-002141', 'ACH-001767', 'ACH-002341', 'ACH-002350', 'ACH-001011', 'ACH-002296', 'ACH-002169', 'ACH-001101', 'ACH-002128', 'ACH-002235', 'ACH-002093', 'ACH-002367', 'ACH-001225', 'ACH-001127', 'ACH-002125', 'ACH-002225', 'ACH-002297', 'ACH-002224', 'ACH-002315', 'ACH-001044', 'ACH-002266', 'ACH-002400', 'ACH-001350', 'ACH-001648', 'ACH-002380', 'ACH-002231', 'ACH-002096', 'ACH-002379', 'ACH-002274', 'ACH-002135', 'ACH-002043', 'ACH-001042', 'ACH-002275', 'ACH-001072', 'ACH-002146', 'ACH-002302', 'ACH-001065', 'ACH-002392', 'ACH-002277', 'ACH-002152', 'ACH-002217', 'ACH-002113', 'ACH-002288', 'ACH-002378', 'ACH-002099', 'ACH-001364', 'ACH-002163', 'ACH-002293', 'ACH-002246', 'ACH-002124', 'ACH-002372', 'ACH-002174', 'ACH-002243', 'ACH-002162', 'ACH-002342', 'ACH-002339', 'ACH-002210', 'ACH-001189', 'ACH-002212', 'ACH-001091', 'ACH-001066', 'ACH-001214', 'ACH-002256', 'ACH-002121', 'ACH-002228', 'ACH-002221', 'ACH-002134', 'ACH-002463', 'ACH-002280', 'ACH-002349', 'ACH-002255', 'ACH-002337', 'ACH-002287', 'ACH-002132', 'ACH-002283', 'ACH-001094', 'ACH-002209', 'ACH-001150', 'ACH-001000', 'ACH-002107', 'ACH-002089', 'ACH-001017', 'ACH-001224', 'ACH-002279', 'ACH-002270', 'ACH-001577', 'ACH-002273', 'ACH-002112', 'ACH-001108', 'ACH-002229', 'ACH-002150', 'ACH-001490', 'ACH-002338', 'ACH-002186', 'ACH-002239', 'ACH-002202', 'ACH-002097', 'ACH-002286', 'ACH-002272', 'ACH-001206', 'ACH-001738', 'ACH-002397', 'ACH-002131', 'ACH-001087', 'ACH-002304', 'ACH-001071', 'ACH-002365', 'ACH-001021', 'ACH-001230', 'ACH-002108', 'ACH-001363', 'ACH-001136', 'ACH-002259', 'ACH-002051', 'ACH-002101', 'ACH-002153', 'ACH-002020', 'ACH-002301', 'ACH-001131', 'ACH-002120', 'ACH-002346', 'ACH-002358', 'ACH-001126', 'ACH-001039', 'ACH-002393', 'ACH-001452', 'ACH-002262', 'ACH-002040', 'ACH-002189', 'ACH-002268', 'ACH-002094', 'ACH-002381', 'ACH-002092', 'ACH-002241', 'ACH-002370', 'ACH-002165', 'ACH-002144', 'ACH-002245', 'ACH-002187', 'ACH-002285', 'ACH-002116', 'ACH-001171', 'ACH-001958', 'ACH-002356', 'ACH-002130', 'ACH-002233', 'ACH-002376', 'ACH-002364', 'ACH-002098', 'ACH-001146', 'ACH-002264', 'ACH-002178', 'ACH-002171', 'ACH-001606', 'ACH-001234', 'ACH-001002', 'ACH-002149', 'ACH-002308', 'ACH-002122', 'ACH-002220', 'ACH-002317', 'ACH-001049', 'ACH-002316', 'ACH-002252', 'ACH-002118', 'ACH-002140', 'ACH-001198', 'ACH-002109', 'ACH-002126', 'ACH-002340', 'ACH-001090', 'ACH-001015', 'ACH-001121', 'ACH-001957', 'ACH-002306', 'ACH-001079', 'ACH-002160', 'ACH-002148', 'ACH-001047', 'ACH-002353', 'ACH-002311', 'ACH-001358', 'ACH-002257', 'ACH-002313', 'ACH-001417', 'ACH-001081', 'ACH-001359', 'ACH-002117', 'ACH-002388', 'ACH-001955', 'ACH-002166', 'ACH-002192', 'ACH-002386', 'ACH-002145', 'ACH-002184', 'ACH-002348', 'ACH-002176', 'ACH-002310', 'ACH-002362', 'ACH-001639', 'ACH-002347', 'ACH-001704', 'ACH-002248', 'ACH-001024', 'ACH-002278', 'ACH-002139', 'ACH-002254', 'ACH-002249', 'ACH-002103', 'ACH-002105', 'ACH-002240', 'ACH-002155', 'ACH-001130', 'ACH-002389', 'ACH-002223', 'ACH-001175', 'ACH-002181', 'ACH-002307', 'ACH-002390', 'ACH-002100', 'ACH-002211', 'ACH-001489', 'ACH-002354', 'ACH-002357', 'ACH-002335', 'ACH-002343', 'ACH-001162', 'ACH-001088', 'ACH-002298', 'ACH-002214', 'ACH-002265', 'ACH-002194', 'ACH-002111', 'ACH-001355', 'ACH-001362', 'ACH-002215', 'ACH-002206', 'ACH-002371', 'ACH-002352', 'ACH-002156', 'ACH-002177', 'ACH-002355', 'ACH-002234', 'ACH-002244', 'ACH-001249', 'ACH-001063', 'ACH-001107', 'ACH-002345', 'ACH-002251', 'ACH-002090', 'ACH-002368', 'ACH-001365', 'ACH-002236', 'ACH-002052', 'ACH-002303', 'ACH-002173', 'ACH-001544', 'ACH-002170', 'ACH-002195', 'ACH-001138', 'ACH-002366', 'ACH-002133', 'ACH-002110', 'ACH-002222', 'ACH-002295', 'ACH-002271', 'ACH-002363', 'ACH-002154', 'ACH-001043', 'ACH-002115', 'ACH-002226', 'ACH-002142', 'ACH-001956', 'ACH-002309', 'ACH-001188', 'ACH-002083', 'ACH-002261', 'ACH-002161', 'ACH-002179', 'ACH-002263', 'ACH-002258', 'ACH-002227', 'ACH-002164', 'ACH-002218', 'ACH-002373', 'ACH-001282', 'ACH-002151', 'ACH-002077'}\n",
      "dmc\n",
      "mismatch cn/mut\n",
      "{'ACH-001037', 'ACH-001970', 'ACH-002396', 'ACH-000629', 'ACH-002399', 'ACH-001045', 'ACH-001018', 'ACH-001678', 'ACH-001098', 'ACH-001101', 'ACH-002464', 'ACH-001225', 'ACH-001017', 'ACH-001224', 'ACH-001108', 'ACH-001087', 'ACH-001071', 'ACH-001171', 'ACH-001198', 'ACH-001121', 'ACH-001079', 'ACH-000010', 'ACH-001175', 'ACH-000084', 'ACH-001194', 'ACH-002204', 'ACH-002395', 'ACH-001973', 'ACH-001187', 'ACH-002394', 'ACH-002401', 'ACH-002048', 'ACH-002391', 'ACH-001547', 'ACH-001011', 'ACH-001109', 'ACH-001078', 'ACH-002400', 'ACH-002392', 'ACH-001847', 'ACH-002466', 'ACH-002467', 'ACH-000033', 'ACH-002463', 'ACH-001000', 'ACH-001131', 'ACH-002462', 'ACH-002393', 'ACH-001061', 'ACH-001210', 'ACH-001015', 'ACH-001679', 'ACH-002390', 'ACH-000712', 'ACH-002335', 'ACH-001088', 'ACH-002465', 'ACH-001249'}\n",
      "mismatch rna+cn/mut\n",
      "{'ACH-002399', 'ACH-001249', 'ACH-001079', 'ACH-002709', 'ACH-002335', 'ACH-001088', 'ACH-001000', 'ACH-001101', 'ACH-001045', 'ACH-001493', 'ACH-001017', 'ACH-001970', 'ACH-001449', 'ACH-001712', 'ACH-002401', 'ACH-001087', 'ACH-002464', 'ACH-001224', 'ACH-001171', 'ACH-002010', 'ACH-001037', 'ACH-001071', 'ACH-001502', 'ACH-001662', 'ACH-002400', 'ACH-001669', 'ACH-001672', 'ACH-002465', 'ACH-002467', 'ACH-001743', 'ACH-001973', 'ACH-001225', 'ACH-001693', 'ACH-001547', 'ACH-001293', 'ACH-001847', 'ACH-001971', 'ACH-002014', 'ACH-002463', 'ACH-001316', 'ACH-001854', 'ACH-001349', 'ACH-001696', 'ACH-001061', 'ACH-001741', 'ACH-002466', 'ACH-001018', 'ACH-001194', 'ACH-001437', 'ACH-002204', 'ACH-002048', 'ACH-001679', 'ACH-001678', 'ACH-001175', 'ACH-001676', 'ACH-001537', 'ACH-002462', 'ACH-001855', 'ACH-001198', 'ACH-001098', 'ACH-002512', 'ACH-001438', 'ACH-001015', 'ACH-001121', 'ACH-001429'}\n",
      "mismatch mut+cn/rna\n",
      "{'ACH-002196', 'ACH-002205', 'ACH-002289', 'ACH-001064', 'ACH-001641', 'ACH-002127', 'ACH-002344', 'ACH-002384', 'ACH-002383', 'ACH-002157', 'ACH-001037', 'ACH-001398', 'ACH-001688', 'ACH-002216', 'ACH-001680', 'ACH-001419', 'ACH-002351', 'ACH-002207', 'ACH-002114', 'ACH-002300', 'ACH-002377', 'ACH-002204', 'ACH-002360', 'ACH-002292', 'ACH-002058', 'ACH-002104', 'ACH-002314', 'ACH-002183', 'ACH-002213', 'ACH-002168', 'ACH-002382', 'ACH-002260', 'ACH-001208', 'ACH-002095', 'ACH-002200', 'ACH-002269', 'ACH-002387', 'ACH-002375', 'ACH-002038', 'ACH-002129', 'ACH-002046', 'ACH-001199', 'ACH-002312', 'ACH-002282', 'ACH-002395', 'ACH-001338', 'ACH-001516', 'ACH-002232', 'ACH-002267', 'ACH-002190', 'ACH-001093', 'ACH-002336', 'ACH-002281', 'ACH-001137', 'ACH-002199', 'ACH-001370', 'ACH-002185', 'ACH-002208', 'ACH-002276', 'ACH-002374', 'ACH-002396', 'ACH-001687', 'ACH-001383', 'ACH-002237', 'ACH-001151', 'ACH-002119', 'ACH-002136', 'ACH-002359', 'ACH-001182', 'ACH-002022', 'ACH-002399', 'ACH-002106', 'ACH-001187', 'ACH-002394', 'ACH-002180', 'ACH-001045', 'ACH-002291', 'ACH-002230', 'ACH-002193', 'ACH-001089', 'ACH-001331', 'ACH-002401', 'ACH-002147', 'ACH-002242', 'ACH-002361', 'ACH-002201', 'ACH-002191', 'ACH-002143', 'ACH-001203', 'ACH-002290', 'ACH-002188', 'ACH-001018', 'ACH-002294', 'ACH-001388', 'ACH-002247', 'ACH-002167', 'ACH-002391', 'ACH-001125', 'ACH-001591', 'ACH-001118', 'ACH-002159', 'ACH-002197', 'ACH-002253', 'ACH-002102', 'ACH-001023', 'ACH-002238', 'ACH-002182', 'ACH-002198', 'ACH-002175', 'ACH-001453', 'ACH-001599', 'ACH-002250', 'ACH-002284', 'ACH-001573', 'ACH-002091', 'ACH-001233', 'ACH-002299', 'ACH-001092', 'ACH-002369', 'ACH-002123', 'ACH-002305', 'ACH-002141', 'ACH-001767', 'ACH-001422', 'ACH-002341', 'ACH-002350', 'ACH-002039', 'ACH-001011', 'ACH-002296', 'ACH-002169', 'ACH-001101', 'ACH-002128', 'ACH-002235', 'ACH-002093', 'ACH-002367', 'ACH-001225', 'ACH-001127', 'ACH-002125', 'ACH-002225', 'ACH-002297', 'ACH-002224', 'ACH-002315', 'ACH-001044', 'ACH-002266', 'ACH-002400', 'ACH-001350', 'ACH-001648', 'ACH-002380', 'ACH-002231', 'ACH-002096', 'ACH-001709', 'ACH-002379', 'ACH-002274', 'ACH-001339', 'ACH-002135', 'ACH-002043', 'ACH-001042', 'ACH-002026', 'ACH-002275', 'ACH-001072', 'ACH-002146', 'ACH-002302', 'ACH-001065', 'ACH-002392', 'ACH-002277', 'ACH-002152', 'ACH-002217', 'ACH-002113', 'ACH-002288', 'ACH-002378', 'ACH-002099', 'ACH-001364', 'ACH-002163', 'ACH-002293', 'ACH-002246', 'ACH-002124', 'ACH-002372', 'ACH-002174', 'ACH-002243', 'ACH-002162', 'ACH-002342', 'ACH-002339', 'ACH-002067', 'ACH-002210', 'ACH-001189', 'ACH-002212', 'ACH-001091', 'ACH-001066', 'ACH-001214', 'ACH-001690', 'ACH-002256', 'ACH-002121', 'ACH-002228', 'ACH-002221', 'ACH-002134', 'ACH-001395', 'ACH-002463', 'ACH-002280', 'ACH-002349', 'ACH-002255', 'ACH-002337', 'ACH-002287', 'ACH-002132', 'ACH-002283', 'ACH-001094', 'ACH-002209', 'ACH-001150', 'ACH-001000', 'ACH-002107', 'ACH-002089', 'ACH-001017', 'ACH-001224', 'ACH-002279', 'ACH-002270', 'ACH-001577', 'ACH-002273', 'ACH-002112', 'ACH-001108', 'ACH-002229', 'ACH-002150', 'ACH-001490', 'ACH-002338', 'ACH-002186', 'ACH-002239', 'ACH-001384', 'ACH-002202', 'ACH-002097', 'ACH-002286', 'ACH-002272', 'ACH-001206', 'ACH-001738', 'ACH-002397', 'ACH-002131', 'ACH-001087', 'ACH-002304', 'ACH-001071', 'ACH-002365', 'ACH-001021', 'ACH-001230', 'ACH-002108', 'ACH-002023', 'ACH-001363', 'ACH-001136', 'ACH-002259', 'ACH-002051', 'ACH-002101', 'ACH-002153', 'ACH-002020', 'ACH-002301', 'ACH-001131', 'ACH-002120', 'ACH-002346', 'ACH-002358', 'ACH-001126', 'ACH-001039', 'ACH-002393', 'ACH-001452', 'ACH-002262', 'ACH-002040', 'ACH-002189', 'ACH-001389', 'ACH-002268', 'ACH-002094', 'ACH-002381', 'ACH-002092', 'ACH-002241', 'ACH-002370', 'ACH-002165', 'ACH-002144', 'ACH-002245', 'ACH-002019', 'ACH-002187', 'ACH-002285', 'ACH-002116', 'ACH-001171', 'ACH-001958', 'ACH-002356', 'ACH-002130', 'ACH-002233', 'ACH-002376', 'ACH-002364', 'ACH-002098', 'ACH-001146', 'ACH-002264', 'ACH-001692', 'ACH-002178', 'ACH-002171', 'ACH-001606', 'ACH-002062', 'ACH-001234', 'ACH-001002', 'ACH-002149', 'ACH-002308', 'ACH-001991', 'ACH-001694', 'ACH-002122', 'ACH-002220', 'ACH-002317', 'ACH-001049', 'ACH-002316', 'ACH-002252', 'ACH-002118', 'ACH-002140', 'ACH-001198', 'ACH-002109', 'ACH-001541', 'ACH-002126', 'ACH-002340', 'ACH-001090', 'ACH-001015', 'ACH-001121', 'ACH-001957', 'ACH-002306', 'ACH-001079', 'ACH-002160', 'ACH-002148', 'ACH-001047', 'ACH-002353', 'ACH-002311', 'ACH-001358', 'ACH-002257', 'ACH-002313', 'ACH-001417', 'ACH-002025', 'ACH-001081', 'ACH-001359', 'ACH-002117', 'ACH-002388', 'ACH-001955', 'ACH-002166', 'ACH-002192', 'ACH-002386', 'ACH-001441', 'ACH-002145', 'ACH-002184', 'ACH-002348', 'ACH-002176', 'ACH-002310', 'ACH-002362', 'ACH-001639', 'ACH-002347', 'ACH-001704', 'ACH-002248', 'ACH-001024', 'ACH-002278', 'ACH-001569', 'ACH-002139', 'ACH-002254', 'ACH-002249', 'ACH-002103', 'ACH-002105', 'ACH-002240', 'ACH-002155', 'ACH-001130', 'ACH-002389', 'ACH-002223', 'ACH-001679', 'ACH-001175', 'ACH-002181', 'ACH-001649', 'ACH-002307', 'ACH-002390', 'ACH-002100', 'ACH-002211', 'ACH-001489', 'ACH-002354', 'ACH-002357', 'ACH-002335', 'ACH-002343', 'ACH-001162', 'ACH-001088', 'ACH-001719', 'ACH-002298', 'ACH-002214', 'ACH-002265', 'ACH-002194', 'ACH-002111', 'ACH-001355', 'ACH-001362', 'ACH-002215', 'ACH-002206', 'ACH-002371', 'ACH-002352', 'ACH-002156', 'ACH-002177', 'ACH-002355', 'ACH-002234', 'ACH-002244', 'ACH-001528', 'ACH-001249', 'ACH-001063', 'ACH-001107', 'ACH-002345', 'ACH-002251', 'ACH-002090', 'ACH-002368', 'ACH-001365', 'ACH-002236', 'ACH-002052', 'ACH-002303', 'ACH-002173', 'ACH-001544', 'ACH-002170', 'ACH-002195', 'ACH-001138', 'ACH-002366', 'ACH-001627', 'ACH-002133', 'ACH-002110', 'ACH-002222', 'ACH-002295', 'ACH-002041', 'ACH-002024', 'ACH-002271', 'ACH-002363', 'ACH-002154', 'ACH-001043', 'ACH-002115', 'ACH-002226', 'ACH-002142', 'ACH-001956', 'ACH-002309', 'ACH-001188', 'ACH-002083', 'ACH-002261', 'ACH-002161', 'ACH-002179', 'ACH-002263', 'ACH-002258', 'ACH-001518', 'ACH-002227', 'ACH-001194', 'ACH-002164', 'ACH-002218', 'ACH-002373', 'ACH-001282', 'ACH-002151', 'ACH-002077', 'ACH-001519'}\n",
      "public\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch cn/mut\n",
      "{'ACH-001037', 'ACH-002396', 'ACH-000629', 'ACH-001045', 'ACH-001018', 'ACH-001098', 'ACH-001101', 'ACH-001225', 'ACH-001017', 'ACH-001224', 'ACH-001108', 'ACH-001087', 'ACH-001071', 'ACH-001171', 'ACH-001198', 'ACH-001121', 'ACH-001079', 'ACH-000010', 'ACH-001175', 'ACH-000084', 'ACH-001194', 'ACH-002204', 'ACH-002395', 'ACH-001187', 'ACH-002394', 'ACH-002391', 'ACH-001011', 'ACH-001109', 'ACH-001078', 'ACH-002392', 'ACH-000033', 'ACH-001000', 'ACH-001131', 'ACH-002393', 'ACH-001061', 'ACH-001210', 'ACH-001015', 'ACH-002390', 'ACH-000712', 'ACH-002335', 'ACH-001088', 'ACH-001249'}\n",
      "mismatch rna+cn/mut\n",
      "{'ACH-001249', 'ACH-001079', 'ACH-002335', 'ACH-001088', 'ACH-001000', 'ACH-001101', 'ACH-001045', 'ACH-001017', 'ACH-001712', 'ACH-001087', 'ACH-001224', 'ACH-001171', 'ACH-001037', 'ACH-001071', 'ACH-001743', 'ACH-001225', 'ACH-001316', 'ACH-001061', 'ACH-001741', 'ACH-001018', 'ACH-001194', 'ACH-002204', 'ACH-001175', 'ACH-001198', 'ACH-001098', 'ACH-001015', 'ACH-001121'}\n",
      "mismatch mut+cn/rna\n",
      "{'ACH-002196', 'ACH-002205', 'ACH-002289', 'ACH-001064', 'ACH-001641', 'ACH-002127', 'ACH-002344', 'ACH-002384', 'ACH-002383', 'ACH-002157', 'ACH-001037', 'ACH-001398', 'ACH-001688', 'ACH-002216', 'ACH-001680', 'ACH-001419', 'ACH-001698', 'ACH-002351', 'ACH-002207', 'ACH-002114', 'ACH-002300', 'ACH-002377', 'ACH-002475', 'ACH-002204', 'ACH-002360', 'ACH-002292', 'ACH-002058', 'ACH-001834', 'ACH-002104', 'ACH-002314', 'ACH-002183', 'ACH-002213', 'ACH-002168', 'ACH-002382', 'ACH-002260', 'ACH-001208', 'ACH-002095', 'ACH-002200', 'ACH-002269', 'ACH-002387', 'ACH-002375', 'ACH-002069', 'ACH-002038', 'ACH-002129', 'ACH-002046', 'ACH-001199', 'ACH-002312', 'ACH-002282', 'ACH-002395', 'ACH-001338', 'ACH-001516', 'ACH-002232', 'ACH-002267', 'ACH-002190', 'ACH-001093', 'ACH-002336', 'ACH-002281', 'ACH-001137', 'ACH-002199', 'ACH-001370', 'ACH-002185', 'ACH-002208', 'ACH-002276', 'ACH-002461', 'ACH-002374', 'ACH-002396', 'ACH-001687', 'ACH-001383', 'ACH-002237', 'ACH-001151', 'ACH-002042', 'ACH-002119', 'ACH-002136', 'ACH-002359', 'ACH-001182', 'ACH-002022', 'ACH-002106', 'ACH-001187', 'ACH-002394', 'ACH-002180', 'ACH-001385', 'ACH-001045', 'ACH-002291', 'ACH-002230', 'ACH-002193', 'ACH-001089', 'ACH-001331', 'ACH-002147', 'ACH-002242', 'ACH-002361', 'ACH-002201', 'ACH-002191', 'ACH-002143', 'ACH-001203', 'ACH-002290', 'ACH-002188', 'ACH-001018', 'ACH-002294', 'ACH-001388', 'ACH-002247', 'ACH-002167', 'ACH-002391', 'ACH-001125', 'ACH-001591', 'ACH-001118', 'ACH-002159', 'ACH-002197', 'ACH-002253', 'ACH-002102', 'ACH-001023', 'ACH-002238', 'ACH-002182', 'ACH-002198', 'ACH-002175', 'ACH-001716', 'ACH-002508', 'ACH-001453', 'ACH-001599', 'ACH-002250', 'ACH-002284', 'ACH-001573', 'ACH-002091', 'ACH-001233', 'ACH-002299', 'ACH-001092', 'ACH-002369', 'ACH-002123', 'ACH-002305', 'ACH-002141', 'ACH-001767', 'ACH-001422', 'ACH-001703', 'ACH-002341', 'ACH-002350', 'ACH-002039', 'ACH-001011', 'ACH-002296', 'ACH-002169', 'ACH-001625', 'ACH-001101', 'ACH-002128', 'ACH-002235', 'ACH-002093', 'ACH-002367', 'ACH-001225', 'ACH-001127', 'ACH-002125', 'ACH-002460', 'ACH-002225', 'ACH-001539', 'ACH-002297', 'ACH-002224', 'ACH-002315', 'ACH-001044', 'ACH-002266', 'ACH-001350', 'ACH-001630', 'ACH-001648', 'ACH-002459', 'ACH-002380', 'ACH-002231', 'ACH-002096', 'ACH-001709', 'ACH-001605', 'ACH-002379', 'ACH-002274', 'ACH-001339', 'ACH-002135', 'ACH-002043', 'ACH-001042', 'ACH-002026', 'ACH-002275', 'ACH-001626', 'ACH-001072', 'ACH-002146', 'ACH-002510', 'ACH-002302', 'ACH-001065', 'ACH-002392', 'ACH-002277', 'ACH-002152', 'ACH-002217', 'ACH-002113', 'ACH-002288', 'ACH-002378', 'ACH-002099', 'ACH-001364', 'ACH-002163', 'ACH-002293', 'ACH-002246', 'ACH-002124', 'ACH-002372', 'ACH-002174', 'ACH-002243', 'ACH-002162', 'ACH-002342', 'ACH-002339', 'ACH-002067', 'ACH-002210', 'ACH-001189', 'ACH-002212', 'ACH-001091', 'ACH-001066', 'ACH-001214', 'ACH-001690', 'ACH-002256', 'ACH-002121', 'ACH-002228', 'ACH-002221', 'ACH-002134', 'ACH-001395', 'ACH-002280', 'ACH-002349', 'ACH-002255', 'ACH-002337', 'ACH-002287', 'ACH-002132', 'ACH-002283', 'ACH-001094', 'ACH-002209', 'ACH-001150', 'ACH-001000', 'ACH-002107', 'ACH-002089', 'ACH-001017', 'ACH-001224', 'ACH-002279', 'ACH-001603', 'ACH-002270', 'ACH-001577', 'ACH-002273', 'ACH-001820', 'ACH-002112', 'ACH-001108', 'ACH-002229', 'ACH-002150', 'ACH-001490', 'ACH-002338', 'ACH-002186', 'ACH-002239', 'ACH-001384', 'ACH-002202', 'ACH-002097', 'ACH-002286', 'ACH-002272', 'ACH-001206', 'ACH-001578', 'ACH-001738', 'ACH-002397', 'ACH-002131', 'ACH-001087', 'ACH-002304', 'ACH-001071', 'ACH-002365', 'ACH-001021', 'ACH-001230', 'ACH-002108', 'ACH-002023', 'ACH-001363', 'ACH-001136', 'ACH-002259', 'ACH-002051', 'ACH-002101', 'ACH-002153', 'ACH-002020', 'ACH-002301', 'ACH-001131', 'ACH-002120', 'ACH-002346', 'ACH-002358', 'ACH-001126', 'ACH-001039', 'ACH-002393', 'ACH-001452', 'ACH-002262', 'ACH-002040', 'ACH-002189', 'ACH-001389', 'ACH-002268', 'ACH-002094', 'ACH-002381', 'ACH-002092', 'ACH-002241', 'ACH-002370', 'ACH-002165', 'ACH-002144', 'ACH-002245', 'ACH-002019', 'ACH-002187', 'ACH-002285', 'ACH-002116', 'ACH-001171', 'ACH-001958', 'ACH-002356', 'ACH-001616', 'ACH-002130', 'ACH-002233', 'ACH-002376', 'ACH-002364', 'ACH-002098', 'ACH-001146', 'ACH-002264', 'ACH-001692', 'ACH-002178', 'ACH-002171', 'ACH-001606', 'ACH-002062', 'ACH-001234', 'ACH-001002', 'ACH-001632', 'ACH-002149', 'ACH-002308', 'ACH-001991', 'ACH-001694', 'ACH-002458', 'ACH-002122', 'ACH-002220', 'ACH-002317', 'ACH-001049', 'ACH-002316', 'ACH-002252', 'ACH-002118', 'ACH-002140', 'ACH-001198', 'ACH-002109', 'ACH-001541', 'ACH-002126', 'ACH-002340', 'ACH-001090', 'ACH-001015', 'ACH-001121', 'ACH-001957', 'ACH-002306', 'ACH-001079', 'ACH-002160', 'ACH-002148', 'ACH-001047', 'ACH-002353', 'ACH-002311', 'ACH-001358', 'ACH-002257', 'ACH-002313', 'ACH-001417', 'ACH-002025', 'ACH-001081', 'ACH-001359', 'ACH-002117', 'ACH-002388', 'ACH-001955', 'ACH-002166', 'ACH-002192', 'ACH-002386', 'ACH-001441', 'ACH-002145', 'ACH-002184', 'ACH-002176', 'ACH-002348', 'ACH-002310', 'ACH-002362', 'ACH-001639', 'ACH-002347', 'ACH-001704', 'ACH-002248', 'ACH-001024', 'ACH-002278', 'ACH-001569', 'ACH-002139', 'ACH-002511', 'ACH-001036', 'ACH-002254', 'ACH-002249', 'ACH-002103', 'ACH-002105', 'ACH-002240', 'ACH-002155', 'ACH-001130', 'ACH-002389', 'ACH-002223', 'ACH-001175', 'ACH-002181', 'ACH-001649', 'ACH-002307', 'ACH-002390', 'ACH-002100', 'ACH-002211', 'ACH-001489', 'ACH-002354', 'ACH-002357', 'ACH-002335', 'ACH-002343', 'ACH-001162', 'ACH-001088', 'ACH-001719', 'ACH-002298', 'ACH-002214', 'ACH-002265', 'ACH-002194', 'ACH-002111', 'ACH-001355', 'ACH-001362', 'ACH-002215', 'ACH-002206', 'ACH-002371', 'ACH-002352', 'ACH-002156', 'ACH-002177', 'ACH-002355', 'ACH-002234', 'ACH-002244', 'ACH-001528', 'ACH-001249', 'ACH-001063', 'ACH-001107', 'ACH-002345', 'ACH-002251', 'ACH-002090', 'ACH-002368', 'ACH-001365', 'ACH-002236', 'ACH-002052', 'ACH-002303', 'ACH-002173', 'ACH-001544', 'ACH-002170', 'ACH-002195', 'ACH-001138', 'ACH-002366', 'ACH-001627', 'ACH-002133', 'ACH-002110', 'ACH-002222', 'ACH-002295', 'ACH-002041', 'ACH-002024', 'ACH-002271', 'ACH-002363', 'ACH-002154', 'ACH-001229', 'ACH-001347', 'ACH-001043', 'ACH-002115', 'ACH-002226', 'ACH-002142', 'ACH-001956', 'ACH-002309', 'ACH-002027', 'ACH-001188', 'ACH-002083', 'ACH-002261', 'ACH-002161', 'ACH-002179', 'ACH-002263', 'ACH-002258', 'ACH-001518', 'ACH-002227', 'ACH-001194', 'ACH-002164', 'ACH-002218', 'ACH-002373', 'ACH-001282', 'ACH-002151', 'ACH-002077', 'ACH-001519'}\n"
     ]
    }
   ],
   "source": [
    "print('internal')\n",
    "internal_mut = set(tc.get(name=prev_virtual_internal, file='CCLE_mutations').DepMap_ID)\n",
    "internal_rna = set(tc.get(name=prev_virtual_internal, file='CCLE_expression').index)\n",
    "internal_cn = set(tc.get(name=prev_virtual_internal, file='CCLE_segment_cn').DepMap_ID)\n",
    "previnternal = internal_mut | internal_rna | internal_cn\n",
    "print('mismatch cn/mut')\n",
    "print(internal_mut ^ internal_cn)\n",
    "print('mismatch rna+cn/mut')\n",
    "print(previnternal - internal_mut)\n",
    "print('mismatch mut+cn/rna')\n",
    "print(previnternal - internal_rna)\n",
    "\n",
    "#ibm_mut = set(tc.get(name=prev_virtual_ibm, file='CCLE_mutations').DepMap_ID)\n",
    "#ibm_rna = set(tc.get(name=prev_virtual_ibm, file='CCLE_expression').index)\n",
    "#ibm_cn = tc.get(name=prev_virtual_ibm, file='CCLE_segment_cn')\n",
    "\n",
    "print('dmc')\n",
    "dmc_mut = set(tc.get(name=prev_virtual_dmc, file='CCLE_mutations').DepMap_ID)\n",
    "dmc_rna = set(tc.get(name=prev_virtual_dmc, file='CCLE_expression').index)\n",
    "dmc_cn = set(tc.get(name=prev_virtual_dmc, file='CCLE_segment_cn').DepMap_ID)\n",
    "prevdmc = dmc_mut | dmc_rna | dmc_cn\n",
    "print('mismatch cn/mut')\n",
    "print(dmc_mut ^ dmc_cn)\n",
    "print('mismatch rna+cn/mut')\n",
    "print(prevdmc - dmc_mut)\n",
    "print('mismatch mut+cn/rna')\n",
    "print(prevdmc - dmc_rna)\n",
    "\n",
    "print('public')\n",
    "public_mut = set(tc.get(name=prev_virtual_public, file='CCLE_mutations').DepMap_ID)\n",
    "public_rna = set(tc.get(name=prev_virtual_public, file='CCLE_expression').index)\n",
    "public_cn = set(tc.get(name=prev_virtual_public, file='CCLE_segment_cn').DepMap_ID)\n",
    "prevpublic = public_mut | public_rna | public_cn\n",
    "print('mismatch cn/mut')\n",
    "print(public_mut ^ public_cn)\n",
    "print('mismatch rna+cn/mut')\n",
    "print(prevpublic - public_mut)\n",
    "print('mismatch mut+cn/rna')\n",
    "print(prevpublic - public_rna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## managing the readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'depmap-release-readmes' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "! cd .. && git clone https://github.com/broadinstitute/depmap-release-readmes.git && cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 27, done.\u001b[K\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
      "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
      "remote: Total 26 (delta 14), reused 19 (delta 9), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (26/26), done.\n",
      "From https://github.com/broadinstitute/depmap-release-readmes\n",
      "   5e66713..32bbcb4  master     -> origin/master\n",
      "Updating 5e66713..32bbcb4\n",
      "Fast-forward\n",
      " .gitignore                   |   1 \u001b[32m+\u001b[m\n",
      " release-20q3/.DS_Store       | Bin \u001b[31m0\u001b[m -> \u001b[32m6148\u001b[m bytes\n",
      " release-20q3/dmc-20q3.txt    | 348 \u001b[32m+++++++++++++++++++++++++++++++++++++++++++\u001b[m\n",
      " release-20q3/public-20q3.txt | 342 \u001b[32m++++++++++++++++++++++++++++++++++++++++++\u001b[m\n",
      " 4 files changed, 691 insertions(+)\n",
      " create mode 100644 .gitignore\n",
      " create mode 100644 release-20q3/.DS_Store\n",
      " create mode 100644 release-20q3/dmc-20q3.txt\n",
      " create mode 100644 release-20q3/public-20q3.txt\n"
     ]
    }
   ],
   "source": [
    "! cd ../depmap-release-readmes && git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making public\n",
      "Making internal\n",
      "Making dmc\n",
      "[master c7fb45e] 20Q4\n",
      " 4 files changed, 1386 insertions(+)\n",
      " create mode 100644 release-20q3/internal-20q3.txt\n",
      " create mode 100644 release-20q4/dmc-20q4.txt\n",
      " create mode 100644 release-20q4/internal-20q4.txt\n",
      " create mode 100644 release-20q4/public-20q4.txt\n",
      "Counting objects: 6, done.\n",
      "Delta compression using up to 12 threads.\n",
      "Compressing objects: 100% (6/6), done.\n",
      "Writing objects: 100% (6/6), 6.32 KiB | 0 bytes/s, done.\n",
      "Total 6 (delta 3), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (3/3), completed with 2 local objects.\u001b[K\n",
      "To https://github.com/broadinstitute/depmap-release-readmes.git\n",
      "   32bbcb4..c7fb45e  master -> master\n"
     ]
    }
   ],
   "source": [
    "!cd ../depmap-release-readmes/ && python3 make_new_release.py $release && git add . && git commit -m $release && git push "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir temp/README/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up-to-date.\n",
      "/home/jeremie/ccle_processing\n"
     ]
    }
   ],
   "source": [
    "! cd ../depmap-release-readmes && git pull && cp -r release-* ../ccle_processing/temp/README/ && cd -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Somatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremie/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (4,23,26,32,34,35,36,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "mutations = pd.read_csv(\"temp/wes_somatic_mutations_withlegacy_\"+release+\".csv\")\n",
    "#damaging = pd.read_csv('temp/wes_somatic_mutations_boolmatrix_fordepmap_damaging_' + samplesetname + \".csv\", index_col=0)\n",
    "#othercons = pd.read_csv('temp/wes_somatic_mutations_boolmatrix_fordepmap_othercons_' + samplesetname + \".csv\", index_col=0)\n",
    "#othernoncons = pd.read_csv('temp/wes_somatic_mutations_boolmatrix_fordepmap_othernoncons_' + samplesetname + \".csv\", index_col=0)\n",
    "#hotspot = pd.read_csv('temp/wes_somatic_mutations_boolmatrix_fordepmap_hotspot_' + samplesetname + '.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Hugo_Symbol</th>\n",
       "      <th>Entrez_Gene_Id</th>\n",
       "      <th>NCBI_Build</th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Start_position</th>\n",
       "      <th>End_position</th>\n",
       "      <th>Strand</th>\n",
       "      <th>Variant_Classification</th>\n",
       "      <th>Variant_Type</th>\n",
       "      <th>...</th>\n",
       "      <th>ExAC_AF</th>\n",
       "      <th>PASS</th>\n",
       "      <th>is_likely_immortalization</th>\n",
       "      <th>CGA_WES_AC</th>\n",
       "      <th>HC_AC</th>\n",
       "      <th>Variant_annotation</th>\n",
       "      <th>RD_AC</th>\n",
       "      <th>RNAseq_AC</th>\n",
       "      <th>SangerWES_AC</th>\n",
       "      <th>WGS_AC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1302147</th>\n",
       "      <td>1204721</td>\n",
       "      <td>COL16A1</td>\n",
       "      <td>1307</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>32163671</td>\n",
       "      <td>32163671</td>\n",
       "      <td>+</td>\n",
       "      <td>Missense_Mutation</td>\n",
       "      <td>SNP</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>45:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other non-conserving</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302148</th>\n",
       "      <td>1204722</td>\n",
       "      <td>MTF1</td>\n",
       "      <td>4520</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>38289412</td>\n",
       "      <td>38289412</td>\n",
       "      <td>+</td>\n",
       "      <td>Missense_Mutation</td>\n",
       "      <td>SNP</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>21:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other non-conserving</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302149</th>\n",
       "      <td>1204723</td>\n",
       "      <td>FAAH</td>\n",
       "      <td>2166</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>46872008</td>\n",
       "      <td>46872008</td>\n",
       "      <td>+</td>\n",
       "      <td>Missense_Mutation</td>\n",
       "      <td>SNP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>21:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other non-conserving</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302150</th>\n",
       "      <td>1204724</td>\n",
       "      <td>ZCCHC11</td>\n",
       "      <td>23318</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>52896892</td>\n",
       "      <td>52896892</td>\n",
       "      <td>+</td>\n",
       "      <td>Missense_Mutation</td>\n",
       "      <td>SNP</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>31:24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other non-conserving</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302151</th>\n",
       "      <td>1204725</td>\n",
       "      <td>SAMD13</td>\n",
       "      <td>148418</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>84815454</td>\n",
       "      <td>84815454</td>\n",
       "      <td>+</td>\n",
       "      <td>Silent</td>\n",
       "      <td>SNP</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>61:71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>silent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302339</th>\n",
       "      <td>1204803</td>\n",
       "      <td>UNC13B</td>\n",
       "      <td>10497</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>35397690</td>\n",
       "      <td>35397690</td>\n",
       "      <td>+</td>\n",
       "      <td>Missense_Mutation</td>\n",
       "      <td>SNP</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>20:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other non-conserving</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302340</th>\n",
       "      <td>1204804</td>\n",
       "      <td>TESK1</td>\n",
       "      <td>7016</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>35609184</td>\n",
       "      <td>35609184</td>\n",
       "      <td>+</td>\n",
       "      <td>Silent</td>\n",
       "      <td>SNP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>38:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>silent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302341</th>\n",
       "      <td>1204805</td>\n",
       "      <td>RNF20</td>\n",
       "      <td>56254</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>104324630</td>\n",
       "      <td>104324630</td>\n",
       "      <td>+</td>\n",
       "      <td>Missense_Mutation</td>\n",
       "      <td>SNP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>20:60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other non-conserving</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302342</th>\n",
       "      <td>1204806</td>\n",
       "      <td>SH2D3C</td>\n",
       "      <td>10044</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>130507316</td>\n",
       "      <td>130507316</td>\n",
       "      <td>+</td>\n",
       "      <td>Missense_Mutation</td>\n",
       "      <td>SNP</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other non-conserving</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302343</th>\n",
       "      <td>1204807</td>\n",
       "      <td>PPP2R4</td>\n",
       "      <td>5524</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>131909674</td>\n",
       "      <td>131909674</td>\n",
       "      <td>+</td>\n",
       "      <td>Missense_Mutation</td>\n",
       "      <td>SNP</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>29:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other non-conserving</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0 Hugo_Symbol  Entrez_Gene_Id  NCBI_Build Chromosome  \\\n",
       "1302147     1204721     COL16A1            1307          37          1   \n",
       "1302148     1204722        MTF1            4520          37          1   \n",
       "1302149     1204723        FAAH            2166          37          1   \n",
       "1302150     1204724     ZCCHC11           23318          37          1   \n",
       "1302151     1204725      SAMD13          148418          37          1   \n",
       "...             ...         ...             ...         ...        ...   \n",
       "1302339     1204803      UNC13B           10497          37          9   \n",
       "1302340     1204804       TESK1            7016          37          9   \n",
       "1302341     1204805       RNF20           56254          37          9   \n",
       "1302342     1204806      SH2D3C           10044          37          9   \n",
       "1302343     1204807      PPP2R4            5524          37          9   \n",
       "\n",
       "         Start_position  End_position Strand Variant_Classification  \\\n",
       "1302147        32163671      32163671      +      Missense_Mutation   \n",
       "1302148        38289412      38289412      +      Missense_Mutation   \n",
       "1302149        46872008      46872008      +      Missense_Mutation   \n",
       "1302150        52896892      52896892      +      Missense_Mutation   \n",
       "1302151        84815454      84815454      +                 Silent   \n",
       "...                 ...           ...    ...                    ...   \n",
       "1302339        35397690      35397690      +      Missense_Mutation   \n",
       "1302340        35609184      35609184      +                 Silent   \n",
       "1302341       104324630     104324630      +      Missense_Mutation   \n",
       "1302342       130507316     130507316      +      Missense_Mutation   \n",
       "1302343       131909674     131909674      +      Missense_Mutation   \n",
       "\n",
       "        Variant_Type  ...   ExAC_AF  PASS is_likely_immortalization  \\\n",
       "1302147          SNP  ...  0.000008  True                     False   \n",
       "1302148          SNP  ...  0.000008  True                     False   \n",
       "1302149          SNP  ...       NaN  True                     False   \n",
       "1302150          SNP  ...  0.000041  True                     False   \n",
       "1302151          SNP  ...  0.000008  True                     False   \n",
       "...              ...  ...       ...   ...                       ...   \n",
       "1302339          SNP  ...  0.000033  True                     False   \n",
       "1302340          SNP  ...       NaN  True                     False   \n",
       "1302341          SNP  ...       NaN  True                     False   \n",
       "1302342          SNP  ...  0.000043  True                     False   \n",
       "1302343          SNP  ...  0.000033  True                     False   \n",
       "\n",
       "        CGA_WES_AC HC_AC    Variant_annotation RD_AC RNAseq_AC SangerWES_AC  \\\n",
       "1302147      45:43   NaN  other non-conserving   NaN       NaN          NaN   \n",
       "1302148      21:19   NaN  other non-conserving   NaN       NaN          NaN   \n",
       "1302149      21:30   NaN  other non-conserving   NaN       NaN          NaN   \n",
       "1302150      31:24   NaN  other non-conserving   NaN       NaN          NaN   \n",
       "1302151      61:71   NaN                silent   NaN       NaN          NaN   \n",
       "...            ...   ...                   ...   ...       ...          ...   \n",
       "1302339      20:16   NaN  other non-conserving   NaN       NaN          NaN   \n",
       "1302340      38:27   NaN                silent   NaN       NaN          NaN   \n",
       "1302341      20:60   NaN  other non-conserving   NaN       NaN          NaN   \n",
       "1302342       6:15   NaN  other non-conserving   NaN       NaN          NaN   \n",
       "1302343      29:46   NaN  other non-conserving   NaN       NaN          NaN   \n",
       "\n",
       "        WGS_AC  \n",
       "1302147    NaN  \n",
       "1302148    NaN  \n",
       "1302149    NaN  \n",
       "1302150    NaN  \n",
       "1302151    NaN  \n",
       "...        ...  \n",
       "1302339    NaN  \n",
       "1302340    NaN  \n",
       "1302341    NaN  \n",
       "1302342    NaN  \n",
       "1302343    NaN  \n",
       "\n",
       "[197 rows x 38 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutations[mutations.DepMap_ID==\"ACH-002359\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = mutations[mutations.is_likely_immortalization!=True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = mutations[['Hugo_Symbol', 'Entrez_Gene_Id', 'NCBI_Build', 'Chromosome',\n",
    "       'Start_position', 'End_position', 'Strand', 'Variant_Classification',\n",
    "       'Variant_Type', 'Reference_Allele', 'Tumor_Allele', 'dbSNP_RS',\n",
    "       'dbSNP_Val_Status', 'Genome_Change', 'Annotation_Transcript',\n",
    "       'DepMap_ID', 'cDNA_Change', 'Codon_Change', 'Protein_Change', 'isDeleterious',\n",
    "       'isTCGAhotspot', 'TCGAhsCnt', 'isCOSMIChotspot', 'COSMIChsCnt',\n",
    "       'ExAC_AF',\"Variant_annotation\", 'CGA_WES_AC', 'HC_AC',\n",
    "       'RD_AC', 'RNAseq_AC', 'SangerWES_AC', 'WGS_AC']].rename(columns={\"Tumor_Allele\":\"Tumor_Seq_Allele1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = mutations[~mutations.DepMap_ID.isin([\"ACH-001714\",\n",
    "\"ACH-002709\",\n",
    "\"ACH-002874\",\n",
    "\"ACH-002875\",\n",
    "\"ACH-001189\",\n",
    "\"ACH-002303\",\n",
    "\"ACH-002315\",\n",
    "\"ACH-002341\"])]\n",
    "damaging = damaging[set(damaging.columns)-set([\"ACH-001714\",\n",
    "\"ACH-002709\",\n",
    "\"ACH-002874\",\n",
    "\"ACH-002875\",\n",
    "\"ACH-001189\",\n",
    "\"ACH-002303\",\n",
    "\"ACH-002315\",\n",
    "\"ACH-002341\"])]\n",
    "othercons = othercons[set(othercons.columns)-set([\"ACH-001714\",\n",
    "\"ACH-002709\",\n",
    "\"ACH-002874\",\n",
    "\"ACH-002875\",\n",
    "\"ACH-001189\",\n",
    "\"ACH-002303\",\n",
    "\"ACH-002315\",\n",
    "\"ACH-002341\"])]\n",
    "othernoncons = othernoncons[set(othernoncons.columns)-set([\"ACH-001714\",\n",
    "\"ACH-002709\",\n",
    "\"ACH-002874\",\n",
    "\"ACH-002875\",\n",
    "\"ACH-001189\",\n",
    "\"ACH-002303\",\n",
    "\"ACH-002315\",\n",
    "\"ACH-002341\"])]\n",
    "hotspot = hotspot[set(hotspot.columns)-set([\"ACH-001714\",\n",
    "\"ACH-002709\",\n",
    "\"ACH-002874\",\n",
    "\"ACH-002875\",\n",
    "\"ACH-001189\",\n",
    "\"ACH-002303\",\n",
    "\"ACH-002315\",\n",
    "\"ACH-002341\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotspot=hotspot.astype(int)\n",
    "damaging=damaging.astype(int)\n",
    "othercons=othercons.astype(int)\n",
    "othernoncons=othernoncons.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nott present\n",
      "{'ACH-001189', 'ACH-001249', 'ACH-001079', 'ACH-002709', 'ACH-002335', 'ACH-001088', 'ACH-001000', 'ACH-001101', 'ACH-001045', 'ACH-001017', 'ACH-001712', 'ACH-001087', 'ACH-001224', 'ACH-001171', 'ACH-001037', 'ACH-001071', 'ACH-001743', 'ACH-002303', 'ACH-001225', 'ACH-001316', 'ACH-001741', 'ACH-001018', 'ACH-001175', 'ACH-001393', 'ACH-001198', 'ACH-002315', 'ACH-002341', 'ACH-001015', 'ACH-001121', 'ACH-001429'}\n",
      "removed\n",
      "{'ACH-002341', 'ACH-001189', 'ACH-002315', 'ACH-002303'}\n",
      "missing\n",
      "set()\n",
      "blacklist\n",
      "17 {'ACH-001756', 'ACH-001705', 'ACH-002055', 'ACH-001760', 'ACH-001828', 'ACH-001553', 'ACH-002476', 'ACH-001227', 'ACH-002138', 'ACH-001707', 'ACH-001046', 'ACH-001686', 'ACH-002013', 'ACH-003000', 'ACH-001758', 'ACH-001759', 'ACH-001434'}\n"
     ]
    }
   ],
   "source": [
    "print('nott present')\n",
    "removed = set(previnternal) - set(mutations.DepMap_ID)\n",
    "print(removed)\n",
    "print('removed')\n",
    "removed = set(internal_mut) - set(mutations.DepMap_ID)\n",
    "print(removed)\n",
    "missing = set(internal) - set(mutations.DepMap_ID)\n",
    "blacklist = set(mutations.DepMap_ID) - (previnternal | set(internal))\n",
    "print('missing')\n",
    "print(missing)\n",
    "newlines = set(internal) \n",
    "print('blacklist')\n",
    "print(len(blacklist), blacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7053\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "a = len(mutations)\n",
    "mutations = mutations[~mutations.DepMap_ID.isin(blacklist)]\n",
    "print(a - len(mutations))\n",
    "mutations.to_csv('temp/all_somatic_mutations_withlegacy.csv', index=False)\n",
    "a = len(damaging.columns)\n",
    "damaging = damaging[set(damaging.columns) -blacklist]\n",
    "print(a - len(damaging.columns))\n",
    "damaging.to_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_damaging.csv')\n",
    "a = len(othercons.columns)\n",
    "othercons = othercons[set(othercons.columns) -blacklist]\n",
    "print(a - len(othercons.columns))\n",
    "othercons.to_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_othercons.csv',)\n",
    "a = len(othernoncons.columns)\n",
    "othernoncons = othernoncons[set(othernoncons.columns) -blacklist]\n",
    "print(a - len(othernoncons.columns))\n",
    "othernoncons.to_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_othernoncons.csv',)\n",
    "a = len(hotspot.columns)\n",
    "hotspot = hotspot[set(hotspot.columns) -blacklist]\n",
    "print(a - len(hotspot.columns))\n",
    "hotspot.to_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_hotspot.csv',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading all_somatic_mutations_withlegacy...\n",
      "hitting https://cds.team/taiga/api/datafile/d44b1c7cd81d403dbb3248c4a1d3de23\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: all_somatic_mutations_withlegacy properly converted and uploaded\n",
      "Uploading all_somatic_mutations_boolmatrix_fordepmap_damaging...\n",
      "hitting https://cds.team/taiga/api/datafile/d44b1c7cd81d403dbb3248c4a1d3de23\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 4001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 1750\n",
      "\t Conversion in progress, line 3250\n",
      "\t Conversion in progress, line 4750\n",
      "\t Conversion in progress, line 6000\n",
      "\t Conversion in progress, line 7000\n",
      "\t Conversion in progress, line 8500\n",
      "\t Conversion in progress, line 9750\n",
      "\t Conversion in progress, line 11250\n",
      "\t Conversion in progress, line 12250\n",
      "\t Conversion in progress, line 13750\n",
      "\t Conversion in progress, line 15000\n",
      "\t Conversion in progress, line 16500\n",
      "\t Conversion in progress, line 17500\n",
      "\t Conversion in progress, line 18000\n",
      "\t Conversion in progress, line 18000\n",
      "\t Conversion in progress, line 18000\n",
      "\t Conversion in progress, line 18000\n",
      "\t Conversion in progress, line 18000\n",
      "\t Conversion in progress, line 18000\n",
      "\t Conversion in progress, line 18000\n",
      "\t Conversion in progress, line 18000\n",
      "\t Conversion in progress, line 18000\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: all_somatic_mutations_boolmatrix_fordepmap_damaging properly converted and uploaded\n",
      "Uploading all_somatic_mutations_boolmatrix_fordepmap_othernoncons...\n",
      "hitting https://cds.team/taiga/api/datafile/d44b1c7cd81d403dbb3248c4a1d3de23\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 2001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 1750\n",
      "\t Conversion in progress, line 3250\n",
      "\t Conversion in progress, line 4250\n",
      "\t Conversion in progress, line 5500\n",
      "\t Conversion in progress, line 7000\n",
      "\t Conversion in progress, line 8500\n",
      "\t Conversion in progress, line 9750\n",
      "\t Conversion in progress, line 10750\n",
      "\t Conversion in progress, line 12250\n",
      "\t Conversion in progress, line 13750\n",
      "\t Conversion in progress, line 15000\n",
      "\t Conversion in progress, line 16500\n",
      "\t Conversion in progress, line 17500\n",
      "\t Conversion in progress, line 18750\n",
      "\t Conversion in progress, line 19250\n",
      "\t Conversion in progress, line 19250\n",
      "\t Conversion in progress, line 19250\n",
      "\t Conversion in progress, line 19250\n",
      "\t Conversion in progress, line 19250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: all_somatic_mutations_boolmatrix_fordepmap_othernoncons properly converted and uploaded\n",
      "Uploading all_somatic_mutations_boolmatrix_fordepmap_othercons...\n",
      "hitting https://cds.team/taiga/api/datafile/d44b1c7cd81d403dbb3248c4a1d3de23\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\n",
      "\t Done: all_somatic_mutations_boolmatrix_fordepmap_othercons properly converted and uploaded\n",
      "Uploading all_somatic_mutations_boolmatrix_fordepmap_hotspot...\n",
      "hitting https://cds.team/taiga/api/datafile/d44b1c7cd81d403dbb3248c4a1d3de23\n",
      "Conversion and upload...:\n",
      "\t Waiting in the task queue\n",
      "\t Scanning through file to determine size (line 4001)\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 2250\n",
      "\t Conversion in progress, line 3750\n",
      "\t Conversion in progress, line 5250\n",
      "\t Conversion in progress, line 6500\n",
      "\t Conversion in progress, line 7500\n",
      "\t Conversion in progress, line 8750\n",
      "\t Conversion in progress, line 8750\n",
      "\t Conversion in progress, line 8750\n",
      "\t Conversion in progress, line 8750\n",
      "\t Conversion in progress, line 8750\n",
      "\t Conversion in progress, line 8750\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: all_somatic_mutations_boolmatrix_fordepmap_hotspot properly converted and uploaded\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 1dfeca4e84dc4b76955694fee3a243f3 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/1dfeca4e84dc4b76955694fee3a243f3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1dfeca4e84dc4b76955694fee3a243f3'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.update_dataset(dataset_permaname=\"depmap-mutation-calls-9be3\",\n",
    "                 upload_file_path_dict={\n",
    "'temp/all_somatic_mutations_withlegacy.csv': 'TableCSV',\n",
    "'temp/all_somatic_mutations_boolmatrix_fordepmap_damaging.csv': 'NumericMatrixCSV',\n",
    "'temp/all_somatic_mutations_boolmatrix_fordepmap_othernoncons.csv': 'NumericMatrixCSV',\n",
    "'temp/all_somatic_mutations_boolmatrix_fordepmap_othercons.csv': 'NumericMatrixCSV',\n",
    "'temp/all_somatic_mutations_boolmatrix_fordepmap_hotspot.csv': 'NumericMatrixCSV',\n",
    "                                       },#'temp/README': 'Raw'},\n",
    "                 dataset_description=\"\"\"\n",
    "# Internal Mutations\n",
    "\n",
    "Mutation calls for Internal DepMap data\n",
    "\n",
    "* Version 1 Internal 18Q1*\n",
    "\n",
    "original source: `/xchip/ccle_dist/broad_only/CMAG/mutations/CCLE_depMap_18Q1_maf_20180202.txt`\n",
    "* Version 2-4 Internal 18Q2*\n",
    "\n",
    "merged mutations and indels file (1,606 cell lines, including CCLE and Sanger WES reanalysis)\n",
    "original source: \n",
    "`/xchip/ccle_dist/broad_only/CMAG/mutations/CCLE_depMap_18q2_maf_20180502.txt`\n",
    "Binary matrices:\n",
    "- damaging: if isDeleterious is true\n",
    "- missense: if isDeleterious is false\n",
    "- hotspot: if missense and either TCGA or COSMIC hotspot\n",
    "Version 2 contains the MAF file\n",
    "* Version 5-6 Internal 18Q3*\n",
    "\n",
    "version 5 deprecated\n",
    "\n",
    "original source: `/xchip/ccle_dist/broad_only/CMAG/mutations/CCLE_depMap_18q3_maf_20180716.txt`\n",
    "\n",
    "Binary matrices:\n",
    "- damaging: if isDeleterious is true\n",
    "- missense: if isDeleterious is false\n",
    "- hotspot: if missense and either TCGA or COSMIC hotspot\n",
    "- Rows: cell line, Broad (arxspan) IDs\n",
    "\n",
    "Columns: Gene, HGNC symbol (Entrez ID)\n",
    "\n",
    "MAF file\n",
    "\n",
    "* Version 7-8 Internal 18Q4*\n",
    "\n",
    "version 8 just changes a column name in the MAF file from Broad_ID to DepMap_ID\n",
    "\n",
    "original source: `/xchip/ccle_dist/broad_only/CMAG/mutations/CCLE_DepMap_18Q4_maf_20181028.txt`\n",
    "\n",
    "* Version 9-12 Internal 19Q1*\n",
    "\n",
    "version 12 updates the column name from VA_WES_AC to CCLE_WES_AC\n",
    "\n",
    "version 11+ uses an updated definition for hotspot mutations\n",
    "\n",
    "version 12 contains the correct data for 19Q1\n",
    "\n",
    "* Version 13 Internal 19Q2*\n",
    "\n",
    "* Version 14-15 Internal 19Q3*\n",
    "\n",
    "version 15 fixed entrez ids\n",
    "\n",
    "* Version 16 Internal 19Q4*\n",
    "\n",
    "adding 35 new cell lines.\n",
    "\n",
    "* Version 16 Internal 19Q4*\n",
    "uploading as matrices\n",
    "\n",
    "* Version 17 Internal 19Q4*\n",
    "removing unauthorized lines and setting as matrices\n",
    "\n",
    "* Version 18 Internal 19Q4*\n",
    "removing unauthorized lines and setting as matrices\n",
    "\n",
    "* Version 19 Internal 20Q1*\n",
    "uploading 8 new lines\n",
    "\n",
    "* Version 20 Internal 20Q1*\n",
    "removing unauthorized cl\n",
    "\n",
    "* Version 21 Internal 20Q2*\n",
    "uploading 8 new lines and adding .all to express the fact that this data is the aggregate of all different sequencing methods.\n",
    "\n",
    "* Version 22 Internal 20Q2*\n",
    "removing 2 cell lines\n",
    "\n",
    "* Version 23 Internal 20Q3*\n",
    "nothing different from 20Q2. no new cell lines\n",
    "\n",
    "* Version 24 Internal 20Q3*\n",
    "updating the blacklists\n",
    "\n",
    "* Version 25 Internal 20Q4*\n",
    "removed 'ACH-002303' because wrong line. new dataset, adding wgs mutations, full reprocessing of the mutations, improved filtering\n",
    "\n",
    "* Version 26 Internal 20Q4*\n",
    "failed matrix upload\n",
    "\n",
    "* Version 26 Internal 20Q4*\n",
    "renaming filies\n",
    "\n",
    "*** Variant annotation column ***\n",
    "\n",
    "MAF file, added column (Variant_annotation) classifying each variant as either silent, damaging, other conserving, or other non-conserving, based on this mapping (old annotation from Variant_Classification column - new annotation):\n",
    "\n",
    "Silent - silent\n",
    "Splice_Site - damaging\n",
    "Missense_Mutation - other non-conserving\n",
    "Nonsense_Mutation - damaging\n",
    "De_novo_Start_OutOfFrame - damaging\n",
    "Nonstop_Mutation - other non-conserving\n",
    "Frame_Shift_Del - damaging\n",
    "Frame_Shift_Ins - damaging\n",
    "In_Frame_Del - other non-conserving\n",
    "In_Frame_Ins - other non-conserving\n",
    "Stop_Codon_Del - other non-conserving\n",
    "Stop_Codon_Ins - other non-conserving\n",
    "Start_Codon_SNP - damaging\n",
    "Start_Codon_Del - damaging\n",
    "Start_Codon_Ins - damaging\n",
    "5'Flank - other conserving\n",
    "Intron - other conserving\n",
    "IGR - other conserving\n",
    "3'UTR - other conserving\n",
    "5'UTR - other conserving\n",
    "Binary matrices:\n",
    "\n",
    "- damaging: if damaging\n",
    "- other: if other conserving or other non-conserving\n",
    "- hotspot: if it is not a silent mutation and is either TCGA or COSMIC hotspot\n",
    "- Rows: cell line, DepMap (arxspan) IDs\n",
    "\n",
    "Columns: Gene, HGNC symbol (Entrez ID)\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "BLACKLISTED:\n",
    "\"\"\"+str(blacklist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CCLE_mutations', 'depmap-mutation-calls-9be3.30/all_somatic_mutations_withlegacy'), ('all_somatic_mutations_boolmatrix_fordepmap_damaging', 'depmap-mutation-calls-9be3.30/all_somatic_mutations_boolmatrix_fordepmap_damaging'), ('all_somatic_mutations_boolmatrix_fordepmap_othernoncons', 'depmap-mutation-calls-9be3.30/all_somatic_mutations_boolmatrix_fordepmap_othernoncons'), ('all_somatic_mutations_boolmatrix_fordepmap_othercons', 'depmap-mutation-calls-9be3.30/all_somatic_mutations_boolmatrix_fordepmap_othercons'), ('all_somatic_mutations_boolmatrix_fordepmap_hotspot', 'depmap-mutation-calls-9be3.30/all_somatic_mutations_boolmatrix_fordepmap_hotspot')]\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datafile/cf78b026ca274b6d8ae86c787012c606\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id e3cd3dafab9d4946b0ee6cfe179e56a3 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/e3cd3dafab9d4946b0ee6cfe179e56a3\n",
      "[('CCLE_mutations', 'depmap-mutation-calls-9be3.30/all_somatic_mutations_withlegacy'), ('all_somatic_mutations_boolmatrix_fordepmap_damaging', 'depmap-mutation-calls-9be3.30/all_somatic_mutations_boolmatrix_fordepmap_damaging'), ('all_somatic_mutations_boolmatrix_fordepmap_othernoncons', 'depmap-mutation-calls-9be3.30/all_somatic_mutations_boolmatrix_fordepmap_othernoncons'), ('all_somatic_mutations_boolmatrix_fordepmap_othercons', 'depmap-mutation-calls-9be3.30/all_somatic_mutations_boolmatrix_fordepmap_othercons'), ('all_somatic_mutations_boolmatrix_fordepmap_hotspot', 'depmap-mutation-calls-9be3.30/all_somatic_mutations_boolmatrix_fordepmap_hotspot')]\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datafile/cc3395ea162f47c4a7035ef510c5d877\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id b53a973b68e34705a05996b04208d8ff created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/b53a973b68e34705a05996b04208d8ff\n"
     ]
    }
   ],
   "source": [
    "# To add to a virtual dataset\n",
    "AddToVirtual(virtual_internal, 'depmap-mutation-calls-9be3', [('CCLE_mutations', 'all_somatic_mutations_withlegacy'),\n",
    "('all_somatic_mutations_boolmatrix_fordepmap_damaging', 'all_somatic_mutations_boolmatrix_fordepmap_damaging'),\n",
    "('all_somatic_mutations_boolmatrix_fordepmap_othernoncons', 'all_somatic_mutations_boolmatrix_fordepmap_othernoncons'),\n",
    "('all_somatic_mutations_boolmatrix_fordepmap_othercons', 'all_somatic_mutations_boolmatrix_fordepmap_othercons'),\n",
    "('all_somatic_mutations_boolmatrix_fordepmap_hotspot', 'all_somatic_mutations_boolmatrix_fordepmap_hotspot')])#('README','README')])\n",
    "# To add to a eternal dataset\n",
    "AddToVirtual('depmap-a0ab', 'depmap-mutation-calls-9be3', [('CCLE_mutations', 'all_somatic_mutations_withlegacy'),\n",
    "('all_somatic_mutations_boolmatrix_fordepmap_damaging', 'all_somatic_mutations_boolmatrix_fordepmap_damaging'),\n",
    "('all_somatic_mutations_boolmatrix_fordepmap_othernoncons', 'all_somatic_mutations_boolmatrix_fordepmap_othernoncons'),\n",
    "('all_somatic_mutations_boolmatrix_fordepmap_othercons', 'all_somatic_mutations_boolmatrix_fordepmap_othercons'),\n",
    "('all_somatic_mutations_boolmatrix_fordepmap_hotspot', 'all_somatic_mutations_boolmatrix_fordepmap_hotspot')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('missing')\n",
    "missing = set(ibm) - set(mutations.DepMap_ID)\n",
    "print(missing)\n",
    "print('ibm_embargo')\n",
    "ibm_embargo = set(mutations.DepMap_ID) - (prevdmc | set(ibm))\n",
    "print(len(ibm_embargo), ibm_embargo)\n",
    "newlines = set(ibm) \n",
    "print(len(newlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = len(mutations)\n",
    "b = mutations[~mutations.DepMap_ID.isin(ibm_embargo| prevdmc)]\n",
    "print(a - len(b))\n",
    "b.to_csv('temp/all_somatic_mutations_withlegacy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading wes_somatic_mutations_withlegacy...\n",
      "hitting https://cds.team/taiga/api/datafile/6773edbe2a724e01b90f2f15d37644c7\n",
      "Conversion and upload...:\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: wes_somatic_mutations_withlegacy properly converted and uploaded\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 83fb71cb317c48db8e9d52e5b50c01fe created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/83fb71cb317c48db8e9d52e5b50c01fe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'83fb71cb317c48db8e9d52e5b50c01fe'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.update_dataset(dataset_permaname=\"mutations-b05c\",\n",
    "                 upload_file_path_dict={\n",
    "'temp/all_somatic_mutations_withlegacy.csv': 'TableCSV',\n",
    "                                       },#'temp/README': 'Raw'},\n",
    "                 dataset_description=\"\"\"\n",
    "# DMC Mutations\n",
    "\n",
    "## Versions\n",
    "\n",
    "* Version 1 empty*\n",
    "\n",
    "* Version 2 Internal 20Q4*\n",
    "First IBM version\n",
    "\n",
    "* Version 3 Internal 20Q4*\n",
    "updated issue in IBM version 2 (had duplicate lines with DMC)\n",
    "\n",
    "* Version 4 Internal 20Q4*\n",
    "reworking the readme\n",
    "\n",
    "* Version 5 Internal 20Q4*\n",
    "renaming files\n",
    "\n",
    "## Notations\n",
    "\n",
    "MAF file, added column (Variant_annotation) classifying each variant as either silent, damaging, other conserving, or other non-conserving, based on this mapping (old annotation from Variant_Classification column - new annotation):\n",
    "\n",
    "Silent - silent\n",
    "Splice_Site - damaging\n",
    "Missense_Mutation - other non-conserving\n",
    "Nonsense_Mutation - damaging\n",
    "De_novo_Start_OutOfFrame - damaging\n",
    "Nonstop_Mutation - other non-conserving\n",
    "Frame_Shift_Del - damaging\n",
    "Frame_Shift_Ins - damaging\n",
    "In_Frame_Del - other non-conserving\n",
    "In_Frame_Ins - other non-conserving\n",
    "Stop_Codon_Del - other non-conserving\n",
    "Stop_Codon_Ins - other non-conserving\n",
    "Start_Codon_SNP - damaging\n",
    "Start_Codon_Del - damaging\n",
    "Start_Codon_Ins - damaging\n",
    "5'Flank - other conserving\n",
    "Intron - other conserving\n",
    "IGR - other conserving\n",
    "3'UTR - other conserving\n",
    "5'UTR - other conserving\n",
    "Binary matrices:\n",
    "- damaging: if damaging\n",
    "- other cons: if other conserving\n",
    "- other non cons: if other non-conserving\n",
    "- hotspot: if it is not a silent mutation and is either TCGA or COSMIC hotspot\n",
    "- Rows: cell line, DepMap (arxspan) IDs\n",
    "\n",
    "Columns: Gene, HGNC symbol (Entrez ID)\n",
    "\n",
    "## Update\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "EMBARGO:\n",
    "\"\"\"+str(ibm_embargo|blacklist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('all_somatic_mutations_withlegacy', 'mutations-b05c.5/all_somatic_mutations_withlegacy')]\n",
      "hitting https://cds.team/taiga/api/datafile/bbd8eda063f0466cb00fc672fa98cfe9\n",
      "hitting https://cds.team/taiga/api/datafile/bbd8eda063f0466cb00fc672fa98cfe9\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id b4616d4c78b14a35a705ca6b6c83b025 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/b4616d4c78b14a35a705ca6b6c83b025\n"
     ]
    }
   ],
   "source": [
    "# To add to a virtual dataset\n",
    "AddToVirtual(virtual_ibm, 'mutations-b05c', [('all_somatic_mutations_withlegacy', 'all_somatic_mutations_withlegacy'),])#('README','README')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing\n",
      "set()\n",
      "dmc_embargo\n",
      "2 {'ACH-001512', 'ACH-001708'}\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "print('missing')\n",
    "missing = set(dmc) - set(mutations.DepMap_ID)\n",
    "dmc_embargo = set(mutations.DepMap_ID) - (prevdmc | set(dmc))\n",
    "print(missing)\n",
    "newlines = set(dmc) \n",
    "print('dmc_embargo')\n",
    "print(len(dmc_embargo), dmc_embargo)\n",
    "print(len(newlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585\n"
     ]
    }
   ],
   "source": [
    "a = len(mutations)\n",
    "mutations = mutations[~mutations.DepMap_ID.isin(dmc_embargo)]\n",
    "print(a - len(mutations))\n",
    "mutations.to_csv('temp/all_somatic_mutations_withlegacy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading all_somatic_mutations_withlegacy...\n",
      "hitting https://cds.team/taiga/api/datafile/f39e38d7dde841e794fa288f3fc7f2be\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: all_somatic_mutations_withlegacy properly converted and uploaded\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 1b7e5173dca44a739c2e83a35d820b77 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/1b7e5173dca44a739c2e83a35d820b77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1b7e5173dca44a739c2e83a35d820b77'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.update_dataset(dataset_permaname=\"depmap-mutation-calls-dfce\",\n",
    "                 upload_file_path_dict={\n",
    "'temp/all_somatic_mutations_withlegacy.csv': 'TableCSV',\n",
    "                                       },#'temp/README': 'Raw'},\n",
    "                 dataset_description=\"\"\"\n",
    "# DMC Mutations\n",
    "\n",
    "* Version 1-5 DMC 19Q1*\n",
    "\n",
    "version 5 is a one-off portal thing because dmc wanted to be able to plot if a gene has any mutation as one-hot encoded value in the x/y axes of the data explorer It adds the any_mutation matrix, but does not change the others. Code used to generate:\n",
    "\n",
    "```\n",
    "from taigapy import TaigaClient\n",
    "\n",
    "c = TaigaClient()\n",
    "\n",
    "dmc_19q1_mutation_taiga_root = \"depmap-mutation-calls-dfce.3/\"\n",
    "other_matrix = c.get(dmc_19q1_mutation_taiga_root + \"other_mutation\")\n",
    "damaging_matrix = c.get(dmc_19q1_mutation_taiga_root + \"damaging_mutation\")\n",
    "hotspot_matrix = c.get(dmc_19q1_mutation_taiga_root + \"hotspot_mutation\")\n",
    "\n",
    "df = other_matrix.append(damaging_matrix)\n",
    "df = df.groupby(level=0).sum()\n",
    "\n",
    "df = df.append(hotspot_matrix)\n",
    "df = df.groupby(level=0).sum()\n",
    "\n",
    "df[df > 1] = 1\n",
    "\n",
    "df.to_csv('any_mutation.csv')\n",
    "```\n",
    "The code uses version 3 because the dmc portal was using version 3\n",
    "\n",
    "version 4 updates the column name from VA_WES_AC to CCLE_WES_AC\n",
    "\n",
    "version 3 has an updated definition for hotspot mutations\n",
    "\n",
    "version 2+ contains the correct data for 19Q1\n",
    "\n",
    "* Version 6 DMC 19Q2*\n",
    "\n",
    "* Version 7-8 DMC 19Q3*\n",
    "version 8 fixed entrez ids\n",
    "\n",
    "* Version 9 DMC 19Q4*\n",
    "adding 52 new cell lines.\n",
    "\n",
    "* Version 10 DMC 19Q4*\n",
    "removing unauthorized lines and setting as matrices\n",
    "\n",
    "* Version 11 DMC 19Q4*\n",
    "removing unauthorized lines and setting as matrices\n",
    "\n",
    "* Version 12 DMC 20Q1*\n",
    "uploading 8 new lines\n",
    "\n",
    "* Version 13 DMC 20Q1*\n",
    "removing unauthorized cl\n",
    "\n",
    "* Version 14 DMC 20Q2*\n",
    "uploading 8 new lines and adding .all to express the fact that this data is the aggregate of all different sequencing methods.\n",
    "\n",
    "* Version 15 DMC 20Q2*\n",
    "removing 2 lines\n",
    "\n",
    "* Version 15 DMC 20Q3*\n",
    "nothing different from 20Q2. no new cell lines\n",
    "\n",
    "* Version 15 DMC 20Q3*\n",
    "updating the blacklists\n",
    "\n",
    "* Version 16 DMC 20Q4*\n",
    "adding more lines, new dataset, adding wgs mutations, full reprocessing of the mutations, improved filtering\n",
    "\n",
    "* Version 17 DMC 20Q4*\n",
    "reaming files\n",
    "\n",
    "MAF file, added column (Variant_annotation) classifying each variant as either silent, damaging, other conserving, or other non-conserving, based on this mapping (old annotation from Variant_Classification column - new annotation):\n",
    "\n",
    "Silent - silent\n",
    "Splice_Site - damaging\n",
    "Missense_Mutation - other non-conserving\n",
    "Nonsense_Mutation - damaging\n",
    "De_novo_Start_OutOfFrame - damaging\n",
    "Nonstop_Mutation - other non-conserving\n",
    "Frame_Shift_Del - damaging\n",
    "Frame_Shift_Ins - damaging\n",
    "In_Frame_Del - other non-conserving\n",
    "In_Frame_Ins - other non-conserving\n",
    "Stop_Codon_Del - other non-conserving\n",
    "Stop_Codon_Ins - other non-conserving\n",
    "Start_Codon_SNP - damaging\n",
    "Start_Codon_Del - damaging\n",
    "Start_Codon_Ins - damaging\n",
    "5'Flank - other conserving\n",
    "Intron - other conserving\n",
    "IGR - other conserving\n",
    "3'UTR - other conserving\n",
    "5'UTR - other conserving\n",
    "Binary matrices:\n",
    "- damaging: if damaging\n",
    "- other cons: if other conserving\n",
    "- other non cons: if other non-conserving\n",
    "- hotspot: if it is not a silent mutation and is either TCGA or COSMIC hotspot\n",
    "- Rows: cell line, DepMap (arxspan) IDs\n",
    "\n",
    "Columns: Gene, HGNC symbol (Entrez ID)\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "EMBARGO:\n",
    "\"\"\"+str(dmc_embargo|blacklist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CCLE_mutations', 'depmap-mutation-calls-dfce.22/all_somatic_mutations_withlegacy')]\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datafile/252e7801fb02469c88097ac93c1601fc\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 84847c6431cb49c89110a8428bbdce38 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/84847c6431cb49c89110a8428bbdce38\n"
     ]
    }
   ],
   "source": [
    "# To add to a virtual dataset\n",
    "AddToVirtual(virtual_dmc, 'depmap-mutation-calls-dfce', [('CCLE_mutations', 'all_somatic_mutations_withlegacy'),])#('README','README')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing\n",
      "{'ACH-002709'}\n",
      "embargo\n",
      "32 {'ACH-001493', 'ACH-001970', 'ACH-001449', 'ACH-002401', 'ACH-002010', 'ACH-001502', 'ACH-001662', 'ACH-001669', 'ACH-001672', 'ACH-002465', 'ACH-001973', 'ACH-001693', 'ACH-001547', 'ACH-001293', 'ACH-001533', 'ACH-001971', 'ACH-001847', 'ACH-002014', 'ACH-001854', 'ACH-001349', 'ACH-001696', 'ACH-001437', 'ACH-002021', 'ACH-002048', 'ACH-001679', 'ACH-001678', 'ACH-001676', 'ACH-001537', 'ACH-001855', 'ACH-002512', 'ACH-001438', 'ACH-002400'}\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "print('missing')\n",
    "missing = set(public) - set(mutations.DepMap_ID)\n",
    "embargo = set(mutations.DepMap_ID) - (prevpublic | set(public))\n",
    "print(missing)\n",
    "newlines = set(public) \n",
    "print('embargo')\n",
    "print(len(embargo), embargo)\n",
    "print(len(newlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15632\n"
     ]
    }
   ],
   "source": [
    "a = len(mutations)\n",
    "mutations = mutations[~mutations.DepMap_ID.isin(embargo)]\n",
    "print(a - len(mutations))\n",
    "mutations.to_csv('temp/all_somatic_mutations_withlegacy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading all_somatic_mutations_withlegacy...\n",
      "hitting https://cds.team/taiga/api/datafile/f8891533f4484ae3b6c6b682fc534b49\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: all_somatic_mutations_withlegacy properly converted and uploaded\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 2d192136539b439f8f71dc9eba2d0882 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/2d192136539b439f8f71dc9eba2d0882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2d192136539b439f8f71dc9eba2d0882'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description=\"\"\"\n",
    "# Public Mutations\n",
    "\n",
    "Mutation calls for Public DepMap data\n",
    "\n",
    "* Version 1 Public 18Q1*\n",
    "\n",
    "original source: CCLE data portal\n",
    "* Version 2 Public 18Q2*\n",
    "\n",
    "merged mutations and indels file (1,549 cell lines total, including data for 63 newly released cell lines)\n",
    "original source: `/xchip/ccle_dist/public/DepMap_18Q2/CCLE_DepMap_18Q2_maf_20180502.txt`\n",
    "* Version 3-4 Public 18Q3*\n",
    "\n",
    "version 3 deprecated\n",
    "\n",
    "original source: `/xchip/ccle_dist/public/DepMap_18Q3/CCLE_DepMap_18q3_maf_20180718.txt`\n",
    "\n",
    "Binary matrices:\n",
    "damaging: if isDeleterious is true\n",
    "missense: if isDeleterious is false\n",
    "hotspot: if missense and either TCGA or COSMIC hotspot\n",
    "Rows: cell line, Broad (arxspan) IDs\n",
    "\n",
    "Columns: Gene, HGNC symbol (Entrez ID)\n",
    "\n",
    "MAF file\n",
    "\n",
    "* Version 5 Public 18Q4*\n",
    "\n",
    "original source: `/xchip/ccle_dist/public/DepMap_18Q4/CCLE_DepMap_18q4_maf_20181029.txt`\n",
    "\n",
    "* Version 6-9 Public 19Q1*\n",
    "\n",
    "version 9 updates the column name from VA_WES_AC to CCLE_WES_AC\n",
    "\n",
    "version 8 uses an updated definition for hotspot mutations\n",
    "\n",
    "version 9 contains the correct data for 19Q1\n",
    "\n",
    "* Version 10 Public 19Q2*\n",
    "\n",
    "* Version 11-12 Public 19Q3*\n",
    "\n",
    "version 12 fixed entrez ids\n",
    "\n",
    "* Version 13 Public 19Q4*\n",
    "\n",
    "adding 52 new cell lines\n",
    "\n",
    "* Version 14 Public 19Q4*\n",
    "removing unauthorized lines and setting matrices\n",
    "\n",
    "* Version 15 Public 20Q1*\n",
    "adding 8 new lines \n",
    "\n",
    "* Version 16 Public 20Q1*\n",
    "removing an unauthorized line\n",
    "\n",
    "* Version 17 Public 20Q2*\n",
    "uploading 8 new lines and adding .all to express the fact that this data is the aggregate of all different sequencing methods.\n",
    "\n",
    "* Version 18 Public 20Q2*\n",
    "removing 2 lines\n",
    "\n",
    "* Version 19 Public 20Q3*\n",
    "nothing different from 20Q2. no new cell lines\n",
    "\n",
    "* Version 20 Public 20Q3*\n",
    "updating the blacklists\n",
    "\n",
    "* Version 21 Public 20Q3*\n",
    "updating the dmc\n",
    "\n",
    "* Version 22 Public 20Q3*\n",
    "readding two already released samples to the public list\n",
    "\n",
    "* Version 23 Public 20Q4*\n",
    "new samples, new dataset, adding wgs mutations, full reprocessing of the mutations, improved filtering\n",
    "\n",
    "* Version 23 Public 20Q4*\n",
    "renaming files\n",
    "\n",
    "* Version 24 Public 20Q4*\n",
    "removing lines\n",
    "\n",
    "MAF file, added column (Variant_annotation) classifying each variant as either silent, damaging, other conserving, or other non-conserving, based on this mapping (old annotation from Variant_Classification column - new annotation):\n",
    "\n",
    "Silent - silent\n",
    "Splice_Site - damaging\n",
    "Missense_Mutation - other non-conserving\n",
    "Nonsense_Mutation - damaging\n",
    "De_novo_Start_OutOfFrame - damaging\n",
    "Nonstop_Mutation - other non-conserving\n",
    "Frame_Shift_Del - damaging\n",
    "Frame_Shift_Ins - damaging\n",
    "In_Frame_Del - other non-conserving\n",
    "In_Frame_Ins - other non-conserving\n",
    "Stop_Codon_Del - other non-conserving\n",
    "Stop_Codon_Ins - other non-conserving\n",
    "Start_Codon_SNP - damaging\n",
    "Start_Codon_Del - damaging\n",
    "Start_Codon_Ins - damaging\n",
    "5'Flank - other conserving\n",
    "Intron - other conserving\n",
    "IGR - other conserving\n",
    "3'UTR - other conserving\n",
    "5'UTR - other conserving\n",
    "Binary matrices:\n",
    "\n",
    "- damaging: if damaging\n",
    "- other: if other conserving or other non-conserving\n",
    "- hotspot: if it is not a silent mutation and is either TCGA or COSMIC hotspot\n",
    "- Rows: cell line, DepMap (arxspan) IDs\n",
    "\n",
    "Columns: Gene, HGNC symbol (Entrez ID)\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "EMBARGOED:\n",
    "\"\"\"+str(embargo)\n",
    "\n",
    "tc.update_dataset(dataset_permaname=\"depmap-mutation-calls-9a1a\",\n",
    "                 upload_file_path_dict={\n",
    "        'temp/all_somatic_mutations_withlegacy.csv': 'TableCSV'\n",
    "                                       },#'temp/README': 'Raw'},\n",
    "                 dataset_description=description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CCLE_mutations', 'depmap-mutation-calls-9a1a.30/all_somatic_mutations_withlegacy')]\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datafile/c0b325228a3f48c1a7fdf5093175b1fa\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id c83374888bac406181a52b7e4ac79970 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/c83374888bac406181a52b7e4ac79970\n"
     ]
    }
   ],
   "source": [
    "# To add to a virtual dataset\n",
    "AddToVirtual(virtual_public, 'depmap-mutation-calls-9a1a', [('CCLE_mutations', 'all_somatic_mutations_withlegacy'),])#('README','README')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "genecn= pd.read_csv('temp/all_'+release+'_gene_cn.csv',index_col=0)\n",
    "segmentcn = pd.read_csv('temp/all_'+release+'_segment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACH-002874', 'ACH-002875', 'ACH-003000'}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([\"ACH-001714\",\n",
    "\"ACH-002709\",\n",
    "\"ACH-002874\",\n",
    "\"ACH-002875\",\n",
    "\"ACH-003000\", \n",
    "\"ACH-002875\", \n",
    "\"ACH-002874\",\n",
    "\"ACH-001189\",\n",
    "\"ACH-002303\",\n",
    "\"ACH-002315\",\n",
    "\"ACH-002341\"])&set(genecn.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "genecn = genecn.drop(set([\"ACH-001714\",\n",
    "\"ACH-002709\",\n",
    "\"ACH-002874\",\n",
    "\"ACH-002875\",\n",
    "\"ACH-003000\",\n",
    "\"ACH-001189\",\n",
    "\"ACH-002303\",\n",
    "\"ACH-002315\",\n",
    "\"ACH-002341\"])&set(genecn.index))#.apply(lambda x: (x**2)-1)\n",
    "segmentcn = segmentcn[~segmentcn.DepMap_ID.isin([\"ACH-001714\",\n",
    "\"ACH-002709\",\n",
    "\"ACH-002874\",\n",
    "\"ACH-002875\",\n",
    "\"ACH-003000\",\n",
    "\"ACH-001189\",\n",
    "\"ACH-002303\",\n",
    "\"ACH-002315\",\n",
    "\"ACH-002341\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not present\n",
      "{'ACH-001011', 'ACH-001189', 'ACH-002709', 'ACH-001187', 'ACH-002394', 'ACH-000084', 'ACH-001712', 'ACH-002395', 'ACH-001743', 'ACH-002303', 'ACH-001108', 'ACH-000033', 'ACH-001109', 'ACH-001316', 'ACH-002396', 'ACH-001131', 'ACH-001741', 'ACH-001393', 'ACH-002391', 'ACH-002393', 'ACH-002315', 'ACH-002390', 'ACH-002341', 'ACH-002359', 'ACH-001429', 'ACH-000629'}\n",
      "removed\n",
      "{'ACH-001189', 'ACH-002315', 'ACH-002341', 'ACH-002359', 'ACH-002303'}\n",
      "missing\n",
      "set()\n",
      "blacklist\n",
      "16 {'ACH-001756', 'ACH-001705', 'ACH-002055', 'ACH-001760', 'ACH-001828', 'ACH-001553', 'ACH-002476', 'ACH-001227', 'ACH-002138', 'ACH-001707', 'ACH-001046', 'ACH-001686', 'ACH-002013', 'ACH-001758', 'ACH-001759', 'ACH-001434'}\n"
     ]
    }
   ],
   "source": [
    "print('not present')\n",
    "removed = set(previnternal) - set(segmentcn.DepMap_ID)\n",
    "print(removed)\n",
    "print('removed')\n",
    "removed = set(internal_cn) - set(segmentcn.DepMap_ID)\n",
    "print(removed)\n",
    "missing = set(internal) - set(segmentcn.DepMap_ID)\n",
    "blacklist = set(segmentcn.DepMap_ID) - (previnternal | set(internal))\n",
    "print('missing')\n",
    "print(missing)\n",
    "newlines = set(internal) \n",
    "print('blacklist')\n",
    "print(len(blacklist), blacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3231832\n",
      "3173701\n",
      "1803\n",
      "1787\n"
     ]
    }
   ],
   "source": [
    "## for segment removing first blacklisted, then embargoed, to create two datasets\n",
    "print(len(segmentcn))\n",
    "segmentcn = segmentcn[~segmentcn.DepMap_ID.isin(blacklist)]\n",
    "print(len(segmentcn))\n",
    "segmentcn.to_csv('temp/all_merged_segments.csv', index=False)\n",
    "print(len(genecn))\n",
    "genecn = genecn[~genecn.index.isin(blacklist)]\n",
    "print(len(genecn))\n",
    "genecn.to_csv('temp/all_merged_genes_cn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading all_merged_genes_cn...\n",
      "hitting https://cds.team/taiga/api/datafile/84479914f6db47ea8e273d7da5a76f96\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1750\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: all_merged_genes_cn properly converted and uploaded\n",
      "Uploading all_merged_segments...\n",
      "hitting https://cds.team/taiga/api/datafile/84479914f6db47ea8e273d7da5a76f96\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: all_merged_segments properly converted and uploaded\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 800b41429da649359f30c82e3b92feda created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/800b41429da649359f30c82e3b92feda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'800b41429da649359f30c82e3b92feda'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.update_dataset(dataset_permaname=\"depmap-wes-cn-data-81a7\", \n",
    "                  upload_file_path_dict={\n",
    "                    'temp/all_merged_genes_cn.csv': 'NumericMatrixCSV',\n",
    "                    'temp/all_merged_segments.csv': 'TableCSV'},\n",
    "                  dataset_description=\n",
    "\"\"\"\n",
    "# Copy Number\n",
    "\n",
    "\n",
    "## ** Version 1 Internal 18Q1****\n",
    "\n",
    "Generated with the following script:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='gene-level-cn-87aa', \n",
    "                                  data.version=5, \n",
    "                                  data.file='gene_CN_WES_priority')\n",
    "source_info <- data.frame(ccle_name=gsub(\"snp_|sangerWES_|ccleWES_|achillesWES_\", \n",
    "                                         \"\", row.names(wes_pri)), \n",
    "                          source=gsub(\"_.*\", \"\", row.names(wes_pri)))\n",
    "wes_pri %<>% magrittr::set_rownames(source_info$ccle_name)\n",
    "\n",
    "```\n",
    "\n",
    "## ** Version 2 Internal 18Q2****\n",
    "\n",
    "Generated with the following script:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='segmented-cn-wes-prioritzed-7fe1', data.version=9, data.file='wes_priority_cn_gene_matrix') %>% log2()\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "## ** Version 3 Internal 18Q2****\n",
    "\n",
    "Generated with the following script:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='segmented-cn-wes-prioritzed-7fe1', data.version=11, data.file='wes_priority_cn_gene_matrix') %>% log2()\n",
    "\n",
    "\n",
    "```\n",
    "## ** Version 4-6 Internal 18Q3****\n",
    "\n",
    "__Description__: log2 gene level copy number data\n",
    "\n",
    "Generated with the following script:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='segmented-cn-wes-prioritzed-7fe1', data.version=15, data.file='wes_priority_cn_gene_matrix') %>% log2()\n",
    "\n",
    "\n",
    "```\n",
    "__Rows__: Broad (arxspan) cell line IDs\n",
    "\n",
    "__Columns__: gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "\n",
    "Version 5 has updated cell line name mapping\n",
    "\n",
    "Version 4 and 5 the segment level CN for Sanger's data is off by a factor of 2, version 6 corrects this\n",
    "\n",
    "**** Version 7 Internal 18Q4****\n",
    "\n",
    "__Description__: log2 gene level copy number data\n",
    "\n",
    "Generated with the following script:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='segmented-cn-wes-prioritzed-7fe1', data.version=17, data.file='wes_priority_cn_gene_matrix') %>% log2()\n",
    "\n",
    "\n",
    "```\n",
    "__Rows__: DepMap (arxspan) cell line IDs\n",
    "\n",
    "__Columns__: gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "\n",
    "## ** Version 8-9 Internal 19Q1****\n",
    "\n",
    "version 9 has the correct data for 19Q1\n",
    "\n",
    "## ** Version 10-11 Internal 19Q2****\n",
    "\n",
    "__version 11 added an additional 13 cell lines and adds the segment level copy number data__\n",
    "\n",
    "## ** Version 12 Internal 19Q3****\n",
    "\n",
    "__Description__: log2(X + 1) gene level copy number data (data is now log2 transformed with a __pseudocount of 1__ added). CN data is generated using __hg38__. \n",
    "\n",
    "\n",
    "## ** Version 15 Internal 19Q4****\n",
    "\n",
    "Adding 35 new cell lines\n",
    "\n",
    "## ** Version 16 Internal 19Q4****\n",
    "resolving problem with not having log2 transform \n",
    "\n",
    "## ** Version 17 Internal 19Q4****\n",
    "resolving problem with having log2 transform on segments\n",
    "\n",
    "## ** Version 18 Internal 20Q1****\n",
    "adding 8 new cell lines\n",
    "\n",
    "## ** Version 19 Internal 20Q1****\n",
    "unlog2 transforming segmentcn\n",
    "\n",
    "## ** Version 20 Internal 20Q1****\n",
    "adding new cell lines\n",
    "\n",
    "## ** Version 21 Internal 20Q1****\n",
    "reparing some missing lines\n",
    "\n",
    "Some cells lines have been flagged as:\n",
    "\n",
    " - having bad looking copy ration plots = ACH-002511 (M140325) and ACH-001370 (OCIP5X)\n",
    " - having too many segments (format: sample seg_count) = ACH-001079 2586, ACH-000044 1202, ACH-000258 872, ACH-001230 947, ACH-000068 812, ACH-000454 1051, ACH-000216 925, ACH-001150 782, ACH-001214 889, ACH-002335 1312, ACH-000836 1001, ACH-001957 1426, ACH-000960 913, ACH-000458 762, ACH-000578 869, ACH-000327 819, ACH-000090 1024, ACH-000488 954, ACH-000848 1171, ACH-000923 1469, ACH-000904 868, ACH-000452 816, ACH-000600 939, ACH-001656 902, ACH-000854 899, ACH-000774 953, ACH-001000 980, ACH-000941 813, ACH-000887 1408, ACH-001017 1223, ACH-001171 792, ACH-001071 1175, ACH-000593 764, ACH-001239 851, ACH-000071 1287, ACH-001956 1368, ACH-000509 873, ACH-002204 1318, ACH-000550 974, ACH-000738 1064, ACH-000870 1557, ACH-001036 858, ACH-001043 825, ACH-000028 868, ACH-001955 1296, ACH-000419 826, ACH-001234 819, ACH-001094 1036, ACH-001225 792, ACH-000118 794, ACH-000300 1431, ACH-001113 1072, ACH-001045 822, ACH-000444 974, ACH-000901 816, ACH-000865 1358, ACH-000961 763, ACH-001249 1756, ACH-000167 838, ACH-001101 1005, ACH-000842 929, ACH-000837 1015, ACH-000710 968, ACH-000195 2029, ACH-000064 1203, ACH-000690 771, ACH-000635 1368, ACH-000356 1294, ACH-000659 1129, ACH-000868 1422, ACH-000128 767, ACH-000658 927, ACH-001088 1337\n",
    " - Genes having a similar CN value accross all: []\n",
    " \n",
    "## ** Version 20 Internal 20Q2****\n",
    "Added 7 samples.\n",
    "\n",
    "Some cells lines have been flagged as:\n",
    "\n",
    " - having bad looking copy ratio plots (appear to have too many segments): ACH-002399 (CDS-sukIAT, 21NT\\_1), ACH-002401 (CDS-tVy3GF, 21MT2\\_1), ACH-002400 (CDS-VUHMHG, 21MT1\\_1)\n",
    " - having too many segments (format: sample seg_count): same as for 20Q1\n",
    " - Genes having a similar CN value accross all samples: []\n",
    " \n",
    " \n",
    "## ** Version 21 Internal 20Q2****\n",
    " \n",
    "Duplicating the CN data in genecn and segmentcn for ACH-000219 so we have CN data for ACH-002874, the same cell line grown in different media. This step is required for Achilles / CERES.\n",
    "\n",
    "Version 22: removing two weird undefined lines \n",
    "\n",
    "## ** Version 23 Internal 20Q3****\n",
    "same  as  20Q2 for this release. no new lines\n",
    "\n",
    "## ** Version 24 Internal 20Q3****\n",
    "updating the blacklists\n",
    "\n",
    "## ** Version 25 Internal 20Q4****\n",
    "more cell lines, new full reprocessing, adding a new columns for amplification status, new way to create gene level cn\n",
    "\n",
    "## ** Version 26 Internal 20Q4****\n",
    "reparing issue with foldtransform\n",
    "\n",
    "## ** Version 27 Internal 20Q4****\n",
    "adding a missing line\n",
    "\n",
    "## ** Version 27 Internal 20Q4****\n",
    "reverting to logfold change\n",
    "\n",
    "Gene level CN data:\n",
    "\n",
    "__Rows__: DepMap cell line IDs\n",
    "\n",
    "__Columns__: gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "\n",
    "Segment level data:\n",
    "\n",
    "__Columns__: DepMap\\_ID, Chromosome, Start, End, Num\\_Probes, Segment\\_Mean\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "BLACKLIST:\n",
    "\"\"\"+str(blacklist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CCLE_gene_cn', 'depmap-wes-cn-data-81a7.30/all_merged_genes_cn'), ('CCLE_segment_cn', 'depmap-wes-cn-data-81a7.30/all_merged_segments')]\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datafile/716086914a0448beb961bb7413fe9358\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id af4deca77ed9440395842b1eee5b7505 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/af4deca77ed9440395842b1eee5b7505\n",
      "[('CCLE_gene_cn', 'depmap-wes-cn-data-81a7.30/all_merged_genes_cn'), ('CCLE_segment_cn', 'depmap-wes-cn-data-81a7.30/all_merged_segments')]\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datafile/3309fe8c82854d4ba6178296212c2653\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 31fb27e9822440938eb53c2d8552db74 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/31fb27e9822440938eb53c2d8552db74\n"
     ]
    }
   ],
   "source": [
    "# To add to a virtual dataset\n",
    "AddToVirtual(virtual_internal, 'depmap-wes-cn-data-81a7', [('CCLE_gene_cn', 'all_merged_genes_cn'),('CCLE_segment_cn','all_merged_segments')])\n",
    "# To add to a eternal dataset\n",
    "AddToVirtual('depmap-a0ab', 'depmap-wes-cn-data-81a7', [('CCLE_gene_cn', 'all_merged_genes_cn'),('CCLE_segment_cn', 'all_merged_segments')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing\n",
      "set()\n",
      "ibm_embargo\n",
      "2 {'ACH-001512', 'ACH-001708'}\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "print('missing')\n",
    "missing = set(ibm) - set(segmentcn.DepMap_ID)\n",
    "print(missing)\n",
    "print('ibm_embargo')\n",
    "ibm_embargo = set(segmentcn.DepMap_ID) - (prevdmc | set(ibm))\n",
    "print(len(ibm_embargo), ibm_embargo)\n",
    "newlines = set(ibm) \n",
    "print(len(newlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3173701\n",
      "0\n",
      "1787\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## for segment removing first blacklisted, then embargoed, to create two datasets\n",
    "print(len(segmentcn))\n",
    "a = segmentcn[~segmentcn.DepMap_ID.isin(ibm_embargo|prevdmc)]\n",
    "print(len(a))\n",
    "a.to_csv('temp/all_merged_segments.csv', index=False)\n",
    "print(len(genecn))\n",
    "b = genecn[~genecn.index.isin(ibm_embargo|prevdmc)]\n",
    "print(len(b))\n",
    "b.to_csv('temp/all_merged_genes_cn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading all_merged_genes_cn...\n",
      "hitting https://cds.team/taiga/api/datafile/c95080b2f41a438d8a4c089f5a3ca858\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'message'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-213-5f76a93f558e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mEMBARGOED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \"\"\"+str(ibm_embargo))\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/taigapy/__init__.py\u001b[0m in \u001b[0;36mupdate_dataset\u001b[0;34m(self, dataset_id, dataset_permaname, dataset_version, dataset_description, changes_description, upload_file_path_dict, add_taiga_ids, add_all_existing_files)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m         new_session_id = self.upload_session_files(\n\u001b[0;32m-> 1255\u001b[0;31m             \u001b[0mupload_file_path_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupload_file_path_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_taiga_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_taiga_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         )\n\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/taigapy/__init__.py\u001b[0m in \u001b[0;36mupload_session_files\u001b[0;34m(self, upload_file_path_dict, add_taiga_ids)\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 print(\n\u001b[1;32m   1076\u001b[0m                     \"\\n\\t While processing {}, we got this error {}\".format(\n\u001b[0;32m-> 1077\u001b[0;31m                         \u001b[0mupload_file_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1078\u001b[0m                     )\n\u001b[1;32m   1079\u001b[0m                 )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'message'"
     ]
    }
   ],
   "source": [
    "tc.update_dataset(dataset_permaname=\"cn-e20f\",\n",
    "                upload_file_path_dict={\n",
    "                    'temp/all_merged_genes_cn.csv':'NumericMatrixCSV',\n",
    "                    'temp/all_merged_segments.csv': 'TableCSV',\n",
    "                   },\n",
    "                  changes_description=\n",
    "\"\"\"\n",
    "\"\"\",\n",
    "                \n",
    "                  dataset_description=\"\"\"\n",
    "\n",
    "## Versions:\n",
    "\n",
    "V1: 20Q4\n",
    "new cell lines, new full reprocessing, adding a new columns for amplification status, new way to create gene level cn\n",
    "\n",
    "\n",
    "## Annotations:\n",
    "\n",
    "__Description__: log2(X + 1) gene level copy number data (data is now log2 transformed with a __pseudocount of 1__ added). CN data is generated using __hg38__.  The segment copy number data includes the mean segment copy number segments.\n",
    "\n",
    "Gene level CN data:\n",
    "\n",
    "__Rows__: DepMap cell line IDs\n",
    "\n",
    "__Columns__: gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "\n",
    "Segment level data:\n",
    "\n",
    "__Columns__: DepMap\\_ID, Chromosome, Start, End, Num\\_Probes, Segment\\_Mean\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "EMBARGOED:\n",
    "\"\"\"+str(ibm_embargo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('all_merged_genes_cn', 'cn-e20f.1/all_merged_genes_cn'), ('all_merged_segments', 'cn-e20f.1/all_merged_segments')]\n",
      "hitting https://cds.team/taiga/api/datafile/f5aba24ec71b4d139c9c4d359113d0ec\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Bad status code: 400",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-5f31be188dc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAddToVirtual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvirtual_ibm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cn-e20f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all_merged_genes_cn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'all_merged_genes_cn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all_merged_segments'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'all_merged_segments'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ccle_processing/src/CCLE_postp_function.py\u001b[0m in \u001b[0;36mAddToVirtual\u001b[0;34m(virtualname, folderfrom, files)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolderfrom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversiona\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m   \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_permaname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvirtualname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_taiga_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupload_file_path_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_all_existing_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/taigapy/__init__.py\u001b[0m in \u001b[0;36mupdate_dataset\u001b[0;34m(self, dataset_id, dataset_permaname, dataset_version, dataset_description, changes_description, upload_file_path_dict, add_taiga_ids, add_all_existing_files)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m         new_session_id = self.upload_session_files(\n\u001b[0;32m-> 1255\u001b[0;31m             \u001b[0mupload_file_path_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupload_file_path_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_taiga_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_taiga_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         )\n\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/taigapy/__init__.py\u001b[0m in \u001b[0;36mupload_session_files\u001b[0;34m(self, upload_file_path_dict, add_taiga_ids)\u001b[0m\n\u001b[1;32m   1021\u001b[0m             self.request_post(\n\u001b[1;32m   1022\u001b[0m                 \u001b[0mapi_endpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_datafile_api_endpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_create_upload_session_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m             )\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/taigapy/__init__.py\u001b[0m in \u001b[0;36mrequest_post\u001b[0;34m(self, api_endpoint, data, standard_reponse_handling)\u001b[0m\n\u001b[1;32m   1323\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bad status code: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Bad status code: 400"
     ]
    }
   ],
   "source": [
    "AddToVirtual(virtual_ibm, \"cn-e20f\", files=[('all_merged_genes_cn', 'all_merged_genes_cn'),('all_merged_segments', 'all_merged_segments'),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMC\n",
    "\n",
    "* **NOTE: change as of 20Q2 onwards**. We need to remove lines in WES_DMC_embargo from the Internal version of the CN datasets before we upload the `genecn` and `segmentcn` files to DMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing\n",
      "set()\n",
      "dmc_embargo\n",
      "2 {'ACH-001512', 'ACH-001708'}\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "print('missing')\n",
    "missing = set(dmc) - set(segmentcn.DepMap_ID)\n",
    "print(missing)\n",
    "print('dmc_embargo')\n",
    "dmc_embargo = set(segmentcn.DepMap_ID) - (prevdmc | set(dmc))\n",
    "print(len(dmc_embargo), dmc_embargo)\n",
    "newlines = set(dmc) \n",
    "print(len(newlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3173701\n",
      "3173256\n",
      "1787\n",
      "1785\n"
     ]
    }
   ],
   "source": [
    "## for segment removing first blacklisted, then embargoed, to create two datasets\n",
    "print(len(segmentcn))\n",
    "segmentcn = segmentcn[~segmentcn.DepMap_ID.isin(dmc_embargo)]\n",
    "print(len(segmentcn))\n",
    "segmentcn.to_csv('temp/all_merged_segments.csv', index=False)\n",
    "print(len(genecn))\n",
    "genecn = genecn[~genecn.index.isin(dmc_embargo)]\n",
    "print(len(genecn))\n",
    "genecn.to_csv('temp/all_merged_genes_cn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading all_merged_segments...\n",
      "hitting https://cds.team/taiga/api/datafile/0d6150560adb4d2c8e395efdd17ca2a9\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: all_merged_segments properly converted and uploaded\n",
      "Uploading all_merged_genes_cn...\n",
      "hitting https://cds.team/taiga/api/datafile/0d6150560adb4d2c8e395efdd17ca2a9\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1750\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: all_merged_genes_cn properly converted and uploaded\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 8707f9507f58402eb67ec4748ef85080 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/8707f9507f58402eb67ec4748ef85080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'8707f9507f58402eb67ec4748ef85080'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.update_dataset(dataset_permaname=\"depmap-cn-data-9b9d\",\n",
    "                upload_file_path_dict={\n",
    "                    'temp/all_merged_segments.csv':'TableCSV',\n",
    "                    'temp/all_merged_genes_cn.csv': 'NumericMatrixCSV',\n",
    "                   },\n",
    "                  changes_description=\n",
    "\"\"\"\n",
    "\"\"\",\n",
    "                \n",
    "                  dataset_description=\"\"\"\n",
    "                  \n",
    "## Versions:\n",
    "\n",
    "**** Version 1-2 DMC 19Q1****\n",
    "\n",
    "version 2 contains the correct data for 19Q1\n",
    "\n",
    "**** Version 3-4 DMC 19Q2****\n",
    "\n",
    "__version 4 added an additional 13 cell lines and adds the segment level copy number data__\n",
    "\n",
    "**** Version 5 DMC 19Q3***\n",
    "\n",
    "**** Version 7 DMC 19Q4***\n",
    "adding 35 new cell lines\n",
    "\n",
    "**** Version 8 DMC 19Q4****\n",
    "resolving problem with not having log2 transform \n",
    "\n",
    "**** Version 9 DMC 19Q4****\n",
    "resolving problem with having log2 transformed the segments\n",
    "\n",
    "**** Version 10 DMC 20Q1****\n",
    "adding new samples\n",
    "\n",
    "**** Version 11 DMC 20Q1****\n",
    "unlog2 transforming segmentcn\n",
    "\n",
    "**** Version 12 DMC 20Q2****\n",
    "Adding samples to be included in 20Q2\n",
    "\n",
    "**** Version 13 DMC 20Q2****\n",
    "unknown changes\n",
    "\n",
    "**** Version 14 DMC 20Q3****\n",
    "updated blacklists\n",
    "\n",
    "**** Version 15 DMC 20Q3****\n",
    "issues with blacklists\n",
    "\n",
    "**** Version 16 DMC 20Q4****\n",
    "new cell lines, new full reprocessing, adding a new columns for amplification status, new way to create gene level cn\n",
    "\n",
    "**** Version 17 DMC 20Q4****\n",
    "adding a missing line\n",
    "\n",
    "**** Version 17 DMC 20Q4****\n",
    "reverting log transform\n",
    "\n",
    "## Annotations\n",
    "\n",
    "__Description__: log2(X + 1) gene level copy number data (data is now log2 transformed with a __pseudocount of 1__ added). CN data is generated using __hg38__.  The segment copy number data includes the mean segment copy number segments.\n",
    "\n",
    "Gene level CN data:\n",
    "\n",
    "__Rows__: DepMap cell line IDs\n",
    "\n",
    "__Columns__: gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "\n",
    "Segment level data:\n",
    "\n",
    "__Columns__: DepMap\\_ID, Chromosome, Start, End, Num\\_Probes, Segment\\_Mean\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "EMBARGOED:\n",
    "\"\"\"+str(dmc_embargo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CCLE_gene_cn', 'depmap-cn-data-9b9d.19/all_merged_genes_cn'), ('CCLE_segment_cn', 'depmap-cn-data-9b9d.19/all_merged_segments')]\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datafile/f2f38a131464455696f5f575f6f39157\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id b9840b162f4945d89b5d2f9f0b0153b3 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/b9840b162f4945d89b5d2f9f0b0153b3\n"
     ]
    }
   ],
   "source": [
    "AddToVirtual(virtual_dmc, \"depmap-cn-data-9b9d\", files=[('CCLE_gene_cn', 'all_merged_genes_cn'),('CCLE_segment_cn', 'all_merged_segments')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public\n",
    "\n",
    "We add to public as internal minus dmc embargoed and only cell lines from previous previous release (6 month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing\n",
      "{'ACH-002709'}\n",
      "embargo\n",
      "32 {'ACH-001493', 'ACH-001970', 'ACH-001449', 'ACH-002401', 'ACH-002010', 'ACH-001502', 'ACH-001662', 'ACH-001669', 'ACH-001672', 'ACH-002465', 'ACH-001973', 'ACH-001693', 'ACH-001547', 'ACH-001293', 'ACH-001533', 'ACH-001971', 'ACH-001847', 'ACH-002014', 'ACH-001854', 'ACH-001349', 'ACH-001696', 'ACH-001437', 'ACH-002021', 'ACH-002048', 'ACH-001679', 'ACH-001678', 'ACH-001676', 'ACH-001537', 'ACH-001855', 'ACH-002512', 'ACH-001438', 'ACH-002400'}\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "print('missing')\n",
    "missing = set(public) - set(segmentcn.DepMap_ID)\n",
    "embargo = set(segmentcn.DepMap_ID) - (prevpublic | set(public))\n",
    "print(missing)\n",
    "newlines = set(public) \n",
    "print('embargo')\n",
    "print(len(embargo), embargo)\n",
    "print(len(newlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3173256\n",
      "3134184\n",
      "1787\n",
      "1755\n"
     ]
    }
   ],
   "source": [
    "print(len(segmentcn))\n",
    "a = segmentcn[~segmentcn.DepMap_ID.isin(set(embargo))]\n",
    "print(len(a))\n",
    "a.to_csv('temp/all_merged_segments.csv', index=False)\n",
    "print(len(genecn))\n",
    "b = genecn[~genecn.index.isin(set(embargo))]\n",
    "print(len(b))\n",
    "b.to_csv('temp/all_merged_genes_cn.csv',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading all_merged_genes_cn...\n",
      "hitting https://cds.team/taiga/api/datafile/29507b79b9fc4dda855a0afa67461297\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1750\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: all_merged_genes_cn properly converted and uploaded\n",
      "Uploading all_merged_segments...\n",
      "hitting https://cds.team/taiga/api/datafile/29507b79b9fc4dda855a0afa67461297\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: all_merged_segments properly converted and uploaded\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id deb6c8996f0d46419a4a1b9e574b16cb created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/deb6c8996f0d46419a4a1b9e574b16cb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'deb6c8996f0d46419a4a1b9e574b16cb'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.update_dataset(dataset_permaname='depmap-wes-cn-data-97cc',\n",
    "                    upload_file_path_dict={\n",
    "                    'temp/all_merged_genes_cn.csv':'NumericMatrixCSV',\n",
    "                    'temp/all_merged_segments.csv': 'TableCSV',\n",
    "                   },\n",
    "                  dataset_description=\"\"\"\n",
    "**** Versions 1-5 Public 18Q1****\n",
    "\n",
    "Gene-level WES copy-number data for publicly accessible CCLE data. \n",
    "\n",
    "```\n",
    "\n",
    "internal_lines <- readr::read_csv(\"~/Downloads/avana-broad-18q1_v2-sample-info.csv\")$cell_line\n",
    "public_lines <- readr::read_csv(\"~/Downloads/avana-public-tentative-18q1_v5-sample-info.csv\")$cell_line\n",
    "non_public_lines <- setdiff(internal_lines, public_lines)\n",
    "\n",
    "full_cn_set <- taigr::load.from.taiga(data.name='gene-level-cn-87aa', data.version=5, data.file='full_gene_CN')\n",
    "source_info <- data.frame(source=gsub(\"_.*\", \"\", row.names(full_cn_set)),\n",
    "                          ccle_name=gsub(\"snp_|achillesWES_|ccleWES_|sangerWES_\", \"\",\n",
    "                                         row.names(full_cn_set)),\n",
    "                          row_idx=1:nrow(full_cn_set))\n",
    "to_remove <- source_info %>%\n",
    "  dplyr::filter(ccle_name %in% non_public_lines,\n",
    "                source %in% c(\"ccleWES\", \"achillesWES\"))\n",
    "also_to_remove <- source_info %>%\n",
    "                    dplyr::filter(source == \"sangerWES\")\n",
    "indices_to_remove <- c(to_remove$row_idx, also_to_remove$row_idx) %>% unique()\n",
    "indices_to_keep <- source_info %>%\n",
    "  dplyr::filter(!(row_idx %in% indices_to_remove)) %>%\n",
    "  dplyr::group_by(ccle_name) %>%\n",
    "  dplyr::mutate(priority=ifelse(source == \"snp\", 4,\n",
    "                                ifelse(source == \"sangerWES\", 3,\n",
    "                                       ifelse(source == \"ccleWES\", 2, 1)))) %>%\n",
    "  dplyr::filter(priority == min(priority)) %>%\n",
    "  dplyr::ungroup()\n",
    "\n",
    "public_cn <- full_cn_set[indices_to_keep$row_idx,]\n",
    "source_info <- data.frame(source=gsub(\"_.*\", \"\", row.names(public_cn)),\n",
    "                          ccle_name=gsub(\"snp_|achillesWES_|ccleWES_|sangerWES_\", \"\",\n",
    "                                         row.names(public_cn)))\n",
    "public_cn %<>% magrittr::set_rownames(source_info$ccle_name)\n",
    "```\n",
    "\n",
    "CN data are on a log2 scale.\n",
    "\n",
    "`WES_source_info` tracks the source data for each cell line. Sources are `snp`, `achillesWES`, `ccleWES`, and `sangerWES`\n",
    "\n",
    "NOTE: Version 1 contained WES data from cell lines not available in the 18Q1 Public release. Versions 2-4 contained Sanger's WES CN data\n",
    "\n",
    "**** Version 6 Public 18Q2****\n",
    "\n",
    "Generated by running:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='segmented-cn-wes-prioritzed-7fe1', data.version=10, data.file='public_wes_priority_cn_gene_matrix') %>% log2()\n",
    "```\n",
    "\n",
    "**** Version 7 Public 18Q2****\n",
    "\n",
    "Generated by running:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='segmented-cn-wes-prioritzed-7fe1', data.version=11, data.file='public_wes_priority_cn_gene_matrix') %>% log2()\n",
    "```\n",
    "\n",
    "\n",
    "**** Version 8-9 Public 18Q3****\n",
    "\n",
    "Generated by running:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='segmented-cn-wes-prioritzed-7fe1', data.version=15, data.file='public_wes_priority_cn_gene_matrix') %>% log2()\n",
    "```\n",
    "Version 8 the segment level CN for Sanger's data is off by a factor of 2, version 9 corrects this\n",
    "\n",
    "includes cell lines that should not be public\n",
    "\n",
    "**** Version 10 Public 18Q1, 18Q2, 18Q3****\n",
    "\n",
    "__use version 10 for 18Q1, 18Q2 and 18Q3 datasets__ \n",
    "\n",
    "Version 10 is the most up-to-date version of \"public\\_18Q3\\_gene\\_cn.csv\". The three datasets have been updated to remove cell lines that should not have been made public. They are named in the portal and google bucket for portal downloads as v2, e.g. public\\_18Q3\\_gene\\_cn\\_v2.csv.\n",
    "\n",
    "__Rows__: Broad (arxspan) cell line IDs\n",
    "\n",
    "__Columns__: gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "\n",
    "**** Version 11 Public 18Q4****\n",
    "\n",
    "Generated by running:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='segmented-cn-wes-prioritzed-7fe1', data.version=17, data.file='public_wes_priority_cn_gene_matrix') %>% log2()\n",
    "```\n",
    "\n",
    "__Rows__: DepMap (arxspan) cell line IDs\n",
    "\n",
    "__Columns__: gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "\n",
    "**** Version 12-14 Public 19Q1****\n",
    "\n",
    "version 14 contains the correct data for 19Q1\n",
    "\n",
    "version 13 is the same as v12 except that it uses the original hg19 coordinates not hg38. The Achilles public data set uses the hg19 coordinates. \n",
    "\n",
    "**** Version 15-16 Public 19Q2****\n",
    "\n",
    "__version 16 also adds the segment level copy number data__\n",
    "\n",
    "**** Version 17-18 Public 19Q3****\n",
    "\n",
    "\n",
    "**** Version 23 Public 19Q4****\n",
    "adding new cell lines\n",
    "\n",
    "**** Version 24 Public 19Q4****\n",
    "resolving problem with not having log2 transform \n",
    "\n",
    "**** Version 25 Public 19Q4****\n",
    "another issue in log transform\n",
    "\n",
    "**** Version 26 Public 19Q4****\n",
    "unlog2 transforming segmentcn FINAL\n",
    "\n",
    "**** Version 27 Public 20Q1****\n",
    "adding new samples\n",
    "\n",
    "**** Version 28 Public 20Q1****\n",
    "log 2 transform issues\n",
    "\n",
    "**** Version 29 Public 20Q1****\n",
    "readding one missing column in segments\n",
    "\n",
    "**** Version 30 Public 20Q2****\n",
    "Adding new samples\n",
    "\n",
    "**** Version 31 Public 20Q2****\n",
    "unknown changes\n",
    "\n",
    "**** Version 32 Public 20Q3****\n",
    "same  as  20Q2 for this release. no new lines\n",
    "\n",
    "**** Version 33 Public 20Q3****\n",
    "updated blacklist\n",
    "\n",
    "**** Version 34 Public 20Q3****\n",
    "updated dmc list\n",
    "\n",
    "**** Version 35 Public 20Q4****\n",
    "new cell lines, new full reprocessing, adding a new columns for amplification status, new way to create gene level cn\n",
    "\n",
    "**** Version 36 Public 20Q4****\n",
    "reverting to logtransform\n",
    "\n",
    "**** Version 37 Public 20Q4****\n",
    "removing lines\n",
    "\n",
    "## Gene level CN data:\n",
    "\n",
    "__data is hg38 liftover__\n",
    "\n",
    "__Description__: log2 + 1 gene level copy number data (data is log2 transformed with a __pseudocount of 1__ added). It uses hg19 coordinates. Also the segment level copy number data.\n",
    "\n",
    "__Rows__: DepMap cell line IDs\n",
    "\n",
    "__Columns__: gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "\n",
    "Segment level data:\n",
    "\n",
    "__Columns__: DepMap\\_ID, Chromosome, Start, End, Num\\_Probes, Segment\\_Mean, CCLE\\_name\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "EMBARGOED:\n",
    "\"\"\"+str(embargo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting objects: 76, done.\n",
      "Delta compression using up to 12 threads.\n",
      "Compressing objects: 100% (76/76), done.\n",
      "Writing objects: 100% (76/76), 6.69 MiB | 1.53 MiB/s, done.\n",
      "Total 76 (delta 57), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (57/57), completed with 9 local objects.\u001b[K\n",
      "remote: warning: File WGS_CCLE.ipynb is 53.08 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n",
      "remote: error: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.\u001b[K\n",
      "remote: error: Trace: 5938e8fa34910bcbf615473a02ae2b5b0ef97f74049e9de0a1416d0696f03b17\u001b[K\n",
      "remote: error: See http://git.io/iEPt8g for more information.\u001b[K\n",
      "remote: error: File 20Q4.csv is 178.93 MB; this exceeds GitHub's file size limit of 100.00 MB\u001b[K\n",
      "To https://github.com/broadinstitute/ccle_processing.git\n",
      " ! [remote rejected] master -> master (pre-receive hook declined)\n",
      "error: failed to push some refs to 'https://github.com/broadinstitute/ccle_processing.git'\n"
     ]
    }
   ],
   "source": [
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CCLE_gene_cn', 'depmap-wes-cn-data-97cc.38/all_merged_genes_cn'), ('CCLE_segment_cn', 'depmap-wes-cn-data-97cc.38/all_merged_segments')]\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datafile/d5c6453657944089b45c08320012f809\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id d89ee145def541ab8298ded4ee29e4aa created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/d89ee145def541ab8298ded4ee29e4aa\n"
     ]
    }
   ],
   "source": [
    "# To add to a virtual dataset\n",
    "AddToVirtual(virtual_public, \"depmap-wes-cn-data-97cc\", files=[('CCLE_gene_cn', 'all_merged_genes_cn'),('CCLE_segment_cn', 'all_merged_segments')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_tpm = pd.read_csv('temp/expression_' + release + '_transcripts_tpm.csv',index_col=0)\n",
    "genes_tpm = pd.read_csv('temp/expression_' + release + '_genes_tpm.csv',index_col=0)\n",
    "genes_expected_count = pd.read_csv('temp/expression_' + release + '_genes_expected_count.csv',index_col=0)\n",
    "proteincoding_genes_expected_count = pd.read_csv('temp/expression_' + release + '_proteincoding_genes_expected_count.csv',index_col=0)\n",
    "proteincoding_genes_tpm = pd.read_csv('temp/expression_' + release + '_proteincoding_genes_tpm.csv',index_col=0)\n",
    "transcripts_expected_count = pd.read_csv('temp/expression_' + release + '_transcripts_expected_count.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteincoding_genes_expected_count = proteincoding_genes_expected_count[[i for i in proteincoding_genes_expected_count.columns if ' (' in i]]\n",
    "proteincoding_genes_tpm = proteincoding_genes_tpm[[i for i in proteincoding_genes_tpm.columns if ' (' in i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "store -r rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not present\n",
      "{'ACH-002196', 'ACH-002205', 'ACH-002289', 'ACH-001064', 'ACH-001641', 'ACH-002127', 'ACH-002344', 'ACH-002384', 'ACH-002383', 'ACH-002157', 'ACH-001037', 'ACH-001143', 'ACH-002216', 'ACH-001680', 'ACH-000727', 'ACH-002351', 'ACH-002207', 'ACH-002114', 'ACH-002300', 'ACH-000795', 'ACH-002377', 'ACH-002204', 'ACH-002360', 'ACH-002292', 'ACH-002058', 'ACH-002104', 'ACH-002314', 'ACH-002183', 'ACH-002213', 'ACH-002168', 'ACH-002382', 'ACH-002260', 'ACH-001208', 'ACH-002095', 'ACH-002200', 'ACH-002269', 'ACH-002387', 'ACH-002375', 'ACH-002129', 'ACH-001199', 'ACH-002312', 'ACH-002282', 'ACH-002395', 'ACH-001338', 'ACH-002232', 'ACH-002267', 'ACH-002190', 'ACH-001502', 'ACH-001093', 'ACH-002336', 'ACH-002281', 'ACH-001137', 'ACH-002199', 'ACH-002208', 'ACH-002185', 'ACH-002276', 'ACH-002374', 'ACH-002396', 'ACH-001383', 'ACH-002237', 'ACH-002119', 'ACH-002136', 'ACH-002359', 'ACH-001182', 'ACH-002399', 'ACH-002106', 'ACH-001187', 'ACH-002394', 'ACH-002180', 'ACH-001045', 'ACH-002291', 'ACH-002230', 'ACH-002193', 'ACH-001089', 'ACH-001331', 'ACH-002401', 'ACH-002147', 'ACH-002242', 'ACH-002361', 'ACH-001205', 'ACH-002201', 'ACH-002191', 'ACH-002143', 'ACH-001203', 'ACH-002290', 'ACH-002188', 'ACH-001018', 'ACH-002294', 'ACH-002247', 'ACH-002167', 'ACH-002391', 'ACH-001125', 'ACH-001591', 'ACH-001118', 'ACH-002159', 'ACH-002197', 'ACH-002253', 'ACH-002102', 'ACH-001023', 'ACH-002238', 'ACH-002182', 'ACH-002198', 'ACH-002175', 'ACH-001599', 'ACH-002250', 'ACH-002284', 'ACH-002091', 'ACH-001233', 'ACH-002299', 'ACH-001092', 'ACH-002369', 'ACH-002123', 'ACH-002305', 'ACH-002141', 'ACH-001767', 'ACH-002341', 'ACH-002350', 'ACH-001011', 'ACH-002296', 'ACH-002169', 'ACH-001101', 'ACH-002128', 'ACH-002235', 'ACH-002093', 'ACH-002367', 'ACH-001225', 'ACH-001127', 'ACH-002125', 'ACH-002225', 'ACH-002297', 'ACH-002224', 'ACH-002315', 'ACH-001044', 'ACH-002266', 'ACH-002400', 'ACH-001350', 'ACH-002380', 'ACH-002231', 'ACH-002096', 'ACH-002274', 'ACH-002379', 'ACH-002135', 'ACH-002043', 'ACH-001042', 'ACH-002275', 'ACH-001072', 'ACH-002146', 'ACH-002302', 'ACH-001065', 'ACH-002392', 'ACH-002277', 'ACH-002152', 'ACH-002217', 'ACH-002113', 'ACH-002288', 'ACH-002378', 'ACH-002099', 'ACH-001364', 'ACH-002163', 'ACH-002293', 'ACH-002246', 'ACH-002124', 'ACH-002372', 'ACH-002174', 'ACH-002243', 'ACH-002162', 'ACH-002342', 'ACH-002339', 'ACH-002210', 'ACH-001189', 'ACH-002212', 'ACH-001091', 'ACH-001066', 'ACH-001214', 'ACH-002256', 'ACH-002121', 'ACH-002228', 'ACH-002221', 'ACH-002134', 'ACH-002280', 'ACH-002349', 'ACH-002255', 'ACH-002337', 'ACH-002287', 'ACH-002132', 'ACH-002283', 'ACH-000426', 'ACH-001094', 'ACH-002209', 'ACH-001150', 'ACH-001000', 'ACH-002107', 'ACH-002089', 'ACH-001017', 'ACH-001224', 'ACH-002279', 'ACH-002270', 'ACH-002273', 'ACH-002112', 'ACH-001108', 'ACH-000992', 'ACH-002229', 'ACH-002150', 'ACH-001490', 'ACH-002338', 'ACH-002186', 'ACH-002239', 'ACH-002202', 'ACH-002097', 'ACH-002286', 'ACH-002272', 'ACH-001206', 'ACH-001738', 'ACH-002397', 'ACH-002131', 'ACH-001087', 'ACH-002304', 'ACH-001071', 'ACH-002365', 'ACH-001021', 'ACH-001230', 'ACH-002108', 'ACH-001363', 'ACH-001136', 'ACH-002259', 'ACH-002051', 'ACH-002101', 'ACH-002153', 'ACH-002020', 'ACH-002301', 'ACH-001131', 'ACH-000309', 'ACH-000979', 'ACH-002120', 'ACH-002346', 'ACH-002358', 'ACH-001126', 'ACH-001039', 'ACH-002393', 'ACH-001452', 'ACH-002262', 'ACH-002040', 'ACH-002189', 'ACH-002268', 'ACH-002094', 'ACH-002381', 'ACH-002092', 'ACH-002241', 'ACH-002370', 'ACH-002165', 'ACH-002144', 'ACH-002245', 'ACH-002187', 'ACH-002285', 'ACH-002116', 'ACH-001171', 'ACH-001958', 'ACH-002356', 'ACH-002130', 'ACH-002233', 'ACH-002376', 'ACH-002364', 'ACH-002098', 'ACH-001146', 'ACH-002264', 'ACH-002178', 'ACH-002171', 'ACH-001512', 'ACH-001606', 'ACH-001234', 'ACH-001002', 'ACH-002149', 'ACH-002308', 'ACH-002122', 'ACH-002220', 'ACH-002317', 'ACH-001049', 'ACH-002316', 'ACH-002252', 'ACH-002118', 'ACH-002140', 'ACH-001198', 'ACH-002109', 'ACH-002126', 'ACH-002340', 'ACH-001090', 'ACH-001015', 'ACH-001121', 'ACH-001957', 'ACH-002306', 'ACH-001079', 'ACH-002160', 'ACH-002148', 'ACH-001047', 'ACH-002353', 'ACH-002311', 'ACH-001358', 'ACH-002257', 'ACH-002313', 'ACH-001293', 'ACH-001417', 'ACH-001081', 'ACH-001359', 'ACH-002117', 'ACH-002388', 'ACH-001955', 'ACH-002166', 'ACH-002192', 'ACH-002386', 'ACH-002145', 'ACH-002184', 'ACH-002348', 'ACH-002176', 'ACH-002310', 'ACH-002362', 'ACH-002347', 'ACH-001639', 'ACH-001704', 'ACH-002248', 'ACH-001024', 'ACH-002278', 'ACH-002139', 'ACH-002254', 'ACH-002249', 'ACH-002103', 'ACH-002105', 'ACH-002240', 'ACH-002155', 'ACH-001130', 'ACH-002389', 'ACH-002223', 'ACH-001175', 'ACH-002181', 'ACH-002307', 'ACH-002390', 'ACH-002100', 'ACH-002211', 'ACH-000047', 'ACH-001489', 'ACH-002354', 'ACH-002357', 'ACH-002335', 'ACH-002709', 'ACH-002343', 'ACH-001162', 'ACH-001088', 'ACH-002298', 'ACH-002214', 'ACH-002265', 'ACH-002194', 'ACH-002111', 'ACH-001355', 'ACH-001362', 'ACH-002215', 'ACH-002206', 'ACH-002371', 'ACH-002352', 'ACH-002156', 'ACH-002177', 'ACH-002355', 'ACH-002234', 'ACH-002244', 'ACH-001249', 'ACH-001063', 'ACH-001107', 'ACH-002345', 'ACH-002251', 'ACH-002090', 'ACH-002368', 'ACH-001365', 'ACH-002236', 'ACH-002052', 'ACH-002303', 'ACH-002173', 'ACH-001544', 'ACH-002170', 'ACH-002195', 'ACH-001138', 'ACH-002366', 'ACH-002133', 'ACH-002110', 'ACH-002222', 'ACH-002295', 'ACH-002271', 'ACH-002363', 'ACH-002154', 'ACH-001043', 'ACH-002115', 'ACH-002226', 'ACH-002142', 'ACH-001956', 'ACH-002309', 'ACH-001188', 'ACH-002083', 'ACH-002261', 'ACH-002161', 'ACH-002179', 'ACH-002263', 'ACH-002258', 'ACH-002227', 'ACH-002164', 'ACH-002218', 'ACH-002373', 'ACH-001282', 'ACH-002151', 'ACH-002077'}\n",
      "removed for QC reasons\n",
      "{'ACH-000992', 'ACH-001293', 'ACH-002709', 'ACH-001502', 'ACH-001143', 'ACH-000309', 'ACH-001205', 'ACH-000979', 'ACH-000426', 'ACH-000047', 'ACH-001512', 'ACH-000795', 'ACH-000727'}\n",
      "removed\n",
      "set()\n",
      "missing\n",
      "set()\n",
      "blacklist\n",
      "11 {'ACH-001756', 'ACH-002055', 'ACH-001760', 'ACH-002476', 'ACH-001227', 'ACH-001686', 'ACH-001046', 'ACH-001758', 'ACH-001759', 'ACH-001434', 'ACH-002047'}\n"
     ]
    }
   ],
   "source": [
    "print('not present')\n",
    "removed = set(previnternal) - set(genes_tpm.index)\n",
    "print(removed)\n",
    "print('removed for QC reasons')\n",
    "print(set(rename.keys()))\n",
    "print('removed')\n",
    "removed = set(internal_rna) - set(genes_tpm.index)\n",
    "print(removed - set(rename.keys()))\n",
    "missing = set(internal) - set(genes_tpm.index)\n",
    "blacklist = set(genes_tpm.index) - (previnternal | set(internal))\n",
    "print('missing')\n",
    "print(missing)\n",
    "newlines = set(internal) \n",
    "print('blacklist')\n",
    "print(len(blacklist), blacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_tpm=transcripts_tpm.apply(lambda x: np.log2(x+1))\n",
    "genes_tpm=genes_tpm.apply(lambda x: np.log2(x+1))\n",
    "genes_expected_count=genes_expected_count.apply(lambda x: np.log2(x+1))\n",
    "proteincoding_genes_expected_count=proteincoding_genes_expected_count.apply(lambda x: np.log2(x+1))\n",
    "proteincoding_genes_tpm=proteincoding_genes_tpm.apply(lambda x: np.log2(x+1))\n",
    "transcripts_expected_count=transcripts_expected_count.apply(lambda x: np.log2(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1418\n",
      "1407\n",
      "1418\n",
      "1407\n",
      "1418\n",
      "1407\n",
      "1418\n",
      "1407\n",
      "1417\n",
      "1406\n",
      "1417\n",
      "1406\n"
     ]
    }
   ],
   "source": [
    "## removing first blacklisted, then embargoed, to create two datasets\n",
    "print(len(genes_expected_count))\n",
    "genes_expected_count = genes_expected_count[~genes_expected_count.index.isin(blacklist)]\n",
    "print(len(genes_expected_count))\n",
    "genes_expected_count.to_csv('temp/expression_genes_expected_count.csv')\n",
    "print(len(genes_tpm))\n",
    "genes_tpm = genes_tpm[~genes_tpm.index.isin(blacklist)]\n",
    "print(len(genes_tpm))\n",
    "genes_tpm.to_csv('temp/expression_genes_tpm.csv')\n",
    "print(len(proteincoding_genes_tpm))\n",
    "proteincoding_genes_tpm = proteincoding_genes_tpm[~proteincoding_genes_tpm.index.isin(blacklist)]\n",
    "print(len(proteincoding_genes_tpm))\n",
    "proteincoding_genes_tpm.to_csv('temp/expression_proteincoding_genes_tpm.csv')\n",
    "print(len(transcripts_tpm))\n",
    "transcripts_tpm = transcripts_tpm[~transcripts_tpm.index.isin(blacklist)]\n",
    "print(len(transcripts_tpm))\n",
    "transcripts_tpm.to_csv('temp/expression_transcripts_tpm.csv')\n",
    "print(len(proteincoding_genes_expected_count))\n",
    "proteincoding_genes_expected_count = proteincoding_genes_expected_count[~proteincoding_genes_expected_count.index.isin(blacklist)]\n",
    "print(len(proteincoding_genes_expected_count))\n",
    "proteincoding_genes_expected_count.to_csv('temp/expression_proteincoding_genes_expected_count.csv')\n",
    "print(len(transcripts_expected_count))\n",
    "transcripts_expected_count = transcripts_expected_count[~transcripts_expected_count.index.isin(blacklist)]\n",
    "print(len(transcripts_expected_count))\n",
    "transcripts_expected_count.to_csv('temp/expression_transcripts_expected_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading expression_genes_expected_count...\n",
      "hitting https://cds.team/taiga/api/datafile/ea1cd7fbce31449092a43af9f71bd262\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_genes_expected_count properly converted and uploaded\n",
      "Uploading expression_transcripts_tpm...\n",
      "hitting https://cds.team/taiga/api/datafile/ea1cd7fbce31449092a43af9f71bd262\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_transcripts_tpm properly converted and uploaded\n",
      "Uploading expression_genes_tpm...\n",
      "hitting https://cds.team/taiga/api/datafile/ea1cd7fbce31449092a43af9f71bd262\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_genes_tpm properly converted and uploaded\n",
      "Uploading expression_proteincoding_genes_tpm...\n",
      "hitting https://cds.team/taiga/api/datafile/ea1cd7fbce31449092a43af9f71bd262\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_proteincoding_genes_tpm properly converted and uploaded\n",
      "Uploading expression_proteincoding_genes_expected_count...\n",
      "hitting https://cds.team/taiga/api/datafile/ea1cd7fbce31449092a43af9f71bd262\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_proteincoding_genes_expected_count properly converted and uploaded\n",
      "Uploading expression_transcripts_expected_count...\n",
      "hitting https://cds.team/taiga/api/datafile/ea1cd7fbce31449092a43af9f71bd262\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_transcripts_expected_count properly converted and uploaded\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id fa49f001e31142bb9cd9bbff1e0868de created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/fa49f001e31142bb9cd9bbff1e0868de\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fa49f001e31142bb9cd9bbff1e0868de'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.update_dataset(dataset_permaname=\"depmap-rnaseq-expression-data-363a\",\n",
    "                 upload_file_path_dict={\n",
    "                   'temp/expression_genes_expected_count.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_transcripts_tpm.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_genes_tpm.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_proteincoding_genes_tpm.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_proteincoding_genes_expected_count.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_transcripts_expected_count.csv': 'NumericMatrixCSV'},\n",
    "                  dataset_description=\n",
    "\"\"\"\n",
    "# INTERNAL RNA\n",
    "\n",
    "* Version 1-3 Internal 18Q1*\n",
    "\n",
    "All CCLE cell lines with RNAseq data.\n",
    "\n",
    "Original data source:\n",
    "\n",
    "`/xchip/ccle_dist/broad_only/CMAG/expression/CCLE_depMap_18Q1_RNAseq_reads_20180201.gct`\n",
    "`/xchip/ccle_dist/broad_only/CMAG/expression/CCLE_depMap_18Q1_RNAseq_RPKM_20180201.gct`\n",
    "\n",
    "Version 2 of RPKM data are log2-transformed with a noisy floor at -3 (-3 + N(0, 0.1))\n",
    "\n",
    "* Version 4-6 Internal 18Q2*\n",
    "\n",
    "Original data source:\n",
    "\n",
    "`/xchip/ccle_dist/broad_only/CMAG/expression/CCLE_depMap_18q2_RNAseq_reads_20180420.gct` `/xchip/ccle_dist/broad_only/CMAG/expression/CCLE_depMap_18q2_RNAseq_RPKM_20180420.gct`\n",
    "\n",
    "RPKM data are log2-transformed with a noisy floor at -3 (-3 + N(0, 0.1)). Reads file unaltered aside from formatting row / column names.\n",
    "\n",
    "* Version 7 Internal 18Q2*\n",
    "\n",
    "Includes a matrix with genes filtered by HGNC protein-coding gene locus group.\n",
    "\n",
    "* Version 8-10 Internal 18Q3*\n",
    "\n",
    "use version 10\n",
    "\n",
    "Original data source:\n",
    "\n",
    "`/xchip/ccle_dist/broad_only/CMAG/expression/CCLE_depMap_18q3_RNAseq_reads_20180716.gct` `/xchip/ccle_dist/broad_only/CMAG/expression/CCLE_depMap_18q3_RNAseq_RPKM_20180716.gct`\n",
    "\n",
    "RPKM data are log2-transformed with a noisy floor at -3 (-3 + N(0, 0.1)). Reads file unaltered aside from formatting row / column names.\n",
    "\n",
    "The ProteinCoding datasets contain just protein coding genes and are based on protein coding annotations from https://www.genenames.org/cgi-bin/download (locus_group == \"protein-coding gene\")\n",
    "\n",
    "Rows: are Broad (Arxspan) cell line IDs.\n",
    "\n",
    "Columns: In the complete RPKM and read datasets column names are HGNC_symbol (Ensembl_ID), while in the ProteinCoding RPKM and read datasets column names are HGNC_symbol (Entrez_ID)\n",
    "\n",
    "version 9 updates names, and slightly different RPKM values due to randomly added noisy floor (using a seed of 4)\n",
    "\n",
    "version 10 removes duplicate gene names from the protein coding datasets\n",
    "\n",
    "* Version 11-12 Internal 18Q4*\n",
    "\n",
    "18Q4 transcript level data is found in version 14. (In versions 1-13 transcript data contains only gene level not transcript level data)\n",
    "\n",
    "changing to TPM expression\n",
    "\n",
    "Original data source:\n",
    "\n",
    "`/xchip/ccle_dist/broad_only/CMAG/expression/CCLE_DepMap_18Q4_rsem_genes_tpm_20181029.txt` `/xchip/ccle_dist/broad_only/CMAG/expression/CCLE_DepMap_18Q4_rsem_transcripts_tpm_20181029.gct` `/xchip/ccle_dist/broad_only/CMAG/expression/CCLE_DepMap_18Q4_RNAseq_reads_20181029.gct` `/xchip/ccle_dist/broad_only/CMAG/expression/CCLE_DepMap_18Q4_RNAseq_RPKM_20181029.gct`\n",
    "\n",
    "TPM data is the primary expression data now. It is log2-transformed with a pseudo count of 1 added. The TPM data contains 4 cell lines not included in the RPKM data.\n",
    "\n",
    "RPKM data are log2-transformed with a pseudo count of 1 added. RPKM values are no longer thresholded.\n",
    "\n",
    "Reads/transcript files unaltered aside from formatting row / column names.\n",
    "\n",
    "The ProteinCoding datasets contain just protein coding genes and are based on protein coding annotations from https://www.genenames.org/cgi-bin/download (locus_group == \"protein-coding gene\")\n",
    "\n",
    "Rows: are DepMap (Arxspan) cell line IDs\n",
    "\n",
    "Columns: In the complete TPM, TPM transcripts, RPKM and read datasets column names are HGNC_symbol (Ensembl_ID), while in the ProteinCoding TPM dataset column names are HGNC_symbol (Entrez_ID)\n",
    "\n",
    "* Version 13-15 Internal 19Q1*\n",
    "\n",
    "Version 15 contains the correct data sets for 19Q1 - 2 cell lines are removed\n",
    "\n",
    "Version 14 contains the correct transcript level data for 18Q4\n",
    "\n",
    "* Version 16 Internal 19Q2*\n",
    "\n",
    "* Version 17 Internal 19Q3*\n",
    "\n",
    "* Version 18 Internal 19Q4*\n",
    "\n",
    "Adding 93 new cell lines - Blacklisted\n",
    "Some cells lines have been removed because they:\n",
    "\n",
    " - had too many 0 values = [\"ACH-001388\" \"ACH-001577\" \"ACH-001767\" \"ACH-002463\"] \n",
    "\n",
    "Some cells lines have been flagged as:\n",
    "\n",
    " - None\n",
    "* Version 19 Internal 19Q4\n",
    "removing blacklisted\n",
    "\n",
    "* Version 20 Internal 19Q4\n",
    "removing blacklisted in transcripts\n",
    "\n",
    "* Version 21 Internal 19Q4\n",
    "uploading as matrices \n",
    "\n",
    "* Version 22 Internal 20Q1\n",
    "adding 6 new cell lines\n",
    "\n",
    "* Version 23 Internal 20Q2\n",
    "adding  new cell lines\n",
    "\n",
    "* Version 24 Internal 20Q2\n",
    "adding  back ACH-000052\n",
    "\n",
    "* Version 25 Internal 20Q3\n",
    "nothing different from  20Q2. no new cell lines added\n",
    "\n",
    "* Version 26 Internal 20Q3\n",
    "some lines were wrongly added to the blacklist\n",
    "\n",
    "* Version 27 Internal 20Q4\n",
    "new samples, adding a new QC method that removed 10 samples. fully adding the reprocessed samples, removing some wrong genes, adding falsely removed genes (that are still expressed)\n",
    "\n",
    "* Version 28 Internal 20Q4\n",
    "revertig log transform\n",
    "\n",
    "* Version 29 Internal 20Q4\n",
    "reverting gene names\n",
    "\n",
    "data is aligned to hg38\n",
    "\n",
    "read count data is created using RSEM, which, when a read maps to multiple places, splits the counts between genes, with the weight based on the likelihood that it came from one gene or the other, so counts data may not be integers\n",
    "\n",
    "TPM data is log2-transformed with a pseudo count of 1 added. log2(X+1)\n",
    "\n",
    "Reads/transcript files unaltered aside from formatting row / column names.\n",
    "\n",
    "The ProteinCoding datasets contain just protein coding genes and are based on protein coding annotations from https://www.genenames.org/cgi-bin/download (locus_group == \"protein-coding gene\")\n",
    "\n",
    "Rows: are DepMap cell line IDs Mapping between Broad IDs and CCLE IDs can be done using a R or python package\n",
    "\n",
    "To install R implementation: options(repos = c(\"https://iwww.broadinstitute.org/~datasci/R-packages\", \"https://cran.cnr.berkeley.edu\")) install.packages('celllinemapr')\n",
    "\n",
    "To install python implementation: pip install https://intranet.broadinstitute.org/~datasci/python-packages/cell_line_mapper-0.1.9.tar.gz)\n",
    "\n",
    "Columns: In the complete TPM and read counts datasets column names are HGNC_symbol (Ensembl_ID), while in the ProteinCoding TPM dataset column names are HGNC_symbol (Entrez_ID). In the TPM transcript dataset column names are HGNC_symbol (Transcript_ID) - the HGNC symbols are not unique, use the transcript IDs for unique identifiers.\n",
    "\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "REMOVED FOR QC REASONS:\n",
    "\"\"\"+str(rename)+\"\"\"\n",
    "\n",
    "BLACKLIST:\n",
    "\"\"\"+str(blacklist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CCLE_expression_full', 'depmap-rnaseq-expression-data-363a.30/expression_genes_expected_count'), ('CCLE_RNAseq_transcripts', 'depmap-rnaseq-expression-data-363a.30/expression_transcripts_tpm'), ('CCLE_RNAseq_reads', 'depmap-rnaseq-expression-data-363a.30/expression_genes_tpm'), ('CCLE_expression', 'depmap-rnaseq-expression-data-363a.30/expression_proteincoding_genes_tpm'), ('expression_proteincoding_genes_expected_count', 'depmap-rnaseq-expression-data-363a.30/expression_proteincoding_genes_expected_count'), ('expression_transcripts_expected_count', 'depmap-rnaseq-expression-data-363a.30/expression_transcripts_expected_count')]\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datafile/8b3bdc4cdbdc47abb6512719b440cc0a\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id dea3476c0b5947168a54fba3344020df created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/dea3476c0b5947168a54fba3344020df\n",
      "[('CCLE_expression_full', 'depmap-rnaseq-expression-data-363a.30/expression_genes_expected_count'), ('CCLE_RNAseq_transcripts', 'depmap-rnaseq-expression-data-363a.30/expression_transcripts_tpm'), ('CCLE_RNAseq_reads', 'depmap-rnaseq-expression-data-363a.30/expression_genes_tpm'), ('CCLE_expression', 'depmap-rnaseq-expression-data-363a.30/expression_proteincoding_genes_tpm'), ('expression_proteincoding_genes_expected_count', 'depmap-rnaseq-expression-data-363a.30/expression_proteincoding_genes_expected_count'), ('expression_transcripts_expected_count', 'depmap-rnaseq-expression-data-363a.30/expression_transcripts_expected_count')]\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datafile/18928658694c47f19f4b0e5540c3ca03\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 2e2b44672a5b4924aab28ebd8f5fb29f created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/2e2b44672a5b4924aab28ebd8f5fb29f\n"
     ]
    }
   ],
   "source": [
    "AddToVirtual('depmap-a0ab', \"depmap-rnaseq-expression-data-363a\", files=[\n",
    "('CCLE_expression_full', 'expression_genes_expected_count'), \n",
    "('CCLE_RNAseq_transcripts', 'expression_transcripts_tpm'),\n",
    "('CCLE_RNAseq_reads', 'expression_genes_tpm'),\n",
    "('CCLE_expression', 'expression_proteincoding_genes_tpm'), ('expression_proteincoding_genes_expected_count', 'expression_proteincoding_genes_expected_count'),('expression_transcripts_expected_count', 'expression_transcripts_expected_count')])\n",
    "\n",
    "AddToVirtual(virtual_internal, \"depmap-rnaseq-expression-data-363a\", files=[\n",
    "('CCLE_expression_full', 'expression_genes_expected_count'), \n",
    "('CCLE_RNAseq_transcripts', 'expression_transcripts_tpm'),\n",
    "('CCLE_RNAseq_reads', 'expression_genes_tpm'),\n",
    "('CCLE_expression', 'expression_proteincoding_genes_tpm'), ('expression_proteincoding_genes_expected_count', 'expression_proteincoding_genes_expected_count'),('expression_transcripts_expected_count', 'expression_transcripts_expected_count')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not present\n",
      "{'ACH-002196', 'ACH-002205', 'ACH-002289', 'ACH-001064', 'ACH-001641', 'ACH-002127', 'ACH-002344', 'ACH-002384', 'ACH-002383', 'ACH-002157', 'ACH-001037', 'ACH-001143', 'ACH-002216', 'ACH-001680', 'ACH-000727', 'ACH-002351', 'ACH-002207', 'ACH-002114', 'ACH-002300', 'ACH-000795', 'ACH-002377', 'ACH-002204', 'ACH-002360', 'ACH-002292', 'ACH-002058', 'ACH-002104', 'ACH-002314', 'ACH-002183', 'ACH-002213', 'ACH-002168', 'ACH-002382', 'ACH-002260', 'ACH-001208', 'ACH-002095', 'ACH-002200', 'ACH-002269', 'ACH-002387', 'ACH-002375', 'ACH-002129', 'ACH-001199', 'ACH-002312', 'ACH-002282', 'ACH-002395', 'ACH-001338', 'ACH-002232', 'ACH-002267', 'ACH-002190', 'ACH-001502', 'ACH-001093', 'ACH-002336', 'ACH-002281', 'ACH-001137', 'ACH-002199', 'ACH-002208', 'ACH-002185', 'ACH-002276', 'ACH-002374', 'ACH-002396', 'ACH-001383', 'ACH-002237', 'ACH-002119', 'ACH-002136', 'ACH-002359', 'ACH-001182', 'ACH-002399', 'ACH-002106', 'ACH-001187', 'ACH-002394', 'ACH-002180', 'ACH-001045', 'ACH-002291', 'ACH-002230', 'ACH-002193', 'ACH-001089', 'ACH-001331', 'ACH-002401', 'ACH-002147', 'ACH-002242', 'ACH-002361', 'ACH-001205', 'ACH-002201', 'ACH-002191', 'ACH-002143', 'ACH-001203', 'ACH-002290', 'ACH-002188', 'ACH-001018', 'ACH-002294', 'ACH-002247', 'ACH-002167', 'ACH-002391', 'ACH-001125', 'ACH-001591', 'ACH-001118', 'ACH-002159', 'ACH-002197', 'ACH-002253', 'ACH-002102', 'ACH-001023', 'ACH-002238', 'ACH-002182', 'ACH-002198', 'ACH-002175', 'ACH-001599', 'ACH-002250', 'ACH-002284', 'ACH-002091', 'ACH-001233', 'ACH-002299', 'ACH-001092', 'ACH-002369', 'ACH-002123', 'ACH-002305', 'ACH-002141', 'ACH-001767', 'ACH-002341', 'ACH-002350', 'ACH-001011', 'ACH-002296', 'ACH-002169', 'ACH-001101', 'ACH-002128', 'ACH-002235', 'ACH-002093', 'ACH-002367', 'ACH-001225', 'ACH-001127', 'ACH-002125', 'ACH-002225', 'ACH-002297', 'ACH-002224', 'ACH-002315', 'ACH-001044', 'ACH-002266', 'ACH-002400', 'ACH-001350', 'ACH-002380', 'ACH-002231', 'ACH-002096', 'ACH-002274', 'ACH-002379', 'ACH-002135', 'ACH-002043', 'ACH-001042', 'ACH-002275', 'ACH-001072', 'ACH-002146', 'ACH-002302', 'ACH-001065', 'ACH-002392', 'ACH-002277', 'ACH-002152', 'ACH-002217', 'ACH-002113', 'ACH-002288', 'ACH-002378', 'ACH-002099', 'ACH-001364', 'ACH-002163', 'ACH-002293', 'ACH-002246', 'ACH-002124', 'ACH-002372', 'ACH-002174', 'ACH-002243', 'ACH-002162', 'ACH-002342', 'ACH-002339', 'ACH-002210', 'ACH-001189', 'ACH-002212', 'ACH-001091', 'ACH-001066', 'ACH-001214', 'ACH-002256', 'ACH-002121', 'ACH-002228', 'ACH-002221', 'ACH-002134', 'ACH-002280', 'ACH-002349', 'ACH-002255', 'ACH-002337', 'ACH-002287', 'ACH-002132', 'ACH-002283', 'ACH-000426', 'ACH-001094', 'ACH-002209', 'ACH-001150', 'ACH-001000', 'ACH-002107', 'ACH-002089', 'ACH-001017', 'ACH-001224', 'ACH-002279', 'ACH-002270', 'ACH-002273', 'ACH-002112', 'ACH-001108', 'ACH-000992', 'ACH-002229', 'ACH-002150', 'ACH-001490', 'ACH-002338', 'ACH-002186', 'ACH-002239', 'ACH-002202', 'ACH-002097', 'ACH-002286', 'ACH-002272', 'ACH-001206', 'ACH-001738', 'ACH-002397', 'ACH-002131', 'ACH-001087', 'ACH-002304', 'ACH-001071', 'ACH-002365', 'ACH-001021', 'ACH-001230', 'ACH-002108', 'ACH-001363', 'ACH-001136', 'ACH-002259', 'ACH-002051', 'ACH-002101', 'ACH-002153', 'ACH-002020', 'ACH-002301', 'ACH-001131', 'ACH-000309', 'ACH-000979', 'ACH-002120', 'ACH-002346', 'ACH-002358', 'ACH-001126', 'ACH-001039', 'ACH-002393', 'ACH-001452', 'ACH-002262', 'ACH-002040', 'ACH-002189', 'ACH-002268', 'ACH-002094', 'ACH-002381', 'ACH-002092', 'ACH-002241', 'ACH-002370', 'ACH-002165', 'ACH-002144', 'ACH-002245', 'ACH-002187', 'ACH-002285', 'ACH-002116', 'ACH-001171', 'ACH-001958', 'ACH-002356', 'ACH-002130', 'ACH-002233', 'ACH-002376', 'ACH-002364', 'ACH-002098', 'ACH-001146', 'ACH-002264', 'ACH-002178', 'ACH-002171', 'ACH-001606', 'ACH-001234', 'ACH-001002', 'ACH-002149', 'ACH-002308', 'ACH-002122', 'ACH-002220', 'ACH-002317', 'ACH-001049', 'ACH-002316', 'ACH-002252', 'ACH-002118', 'ACH-002140', 'ACH-001198', 'ACH-002109', 'ACH-002126', 'ACH-002340', 'ACH-001090', 'ACH-001015', 'ACH-001121', 'ACH-001957', 'ACH-002306', 'ACH-001079', 'ACH-002160', 'ACH-002148', 'ACH-001047', 'ACH-002353', 'ACH-002311', 'ACH-001358', 'ACH-002257', 'ACH-002313', 'ACH-001293', 'ACH-001417', 'ACH-001081', 'ACH-001359', 'ACH-002117', 'ACH-002388', 'ACH-001955', 'ACH-002166', 'ACH-002192', 'ACH-002386', 'ACH-002145', 'ACH-002184', 'ACH-002348', 'ACH-002176', 'ACH-002310', 'ACH-002362', 'ACH-002347', 'ACH-001639', 'ACH-001704', 'ACH-002248', 'ACH-001024', 'ACH-002278', 'ACH-002139', 'ACH-002254', 'ACH-002249', 'ACH-002103', 'ACH-002105', 'ACH-002240', 'ACH-002155', 'ACH-001130', 'ACH-002389', 'ACH-002223', 'ACH-001175', 'ACH-002181', 'ACH-002307', 'ACH-002390', 'ACH-002100', 'ACH-002211', 'ACH-000047', 'ACH-001489', 'ACH-002354', 'ACH-002357', 'ACH-002335', 'ACH-002709', 'ACH-002343', 'ACH-001162', 'ACH-001088', 'ACH-002298', 'ACH-002214', 'ACH-002265', 'ACH-002194', 'ACH-002111', 'ACH-001355', 'ACH-001362', 'ACH-002215', 'ACH-002206', 'ACH-002371', 'ACH-002352', 'ACH-002156', 'ACH-002177', 'ACH-002355', 'ACH-002234', 'ACH-002244', 'ACH-001249', 'ACH-001063', 'ACH-001107', 'ACH-002345', 'ACH-002251', 'ACH-002090', 'ACH-002368', 'ACH-001365', 'ACH-002236', 'ACH-002052', 'ACH-002303', 'ACH-002173', 'ACH-001544', 'ACH-002170', 'ACH-002195', 'ACH-001138', 'ACH-002366', 'ACH-002133', 'ACH-002110', 'ACH-002222', 'ACH-002295', 'ACH-002271', 'ACH-002363', 'ACH-002154', 'ACH-001043', 'ACH-002115', 'ACH-002226', 'ACH-002142', 'ACH-001956', 'ACH-002309', 'ACH-001188', 'ACH-002083', 'ACH-002261', 'ACH-002161', 'ACH-002179', 'ACH-002263', 'ACH-002258', 'ACH-002227', 'ACH-002164', 'ACH-002218', 'ACH-002373', 'ACH-001282', 'ACH-002151', 'ACH-002077'}\n",
      "removed for QC reasons\n",
      "{'ACH-000992', 'ACH-001293', 'ACH-002709', 'ACH-001502', 'ACH-001143', 'ACH-000309', 'ACH-001205', 'ACH-000979', 'ACH-000426', 'ACH-000047', 'ACH-001512', 'ACH-000795', 'ACH-000727'}\n",
      "removed\n",
      "set()\n",
      "missing\n",
      "set()\n",
      "embargo_ibm\n",
      "2 {'ACH-001708', 'ACH-001393'}\n"
     ]
    }
   ],
   "source": [
    "print('not present')\n",
    "removed = set(prevdmc) - set(genes_tpm.index)\n",
    "print(removed)\n",
    "print('removed for QC reasons')\n",
    "print(set(rename.keys()))\n",
    "print('removed')\n",
    "removed = set(dmc_rna) - set(genes_tpm.index)\n",
    "print(removed - set(rename.keys()))\n",
    "missing = set(ibm) - set(genes_tpm.index)\n",
    "embargo_ibm = set(genes_tpm.index) - (prevdmc | set(ibm))\n",
    "print('missing')\n",
    "print(missing)\n",
    "newlines = set(ibm) \n",
    "print('embargo_ibm')\n",
    "print(len(embargo_ibm), embargo_ibm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407\n",
      "0\n",
      "1407\n",
      "0\n",
      "1407\n",
      "0\n",
      "1407\n",
      "0\n",
      "1406\n",
      "0\n",
      "1406\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## removing first blacklisted, then embargoed, to create two datasets\n",
    "print(len(genes_expected_count))\n",
    "a = genes_expected_count[~genes_expected_count.index.isin(embargo_ibm|prevdmc)]\n",
    "print(len(a))\n",
    "a.to_csv('temp/expression_genes_expected_count.csv')\n",
    "print(len(genes_tpm))\n",
    "a = genes_tpm[~genes_tpm.index.isin(embargo_ibm|prevdmc)]\n",
    "print(len(a))\n",
    "a.to_csv('temp/expression_genes_tpm.csv')\n",
    "print(len(proteincoding_genes_tpm))\n",
    "a = proteincoding_genes_tpm[~proteincoding_genes_tpm.index.isin(embargo_ibm|prevdmc)]\n",
    "print(len(a))\n",
    "a.to_csv('temp/expression_proteincoding_genes_tpm.csv')\n",
    "print(len(transcripts_tpm))\n",
    "a = transcripts_tpm[~transcripts_tpm.index.isin(embargo_ibm|prevdmc)]\n",
    "print(len(a))\n",
    "a.to_csv('temp/expression_transcripts_tpm.csv')\n",
    "print(len(proteincoding_genes_expected_count))\n",
    "a = proteincoding_genes_expected_count[~proteincoding_genes_expected_count.index.isin(embargo_ibm|prevdmc)]\n",
    "print(len(a))\n",
    "a.to_csv('temp/expression_proteincoding_genes_expected_count.csv')\n",
    "print(len(transcripts_expected_count))\n",
    "a = transcripts_expected_count[~transcripts_expected_count.index.isin(embargo_ibm|prevdmc)]\n",
    "print(len(a))\n",
    "a.to_csv('temp/expression_transcripts_expected_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading expression_genes_expected_count...\n",
      "hitting https://cds.team/taiga/api/datafile/db47114a5a204fa69578a449a8601b78\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'message'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-23b2dc3a199a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mBLACKLIST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \"\"\"+str(blacklist))\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/taigapy/__init__.py\u001b[0m in \u001b[0;36mupdate_dataset\u001b[0;34m(self, dataset_id, dataset_permaname, dataset_version, dataset_description, changes_description, upload_file_path_dict, add_taiga_ids, add_all_existing_files)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m         new_session_id = self.upload_session_files(\n\u001b[0;32m-> 1255\u001b[0;31m             \u001b[0mupload_file_path_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupload_file_path_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_taiga_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_taiga_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         )\n\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/taigapy/__init__.py\u001b[0m in \u001b[0;36mupload_session_files\u001b[0;34m(self, upload_file_path_dict, add_taiga_ids)\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 print(\n\u001b[1;32m   1076\u001b[0m                     \"\\n\\t While processing {}, we got this error {}\".format(\n\u001b[0;32m-> 1077\u001b[0;31m                         \u001b[0mupload_file_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1078\u001b[0m                     )\n\u001b[1;32m   1079\u001b[0m                 )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'message'"
     ]
    }
   ],
   "source": [
    "tc.update_dataset(dataset_permaname=\"depmap-rnaseq-expression-data-80ef\",\n",
    "                 upload_file_path_dict={\n",
    "                     'temp/expression_genes_expected_count.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_transcripts_tpm.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_genes_tpm.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_proteincoding_genes_tpm.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_proteincoding_genes_expected_count.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_transcripts_expected_count.csv': 'NumericMatrixCSV'},\n",
    "                  dataset_description=\n",
    "\"\"\"\n",
    "# IBM RNA\n",
    "\n",
    "* Version 1-3 DMC 19Q1*\n",
    "\n",
    "\n",
    "data is aligned to hg38\n",
    "\n",
    "read count data is created using RSEM, which, when a read maps to multiple places, splits the counts between genes, with the weight based on the likelihood that it came from one gene or the other, so counts data may not be integers\n",
    "\n",
    "TPM data is log2-transformed with a pseudo count of 1 added.\n",
    "\n",
    "Reads/transcript files unaltered aside from formatting row / column names.\n",
    "\n",
    "The ProteinCoding datasets contain just protein coding genes and are based on protein coding annotations from https://www.genenames.org/cgi-bin/download (locus_group == \"protein-coding gene\")\n",
    "\n",
    "Rows: are DepMap cell line IDs\n",
    "\n",
    "Columns: In the complete TPM and read counts datasets column names are HGNC_symbol (Ensembl_ID), while in the ProteinCoding TPM dataset column names are HGNC_symbol (Entrez_ID). In the TPM transcript dataset column names are HGNC_symbol (Transcript_ID) - the HGNC symbols are not unique, use the transcript IDs for unique identifiers.\n",
    "\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "REMOVED FOR QC REASONS:\n",
    "\"\"\"+str(rename)+\"\"\"\n",
    "\n",
    "BLACKLIST:\n",
    "\"\"\"+str(blacklist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AddToVirtual(virtual_dmc, \"depmap-rnaseq-expression-data-80ef\", files=[('CCLE_expression_full', 'expression_genes_expected_count'), \n",
    "('CCLE_RNAseq_transcripts', 'expression_transcripts_tpm'),\n",
    "('CCLE_RNAseq_reads', 'expression_genes_tpm'),\n",
    "('CCLE_expression', 'expression_proteincoding_genes_tpm'), ('expression_proteincoding_genes_expected_count', 'expression_proteincoding_genes_expected_count'),('expression_transcripts_expected_count', 'expression_transcripts_expected_count')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not present\n",
      "{'ACH-002196', 'ACH-002205', 'ACH-002289', 'ACH-001064', 'ACH-001641', 'ACH-002127', 'ACH-002344', 'ACH-002384', 'ACH-002383', 'ACH-002157', 'ACH-001037', 'ACH-001143', 'ACH-002216', 'ACH-001680', 'ACH-000727', 'ACH-002351', 'ACH-002207', 'ACH-002114', 'ACH-002300', 'ACH-000795', 'ACH-002377', 'ACH-002204', 'ACH-002360', 'ACH-002292', 'ACH-002058', 'ACH-002104', 'ACH-002314', 'ACH-002183', 'ACH-002213', 'ACH-002168', 'ACH-002382', 'ACH-002260', 'ACH-001208', 'ACH-002095', 'ACH-002200', 'ACH-002269', 'ACH-002387', 'ACH-002375', 'ACH-002129', 'ACH-001199', 'ACH-002312', 'ACH-002282', 'ACH-002395', 'ACH-001338', 'ACH-002232', 'ACH-002267', 'ACH-002190', 'ACH-001502', 'ACH-001093', 'ACH-002336', 'ACH-002281', 'ACH-001137', 'ACH-002199', 'ACH-002208', 'ACH-002185', 'ACH-002276', 'ACH-002374', 'ACH-002396', 'ACH-001383', 'ACH-002237', 'ACH-002119', 'ACH-002136', 'ACH-002359', 'ACH-001182', 'ACH-002399', 'ACH-002106', 'ACH-001187', 'ACH-002394', 'ACH-002180', 'ACH-001045', 'ACH-002291', 'ACH-002230', 'ACH-002193', 'ACH-001089', 'ACH-001331', 'ACH-002401', 'ACH-002147', 'ACH-002242', 'ACH-002361', 'ACH-001205', 'ACH-002201', 'ACH-002191', 'ACH-002143', 'ACH-001203', 'ACH-002290', 'ACH-002188', 'ACH-001018', 'ACH-002294', 'ACH-002247', 'ACH-002167', 'ACH-002391', 'ACH-001125', 'ACH-001591', 'ACH-001118', 'ACH-002159', 'ACH-002197', 'ACH-002253', 'ACH-002102', 'ACH-001023', 'ACH-002238', 'ACH-002182', 'ACH-002198', 'ACH-002175', 'ACH-001599', 'ACH-002250', 'ACH-002284', 'ACH-002091', 'ACH-001233', 'ACH-002299', 'ACH-001092', 'ACH-002369', 'ACH-002123', 'ACH-002305', 'ACH-002141', 'ACH-001767', 'ACH-002341', 'ACH-002350', 'ACH-001011', 'ACH-002296', 'ACH-002169', 'ACH-001101', 'ACH-002128', 'ACH-002235', 'ACH-002093', 'ACH-002367', 'ACH-001225', 'ACH-001127', 'ACH-002125', 'ACH-002225', 'ACH-002297', 'ACH-002224', 'ACH-002315', 'ACH-001044', 'ACH-002266', 'ACH-002400', 'ACH-001350', 'ACH-002380', 'ACH-002231', 'ACH-002096', 'ACH-002274', 'ACH-002379', 'ACH-002135', 'ACH-002043', 'ACH-001042', 'ACH-002275', 'ACH-001072', 'ACH-002146', 'ACH-002302', 'ACH-001065', 'ACH-002392', 'ACH-002277', 'ACH-002152', 'ACH-002217', 'ACH-002113', 'ACH-002288', 'ACH-002378', 'ACH-002099', 'ACH-001364', 'ACH-002163', 'ACH-002293', 'ACH-002246', 'ACH-002124', 'ACH-002372', 'ACH-002174', 'ACH-002243', 'ACH-002162', 'ACH-002342', 'ACH-002339', 'ACH-002210', 'ACH-001189', 'ACH-002212', 'ACH-001091', 'ACH-001066', 'ACH-001214', 'ACH-002256', 'ACH-002121', 'ACH-002228', 'ACH-002221', 'ACH-002134', 'ACH-002280', 'ACH-002349', 'ACH-002255', 'ACH-002337', 'ACH-002287', 'ACH-002132', 'ACH-002283', 'ACH-000426', 'ACH-001094', 'ACH-002209', 'ACH-001150', 'ACH-001000', 'ACH-002107', 'ACH-002089', 'ACH-001017', 'ACH-001224', 'ACH-002279', 'ACH-002270', 'ACH-002273', 'ACH-002112', 'ACH-001108', 'ACH-000992', 'ACH-002229', 'ACH-002150', 'ACH-001490', 'ACH-002338', 'ACH-002186', 'ACH-002239', 'ACH-002202', 'ACH-002097', 'ACH-002286', 'ACH-002272', 'ACH-001206', 'ACH-001738', 'ACH-002397', 'ACH-002131', 'ACH-001087', 'ACH-002304', 'ACH-001071', 'ACH-002365', 'ACH-001021', 'ACH-001230', 'ACH-002108', 'ACH-001363', 'ACH-001136', 'ACH-002259', 'ACH-002051', 'ACH-002101', 'ACH-002153', 'ACH-002020', 'ACH-002301', 'ACH-001131', 'ACH-000309', 'ACH-000979', 'ACH-002120', 'ACH-002346', 'ACH-002358', 'ACH-001126', 'ACH-001039', 'ACH-002393', 'ACH-001452', 'ACH-002262', 'ACH-002040', 'ACH-002189', 'ACH-002268', 'ACH-002094', 'ACH-002381', 'ACH-002092', 'ACH-002241', 'ACH-002370', 'ACH-002165', 'ACH-002144', 'ACH-002245', 'ACH-002187', 'ACH-002285', 'ACH-002116', 'ACH-001171', 'ACH-001958', 'ACH-002356', 'ACH-002130', 'ACH-002233', 'ACH-002376', 'ACH-002364', 'ACH-002098', 'ACH-001146', 'ACH-002264', 'ACH-002178', 'ACH-002171', 'ACH-001606', 'ACH-001234', 'ACH-001002', 'ACH-002149', 'ACH-002308', 'ACH-002122', 'ACH-002220', 'ACH-002317', 'ACH-001049', 'ACH-002316', 'ACH-002252', 'ACH-002118', 'ACH-002140', 'ACH-001198', 'ACH-002109', 'ACH-002126', 'ACH-002340', 'ACH-001090', 'ACH-001015', 'ACH-001121', 'ACH-001957', 'ACH-002306', 'ACH-001079', 'ACH-002160', 'ACH-002148', 'ACH-001047', 'ACH-002353', 'ACH-002311', 'ACH-001358', 'ACH-002257', 'ACH-002313', 'ACH-001293', 'ACH-001417', 'ACH-001081', 'ACH-001359', 'ACH-002117', 'ACH-002388', 'ACH-001955', 'ACH-002166', 'ACH-002192', 'ACH-002386', 'ACH-002145', 'ACH-002184', 'ACH-002348', 'ACH-002176', 'ACH-002310', 'ACH-002362', 'ACH-002347', 'ACH-001639', 'ACH-001704', 'ACH-002248', 'ACH-001024', 'ACH-002278', 'ACH-002139', 'ACH-002254', 'ACH-002249', 'ACH-002103', 'ACH-002105', 'ACH-002240', 'ACH-002155', 'ACH-001130', 'ACH-002389', 'ACH-002223', 'ACH-001175', 'ACH-002181', 'ACH-002307', 'ACH-002390', 'ACH-002100', 'ACH-002211', 'ACH-000047', 'ACH-001489', 'ACH-002354', 'ACH-002357', 'ACH-002335', 'ACH-002709', 'ACH-002343', 'ACH-001162', 'ACH-001088', 'ACH-002298', 'ACH-002214', 'ACH-002265', 'ACH-002194', 'ACH-002111', 'ACH-001355', 'ACH-001362', 'ACH-002215', 'ACH-002206', 'ACH-002371', 'ACH-002352', 'ACH-002156', 'ACH-002177', 'ACH-002355', 'ACH-002234', 'ACH-002244', 'ACH-001249', 'ACH-001063', 'ACH-001107', 'ACH-002345', 'ACH-002251', 'ACH-002090', 'ACH-002368', 'ACH-001365', 'ACH-002236', 'ACH-002052', 'ACH-002303', 'ACH-002173', 'ACH-001544', 'ACH-002170', 'ACH-002195', 'ACH-001138', 'ACH-002366', 'ACH-002133', 'ACH-002110', 'ACH-002222', 'ACH-002295', 'ACH-002271', 'ACH-002363', 'ACH-002154', 'ACH-001043', 'ACH-002115', 'ACH-002226', 'ACH-002142', 'ACH-001956', 'ACH-002309', 'ACH-001188', 'ACH-002083', 'ACH-002261', 'ACH-002161', 'ACH-002179', 'ACH-002263', 'ACH-002258', 'ACH-002227', 'ACH-002164', 'ACH-002218', 'ACH-002373', 'ACH-001282', 'ACH-002151', 'ACH-002077'}\n",
      "removed for QC reasons\n",
      "{'ACH-000992', 'ACH-001293', 'ACH-002709', 'ACH-001502', 'ACH-001143', 'ACH-000309', 'ACH-001205', 'ACH-000979', 'ACH-000426', 'ACH-000047', 'ACH-001512', 'ACH-000795', 'ACH-000727'}\n",
      "removed\n",
      "set()\n",
      "missing\n",
      "set()\n",
      "embargo_dmc\n",
      "2 {'ACH-001708', 'ACH-001393'}\n"
     ]
    }
   ],
   "source": [
    "print('not present')\n",
    "removed = set(prevdmc) - set(genes_tpm.index)\n",
    "print(removed)\n",
    "print('removed for QC reasons')\n",
    "print(set(rename.keys()))\n",
    "print('removed')\n",
    "removed = set(dmc_rna) - set(genes_tpm.index)\n",
    "print(removed - set(rename.keys()))\n",
    "missing = set(internal) - set(genes_tpm.index)\n",
    "embargo_dmc = set(genes_tpm.index) - (prevdmc | set(dmc))\n",
    "print('missing')\n",
    "print(missing)\n",
    "newlines = set(dmc) \n",
    "print('embargo_dmc')\n",
    "print(len(embargo_dmc), embargo_dmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407\n",
      "1405\n",
      "1407\n",
      "1405\n",
      "1407\n",
      "1405\n",
      "1407\n",
      "1405\n",
      "1406\n",
      "1404\n",
      "1406\n",
      "1404\n"
     ]
    }
   ],
   "source": [
    "## removing first blacklisted, then embargoed, to create two datasets\n",
    "print(len(genes_expected_count))\n",
    "genes_expected_count = genes_expected_count[~genes_expected_count.index.isin(embargo_dmc)]\n",
    "print(len(genes_expected_count))\n",
    "genes_expected_count.to_csv('temp/expression_genes_expected_count.csv')\n",
    "print(len(genes_tpm))\n",
    "genes_tpm = genes_tpm[~genes_tpm.index.isin(embargo_dmc)]\n",
    "print(len(genes_tpm))\n",
    "genes_tpm.to_csv('temp/expression_genes_tpm.csv')\n",
    "print(len(proteincoding_genes_tpm))\n",
    "proteincoding_genes_tpm = proteincoding_genes_tpm[~proteincoding_genes_tpm.index.isin(embargo_dmc)]\n",
    "print(len(proteincoding_genes_tpm))\n",
    "proteincoding_genes_tpm.to_csv('temp/expression_proteincoding_genes_tpm.csv')\n",
    "print(len(transcripts_tpm))\n",
    "transcripts_tpm = transcripts_tpm[~transcripts_tpm.index.isin(embargo_dmc)]\n",
    "print(len(transcripts_tpm))\n",
    "transcripts_tpm.to_csv('temp/expression_transcripts_tpm.csv')\n",
    "print(len(proteincoding_genes_expected_count))\n",
    "proteincoding_genes_expected_count = proteincoding_genes_expected_count[~proteincoding_genes_expected_count.index.isin(embargo_dmc)]\n",
    "print(len(proteincoding_genes_expected_count))\n",
    "proteincoding_genes_expected_count.to_csv('temp/expression_proteincoding_genes_expected_count.csv')\n",
    "print(len(transcripts_expected_count))\n",
    "transcripts_expected_count = transcripts_expected_count[~transcripts_expected_count.index.isin(embargo_dmc)]\n",
    "print(len(transcripts_expected_count))\n",
    "transcripts_expected_count.to_csv('temp/expression_transcripts_expected_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading expression_genes_expected_count...\n",
      "hitting https://cds.team/taiga/api/datafile/19b98e19792d47749558e1b906dd8cec\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_genes_expected_count properly converted and uploaded\n",
      "Uploading expression_transcripts_tpm...\n",
      "hitting https://cds.team/taiga/api/datafile/19b98e19792d47749558e1b906dd8cec\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_transcripts_tpm properly converted and uploaded\n",
      "Uploading expression_genes_tpm...\n",
      "hitting https://cds.team/taiga/api/datafile/19b98e19792d47749558e1b906dd8cec\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_genes_tpm properly converted and uploaded\n",
      "Uploading expression_proteincoding_genes_tpm...\n",
      "hitting https://cds.team/taiga/api/datafile/19b98e19792d47749558e1b906dd8cec\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_proteincoding_genes_tpm properly converted and uploaded\n",
      "Uploading expression_proteincoding_genes_expected_count...\n",
      "hitting https://cds.team/taiga/api/datafile/19b98e19792d47749558e1b906dd8cec\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_proteincoding_genes_expected_count properly converted and uploaded\n",
      "Uploading expression_transcripts_expected_count...\n",
      "hitting https://cds.team/taiga/api/datafile/19b98e19792d47749558e1b906dd8cec\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_transcripts_expected_count properly converted and uploaded\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id c3c447b0823a438396c828b9b05a3596 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/c3c447b0823a438396c828b9b05a3596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c3c447b0823a438396c828b9b05a3596'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.update_dataset(dataset_permaname=\"depmap-rnaseq-expression-data-80ef\",\n",
    "                 upload_file_path_dict={\n",
    "                     'temp/expression_genes_expected_count.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_transcripts_tpm.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_genes_tpm.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_proteincoding_genes_tpm.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_proteincoding_genes_expected_count.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_transcripts_expected_count.csv': 'NumericMatrixCSV'},\n",
    "                  dataset_description=\n",
    "\"\"\"\n",
    "# DMC RNA\n",
    "\n",
    "* Version 1-3 DMC 19Q1*\n",
    "\n",
    "version 3 contains the correct data for 19Q1\n",
    "\n",
    "version 2 contains correct TPM transcript data (in version 1 transcript data contains only gene level not transcript level data)\n",
    "\n",
    "* Version 4 DMC 19Q2*\n",
    "\n",
    "* Version 5 DMC 19Q3*\n",
    "\n",
    "* Version 6 DMC 19Q4*\n",
    "\n",
    "Adding 93 new cell lines - Blacklisted - IBM\n",
    "Some cells lines have been removed because they:\n",
    "\n",
    " - had too many 0 values = [\"ACH-001388\" \"ACH-001577\" \"ACH-001767\" \"ACH-002463\"] \n",
    "\n",
    "Some cells lines have been flagged as:\n",
    "\n",
    " - None\n",
    "\n",
    "* Version 7 DMC 19Q4\n",
    "\n",
    "removing blacklisted\n",
    "\n",
    "* Version 8 DMC 19Q4\n",
    "\n",
    "removing blacklisted in transcripts\n",
    "\n",
    "* Version 9 DMC 19Q4\n",
    "\n",
    "uploading as numeric matrix\n",
    "\n",
    "* Version 10 DMC 20Q1\n",
    "unknown reupload\n",
    "\n",
    "* Version 11 DMC 20Q2\n",
    "adding  new cell lines\n",
    "\n",
    "* Version 12 DMC 20Q2\n",
    "unknown reupload\n",
    "\n",
    "* Version 13 DMC 20Q2\n",
    "removing some missed blacklisted lines\n",
    "\n",
    "* Version 14 DMC 20Q2\n",
    "Adding one missing line\n",
    "\n",
    "* Version 15 DMC 20Q3\n",
    "nothing different from  20Q2. no new cell lines added\n",
    "\n",
    "* Version 16 DMC 20Q3\n",
    "Some wrong annotations in the blacklists\n",
    "\n",
    "* Version 17 DMC 20Q3\n",
    "Updated annotations in the blacklists\n",
    "\n",
    "* Version 18 DMC 20Q4\n",
    "new samples, adding a new QC method that removed 10 samples. fully adding the reprocessed samples, removing some wrong genes, adding falsely removed genes (that are still expressed)\n",
    "\n",
    "* Version 18 DMC 20Q4\n",
    "revertig logtransform\n",
    "\n",
    "* Version 19 DMC 20Q4\n",
    "reverting gene names\n",
    "\n",
    "data is aligned to hg38\n",
    "\n",
    "read count data is created using RSEM, which, when a read maps to multiple places, splits the counts between genes, with the weight based on the likelihood that it came from one gene or the other, so counts data may not be integers\n",
    "\n",
    "TPM data is log2-transformed with a pseudo count of 1 added.\n",
    "\n",
    "Reads/transcript files unaltered aside from formatting row / column names.\n",
    "\n",
    "The ProteinCoding datasets contain just protein coding genes and are based on protein coding annotations from https://www.genenames.org/cgi-bin/download (locus_group == \"protein-coding gene\")\n",
    "\n",
    "Rows: are DepMap cell line IDs\n",
    "\n",
    "Columns: In the complete TPM and read counts datasets column names are HGNC_symbol (Ensembl_ID), while in the ProteinCoding TPM dataset column names are HGNC_symbol (Entrez_ID). In the TPM transcript dataset column names are HGNC_symbol (Transcript_ID) - the HGNC symbols are not unique, use the transcript IDs for unique identifiers.\n",
    "\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "REMOVED FOR QC REASONS:\n",
    "\"\"\"+str(rename)+\"\"\"\n",
    "\n",
    "BLACKLIST:\n",
    "\"\"\"+str(embargo_dmc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CCLE_expression_full', 'depmap-rnaseq-expression-data-80ef.21/expression_genes_expected_count'), ('CCLE_RNAseq_transcripts', 'depmap-rnaseq-expression-data-80ef.21/expression_transcripts_tpm'), ('CCLE_RNAseq_reads', 'depmap-rnaseq-expression-data-80ef.21/expression_genes_tpm'), ('CCLE_expression', 'depmap-rnaseq-expression-data-80ef.21/expression_proteincoding_genes_tpm'), ('expression_proteincoding_genes_expected_count', 'depmap-rnaseq-expression-data-80ef.21/expression_proteincoding_genes_expected_count'), ('expression_transcripts_expected_count', 'depmap-rnaseq-expression-data-80ef.21/expression_transcripts_expected_count')]\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datafile/e90c75655bcd49828604a9956132b74c\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 8641c07a4a0e4bd7994a70a214a14743 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/8641c07a4a0e4bd7994a70a214a14743\n"
     ]
    }
   ],
   "source": [
    "AddToVirtual(virtual_dmc, \"depmap-rnaseq-expression-data-80ef\", files=[('CCLE_expression_full', 'expression_genes_expected_count'), \n",
    "('CCLE_RNAseq_transcripts', 'expression_transcripts_tpm'),\n",
    "('CCLE_RNAseq_reads', 'expression_genes_tpm'),\n",
    "('CCLE_expression', 'expression_proteincoding_genes_tpm'), ('expression_proteincoding_genes_expected_count', 'expression_proteincoding_genes_expected_count'),('expression_transcripts_expected_count', 'expression_transcripts_expected_count')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not present\n",
      "{'ACH-002196', 'ACH-002205', 'ACH-002289', 'ACH-001064', 'ACH-001641', 'ACH-002127', 'ACH-002344', 'ACH-002384', 'ACH-002383', 'ACH-002157', 'ACH-001037', 'ACH-001143', 'ACH-002216', 'ACH-001680', 'ACH-000727', 'ACH-002351', 'ACH-002207', 'ACH-002114', 'ACH-002300', 'ACH-000795', 'ACH-002377', 'ACH-002204', 'ACH-002360', 'ACH-002292', 'ACH-002058', 'ACH-002104', 'ACH-002314', 'ACH-002183', 'ACH-002213', 'ACH-002168', 'ACH-002382', 'ACH-002260', 'ACH-001208', 'ACH-002095', 'ACH-002200', 'ACH-002269', 'ACH-002387', 'ACH-002375', 'ACH-002129', 'ACH-001199', 'ACH-002312', 'ACH-002282', 'ACH-002395', 'ACH-001338', 'ACH-002232', 'ACH-002267', 'ACH-002190', 'ACH-001093', 'ACH-002336', 'ACH-002281', 'ACH-001137', 'ACH-002199', 'ACH-002208', 'ACH-002185', 'ACH-002276', 'ACH-002374', 'ACH-002396', 'ACH-001383', 'ACH-002237', 'ACH-002119', 'ACH-002136', 'ACH-002359', 'ACH-001182', 'ACH-002106', 'ACH-001187', 'ACH-002394', 'ACH-002180', 'ACH-001045', 'ACH-002291', 'ACH-002230', 'ACH-002193', 'ACH-001089', 'ACH-001331', 'ACH-002147', 'ACH-002242', 'ACH-002361', 'ACH-001205', 'ACH-002201', 'ACH-002191', 'ACH-002143', 'ACH-001203', 'ACH-002290', 'ACH-002188', 'ACH-001018', 'ACH-002294', 'ACH-002247', 'ACH-002167', 'ACH-002391', 'ACH-001125', 'ACH-001591', 'ACH-001118', 'ACH-002159', 'ACH-002197', 'ACH-002253', 'ACH-002102', 'ACH-001023', 'ACH-002238', 'ACH-002182', 'ACH-002198', 'ACH-002175', 'ACH-001599', 'ACH-002250', 'ACH-002284', 'ACH-002091', 'ACH-001233', 'ACH-002299', 'ACH-001092', 'ACH-002369', 'ACH-002123', 'ACH-002305', 'ACH-002141', 'ACH-001767', 'ACH-002341', 'ACH-002350', 'ACH-001011', 'ACH-002296', 'ACH-002169', 'ACH-001101', 'ACH-002128', 'ACH-002235', 'ACH-002093', 'ACH-002367', 'ACH-001225', 'ACH-001127', 'ACH-002125', 'ACH-002225', 'ACH-002297', 'ACH-002224', 'ACH-002315', 'ACH-001044', 'ACH-002266', 'ACH-001350', 'ACH-002380', 'ACH-002231', 'ACH-002096', 'ACH-002274', 'ACH-002379', 'ACH-002135', 'ACH-002043', 'ACH-001042', 'ACH-002275', 'ACH-001072', 'ACH-002146', 'ACH-002302', 'ACH-001065', 'ACH-002392', 'ACH-002277', 'ACH-002152', 'ACH-002217', 'ACH-002113', 'ACH-002288', 'ACH-002378', 'ACH-002099', 'ACH-001364', 'ACH-002163', 'ACH-002293', 'ACH-002246', 'ACH-002124', 'ACH-002372', 'ACH-002174', 'ACH-002243', 'ACH-002162', 'ACH-002342', 'ACH-002339', 'ACH-002210', 'ACH-001189', 'ACH-002212', 'ACH-001091', 'ACH-001066', 'ACH-001214', 'ACH-002256', 'ACH-002121', 'ACH-002228', 'ACH-002221', 'ACH-002134', 'ACH-002280', 'ACH-002349', 'ACH-002255', 'ACH-002337', 'ACH-002287', 'ACH-002132', 'ACH-002283', 'ACH-000426', 'ACH-001094', 'ACH-002209', 'ACH-001150', 'ACH-001000', 'ACH-002107', 'ACH-002089', 'ACH-001017', 'ACH-001224', 'ACH-002279', 'ACH-002270', 'ACH-002273', 'ACH-002112', 'ACH-001108', 'ACH-000992', 'ACH-002229', 'ACH-002150', 'ACH-001490', 'ACH-002338', 'ACH-002186', 'ACH-002239', 'ACH-002202', 'ACH-002097', 'ACH-002286', 'ACH-002272', 'ACH-001206', 'ACH-001738', 'ACH-002397', 'ACH-002131', 'ACH-001087', 'ACH-002304', 'ACH-001071', 'ACH-002365', 'ACH-001021', 'ACH-001230', 'ACH-002108', 'ACH-001363', 'ACH-001136', 'ACH-002259', 'ACH-002051', 'ACH-002101', 'ACH-002153', 'ACH-002020', 'ACH-002301', 'ACH-001131', 'ACH-000309', 'ACH-000979', 'ACH-002120', 'ACH-002346', 'ACH-002358', 'ACH-001126', 'ACH-001039', 'ACH-002393', 'ACH-001452', 'ACH-002262', 'ACH-002040', 'ACH-002189', 'ACH-002268', 'ACH-002094', 'ACH-002381', 'ACH-002092', 'ACH-002241', 'ACH-002370', 'ACH-002165', 'ACH-002144', 'ACH-002245', 'ACH-002187', 'ACH-002285', 'ACH-002116', 'ACH-001171', 'ACH-001958', 'ACH-002356', 'ACH-002130', 'ACH-002233', 'ACH-002376', 'ACH-002364', 'ACH-002098', 'ACH-001146', 'ACH-002264', 'ACH-002178', 'ACH-002171', 'ACH-001606', 'ACH-001234', 'ACH-001002', 'ACH-002149', 'ACH-002308', 'ACH-002122', 'ACH-002220', 'ACH-002317', 'ACH-001049', 'ACH-002316', 'ACH-002252', 'ACH-002118', 'ACH-002140', 'ACH-001198', 'ACH-002109', 'ACH-002126', 'ACH-002340', 'ACH-001090', 'ACH-001015', 'ACH-001121', 'ACH-001957', 'ACH-002306', 'ACH-001079', 'ACH-002160', 'ACH-002148', 'ACH-001047', 'ACH-002353', 'ACH-002311', 'ACH-001358', 'ACH-002257', 'ACH-002313', 'ACH-001417', 'ACH-001081', 'ACH-001359', 'ACH-002117', 'ACH-002388', 'ACH-001955', 'ACH-002166', 'ACH-002192', 'ACH-002386', 'ACH-002145', 'ACH-002184', 'ACH-002348', 'ACH-002176', 'ACH-002310', 'ACH-002362', 'ACH-002347', 'ACH-001639', 'ACH-001704', 'ACH-002248', 'ACH-001024', 'ACH-002278', 'ACH-002139', 'ACH-002254', 'ACH-002249', 'ACH-002103', 'ACH-002105', 'ACH-002240', 'ACH-002155', 'ACH-001130', 'ACH-002389', 'ACH-002223', 'ACH-001175', 'ACH-002181', 'ACH-002307', 'ACH-002390', 'ACH-002100', 'ACH-002211', 'ACH-000047', 'ACH-001489', 'ACH-002354', 'ACH-002357', 'ACH-002335', 'ACH-002343', 'ACH-001162', 'ACH-001088', 'ACH-002298', 'ACH-002214', 'ACH-002265', 'ACH-002194', 'ACH-002111', 'ACH-001355', 'ACH-001362', 'ACH-002215', 'ACH-002206', 'ACH-002371', 'ACH-002352', 'ACH-002156', 'ACH-002177', 'ACH-002355', 'ACH-002234', 'ACH-002244', 'ACH-001249', 'ACH-001063', 'ACH-001107', 'ACH-002345', 'ACH-002251', 'ACH-002090', 'ACH-002368', 'ACH-001365', 'ACH-002236', 'ACH-002052', 'ACH-002303', 'ACH-002173', 'ACH-001544', 'ACH-002170', 'ACH-002195', 'ACH-001138', 'ACH-002366', 'ACH-002133', 'ACH-002110', 'ACH-002222', 'ACH-002295', 'ACH-002271', 'ACH-002363', 'ACH-002154', 'ACH-001043', 'ACH-002115', 'ACH-002226', 'ACH-002142', 'ACH-001956', 'ACH-002309', 'ACH-001188', 'ACH-002083', 'ACH-002261', 'ACH-002161', 'ACH-002179', 'ACH-002263', 'ACH-002258', 'ACH-002227', 'ACH-002164', 'ACH-002218', 'ACH-002373', 'ACH-001282', 'ACH-002151', 'ACH-002077'}\n",
      "removed for QC reasons\n",
      "{'ACH-000992', 'ACH-001293', 'ACH-002709', 'ACH-001502', 'ACH-001143', 'ACH-000309', 'ACH-001205', 'ACH-000979', 'ACH-000426', 'ACH-000047', 'ACH-001512', 'ACH-000795', 'ACH-000727'}\n",
      "removed\n",
      "set()\n",
      "missing\n",
      "{'ACH-002399', 'ACH-002709'}\n",
      "embargo\n",
      "29 {'ACH-001493', 'ACH-001970', 'ACH-001449', 'ACH-002010', 'ACH-001662', 'ACH-001669', 'ACH-001672', 'ACH-002465', 'ACH-001973', 'ACH-001693', 'ACH-001547', 'ACH-002014', 'ACH-001847', 'ACH-001971', 'ACH-001533', 'ACH-001854', 'ACH-001349', 'ACH-001696', 'ACH-001437', 'ACH-002048', 'ACH-002021', 'ACH-001679', 'ACH-001678', 'ACH-001676', 'ACH-001537', 'ACH-001855', 'ACH-002512', 'ACH-001438', 'ACH-001429'}\n",
      "{'ACH-001041', 'ACH-000886', 'ACH-002399', 'ACH-000949', 'ACH-000353', 'ACH-001456', 'ACH-000396', 'ACH-000124', 'ACH-000090', 'ACH-001613', 'ACH-002709', 'ACH-001993', 'ACH-000568', 'ACH-000972', 'ACH-001392', 'ACH-001497', 'ACH-000538', 'ACH-002065', 'ACH-000565', 'ACH-000267', 'ACH-002464', 'ACH-001638', 'ACH-001574', 'ACH-001850', 'ACH-000672', 'ACH-000533', 'ACH-000327', 'ACH-002510', 'ACH-000357', 'ACH-002508', 'ACH-002467', 'ACH-001376', 'ACH-000144', 'ACH-000955', 'ACH-002463', 'ACH-000161', 'ACH-001378', 'ACH-000072', 'ACH-001498', 'ACH-001846', 'ACH-000110', 'ACH-002466', 'ACH-000845', 'ACH-000999', 'ACH-002462', 'ACH-000462', 'ACH-001556', 'ACH-000268', 'ACH-001819', 'ACH-000609', 'ACH-000989', 'ACH-000602'}\n"
     ]
    }
   ],
   "source": [
    "print('not present')\n",
    "removed = set(prevpublic) - set(genes_tpm.index)\n",
    "print(removed)\n",
    "print('removed for QC reasons')\n",
    "print(set(rename.keys()))\n",
    "print('removed')\n",
    "removed = set(public_rna) - set(genes_tpm.index)\n",
    "print(removed - set(rename.keys()))\n",
    "missing = set(public) - set(genes_tpm.index)\n",
    "embargo = set(genes_tpm.index) - (prevpublic | set(public))\n",
    "print('missing')\n",
    "print(missing)\n",
    "newlines = set(public) \n",
    "print('embargo')\n",
    "print(len(embargo), embargo)\n",
    "print(newlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1405\n",
      "1376\n",
      "1405\n",
      "1376\n",
      "1405\n",
      "1376\n",
      "1405\n",
      "1376\n",
      "1404\n",
      "1375\n",
      "1404\n",
      "1375\n"
     ]
    }
   ],
   "source": [
    "## removing first blacklisted, then embargoed, to create two datasets\n",
    "print(len(genes_expected_count))\n",
    "genes_expected_count = genes_expected_count[~genes_expected_count.index.isin(embargo)]\n",
    "print(len(genes_expected_count))\n",
    "genes_expected_count.to_csv('temp/expression_genes_expected_count.csv')\n",
    "print(len(genes_tpm))\n",
    "genes_tpm = genes_tpm[~genes_tpm.index.isin(embargo)]\n",
    "print(len(genes_tpm))\n",
    "genes_tpm.to_csv('temp/expression_genes_tpm.csv')\n",
    "print(len(proteincoding_genes_tpm))\n",
    "proteincoding_genes_tpm = proteincoding_genes_tpm[~proteincoding_genes_tpm.index.isin(embargo)]\n",
    "print(len(proteincoding_genes_tpm))\n",
    "proteincoding_genes_tpm.to_csv('temp/expression_proteincoding_genes_tpm.csv')\n",
    "print(len(transcripts_tpm))\n",
    "transcripts_tpm = transcripts_tpm[~transcripts_tpm.index.isin(embargo)]\n",
    "print(len(transcripts_tpm))\n",
    "transcripts_tpm.to_csv('temp/expression_transcripts_tpm.csv')\n",
    "print(len(proteincoding_genes_expected_count))\n",
    "proteincoding_genes_expected_count = proteincoding_genes_expected_count[~proteincoding_genes_expected_count.index.isin(embargo)]\n",
    "print(len(proteincoding_genes_expected_count))\n",
    "proteincoding_genes_expected_count.to_csv('temp/expression_proteincoding_genes_expected_count.csv')\n",
    "print(len(transcripts_expected_count))\n",
    "transcripts_expected_count = transcripts_expected_count[~transcripts_expected_count.index.isin(embargo)]\n",
    "print(len(transcripts_expected_count))\n",
    "transcripts_expected_count.to_csv('temp/expression_transcripts_expected_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading expression_genes_expected_count...\n",
      "hitting https://cds.team/taiga/api/datafile/f185c92e3504461ea65f139ccf545935\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_genes_expected_count properly converted and uploaded\n",
      "Uploading expression_transcripts_tpm...\n",
      "hitting https://cds.team/taiga/api/datafile/f185c92e3504461ea65f139ccf545935\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_transcripts_tpm properly converted and uploaded\n",
      "Uploading expression_genes_tpm...\n",
      "hitting https://cds.team/taiga/api/datafile/f185c92e3504461ea65f139ccf545935\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_genes_tpm properly converted and uploaded\n",
      "Uploading expression_proteincoding_genes_tpm...\n",
      "hitting https://cds.team/taiga/api/datafile/f185c92e3504461ea65f139ccf545935\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_proteincoding_genes_tpm properly converted and uploaded\n",
      "Uploading expression_proteincoding_genes_expected_count...\n",
      "hitting https://cds.team/taiga/api/datafile/f185c92e3504461ea65f139ccf545935\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_proteincoding_genes_expected_count properly converted and uploaded\n",
      "Uploading expression_transcripts_expected_count...\n",
      "hitting https://cds.team/taiga/api/datafile/f185c92e3504461ea65f139ccf545935\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: expression_transcripts_expected_count properly converted and uploaded\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset version with id e964dfa4d9414ee2b211977b2e2877db created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/e964dfa4d9414ee2b211977b2e2877db\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'e964dfa4d9414ee2b211977b2e2877db'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.update_dataset(dataset_permaname=\"depmap-rnaseq-expression-data-ccd0\",\n",
    "                 upload_file_path_dict={\n",
    "                     'temp/expression_genes_expected_count.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_transcripts_tpm.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_genes_tpm.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_proteincoding_genes_tpm.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_proteincoding_genes_expected_count.csv': 'NumericMatrixCSV',\n",
    "                   'temp/expression_transcripts_expected_count.csv': 'NumericMatrixCSV'},\n",
    "                  dataset_description=\n",
    "\"\"\"\n",
    "# PUBLIC RNA\n",
    "\n",
    "* Version 1-2 Public 18Q1*\n",
    "\n",
    "Original source (`CCLE_DepMap_18Q1_RNAseq_reads_20180214.gct`, `CCLE_DepMap_18Q1_RNAseq_RPKM_20180214.gct`) downloaded from portals.broadinstitute.org/ccle\n",
    "RPKM file is log2(RPKM) with a \"noisy floor\" around -3 (-3 + N(0, 0.1))\n",
    "\n",
    "* Version 3-5 Public 18Q2*\n",
    "\n",
    "gene expression data (RNAseq for1,076 cell lines, including data for 28 newly released cell lines)\n",
    "\n",
    "original source: (`/xchip/ccle_dist/public/DepMap_18Q2/CCLE_DepMap_18Q2_RNAseq_RPKM_20180502.gct`, `/xchip/ccle_dist/public/DepMap_18Q2/CCLE_DepMap_18Q2_RNAseq_reads_20180502.gct`)\n",
    "* Version 6-7 Public 18Q3*\n",
    "\n",
    "gene expression data (80 newly released cell lines)\n",
    "\n",
    "Original data source:\n",
    "\n",
    "`/xchip/ccle_dist/public/DepMap_18Q3/CCLE_DepMap_18q3_RNAseq_reads_20180718.gct`\n",
    "`/xchip/ccle_dist/public/DepMap_18Q3/CCLE_DepMap_18q3_RNAseq_RPKM_20180718.gct`\n",
    "\n",
    "RPKM data are log2-transformed with a noisy floor at -3 (-3 + N(0, 0.1)). Reads file unaltered aside from formatting row / column names.\n",
    "\n",
    "The ProteinCoding datasets contain just protein coding genes and are based on protein coding annotations from https://www.genenames.org/cgi-bin/download (locus_group == \"protein-coding gene\")\n",
    "\n",
    "Rows: are Broad (Arxspan) cell line IDs. Mapping between Broad IDs and CCLE IDs can be done using a R or python package\n",
    "\n",
    "To install R implementation: options(repos = c(\"https://iwww.broadinstitute.org/~datasci/R-packages\", \"https://cran.cnr.berkeley.edu\")) install.packages('celllinemapr')\n",
    "\n",
    "To install python implementation: pip install https://intranet.broadinstitute.org/~datasci/python-packages/cell_line_mapper-0.1.9.tar.gz)\n",
    "\n",
    "Columns: In the complete RPKM and read datasets column names are HGNC_symbol (Ensembl_ID), while in the ProteinCoding RPKM and read datasets column names are HGNC_symbol (Entrez_ID)\n",
    "\n",
    "version 7 removes duplicate gene names from the protein coding datasets\n",
    "\n",
    "* Version 8-9 Public 18Q4*\n",
    "\n",
    "_ 18Q4 transcript level data is found in version 11. (In versions 8-9 transcript data contains only gene level not transcript level data)\n",
    "\n",
    "changing to TPM expression\n",
    "\n",
    "Original data source:\n",
    "\n",
    "`/xchip/ccle_dist/broad_only/CMAG/expression/CCLE_DepMap_18Q4_rsem_genes_tpm_20181029.txt`\n",
    "`/xchip/ccle_dist/broad_only/CMAG/expression/CCLE_DepMap_18Q4_rsem_transcripts_tpm_20181029.gct`\n",
    "`/xchip/ccle_dist/public/DepMap_18Q4/CCLE_DepMap_18q4_RNAseq_reads_20181029.gct`\n",
    "\n",
    "`/xchip/ccle_dist/public/DepMap_18Q4/CCLE_DepMap_18q4_RNAseq_RPKM_20181029.gct`\n",
    "\n",
    "TPM data is subsetted to just public cell lines using the cell line found in the RPKM dataset.\n",
    "\n",
    "TPM data is the primary expression data now. It is log2-transformed with a pseudo count of 1 added\n",
    "\n",
    "RPKM data are log2-transformed with a pseudo count of 1 added. RPKM values are no longer thresholded.\n",
    "\n",
    "Reads/transcript files unaltered aside from formatting row / column names.\n",
    "\n",
    "The ProteinCoding datasets contain just protein coding genes and are based on protein coding annotations from https://www.genenames.org/cgi-bin/download (locus_group == \"protein-coding gene\")\n",
    "\n",
    "Rows: are DepMap (Arxspan) cell line IDs\n",
    "\n",
    "Columns: In the complete TPM, TPM transcripts, RPKM and read datasets column names are HGNC_symbol (Ensembl_ID), while in the ProteinCoding TPM and read datasets column names are HGNC_symbol (Entrez_ID)\n",
    "\n",
    "* Version 10-12 Public 19Q1*\n",
    "\n",
    "version 12 contains the correct data for 19Q1\n",
    "\n",
    "version 11 contains the correct transcript level data for 19Q1 and 18Q4\n",
    "\n",
    "* Version 13 Public 19Q2*\n",
    "\n",
    "* Version 14 Public 19Q3*\n",
    "\n",
    "* Version 15 Public 19Q4*\n",
    "Adding 93 new cell lines - Blacklisted - IBM - DMC\n",
    "Some cells lines have been removed because they:\n",
    "\n",
    " - had too many 0 values = [\"ACH-001388\" \"ACH-001577\" \"ACH-001767\" \"ACH-002463\"] \n",
    "\n",
    "Some cells lines have been flagged as:\n",
    "\n",
    " - None\n",
    " \n",
    "* Version 16 Public 19Q4*\n",
    "removing unauthorized cell lines\n",
    "\n",
    "* Version 17 Public 20Q1*\n",
    "adding 6 new lines\n",
    "\n",
    "* Version 18 Public 20Q1\n",
    "Unknown reupdate\n",
    "\n",
    "* Version 19 Public 20Q2\n",
    "adding  new cell lines\n",
    "\n",
    "* Version 20 Public 20Q2\n",
    "unknown reupload\n",
    "\n",
    "* Version 21 Public 20Q2\n",
    "removing some missed blacklisted lines\n",
    "\n",
    "* Version 22 Public 20Q3\n",
    "nothing different from  20Q2. no new cell lines added\n",
    "\n",
    "* Version 23 Public 20Q3\n",
    "Some wrong annotations in the blacklists\n",
    "\n",
    "* Version 24 Public 20Q3\n",
    "Updated annotations in the blacklists\n",
    "\n",
    "* Version 25 Public 20Q3\n",
    "Updated the dmc list\n",
    "\n",
    "* Version 25 Public 20Q3\n",
    "Readding a cell line that was already in public before.\n",
    "\n",
    "* Version 26 Public 20Q4\n",
    "new samples, adding a new QC method that removed 10 samples. fully adding the reprocessed samples, removing some wrong genes, adding falsely removed genes (that are still expressed)\n",
    "\n",
    "* Version 26 Public 20Q4\n",
    "adding log transform\n",
    "\n",
    "* Version 27 Public 20Q4\n",
    "reverting gene names\n",
    "\n",
    "* Version 28 Public 20Q4\n",
    "removing more lines\n",
    "\n",
    "data is hg38 aligned\n",
    "\n",
    "read count data is created using RSEM, which, when a read maps to multiple places, splits the counts between genes, with the weight based on the likelihood that it came from one gene or the other, so counts data may not be integers\n",
    "\n",
    "TPM data is log2-transformed with a pseudo count of 1 added. log2(X+1)\n",
    "\n",
    "Reads/transcript files unaltered aside from formatting row / column names.\n",
    "\n",
    "The ProteinCoding datasets contain just protein coding genes and are based on protein coding annotations from https://www.genenames.org/cgi-bin/download (locus_group == \"protein-coding gene\")\n",
    "\n",
    "reverting gene names\n",
    "Rows: are DepMap cell line IDs\n",
    "\n",
    "Columns: In the complete TPM and read counts datasets column names are HGNC_symbol (Ensembl_ID), while in the ProteinCoding TPM dataset column names are HGNC_symbol (Entrez_ID). In the TPM transcript dataset column names are HGNC_symbol (Transcript_ID) - the HGNC symbols are not unique, use the transcript IDs for unique identifiers.\n",
    "\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "REMOVED FOR QC REASONS:\n",
    "\"\"\"+str(rename)+\"\"\"\n",
    "\n",
    "BLACKLIST:\n",
    "\"\"\"+str(embargo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CCLE_expression_full', 'depmap-rnaseq-expression-data-ccd0.31/expression_genes_expected_count'), ('CCLE_RNAseq_transcripts', 'depmap-rnaseq-expression-data-ccd0.31/expression_transcripts_tpm'), ('CCLE_RNAseq_reads', 'depmap-rnaseq-expression-data-ccd0.31/expression_genes_tpm'), ('CCLE_expression', 'depmap-rnaseq-expression-data-ccd0.31/expression_proteincoding_genes_tpm'), ('expression_proteincoding_genes_expected_count', 'depmap-rnaseq-expression-data-ccd0.31/expression_proteincoding_genes_expected_count'), ('expression_transcripts_expected_count', 'depmap-rnaseq-expression-data-ccd0.31/expression_transcripts_expected_count')]\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datafile/2df40e32ef21449dbff869bce1d1d918\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 9a44587ab0e342c89c3323ffb60a8958 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/9a44587ab0e342c89c3323ffb60a8958\n"
     ]
    }
   ],
   "source": [
    "AddToVirtual(virtual_public, \"depmap-rnaseq-expression-data-ccd0\", files=[('CCLE_expression_full', 'expression_genes_expected_count'), \n",
    "('CCLE_RNAseq_transcripts', 'expression_transcripts_tpm'),\n",
    "('CCLE_RNAseq_reads', 'expression_genes_tpm'),\n",
    "('CCLE_expression', 'expression_proteincoding_genes_tpm'), ('expression_proteincoding_genes_expected_count', 'expression_proteincoding_genes_expected_count'),('expression_transcripts_expected_count', 'expression_transcripts_expected_count')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'temp/unfiltered_fusions_20Q4.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-e248d4212cc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfusions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'temp/unfiltered_fusions_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'temp/fusions_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'temp/unfiltered_fusions_20Q4.csv'"
     ]
    }
   ],
   "source": [
    "fusions=pd.read_csv('temp/unfiltered_fusions_'+release+'.csv')\n",
    "filtered=pd.read_csv('temp/fusions_'+release+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not present\n",
      "{'ACH-002196', 'ACH-002205', 'ACH-002289', 'ACH-001064', 'ACH-001641', 'ACH-002127', 'ACH-002344', 'ACH-002384', 'ACH-002383', 'ACH-002157', 'ACH-001037', 'ACH-001143', 'ACH-002216', 'ACH-001680', 'ACH-000727', 'ACH-002351', 'ACH-002207', 'ACH-002114', 'ACH-002300', 'ACH-000795', 'ACH-002377', 'ACH-002204', 'ACH-002360', 'ACH-002292', 'ACH-002058', 'ACH-002104', 'ACH-002314', 'ACH-002183', 'ACH-002213', 'ACH-002168', 'ACH-002382', 'ACH-002260', 'ACH-001208', 'ACH-002095', 'ACH-002200', 'ACH-002269', 'ACH-002387', 'ACH-002375', 'ACH-002129', 'ACH-001199', 'ACH-002312', 'ACH-000561', 'ACH-002282', 'ACH-002395', 'ACH-001338', 'ACH-002232', 'ACH-002267', 'ACH-002190', 'ACH-001502', 'ACH-001093', 'ACH-002336', 'ACH-002281', 'ACH-001137', 'ACH-002199', 'ACH-002208', 'ACH-002185', 'ACH-002276', 'ACH-002374', 'ACH-002396', 'ACH-001383', 'ACH-002237', 'ACH-001151', 'ACH-002119', 'ACH-002136', 'ACH-002359', 'ACH-001182', 'ACH-002399', 'ACH-002106', 'ACH-001187', 'ACH-002394', 'ACH-002180', 'ACH-001045', 'ACH-002291', 'ACH-002230', 'ACH-002193', 'ACH-001089', 'ACH-001331', 'ACH-002401', 'ACH-002147', 'ACH-002242', 'ACH-002361', 'ACH-001205', 'ACH-002201', 'ACH-002191', 'ACH-002143', 'ACH-001203', 'ACH-002290', 'ACH-002188', 'ACH-001018', 'ACH-002294', 'ACH-002247', 'ACH-002167', 'ACH-002391', 'ACH-001125', 'ACH-001591', 'ACH-001118', 'ACH-002159', 'ACH-002197', 'ACH-002253', 'ACH-002102', 'ACH-001023', 'ACH-002238', 'ACH-002182', 'ACH-002198', 'ACH-002175', 'ACH-001599', 'ACH-002250', 'ACH-002284', 'ACH-002091', 'ACH-001233', 'ACH-002299', 'ACH-001092', 'ACH-002369', 'ACH-002123', 'ACH-002305', 'ACH-002141', 'ACH-001767', 'ACH-002341', 'ACH-002350', 'ACH-001011', 'ACH-002296', 'ACH-002169', 'ACH-001101', 'ACH-002128', 'ACH-002235', 'ACH-002093', 'ACH-002367', 'ACH-001225', 'ACH-001127', 'ACH-002125', 'ACH-002225', 'ACH-002297', 'ACH-002224', 'ACH-002315', 'ACH-001044', 'ACH-002266', 'ACH-002400', 'ACH-001350', 'ACH-001648', 'ACH-002380', 'ACH-002231', 'ACH-002096', 'ACH-002274', 'ACH-002379', 'ACH-002135', 'ACH-002043', 'ACH-001042', 'ACH-002275', 'ACH-001072', 'ACH-002146', 'ACH-002302', 'ACH-001065', 'ACH-002392', 'ACH-002277', 'ACH-002152', 'ACH-002217', 'ACH-002113', 'ACH-002288', 'ACH-002378', 'ACH-002099', 'ACH-001364', 'ACH-002163', 'ACH-002293', 'ACH-002246', 'ACH-002124', 'ACH-002372', 'ACH-002174', 'ACH-002243', 'ACH-002162', 'ACH-002342', 'ACH-002339', 'ACH-002210', 'ACH-001189', 'ACH-002212', 'ACH-001091', 'ACH-001066', 'ACH-001214', 'ACH-002256', 'ACH-002121', 'ACH-002228', 'ACH-002221', 'ACH-002134', 'ACH-002280', 'ACH-002349', 'ACH-002255', 'ACH-002337', 'ACH-002287', 'ACH-002132', 'ACH-002283', 'ACH-000426', 'ACH-001094', 'ACH-002209', 'ACH-001150', 'ACH-001000', 'ACH-002107', 'ACH-002089', 'ACH-001017', 'ACH-001224', 'ACH-002279', 'ACH-002270', 'ACH-002273', 'ACH-002112', 'ACH-001108', 'ACH-000992', 'ACH-002229', 'ACH-002150', 'ACH-001490', 'ACH-002338', 'ACH-002186', 'ACH-002239', 'ACH-002202', 'ACH-002097', 'ACH-002286', 'ACH-002272', 'ACH-001206', 'ACH-001738', 'ACH-002397', 'ACH-002131', 'ACH-001087', 'ACH-002304', 'ACH-001071', 'ACH-002365', 'ACH-001021', 'ACH-001230', 'ACH-002108', 'ACH-001363', 'ACH-001136', 'ACH-002259', 'ACH-002051', 'ACH-002101', 'ACH-002153', 'ACH-002020', 'ACH-002301', 'ACH-001131', 'ACH-000309', 'ACH-000979', 'ACH-002120', 'ACH-002346', 'ACH-002358', 'ACH-001126', 'ACH-001039', 'ACH-002393', 'ACH-001452', 'ACH-002262', 'ACH-002040', 'ACH-002189', 'ACH-002268', 'ACH-002094', 'ACH-002381', 'ACH-002092', 'ACH-002241', 'ACH-002370', 'ACH-002165', 'ACH-002144', 'ACH-002245', 'ACH-002187', 'ACH-002285', 'ACH-002116', 'ACH-001171', 'ACH-001958', 'ACH-002356', 'ACH-002130', 'ACH-002233', 'ACH-002376', 'ACH-002364', 'ACH-002098', 'ACH-001146', 'ACH-002264', 'ACH-002178', 'ACH-002171', 'ACH-001512', 'ACH-001606', 'ACH-001234', 'ACH-001002', 'ACH-002149', 'ACH-002308', 'ACH-002122', 'ACH-002220', 'ACH-002317', 'ACH-001049', 'ACH-002316', 'ACH-002252', 'ACH-002118', 'ACH-002140', 'ACH-001198', 'ACH-002109', 'ACH-002126', 'ACH-002340', 'ACH-001090', 'ACH-001015', 'ACH-001121', 'ACH-001957', 'ACH-002306', 'ACH-001079', 'ACH-002160', 'ACH-002148', 'ACH-001047', 'ACH-002353', 'ACH-002311', 'ACH-001358', 'ACH-002257', 'ACH-002313', 'ACH-001293', 'ACH-001417', 'ACH-001081', 'ACH-001359', 'ACH-002117', 'ACH-002388', 'ACH-001955', 'ACH-002166', 'ACH-002192', 'ACH-002386', 'ACH-002145', 'ACH-002184', 'ACH-002348', 'ACH-002176', 'ACH-002310', 'ACH-002362', 'ACH-002347', 'ACH-001639', 'ACH-001704', 'ACH-002248', 'ACH-001024', 'ACH-002278', 'ACH-002139', 'ACH-002254', 'ACH-002249', 'ACH-002103', 'ACH-002105', 'ACH-002240', 'ACH-002155', 'ACH-001130', 'ACH-002389', 'ACH-002223', 'ACH-001175', 'ACH-002181', 'ACH-002307', 'ACH-002390', 'ACH-002100', 'ACH-002211', 'ACH-000047', 'ACH-001489', 'ACH-002354', 'ACH-002357', 'ACH-002335', 'ACH-002709', 'ACH-002343', 'ACH-001162', 'ACH-001088', 'ACH-002298', 'ACH-002214', 'ACH-002265', 'ACH-002194', 'ACH-002111', 'ACH-001355', 'ACH-001362', 'ACH-002215', 'ACH-002206', 'ACH-002371', 'ACH-002352', 'ACH-002156', 'ACH-002177', 'ACH-002355', 'ACH-002234', 'ACH-002244', 'ACH-001249', 'ACH-001063', 'ACH-001107', 'ACH-002345', 'ACH-002251', 'ACH-002090', 'ACH-002368', 'ACH-001365', 'ACH-002236', 'ACH-002052', 'ACH-002303', 'ACH-002173', 'ACH-001544', 'ACH-002170', 'ACH-002195', 'ACH-001138', 'ACH-002366', 'ACH-002133', 'ACH-002110', 'ACH-002222', 'ACH-002295', 'ACH-002271', 'ACH-002363', 'ACH-002154', 'ACH-001043', 'ACH-002115', 'ACH-002226', 'ACH-002142', 'ACH-001956', 'ACH-002309', 'ACH-001188', 'ACH-002083', 'ACH-002261', 'ACH-002161', 'ACH-002179', 'ACH-002263', 'ACH-002258', 'ACH-002227', 'ACH-002164', 'ACH-002218', 'ACH-002373', 'ACH-001282', 'ACH-002151', 'ACH-002077'}\n",
      "removed for QC reasons\n",
      "{'ACH-000992', 'ACH-001293', 'ACH-002709', 'ACH-001502', 'ACH-001143', 'ACH-000309', 'ACH-001205', 'ACH-000979', 'ACH-000426', 'ACH-000047', 'ACH-001512', 'ACH-000795', 'ACH-000727'}\n",
      "removed\n",
      "{'ACH-000561'}\n",
      "missing\n",
      "{'ACH-001648'}\n",
      "blacklist\n",
      "8 {'ACH-001756', 'ACH-002055', 'ACH-001760', 'ACH-002476', 'ACH-001686', 'ACH-001758', 'ACH-001759', 'ACH-001434'}\n"
     ]
    }
   ],
   "source": [
    "print('not present')\n",
    "removed = set(previnternal) - set(fusions.DepMap_ID)\n",
    "print(removed)\n",
    "print('removed for QC reasons')\n",
    "print(set(rename.keys()))\n",
    "print('removed')\n",
    "removed = set(internal_rna) - set(fusions.DepMap_ID)\n",
    "print(removed - set(rename.keys()))\n",
    "missing = set(internal) - set(fusions.DepMap_ID)\n",
    "blacklist = set(fusions.DepMap_ID) - (previnternal | set(internal))\n",
    "print('missing')\n",
    "print(missing)\n",
    "newlines = set(internal) \n",
    "print('blacklist')\n",
    "print(len(blacklist), blacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357747\n",
      "356696\n",
      "44411\n",
      "44066\n"
     ]
    }
   ],
   "source": [
    "## removing first blacklisted, then embargoed, to create two datasets\n",
    "print(len(fusions))\n",
    "fusions = fusions[~fusions.DepMap_ID.isin(blacklist)]\n",
    "print(len(fusions))\n",
    "fusions.to_csv('temp/fusions.csv', index=False)\n",
    "print(len(filtered))\n",
    "filtered= filtered[~filtered.DepMap_ID.isin(blacklist)]\n",
    "print(len(filtered))\n",
    "filtered.to_csv('temp/filtered_fusions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading fusions...\n",
      "hitting https://cds.team/taiga/api/datafile/5a3c17c40fc44cf6946175ded53da89d\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: fusions properly converted and uploaded\n",
      "Uploading filtered_fusions...\n",
      "hitting https://cds.team/taiga/api/datafile/5a3c17c40fc44cf6946175ded53da89d\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: filtered_fusions properly converted and uploaded\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 3fac9d6b279142438588a794f0da440a created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/3fac9d6b279142438588a794f0da440a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3fac9d6b279142438588a794f0da440a'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.update_dataset(dataset_permaname=\"gene-fusions-8b7a\",\n",
    "                 upload_file_path_dict={\n",
    "                     'temp/fusions.csv': 'TableCSV',\n",
    "                     'temp/filtered_fusions.csv': 'TableCSV'},\n",
    "                  dataset_description=\n",
    "\"\"\"\n",
    "# Internal Fusions\n",
    "\n",
    "Description: Gene fusions derived from RNAseq data.\n",
    "\n",
    "Rows: cell lines\n",
    "\n",
    "Original Raw Data: Generated by Mahmoud Ghandi on April 25, 2017. Can be found at xchip_ccle_dist/broad_only/unpublished_Novartis_data/RNAseq/fusions.txt\n",
    "\n",
    "Version 3: added a column containing the Broad_ID\n",
    "\n",
    "* Version 4-5 Internal 19Q1*\n",
    "\n",
    "version 5 contains the correct data for 19Q1\n",
    "\n",
    "Description: Gene fusions derived from RNAseq data.\n",
    "\n",
    "Rows: cell lines\n",
    "\n",
    "* Version 6 Internal 19Q2*\n",
    "\n",
    "* Version 7*\n",
    "\n",
    "Josh D added \"common_fusion_matrix\".\n",
    "\n",
    "Binary matrix of the most common gene fusions (those where the two involved genes are fused in at least 5 cell lines) with no additional filtering. Use at your own risk.\n",
    "\n",
    "Description: Gene fusions derived from RNAseq data.\n",
    "\n",
    "Rows: cell lines\n",
    "\n",
    "* Version 8 Internal 19Q3*\n",
    "\n",
    "* Version 9 Internal 19Q4*\n",
    "\n",
    "* Version 10 Internal 20Q1*\n",
    "Adding new lines\n",
    "\n",
    "* Version 11 Internal 20Q1*\n",
    "Adding a file\n",
    "\n",
    "* Version 12 Internal 20Q2*\n",
    "Adding 50 new lines\n",
    "\n",
    "* Version 13 Internal 20Q3*\n",
    "nothing different from  20Q2. no new cell lines added\n",
    "\n",
    "* Version 14 Internal 20Q3*\n",
    "issues with the blacklists\n",
    "\n",
    "* Version 15 Internal 20Q4*\n",
    "adding new lines, new fusion filtering, debugged sample filtering (should recover the same sample as in expression dataset).\n",
    "\n",
    "* Version 16 Internal 20Q4*\n",
    "renaming fusions\n",
    "\n",
    "Description: Gene fusions derived from RNAseq data.\n",
    "\n",
    "Rows: cell lines, IDs contained in the column DepMap_ID\n",
    "\n",
    "Unfiltered data contains all output fusions, while the filtered data uses the filters suggested by the star fusion docs. These filters are:\n",
    "- FFPM > 0.1 -  a cutoff of 0.1 means&nbsp;at least 1 fusion-supporting RNAseq fragment per 10M total reads\n",
    "- Remove known false positives, such as GTEx recurrent fusions and certain paralogs\n",
    "- Genes that are next to each other\n",
    "- Fusions with mitochondrial breakpoints\n",
    "- Removing fusion involving mitochondrial chromosomes or HLA genes\n",
    "- Removed common false positive fusions (red herring annotations as described in the STAR-Fusion docs)\n",
    "- Recurrent fusions observed in CCLE across cell lines (in 10% or more of the samples)\n",
    "- Removed fusions where SpliceType='INCL_NON_REF_SPLICE' and LargeAnchorSupport='NO_LDAS' and FFPM < 0.1\n",
    "- FFPM < 0.05\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "REMOVED FOR QC REASONS:\n",
    "\"\"\"+str(rename)+\"\"\"\n",
    "\n",
    "BLACKLIST:\n",
    "\"\"\"+str(blacklist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CCLE_fusions_unfiltered', 'gene-fusions-8b7a.16/fusions'), ('CCLE_fusions', 'gene-fusions-8b7a.16/filtered_fusions')]\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datafile/e9e5878dd5db4d1585d0184db1854b46\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 7dc5923dd29d4cda930829a534d629f5 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/7dc5923dd29d4cda930829a534d629f5\n",
      "[('CCLE_fusions_unfiltered', 'gene-fusions-8b7a.16/fusions'), ('CCLE_fusions', 'gene-fusions-8b7a.16/filtered_fusions')]\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datafile/a73c2a4dc4d6405d921482142de04ee1\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 23bf1b099ff342c58aef5f3d27551c37 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/23bf1b099ff342c58aef5f3d27551c37\n"
     ]
    }
   ],
   "source": [
    "AddToVirtual('depmap-a0ab', \"gene-fusions-8b7a\", files=[('CCLE_fusions_unfiltered', 'fusions'),('CCLE_fusions', 'filtered_fusions')])\n",
    "\n",
    "AddToVirtual(virtual_internal, \"gene-fusions-8b7a\", files=[('CCLE_fusions_unfiltered', 'fusions'),('CCLE_fusions', 'filtered_fusions')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not present\n",
      "{'ACH-002121', 'ACH-002384', 'ACH-002168', 'ACH-002337', 'ACH-002139', 'ACH-002231', 'ACH-002148', 'ACH-000561', 'ACH-002193', 'ACH-002400', 'ACH-002091', 'ACH-002236', 'ACH-001092', 'ACH-002360', 'ACH-002123', 'ACH-002260', 'ACH-001767', 'ACH-002052', 'ACH-002051', 'ACH-002093', 'ACH-002096', 'ACH-002274', 'ACH-002129', 'ACH-002122', 'ACH-001037', 'ACH-002314', 'ACH-001127', 'ACH-002294', 'ACH-000426', 'ACH-002124', 'ACH-002275', 'ACH-002105', 'ACH-001131', 'ACH-002194', 'ACH-002097', 'ACH-002264', 'ACH-002208', 'ACH-001064', 'ACH-002313', 'ACH-002133', 'ACH-002358', 'ACH-002154', 'ACH-002396', 'ACH-002181', 'ACH-001047', 'ACH-002229', 'ACH-002307', 'ACH-002374', 'ACH-001639', 'ACH-002226', 'ACH-002190', 'ACH-001045', 'ACH-002151', 'ACH-002182', 'ACH-002201', 'ACH-002270', 'ACH-001118', 'ACH-002204', 'ACH-002178', 'ACH-002210', 'ACH-002271', 'ACH-002283', 'ACH-001225', 'ACH-002369', 'ACH-002285', 'ACH-001224', 'ACH-002180', 'ACH-002290', 'ACH-001359', 'ACH-002394', 'ACH-001065', 'ACH-002401', 'ACH-001021', 'ACH-002128', 'ACH-002147', 'ACH-001015', 'ACH-002258', 'ACH-002112', 'ACH-002361', 'ACH-002393', 'ACH-002256', 'ACH-002132', 'ACH-002161', 'ACH-001072', 'ACH-002058', 'ACH-002259', 'ACH-001417', 'ACH-002265', 'ACH-002284', 'ACH-002296', 'ACH-002098', 'ACH-002239', 'ACH-002268', 'ACH-002143', 'ACH-002205', 'ACH-002140', 'ACH-002263', 'ACH-001042', 'ACH-001189', 'ACH-002266', 'ACH-001355', 'ACH-002371', 'ACH-002311', 'ACH-002077', 'ACH-002167', 'ACH-001121', 'ACH-002291', 'ACH-002225', 'ACH-002359', 'ACH-002305', 'ACH-000309', 'ACH-002262', 'ACH-001091', 'ACH-002287', 'ACH-002171', 'ACH-002355', 'ACH-000992', 'ACH-001151', 'ACH-001591', 'ACH-002237', 'ACH-001363', 'ACH-001101', 'ACH-002125', 'ACH-002344', 'ACH-002378', 'ACH-002095', 'ACH-002310', 'ACH-002312', 'ACH-002185', 'ACH-002336', 'ACH-002233', 'ACH-001175', 'ACH-002111', 'ACH-001066', 'ACH-002267', 'ACH-001249', 'ACH-002293', 'ACH-002389', 'ACH-002200', 'ACH-002250', 'ACH-002107', 'ACH-002387', 'ACH-002118', 'ACH-001502', 'ACH-002117', 'ACH-002094', 'ACH-002120', 'ACH-002364', 'ACH-002391', 'ACH-002342', 'ACH-002375', 'ACH-001079', 'ACH-001738', 'ACH-002368', 'ACH-001606', 'ACH-001125', 'ACH-002090', 'ACH-002335', 'ACH-001957', 'ACH-002223', 'ACH-002347', 'ACH-001146', 'ACH-002282', 'ACH-001090', 'ACH-002317', 'ACH-001489', 'ACH-002214', 'ACH-001331', 'ACH-001214', 'ACH-002253', 'ACH-001182', 'ACH-002353', 'ACH-001187', 'ACH-002187', 'ACH-001234', 'ACH-002352', 'ACH-002126', 'ACH-002166', 'ACH-001063', 'ACH-002216', 'ACH-001648', 'ACH-002153', 'ACH-002242', 'ACH-002390', 'ACH-001093', 'ACH-001958', 'ACH-002127', 'ACH-002134', 'ACH-001956', 'ACH-002141', 'ACH-002164', 'ACH-002159', 'ACH-002343', 'ACH-002101', 'ACH-002280', 'ACH-002102', 'ACH-002341', 'ACH-001203', 'ACH-002195', 'ACH-002349', 'ACH-002365', 'ACH-002244', 'ACH-001955', 'ACH-001188', 'ACH-002276', 'ACH-002338', 'ACH-002040', 'ACH-002357', 'ACH-001136', 'ACH-002272', 'ACH-002108', 'ACH-001198', 'ACH-001017', 'ACH-002340', 'ACH-002346', 'ACH-002300', 'ACH-002222', 'ACH-002241', 'ACH-002152', 'ACH-002249', 'ACH-002279', 'ACH-001002', 'ACH-002709', 'ACH-002388', 'ACH-001143', 'ACH-001199', 'ACH-002188', 'ACH-002292', 'ACH-002257', 'ACH-002366', 'ACH-002198', 'ACH-002092', 'ACH-002288', 'ACH-002212', 'ACH-002115', 'ACH-002163', 'ACH-002220', 'ACH-001018', 'ACH-002351', 'ACH-002261', 'ACH-002169', 'ACH-002363', 'ACH-002246', 'ACH-001205', 'ACH-002345', 'ACH-002145', 'ACH-001087', 'ACH-001171', 'ACH-002238', 'ACH-002196', 'ACH-002298', 'ACH-000795', 'ACH-002306', 'ACH-002183', 'ACH-002221', 'ACH-001364', 'ACH-002356', 'ACH-002113', 'ACH-002110', 'ACH-002174', 'ACH-002109', 'ACH-002089', 'ACH-002177', 'ACH-001338', 'ACH-001039', 'ACH-002131', 'ACH-002301', 'ACH-002373', 'ACH-002100', 'ACH-002392', 'ACH-002240', 'ACH-001126', 'ACH-002106', 'ACH-002136', 'ACH-001362', 'ACH-002281', 'ACH-002179', 'ACH-001049', 'ACH-002142', 'ACH-002235', 'ACH-002209', 'ACH-001680', 'ACH-002248', 'ACH-002202', 'ACH-002254', 'ACH-002227', 'ACH-001365', 'ACH-002286', 'ACH-002104', 'ACH-001704', 'ACH-001452', 'ACH-001011', 'ACH-001081', 'ACH-001043', 'ACH-002228', 'ACH-002376', 'ACH-002156', 'ACH-001162', 'ACH-002175', 'ACH-002189', 'ACH-002170', 'ACH-002304', 'ACH-002350', 'ACH-002114', 'ACH-002207', 'ACH-002295', 'ACH-002211', 'ACH-002160', 'ACH-002234', 'ACH-002206', 'ACH-002099', 'ACH-002299', 'ACH-002247', 'ACH-001350', 'ACH-002150', 'ACH-001206', 'ACH-002165', 'ACH-002309', 'ACH-002149', 'ACH-002362', 'ACH-002176', 'ACH-001358', 'ACH-002217', 'ACH-001023', 'ACH-002315', 'ACH-001000', 'ACH-002277', 'ACH-002215', 'ACH-002395', 'ACH-002399', 'ACH-002377', 'ACH-002243', 'ACH-001108', 'ACH-002302', 'ACH-002348', 'ACH-002370', 'ACH-002380', 'ACH-002144', 'ACH-002218', 'ACH-002303', 'ACH-002379', 'ACH-002255', 'ACH-002372', 'ACH-002308', 'ACH-000047', 'ACH-001137', 'ACH-002184', 'ACH-002197', 'ACH-002289', 'ACH-002224', 'ACH-001282', 'ACH-001150', 'ACH-002230', 'ACH-002103', 'ACH-001044', 'ACH-000979', 'ACH-002367', 'ACH-001094', 'ACH-002130', 'ACH-002381', 'ACH-002192', 'ACH-002199', 'ACH-002252', 'ACH-002339', 'ACH-002297', 'ACH-001107', 'ACH-002383', 'ACH-002146', 'ACH-001230', 'ACH-001024', 'ACH-001544', 'ACH-001383', 'ACH-002157', 'ACH-002273', 'ACH-001641', 'ACH-002251', 'ACH-001490', 'ACH-002083', 'ACH-002043', 'ACH-002386', 'ACH-001208', 'ACH-001293', 'ACH-002278', 'ACH-000727', 'ACH-002397', 'ACH-002155', 'ACH-002186', 'ACH-001088', 'ACH-002316', 'ACH-001071', 'ACH-002162', 'ACH-002020', 'ACH-001130', 'ACH-002269', 'ACH-002213', 'ACH-001233', 'ACH-002119', 'ACH-002354', 'ACH-002173', 'ACH-001089', 'ACH-002135', 'ACH-002191', 'ACH-001599', 'ACH-002116', 'ACH-002232', 'ACH-001138', 'ACH-002382', 'ACH-002245'}\n",
      "removed for QC reasons\n",
      "{'ACH-002709', 'ACH-001502', 'ACH-001512', 'ACH-000795', 'ACH-000047', 'ACH-001205', 'ACH-001143', 'ACH-000979', 'ACH-001293', 'ACH-000992', 'ACH-000426', 'ACH-000309', 'ACH-000727'}\n",
      "removed\n",
      "{'ACH-000561'}\n",
      "missing\n",
      "{'ACH-001648'}\n",
      "embargo_ibm\n",
      "2 {'ACH-001708', 'ACH-001393'}\n"
     ]
    }
   ],
   "source": [
    "print('not present')\n",
    "removed = set(prevdmc) - set(fusions.DepMap_ID)\n",
    "print(removed)\n",
    "print('removed for QC reasons')\n",
    "print(set(rename.keys()))\n",
    "print('removed')\n",
    "removed = set(dmc_rna) - set(fusions.DepMap_ID)\n",
    "print(removed - set(rename.keys()))\n",
    "missing = set(ibm) - set(fusions.DepMap_ID)\n",
    "embargo_ibm = set(fusions.DepMap_ID) - (prevdmc | set(ibm))\n",
    "print('missing')\n",
    "print(missing)\n",
    "newlines = set(ibm) \n",
    "print('embargo_ibm')\n",
    "print(len(embargo_ibm), embargo_ibm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356696\n",
      "0\n",
      "44066\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## removing first blacklisted, then embargoed, to create two datasets\n",
    "print(len(fusions))\n",
    "a = fusions[~fusions.DepMap_ID.isin(embargo_ibm | prevdmc)]\n",
    "print(len(a))\n",
    "a.to_csv('temp/fusions.csv', index=False)\n",
    "print(len(filtered))\n",
    "a= filtered[~filtered.DepMap_ID.isin(embargo_ibm | prevdmc)]\n",
    "print(len(a))\n",
    "a.to_csv('temp/unfiltered_fusions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.update_dataset(dataset_permaname=\"gene-fusions-375f\",\n",
    "                 upload_file_path_dict={\n",
    "                     'temp/fusions.csv': 'TableCSV',\n",
    "                     'temp/unfiltered_fusions.csv': 'TableCSV'},\n",
    "                  dataset_description=\n",
    "\"\"\"\n",
    "# IBM Fusions\n",
    "\n",
    "* Version 1*\n",
    "first ibm version, adding new lines, new fusion filtering, debugged sample filtering (should recover the same sample as in expression dataset).\n",
    "\n",
    "\n",
    "Rows: cell lines, IDs contained in the column DepMap_ID\n",
    "\n",
    "Unfiltered data contains all output fusions, while the filtered data uses the filters suggested by the star fusion docs. These filters are:\n",
    "- FFPM > 0.1 -  a cutoff of 0.1 means&nbsp;at least 1 fusion-supporting RNAseq fragment per 10M total reads\n",
    "- Remove known false positives, such as GTEx recurrent fusions and certain paralogs\n",
    "- Genes that are next to each other\n",
    "- Fusions with mitochondrial breakpoints\n",
    "- Removing fusion involving mitochondrial chromosomes or HLA genes\n",
    "- Removed common false positive fusions (red herring annotations as described in the STAR-Fusion docs)\n",
    "- Recurrent fusions observed in CCLE across cell lines (in 10% or more of the samples)\n",
    "- Removed fusions where SpliceType='INCL_NON_REF_SPLICE' and LargeAnchorSupport='NO_LDAS' and FFPM < 0.1\n",
    "- FFPM < 0.05\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "REMOVED FOR QC REASONS:\n",
    "\"\"\"+str(rename)+\"\"\"\n",
    "\n",
    "BLACKLIST:\n",
    "\"\"\"+str(blacklist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AddToVirtual(virtual_ibm, \"gene-fusions-375f\", files=[('CCLE_fusions', 'filtered_fusions_'+release),('CCLE_fusions_unfiltered', 'unfiltered_fusions_'+release)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not present\n",
      "{'ACH-002196', 'ACH-002205', 'ACH-002289', 'ACH-001064', 'ACH-001641', 'ACH-002127', 'ACH-002344', 'ACH-002384', 'ACH-002383', 'ACH-002157', 'ACH-001037', 'ACH-001143', 'ACH-002216', 'ACH-001680', 'ACH-000727', 'ACH-002351', 'ACH-002207', 'ACH-002114', 'ACH-002300', 'ACH-000795', 'ACH-002377', 'ACH-002204', 'ACH-002360', 'ACH-002292', 'ACH-002058', 'ACH-002104', 'ACH-002314', 'ACH-002183', 'ACH-002213', 'ACH-002168', 'ACH-002382', 'ACH-002260', 'ACH-001208', 'ACH-002095', 'ACH-002200', 'ACH-002269', 'ACH-002387', 'ACH-002375', 'ACH-002129', 'ACH-001199', 'ACH-002312', 'ACH-000561', 'ACH-002282', 'ACH-002395', 'ACH-001338', 'ACH-002232', 'ACH-002267', 'ACH-002190', 'ACH-001502', 'ACH-001093', 'ACH-002336', 'ACH-002281', 'ACH-001137', 'ACH-002199', 'ACH-002208', 'ACH-002185', 'ACH-002276', 'ACH-002374', 'ACH-002396', 'ACH-001383', 'ACH-002237', 'ACH-001151', 'ACH-002119', 'ACH-002136', 'ACH-002359', 'ACH-001182', 'ACH-002399', 'ACH-002106', 'ACH-001187', 'ACH-002394', 'ACH-002180', 'ACH-001045', 'ACH-002291', 'ACH-002230', 'ACH-002193', 'ACH-001089', 'ACH-001331', 'ACH-002401', 'ACH-002147', 'ACH-002242', 'ACH-002361', 'ACH-001205', 'ACH-002201', 'ACH-002191', 'ACH-002143', 'ACH-001203', 'ACH-002290', 'ACH-002188', 'ACH-001018', 'ACH-002294', 'ACH-002247', 'ACH-002167', 'ACH-002391', 'ACH-001125', 'ACH-001591', 'ACH-001118', 'ACH-002159', 'ACH-002197', 'ACH-002253', 'ACH-002102', 'ACH-001023', 'ACH-002238', 'ACH-002182', 'ACH-002198', 'ACH-002175', 'ACH-001599', 'ACH-002250', 'ACH-002284', 'ACH-002091', 'ACH-001233', 'ACH-002299', 'ACH-001092', 'ACH-002369', 'ACH-002123', 'ACH-002305', 'ACH-002141', 'ACH-001767', 'ACH-002341', 'ACH-002350', 'ACH-001011', 'ACH-002296', 'ACH-002169', 'ACH-001101', 'ACH-002128', 'ACH-002235', 'ACH-002093', 'ACH-002367', 'ACH-001225', 'ACH-001127', 'ACH-002125', 'ACH-002225', 'ACH-002297', 'ACH-002224', 'ACH-002315', 'ACH-001044', 'ACH-002266', 'ACH-002400', 'ACH-001350', 'ACH-001648', 'ACH-002380', 'ACH-002231', 'ACH-002096', 'ACH-002274', 'ACH-002379', 'ACH-002135', 'ACH-002043', 'ACH-001042', 'ACH-002275', 'ACH-001072', 'ACH-002146', 'ACH-002302', 'ACH-001065', 'ACH-002392', 'ACH-002277', 'ACH-002152', 'ACH-002217', 'ACH-002113', 'ACH-002288', 'ACH-002378', 'ACH-002099', 'ACH-001364', 'ACH-002163', 'ACH-002293', 'ACH-002246', 'ACH-002124', 'ACH-002372', 'ACH-002174', 'ACH-002243', 'ACH-002162', 'ACH-002342', 'ACH-002339', 'ACH-002210', 'ACH-001189', 'ACH-002212', 'ACH-001091', 'ACH-001066', 'ACH-001214', 'ACH-002256', 'ACH-002121', 'ACH-002228', 'ACH-002221', 'ACH-002134', 'ACH-002280', 'ACH-002349', 'ACH-002255', 'ACH-002337', 'ACH-002287', 'ACH-002132', 'ACH-002283', 'ACH-000426', 'ACH-001094', 'ACH-002209', 'ACH-001150', 'ACH-001000', 'ACH-002107', 'ACH-002089', 'ACH-001017', 'ACH-001224', 'ACH-002279', 'ACH-002270', 'ACH-002273', 'ACH-002112', 'ACH-001108', 'ACH-000992', 'ACH-002229', 'ACH-002150', 'ACH-001490', 'ACH-002338', 'ACH-002186', 'ACH-002239', 'ACH-002202', 'ACH-002097', 'ACH-002286', 'ACH-002272', 'ACH-001206', 'ACH-001738', 'ACH-002397', 'ACH-002131', 'ACH-001087', 'ACH-002304', 'ACH-001071', 'ACH-002365', 'ACH-001021', 'ACH-001230', 'ACH-002108', 'ACH-001363', 'ACH-001136', 'ACH-002259', 'ACH-002051', 'ACH-002101', 'ACH-002153', 'ACH-002020', 'ACH-002301', 'ACH-001131', 'ACH-000309', 'ACH-000979', 'ACH-002120', 'ACH-002346', 'ACH-002358', 'ACH-001126', 'ACH-001039', 'ACH-002393', 'ACH-001452', 'ACH-002262', 'ACH-002040', 'ACH-002189', 'ACH-002268', 'ACH-002094', 'ACH-002381', 'ACH-002092', 'ACH-002241', 'ACH-002370', 'ACH-002165', 'ACH-002144', 'ACH-002245', 'ACH-002187', 'ACH-002285', 'ACH-002116', 'ACH-001171', 'ACH-001958', 'ACH-002356', 'ACH-002130', 'ACH-002233', 'ACH-002376', 'ACH-002364', 'ACH-002098', 'ACH-001146', 'ACH-002264', 'ACH-002178', 'ACH-002171', 'ACH-001606', 'ACH-001234', 'ACH-001002', 'ACH-002149', 'ACH-002308', 'ACH-002122', 'ACH-002220', 'ACH-002317', 'ACH-001049', 'ACH-002316', 'ACH-002252', 'ACH-002118', 'ACH-002140', 'ACH-001198', 'ACH-002109', 'ACH-002126', 'ACH-002340', 'ACH-001090', 'ACH-001015', 'ACH-001121', 'ACH-001957', 'ACH-002306', 'ACH-001079', 'ACH-002160', 'ACH-002148', 'ACH-001047', 'ACH-002353', 'ACH-002311', 'ACH-001358', 'ACH-002257', 'ACH-002313', 'ACH-001293', 'ACH-001417', 'ACH-001081', 'ACH-001359', 'ACH-002117', 'ACH-002388', 'ACH-001955', 'ACH-002166', 'ACH-002192', 'ACH-002386', 'ACH-002145', 'ACH-002184', 'ACH-002348', 'ACH-002176', 'ACH-002310', 'ACH-002362', 'ACH-002347', 'ACH-001639', 'ACH-001704', 'ACH-002248', 'ACH-001024', 'ACH-002278', 'ACH-002139', 'ACH-002254', 'ACH-002249', 'ACH-002103', 'ACH-002105', 'ACH-002240', 'ACH-002155', 'ACH-001130', 'ACH-002389', 'ACH-002223', 'ACH-001175', 'ACH-002181', 'ACH-002307', 'ACH-002390', 'ACH-002100', 'ACH-002211', 'ACH-000047', 'ACH-001489', 'ACH-002354', 'ACH-002357', 'ACH-002335', 'ACH-002709', 'ACH-002343', 'ACH-001162', 'ACH-001088', 'ACH-002298', 'ACH-002214', 'ACH-002265', 'ACH-002194', 'ACH-002111', 'ACH-001355', 'ACH-001362', 'ACH-002215', 'ACH-002206', 'ACH-002371', 'ACH-002352', 'ACH-002156', 'ACH-002177', 'ACH-002355', 'ACH-002234', 'ACH-002244', 'ACH-001249', 'ACH-001063', 'ACH-001107', 'ACH-002345', 'ACH-002251', 'ACH-002090', 'ACH-002368', 'ACH-001365', 'ACH-002236', 'ACH-002052', 'ACH-002303', 'ACH-002173', 'ACH-001544', 'ACH-002170', 'ACH-002195', 'ACH-001138', 'ACH-002366', 'ACH-002133', 'ACH-002110', 'ACH-002222', 'ACH-002295', 'ACH-002271', 'ACH-002363', 'ACH-002154', 'ACH-001043', 'ACH-002115', 'ACH-002226', 'ACH-002142', 'ACH-001956', 'ACH-002309', 'ACH-001188', 'ACH-002083', 'ACH-002261', 'ACH-002161', 'ACH-002179', 'ACH-002263', 'ACH-002258', 'ACH-002227', 'ACH-002164', 'ACH-002218', 'ACH-002373', 'ACH-001282', 'ACH-002151', 'ACH-002077'}\n",
      "removed for QC reasons\n",
      "{'ACH-000992', 'ACH-001293', 'ACH-002709', 'ACH-001502', 'ACH-001143', 'ACH-000309', 'ACH-001205', 'ACH-000979', 'ACH-000426', 'ACH-000047', 'ACH-001512', 'ACH-000795', 'ACH-000727'}\n",
      "removed\n",
      "{'ACH-000561'}\n",
      "missing\n",
      "set()\n",
      "dmc_embargo\n",
      "2 {'ACH-001708', 'ACH-001393'}\n"
     ]
    }
   ],
   "source": [
    "print('not present')\n",
    "removed = set(prevdmc) - set(fusions.DepMap_ID)\n",
    "print(removed)\n",
    "print('removed for QC reasons')\n",
    "print(set(rename.keys()))\n",
    "print('removed')\n",
    "removed = set(dmc_rna) - set(fusions.DepMap_ID)\n",
    "print(removed - set(rename.keys()))\n",
    "missing = set(dmc) - set(fusions.DepMap_ID)\n",
    "dmc_embargo = set(fusions.DepMap_ID) - (prevdmc | set(dmc))\n",
    "print('missing')\n",
    "print(missing)\n",
    "newlines = set(dmc) \n",
    "print('dmc_embargo')\n",
    "print(len(dmc_embargo), dmc_embargo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356696\n",
      "356375\n",
      "44066\n",
      "44018\n"
     ]
    }
   ],
   "source": [
    "## removing first blacklisted, then embargoed, to create two datasets\n",
    "print(len(fusions))\n",
    "fusions = fusions[~fusions.DepMap_ID.isin(dmc_embargo)]\n",
    "print(len(fusions))\n",
    "fusions.to_csv('temp/fusions.csv', index=False)\n",
    "print(len(filtered))\n",
    "filtered= filtered[~filtered.DepMap_ID.isin(dmc_embargo)]\n",
    "print(len(filtered))\n",
    "filtered.to_csv('temp/filtered_fusions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading fusions...\n",
      "hitting https://cds.team/taiga/api/datafile/2231566eb1634a3ba2a9349912f3fed7\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: fusions properly converted and uploaded\n",
      "Uploading filtered_fusions...\n",
      "hitting https://cds.team/taiga/api/datafile/2231566eb1634a3ba2a9349912f3fed7\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: filtered_fusions properly converted and uploaded\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 9b521d5f1d644899af1451e2b3fe453f created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/9b521d5f1d644899af1451e2b3fe453f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'9b521d5f1d644899af1451e2b3fe453f'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.update_dataset(dataset_permaname=\"gene-fusions-375f\",\n",
    "                 upload_file_path_dict={\n",
    "                     'temp/fusions.csv': 'TableCSV',\n",
    "                     'temp/filtered_fusions.csv': 'TableCSV'},\n",
    "                  dataset_description=\n",
    "\"\"\"\n",
    "# DMC Fusions\n",
    "\n",
    "* Version 1-2 DMC 19Q1*\n",
    "\n",
    "version 2 contains the correct data for 19Q1\n",
    "\n",
    "Description: Gene fusions derived from RNAseq data.\n",
    "\n",
    "Rows: cell lines\n",
    "\n",
    "Unfiltered data contains all output fusions, while the filtered data uses the filters suggested by the star fusion docs. These filters are:\n",
    "- FFPM > 0.1 -  a cutoff of 0.1 means&nbsp;at least 1 fusion-supporting RNAseq fragment per 10M total reads\n",
    "- Remove known false positives, such as GTEx recurrent fusions and certain paralogs\n",
    "- Genes that are next to each other\n",
    "- Fusions with mitochondrial breakpoints\n",
    "\n",
    "* Version 3 DMC 19Q2*\n",
    "\n",
    "* Version 4 DMC 19Q3*\n",
    "\n",
    "* Version 5 DMC 19Q4*\n",
    "\n",
    "* Version 6 DMC 20Q1*\n",
    "\n",
    "* Version 7 DMC 20Q2*\n",
    "adding 50 new lines\n",
    "\n",
    "* Version 7 DMC 20Q2*\n",
    "Unknown change\n",
    "\n",
    "* Version 9 DMC 20Q3*\n",
    "nothing different from  20Q2. no new cell lines added\n",
    "\n",
    "* Version 10 DMC 20Q3*\n",
    "updating the blacklists\n",
    "\n",
    "* Version 11 DMC 20Q3*\n",
    "issues with the blacklists resolved\n",
    "Description: Gene fusions derived from RNAseq data.\n",
    "\n",
    "* Version 12 DMC 20Q3*\n",
    "update in dmc list\n",
    "\n",
    "* Version 13 DMC 20Q4*\n",
    "adding new lines, new fusion filtering, debugged sample filtering (should recover the same sample as in expression dataset).\n",
    "\n",
    "* Version 14 DMC 20Q4*\n",
    "renaming fusios\n",
    "\n",
    "\n",
    "Rows: cell lines, IDs contained in the column DepMap_ID\n",
    "LeftGene and RightGene separated by an ampersand (\"&\").\n",
    "\n",
    "Unfiltered data contains all output fusions, while the filtered data uses the filters suggested by the star fusion docs. These filters are:\n",
    "- FFPM > 0.1 -  a cutoff of 0.1 means&nbsp;at least 1 fusion-supporting RNAseq fragment per 10M total reads\n",
    "- Remove known false positives, such as GTEx recurrent fusions and certain paralogs\n",
    "- Genes that are next to each other\n",
    "- Fusions with mitochondrial breakpoints\n",
    "- Removing fusion involving mitochondrial chromosomes or HLA genes\n",
    "- Removed common false positive fusions (red herring annotations as described in the STAR-Fusion docs)\n",
    "- Recurrent fusions observed in CCLE across cell lines (in 10% or more the samples)\n",
    "- Removed fusions where SpliceType='INCL_NON_REF_SPLICE' and LargeAnchorSupport='NO_LDAS' and FFPM < 0.1\n",
    "- FFPM < 0.05\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "REMOVED FOR QC REASONS:\n",
    "\"\"\"+str(rename)+\"\"\"\n",
    "\n",
    "EMBARGO:\n",
    "\"\"\"+str(dmc_embargo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CCLE_fusions_unfiltered', 'gene-fusions-375f.14/fusions'), ('CCLE_fusions', 'gene-fusions-375f.14/filtered_fusions')]\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datafile/e2a36844d9b248ecb82600efa0988594\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id fc529263bd29401983f31d2a19dca818 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/fc529263bd29401983f31d2a19dca818\n"
     ]
    }
   ],
   "source": [
    "AddToVirtual(virtual_dmc, \"gene-fusions-375f\", files=[('CCLE_fusions_unfiltered', 'fusions'),('CCLE_fusions', 'filtered_fusions')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not present\n",
      "{'ACH-002196', 'ACH-002205', 'ACH-002289', 'ACH-001064', 'ACH-001641', 'ACH-002127', 'ACH-002344', 'ACH-002384', 'ACH-002383', 'ACH-002157', 'ACH-001037', 'ACH-001143', 'ACH-002216', 'ACH-001680', 'ACH-000727', 'ACH-002351', 'ACH-002207', 'ACH-002114', 'ACH-002300', 'ACH-000795', 'ACH-002377', 'ACH-002204', 'ACH-002360', 'ACH-002292', 'ACH-002058', 'ACH-002104', 'ACH-002314', 'ACH-002183', 'ACH-002213', 'ACH-002168', 'ACH-002382', 'ACH-002260', 'ACH-001208', 'ACH-002095', 'ACH-002200', 'ACH-002269', 'ACH-002387', 'ACH-002375', 'ACH-002129', 'ACH-001199', 'ACH-002312', 'ACH-002282', 'ACH-002395', 'ACH-001338', 'ACH-002232', 'ACH-002267', 'ACH-002190', 'ACH-001093', 'ACH-002336', 'ACH-002281', 'ACH-001137', 'ACH-002199', 'ACH-002208', 'ACH-002185', 'ACH-002276', 'ACH-002374', 'ACH-002396', 'ACH-001383', 'ACH-002237', 'ACH-002119', 'ACH-002136', 'ACH-002359', 'ACH-001182', 'ACH-002106', 'ACH-001187', 'ACH-002394', 'ACH-002180', 'ACH-001045', 'ACH-002291', 'ACH-002230', 'ACH-002193', 'ACH-001089', 'ACH-001331', 'ACH-002147', 'ACH-002242', 'ACH-002361', 'ACH-001205', 'ACH-002201', 'ACH-002191', 'ACH-002143', 'ACH-001203', 'ACH-002290', 'ACH-002188', 'ACH-001018', 'ACH-002294', 'ACH-002247', 'ACH-002167', 'ACH-002391', 'ACH-001125', 'ACH-001591', 'ACH-001118', 'ACH-002159', 'ACH-002197', 'ACH-002253', 'ACH-002102', 'ACH-001023', 'ACH-002238', 'ACH-002182', 'ACH-002198', 'ACH-002175', 'ACH-001599', 'ACH-002250', 'ACH-002284', 'ACH-002091', 'ACH-001233', 'ACH-002299', 'ACH-001092', 'ACH-002369', 'ACH-002123', 'ACH-002305', 'ACH-002141', 'ACH-001767', 'ACH-002341', 'ACH-002350', 'ACH-001011', 'ACH-002296', 'ACH-002169', 'ACH-001101', 'ACH-002128', 'ACH-002235', 'ACH-002093', 'ACH-002367', 'ACH-001225', 'ACH-001127', 'ACH-002125', 'ACH-002225', 'ACH-002297', 'ACH-002224', 'ACH-002315', 'ACH-001044', 'ACH-002266', 'ACH-001350', 'ACH-002380', 'ACH-002231', 'ACH-002096', 'ACH-002274', 'ACH-002379', 'ACH-002135', 'ACH-002043', 'ACH-001042', 'ACH-002275', 'ACH-001072', 'ACH-002146', 'ACH-002302', 'ACH-001065', 'ACH-002392', 'ACH-002277', 'ACH-002152', 'ACH-002217', 'ACH-002113', 'ACH-002288', 'ACH-002378', 'ACH-002099', 'ACH-001364', 'ACH-002163', 'ACH-002293', 'ACH-002246', 'ACH-002124', 'ACH-002372', 'ACH-002174', 'ACH-002243', 'ACH-002162', 'ACH-002342', 'ACH-002339', 'ACH-002210', 'ACH-001189', 'ACH-002212', 'ACH-001091', 'ACH-001066', 'ACH-001214', 'ACH-002256', 'ACH-002121', 'ACH-002228', 'ACH-002221', 'ACH-002134', 'ACH-002280', 'ACH-002349', 'ACH-002255', 'ACH-002337', 'ACH-002287', 'ACH-002132', 'ACH-002283', 'ACH-000426', 'ACH-001094', 'ACH-002209', 'ACH-001150', 'ACH-001000', 'ACH-002107', 'ACH-002089', 'ACH-001017', 'ACH-001224', 'ACH-002279', 'ACH-002270', 'ACH-002273', 'ACH-002112', 'ACH-001108', 'ACH-000992', 'ACH-002229', 'ACH-002150', 'ACH-001490', 'ACH-002338', 'ACH-002186', 'ACH-002239', 'ACH-002202', 'ACH-002097', 'ACH-002286', 'ACH-002272', 'ACH-001206', 'ACH-001738', 'ACH-002397', 'ACH-002131', 'ACH-001087', 'ACH-002304', 'ACH-001071', 'ACH-002365', 'ACH-001021', 'ACH-001230', 'ACH-002108', 'ACH-001363', 'ACH-001136', 'ACH-002259', 'ACH-002051', 'ACH-002101', 'ACH-002153', 'ACH-002020', 'ACH-002301', 'ACH-001131', 'ACH-000309', 'ACH-000979', 'ACH-002120', 'ACH-002346', 'ACH-002358', 'ACH-001126', 'ACH-001039', 'ACH-002393', 'ACH-001452', 'ACH-002262', 'ACH-002040', 'ACH-002189', 'ACH-002268', 'ACH-002094', 'ACH-002381', 'ACH-002092', 'ACH-002241', 'ACH-002370', 'ACH-002165', 'ACH-002144', 'ACH-002245', 'ACH-002187', 'ACH-002285', 'ACH-002116', 'ACH-001171', 'ACH-001958', 'ACH-002356', 'ACH-002130', 'ACH-002233', 'ACH-002376', 'ACH-002364', 'ACH-002098', 'ACH-001146', 'ACH-002264', 'ACH-002178', 'ACH-002171', 'ACH-001606', 'ACH-001234', 'ACH-001002', 'ACH-002149', 'ACH-002308', 'ACH-002122', 'ACH-002220', 'ACH-002317', 'ACH-001049', 'ACH-002316', 'ACH-002252', 'ACH-002118', 'ACH-002140', 'ACH-001198', 'ACH-002109', 'ACH-002126', 'ACH-002340', 'ACH-001090', 'ACH-001015', 'ACH-001121', 'ACH-001957', 'ACH-002306', 'ACH-001079', 'ACH-002160', 'ACH-002148', 'ACH-001047', 'ACH-002353', 'ACH-002311', 'ACH-001358', 'ACH-002257', 'ACH-002313', 'ACH-001417', 'ACH-001081', 'ACH-001359', 'ACH-002117', 'ACH-002388', 'ACH-001955', 'ACH-002166', 'ACH-002192', 'ACH-002386', 'ACH-002145', 'ACH-002184', 'ACH-002348', 'ACH-002176', 'ACH-002310', 'ACH-002362', 'ACH-002347', 'ACH-001639', 'ACH-001704', 'ACH-002248', 'ACH-001024', 'ACH-002278', 'ACH-002139', 'ACH-002254', 'ACH-002249', 'ACH-002103', 'ACH-002105', 'ACH-002240', 'ACH-002155', 'ACH-001130', 'ACH-002389', 'ACH-002223', 'ACH-001175', 'ACH-002181', 'ACH-002307', 'ACH-002390', 'ACH-002100', 'ACH-002211', 'ACH-000047', 'ACH-001489', 'ACH-002354', 'ACH-002357', 'ACH-002335', 'ACH-002343', 'ACH-001162', 'ACH-001088', 'ACH-002298', 'ACH-002214', 'ACH-002265', 'ACH-002194', 'ACH-002111', 'ACH-001355', 'ACH-001362', 'ACH-002215', 'ACH-002206', 'ACH-002371', 'ACH-002352', 'ACH-002156', 'ACH-002177', 'ACH-002355', 'ACH-002234', 'ACH-002244', 'ACH-001249', 'ACH-001063', 'ACH-001107', 'ACH-002345', 'ACH-002251', 'ACH-002090', 'ACH-002368', 'ACH-001365', 'ACH-002236', 'ACH-002052', 'ACH-002303', 'ACH-002173', 'ACH-001544', 'ACH-002170', 'ACH-002195', 'ACH-001138', 'ACH-002366', 'ACH-002133', 'ACH-002110', 'ACH-002222', 'ACH-002295', 'ACH-002271', 'ACH-002363', 'ACH-002154', 'ACH-001043', 'ACH-002115', 'ACH-002226', 'ACH-002142', 'ACH-001956', 'ACH-002309', 'ACH-001188', 'ACH-002083', 'ACH-002261', 'ACH-002161', 'ACH-002179', 'ACH-002263', 'ACH-002258', 'ACH-002227', 'ACH-002164', 'ACH-002218', 'ACH-002373', 'ACH-001282', 'ACH-002151', 'ACH-002077'}\n",
      "removed for QC reasons\n",
      "{'ACH-000992', 'ACH-001293', 'ACH-002709', 'ACH-001502', 'ACH-001143', 'ACH-000309', 'ACH-001205', 'ACH-000979', 'ACH-000426', 'ACH-000047', 'ACH-001512', 'ACH-000795', 'ACH-000727'}\n",
      "removed\n",
      "set()\n",
      "missing\n",
      "{'ACH-002399', 'ACH-002709'}\n",
      "embargo\n",
      "29 {'ACH-001493', 'ACH-001970', 'ACH-001449', 'ACH-002010', 'ACH-001662', 'ACH-001669', 'ACH-001672', 'ACH-002465', 'ACH-001973', 'ACH-001693', 'ACH-001547', 'ACH-002014', 'ACH-001847', 'ACH-001971', 'ACH-001533', 'ACH-001854', 'ACH-001349', 'ACH-001696', 'ACH-001437', 'ACH-002048', 'ACH-002021', 'ACH-001679', 'ACH-001678', 'ACH-001676', 'ACH-001537', 'ACH-001855', 'ACH-002512', 'ACH-001438', 'ACH-001429'}\n",
      "{'ACH-001041', 'ACH-000886', 'ACH-002399', 'ACH-000949', 'ACH-000353', 'ACH-001456', 'ACH-000396', 'ACH-000124', 'ACH-000090', 'ACH-001613', 'ACH-002709', 'ACH-001993', 'ACH-000568', 'ACH-000972', 'ACH-001392', 'ACH-001497', 'ACH-000538', 'ACH-002065', 'ACH-000565', 'ACH-000267', 'ACH-002464', 'ACH-001638', 'ACH-001574', 'ACH-001850', 'ACH-000672', 'ACH-000533', 'ACH-000327', 'ACH-002510', 'ACH-000357', 'ACH-002508', 'ACH-002467', 'ACH-001376', 'ACH-000144', 'ACH-000955', 'ACH-002463', 'ACH-000161', 'ACH-001378', 'ACH-000072', 'ACH-001498', 'ACH-001846', 'ACH-000110', 'ACH-002466', 'ACH-000845', 'ACH-000999', 'ACH-002462', 'ACH-000462', 'ACH-001556', 'ACH-000268', 'ACH-001819', 'ACH-000609', 'ACH-000989', 'ACH-000602'}\n"
     ]
    }
   ],
   "source": [
    "print('not present')\n",
    "removed = set(prevpublic) - set(genes_tpm.index)\n",
    "print(removed)\n",
    "print('removed for QC reasons')\n",
    "print(set(rename.keys()))\n",
    "print('removed')\n",
    "removed = set(public_rna) - set(genes_tpm.index)\n",
    "print(removed - set(rename.keys()))\n",
    "missing = set(public) - set(genes_tpm.index)\n",
    "blacklist = set(genes_tpm.index) - (prevpublic | set(public))\n",
    "print('missing')\n",
    "print(missing)\n",
    "newlines = set(public) \n",
    "print('embargo')\n",
    "print(len(embargo), embargo)\n",
    "print(newlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356375\n",
      "352748\n",
      "44018\n",
      "43394\n"
     ]
    }
   ],
   "source": [
    "## removing first blacklisted, then embargoed, to create two datasets\n",
    "print(len(fusions))\n",
    "fusions = fusions[~fusions.DepMap_ID.isin(embargo)]\n",
    "print(len(fusions))\n",
    "fusions.to_csv('temp/fusions.csv', index=False)\n",
    "print(len(filtered))\n",
    "filtered= filtered[~filtered.DepMap_ID.isin(embargo)]\n",
    "print(len(filtered))\n",
    "filtered.to_csv('temp/filtered_fusions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading fusions...\n",
      "hitting https://cds.team/taiga/api/datafile/1ee63cfe016347a68cecce9a96529cb9\n",
      "Conversion and upload...:\n",
      "\t Waiting in the task queue\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: fusions properly converted and uploaded\n",
      "Uploading filtered_fusions...\n",
      "hitting https://cds.team/taiga/api/datafile/1ee63cfe016347a68cecce9a96529cb9\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: filtered_fusions properly converted and uploaded\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 53052a872f974ab98820c6b0a2367972 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/53052a872f974ab98820c6b0a2367972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'53052a872f974ab98820c6b0a2367972'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.update_dataset(dataset_permaname=\"gene-fusions-6212\",\n",
    "                 upload_file_path_dict={\n",
    "                     'temp/fusions.csv': 'TableCSV',\n",
    "                     'temp/filtered_fusions.csv': 'TableCSV'},\n",
    "                  dataset_description=\n",
    "\"\"\"\n",
    "# PUBLIC Fusions\n",
    "\n",
    "* Version 1 Public 2017 data*\n",
    "\n",
    "Description: Gene fusions derived from RNAseq data.\n",
    "\n",
    "Rows: cell lines, ID contained in the column Broad_ID\n",
    "\n",
    "Original Raw Data: Generated by Mahmoud Ghandi on April 25, 2017. Can be found at xchip_ccle_dist/broad_only/unpublished_Novartis_data/RNAseq/fusions.txt\n",
    "\n",
    "* Version 2-3 Public 19Q1*\n",
    "\n",
    "version 3 contains the correct data for 19Q1\n",
    "\n",
    "* Version 4-6 Public 19Q2*\n",
    "\n",
    "in version 5 formatting of the columns is improved\n",
    "\n",
    "* Version 7 Public 19Q3*\n",
    "\n",
    "* Version 8 Public 19Q4*\n",
    "\n",
    "* Version 9 Public 20Q1*\n",
    "\n",
    "* Version 10 Public 20Q2*\n",
    "adding 50 new lines\n",
    "\n",
    "* Version 11 Public 20Q3*\n",
    "nothing different from  20Q2. no new cell lines added\n",
    "\n",
    "* Version 12 Public 20Q3*\n",
    "updated blacklists\n",
    "\n",
    "* Version 13 Public 20Q3*\n",
    "issues with the blacklists\n",
    "\n",
    "* Version 14 Public 20Q3*\n",
    "updating the dmc list \n",
    "\n",
    "* Version 15 Public 20Q3*\n",
    "re adding two missing, already released samples\n",
    "\n",
    "* Version 16 Public 20Q4*\n",
    "adding new lines, new fusion filtering, debugged sample filtering (should recover the same sample as in expression dataset).\n",
    "\n",
    "* Version 17 Public 20Q4*\n",
    "renaming fusions\n",
    "\n",
    "* Version 18 Public 20Q4*\n",
    "removing lines\n",
    "\n",
    "Description: Gene fusions derived from RNAseq data.\n",
    "\n",
    "Rows: cell lines, IDs contained in the column DepMap_ID\n",
    "LeftGene and RightGene separated by an ampersand (\"&\").\n",
    "\n",
    "Unfiltered data contains all output fusions, while the filtered data uses the filters suggested by the star fusion docs. These filters are:\n",
    "- FFPM > 0.1 -  a cutoff of 0.1 means&nbsp;at least 1 fusion-supporting RNAseq fragment per 10M total reads\n",
    "- Remove known false positives, such as GTEx recurrent fusions and certain paralogs\n",
    "- Genes that are next to each other\n",
    "- Fusions with mitochondrial breakpoints\n",
    "- Removing fusion involving mitochondrial chromosomes or HLA genes\n",
    "- Removed common false positive fusions (red herring annotations as described in the STAR-Fusion docs)\n",
    "- Recurrent fusions observed in CCLE across cell lines (in 10% or more of the samples)\n",
    "- Removed fusions where SpliceType='INCL_NON_REF_SPLICE' and LargeAnchorSupport='NO_LDAS' and FFPM < 0.1\n",
    "- FFPM < 0.05\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "REMOVED FOR QC REASONS:\n",
    "\"\"\"+str(rename)+\"\"\"\n",
    "\n",
    "EMBARGO:\n",
    "\"\"\"+str(embargo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CCLE_fusions_unfiltered', 'gene-fusions-6212.18/fusions'), ('CCLE_fusions', 'gene-fusions-6212.18/filtered_fusions')]\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datafile/6300de9da8644133a9158a143914330d\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 3b0638f663e74439b89d37c0ad74e14b created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/3b0638f663e74439b89d37c0ad74e14b\n"
     ]
    }
   ],
   "source": [
    "AddToVirtual(virtual_public, \"gene-fusions-6212\", files=[('CCLE_fusions_unfiltered', 'fusions'),('CCLE_fusions', 'filtered_fusions')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "268px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
