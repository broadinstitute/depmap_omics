{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro & Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "\n",
    "from genepy.utils import helper as h\n",
    "from gsheets import Sheets\n",
    "from taigapy import TaigaClient\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext rpy2.ipython\n",
    "tc = TaigaClient()\n",
    "output_notebook()\n",
    "\n",
    "my_id = '~/.client_secret.json'\n",
    "mystorage_id = \"~/.storage.json\"\n",
    "sheets = Sheets.from_files(my_id, mystorage_id)\n",
    "replace = {'T': 'Tumor', 'N': 'Normal', 'm': 'Unknown', 'L': 'Unknown'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesetname = \"21Q1\"\n",
    "\n",
    "virtual= {}\n",
    "virtual['public'] = 'public-21q1-4b39'\n",
    "virtual['ibm'] = 'ibm-21q1-abd9'\n",
    "virtual['dmc'] = 'dmc-21q1-0e11'\n",
    "virtual['internal']='internal-21q1-4fc4'\n",
    "\n",
    "\n",
    "taiga_mutation = {}\n",
    "taiga_mutation['internal'] = \"depmap-mutation-calls-9be3\"\n",
    "taiga_mutation['ibm'] = \"mutations-b05c\"\n",
    "taiga_mutation['dmc'] = \"depmap-mutation-calls-dfce\"\n",
    "taiga_mutation['public'] =\"depmap-mutation-calls-9a1a\"\n",
    "\n",
    "taiga_expression = {}\n",
    "taiga_expression['internal'] =\"depmap-rnaseq-expression-data-363a\"\n",
    "taiga_expression['ibm'] = \"expression-9d97\"\n",
    "taiga_expression['dmc'] = \"depmap-rnaseq-expression-data-80ef\"\n",
    "taiga_expression['public'] =\"depmap-rnaseq-expression-data-ccd0\"\n",
    "\n",
    "taiga_fusion = {}\n",
    "taiga_fusion['internal'] = \"gene-fusions-8b7a\"\n",
    "taiga_fusion['ibm'] = \"fusion-dc08\"\n",
    "taiga_fusion['dmc'] = \"gene-fusions-375f\"\n",
    "taiga_fusion['public'] =\"gene-fusions-6212\"\n",
    "\n",
    "taiga_copynumber = {}\n",
    "taiga_copynumber['internal'] =\"depmap-wes-cn-data-81a7\"\n",
    "taiga_copynumber['ibm'] = \"cn-e20f\"\n",
    "taiga_copynumber['dmc'] = \"depmap-cn-data-9b9d\"\n",
    "taiga_copynumber['public'] = \"depmap-wes-cn-data-97cc\"\n",
    "\n",
    "prev_virtual = {}\n",
    "#prev_virtual['public'] = 'public-20q3-3d35'\n",
    "#prev_virtual['dmc'] = 'dmc-20q3-deprecated-never-released--5f55'\n",
    "#prev_virtual['internal'] = 'internal-20q3-00d0'\n",
    "\n",
    "prev_virtual['public'] = 'public-20q4-a4b3'\n",
    "prev_virtual['dmc'] = 'dmc-20q4-fcf4'\n",
    "# prev_virtual['ibm'] = 'ibm-20q4-269f'\n",
    "prev_virtual['internal'] = 'internal-20q4-2540'\n",
    "potential_list_url = \"https://docs.google.com/spreadsheets/d/1YuKEgZ1pFKRYzydvncQt9Y_BKToPlHP-oDB-0CAv3gE\"\n",
    "\n",
    "release = samplesetname.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = {}\n",
    "gsheets = sheets.get(potential_list_url).sheets[0].to_frame()\n",
    "new['internal'] = set([i for i in gsheets['Internal'].values.tolist() if str(i) != \"nan\"])\n",
    "new['dmc'] = set([i for i in gsheets['DMC'].values.tolist() if str(i) != \"nan\"])\n",
    "new['ibm'] = set([i for i in gsheets['IBM'].values.tolist() if str(i) != \"nan\"])\n",
    "new['public'] = set([i for i in gsheets['Public'].values.tolist() if str(i) != \"nan\"])\n",
    "\n",
    "\n",
    "new[\"internal\"] = new[\"internal\"] | new[\"ibm\"] | new[\"dmc\"] | new[\"public\"]\n",
    "new[\"ibm\"] = new[\"ibm\"] | new[\"dmc\"] | new[\"public\"]\n",
    "new[\"dmc\"] = new[\"dmc\"] | new[\"public\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting what was released before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevmut = {}\n",
    "prevrna = {}\n",
    "prevcn = {}\n",
    "prevwes = {}\n",
    "prev = {}\n",
    "for val in ['internal', 'dmc', 'public']:\n",
    "    print(val)\n",
    "    prevmut[val] = set(tc.get(name=prev_virtual[val], file='CCLE_mutations').DepMap_ID)\n",
    "    prevrna[val] = set(tc.get(name=prev_virtual[val], file='CCLE_expression').index)\n",
    "    prevcn[val] = set(tc.get(name=prev_virtual[val], file='CCLE_segment_cn').DepMap_ID)\n",
    "    prev[val] = prevmut[val] | prevrna[val] | prevcn[val]\n",
    "    prevwes[val] = prevmut[val] | prevcn[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevmut[\"dmc\"] = prevmut[\"dmc\"] | prevmut[\"public\"]\n",
    "prevrna[\"dmc\"] = prevrna[\"dmc\"] | prevrna[\"public\"]\n",
    "prevcn[\"dmc\"] = prevcn[\"dmc\"] | prevcn[\"public\"]\n",
    "prev[\"dmc\"] = prev[\"dmc\"] | prev[\"public\"]\n",
    "prevwes[\"dmc\"] = prevwes[\"dmc\"] | prevwes[\"public\"]\n",
    "\n",
    "prevmut[\"internal\"] = prevmut[\"internal\"] | prevmut[\"dmc\"]\n",
    "prevrna[\"internal\"] = prevrna[\"internal\"] | prevrna[\"dmc\"]\n",
    "prevcn[\"internal\"] = prevcn[\"internal\"] | prevcn[\"dmc\"]\n",
    "prev[\"internal\"] = prev[\"internal\"] | prev[\"dmc\"]\n",
    "prevwes[\"internal\"] = prevwes[\"internal\"] | prevwes[\"dmc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('in cn but not mut')\n",
    "print(prevwes[\"internal\"] - prevmut[\"internal\"])\n",
    "print('in mut but not cn')\n",
    "print(prevwes[\"internal\"] - prevcn[\"internal\"])\n",
    "print('in rna but no wes/wgs')\n",
    "print(prev[\"internal\"] - prevwes[\"internal\"])\n",
    "print('in wes/wgs but not rna')\n",
    "print(prev[\"internal\"] - prevrna[\"internal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev['ibm'] = prev['dmc']\n",
    "prevcn['ibm'] = prevcn['dmc']\n",
    "prevmut['ibm'] = prevmut['dmc']\n",
    "prevrna['ibm'] = prevrna['dmc']\n",
    "prevwes['ibm'] = prevwes['dmc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## managing the readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! cd .. && git clone https://github.com/broadinstitute/depmap-release-readmes.git && cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd ../depmap-release-readmes && git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../depmap-release-readmes/ && python3 make_new_release.py $release && git add . && git commit -m $release && git push "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW UPDATE THE READMEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir temp/README/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd ../depmap-release-readmes && cp release-$release/* ../ccle_processing/readmes/ && git add . && git commit -m \"Omics: updating readmes to new release\" && git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd ../depmap-release-readmes && git pull &&  cp release-$release/* ../ccle_processing/readmes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in ['internal', 'ibm', 'dmc', 'public']:\n",
    "    os.popen('cp readmes/'+val+'-'+release+'.txt temp/README').read()\n",
    "    AddToVirtual(virtual[val], files = [('Raw','temp/README')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Somatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = pd.read_csv(\"temp/wes_somatic_mutations_withlegacy_\"+samplesetname+\".csv\")\n",
    "damaging = pd.read_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_damaging.csv', index_col=0)\n",
    "othercons = pd.read_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_othercons.csv', index_col=0)\n",
    "othernoncons = pd.read_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_othernoncons.csv', index_col=0)\n",
    "hotspot = pd.read_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_hotspot.csv', index_col=0)\n",
    "hotspot=hotspot.astype(int)\n",
    "damaging=damaging.astype(int)\n",
    "othercons=othercons.astype(int)\n",
    "othernoncons=othernoncons.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverting to previous versions\n",
    "mutations = mutations[mutations.is_likely_immortalization!=True]\n",
    "mutations = mutations[['Hugo_Symbol', 'Entrez_Gene_Id', 'NCBI_Build', 'Chromosome',\n",
    "       'Start_position', 'End_position', 'Strand', 'Variant_Classification',\n",
    "       'Variant_Type', 'Reference_Allele', 'Tumor_Allele', 'dbSNP_RS',\n",
    "       'dbSNP_Val_Status', 'Genome_Change', 'Annotation_Transcript',\n",
    "       'DepMap_ID', 'cDNA_Change', 'Codon_Change', 'Protein_Change', 'isDeleterious',\n",
    "       'isTCGAhotspot', 'TCGAhsCnt', 'isCOSMIChotspot', 'COSMIChsCnt',\n",
    "       'ExAC_AF',\"Variant_annotation\", 'CGA_WES_AC', 'HC_AC',\n",
    "       'RD_AC', 'RNAseq_AC', 'SangerWES_AC', 'WGS_AC']].rename(columns={\"Tumor_Allele\":\"Tumor_Seq_Allele1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls temp/README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ACH-001502\" in prevmut[\"ibm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = set()\n",
    "for val in ['internal', 'ibm', \"dmc\", \"public\"]:\n",
    "    print('_________________________________________________')\n",
    "    print(val)\n",
    "    missing = set(new[val]) - set(mutations.DepMap_ID)\n",
    "    print('nott present')\n",
    "    removed = set(prev[val]) - set(mutations.DepMap_ID)\n",
    "    print(removed)\n",
    "    print('removed')\n",
    "    removed = set(prevmut[val]) - set(mutations.DepMap_ID)\n",
    "    print(removed)\n",
    "    blacklist = (set(mutations.DepMap_ID) - (prevmut[val] | set(new[val]))) | blacklist\n",
    "    print('missing')\n",
    "    print(missing)\n",
    "    newlines = set(new[val]) \n",
    "    print('blacklist')\n",
    "    print(blacklist)\n",
    "    # adding files\n",
    "    a = mutations[~mutations.DepMap_ID.isin(blacklist)]\n",
    "    print(len(mutations)- len(a))\n",
    "    a.to_csv('temp/all_somatic_mutations_withlegacy.csv', index=False)\n",
    "    a = damaging[~damaging.index.isin(blacklist)]\n",
    "    print(len(damaging) - len(a))\n",
    "    a.to_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_damaging.csv')\n",
    "    a = othercons[~othercons.index.isin(blacklist)]\n",
    "    print(len(othercons) - len(a))\n",
    "    a.to_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_othercons.csv')\n",
    "    a = othernoncons[~othernoncons.index.isin(blacklist)]\n",
    "    print(len(othernoncons) - len(a))\n",
    "    a.to_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_othernoncons.csv')\n",
    "    a = hotspot[~hotspot.index.isin(blacklist)]\n",
    "    print(len(hotspot) - len(a))\n",
    "    a.to_csv('temp/all_somatic_mutations_boolmatrix_fordepmap_hotspot.csv')\n",
    "    os.popen('cp readmes/'+val+'-'+release+'.txt temp/README').read()\n",
    "    \n",
    "    # updating on taiga\n",
    "    tc.update_dataset(dataset_permaname=taiga_mutation[val],\n",
    "                     upload_file_path_dict={\n",
    "    'temp/all_somatic_mutations_withlegacy.csv': 'TableCSV',\n",
    "    'temp/all_somatic_mutations_boolmatrix_fordepmap_damaging.csv': 'NumericMatrixCSV',\n",
    "    'temp/all_somatic_mutations_boolmatrix_fordepmap_othernoncons.csv': 'NumericMatrixCSV',\n",
    "    'temp/all_somatic_mutations_boolmatrix_fordepmap_othercons.csv': 'NumericMatrixCSV',\n",
    "    'temp/all_somatic_mutations_boolmatrix_fordepmap_hotspot.csv': 'NumericMatrixCSV',\n",
    "    'temp/README': 'Raw'},\n",
    "                     dataset_description=\"\"\"\n",
    "    #Mutations Omics:\n",
    "\n",
    "    for informations, see README\n",
    "\n",
    "    NEW LINES:\n",
    "    \"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "    BLACKLISTED:\n",
    "    \"\"\"+str(blacklist))\n",
    "\n",
    "    # To add to a virtual dataset\n",
    "    AddToVirtual(virtual[val], taiga_mutation[val], [('CCLE_mutations', 'all_somatic_mutations_withlegacy'),\n",
    "    ('CCLE_all_somatic_mutations_boolmatrix_fordepmap_damaging', 'all_somatic_mutations_boolmatrix_fordepmap_damaging'),\n",
    "    ('CCLE_all_somatic_mutations_boolmatrix_fordepmap_othernoncons', 'all_somatic_mutations_boolmatrix_fordepmap_othernoncons'),\n",
    "    ('CCLE_all_somatic_mutations_boolmatrix_fordepmap_othercons', 'all_somatic_mutations_boolmatrix_fordepmap_othercons'),\n",
    "    ('CCLE_all_somatic_mutations_boolmatrix_fordepmap_hotspot', 'all_somatic_mutations_boolmatrix_fordepmap_hotspot'), ('README','README')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add to a eternal dataset\n",
    "AddToVirtual('depmap-a0ab', taiga_mutation['internal'], [('CCLE_mutations', 'all_somatic_mutations_withlegacy'),\n",
    "('CCLE_all_somatic_mutations_boolmatrix_fordepmap_damaging', 'all_somatic_mutations_boolmatrix_fordepmap_damaging'),\n",
    "('CCLE_all_somatic_mutations_boolmatrix_fordepmap_othernoncons', 'all_somatic_mutations_boolmatrix_fordepmap_othernoncons'),\n",
    "('CCLE_all_somatic_mutations_boolmatrix_fordepmap_othercons', 'all_somatic_mutations_boolmatrix_fordepmap_othercons'),\n",
    "('CCLE_all_somatic_mutations_boolmatrix_fordepmap_hotspot', 'all_somatic_mutations_boolmatrix_fordepmap_hotspot')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genecn= pd.read_csv('temp/all_'+samplesetname+'_gene_cn.csv',index_col=0)\n",
    "segmentcn = pd.read_csv('temp/all_'+samplesetname+'_segment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genecn = genecn.apply(lambda x: (x**2)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = set()\n",
    "for val in ['internal', 'ibm', 'dmc', 'public']:\n",
    "    print('_________________________________________________')\n",
    "    print(val)\n",
    "    print('not present')\n",
    "    removed = set(prevcn[val]) - set(segmentcn.DepMap_ID)\n",
    "    print(removed)\n",
    "    print('removed')\n",
    "    removed = set(prevcn[val]) - set(segmentcn.DepMap_ID)\n",
    "    print(removed)\n",
    "    missing = set(new[val]) - set(segmentcn.DepMap_ID)\n",
    "    blacklist = (set(segmentcn.DepMap_ID) - (prevcn[val] | set(new[val]))) | blacklist\n",
    "    print('missing')\n",
    "    print(missing)\n",
    "    newlines = set(new[val]) \n",
    "    print('blacklist')\n",
    "    print(len(blacklist), blacklist)\n",
    "    ## for segment removing first blacklisted, then embargoed, to create two datasets\n",
    "    print(len(segmentcn))\n",
    "    a = segmentcn[~segmentcn.DepMap_ID.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/all_merged_segments.csv', index=False)\n",
    "    print(len(genecn))\n",
    "    a = genecn[~genecn.index.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/all_merged_genes_cn.csv')\n",
    "    \n",
    "    os.popen('cp readmes/'+val+'-'+release+'.txt temp/README')\n",
    "\n",
    "    # Add to Taiga\n",
    "    tc.update_dataset(dataset_permaname=taiga_copynumber[val], \n",
    "                      upload_file_path_dict={\n",
    "                        'temp/all_merged_genes_cn.csv': 'NumericMatrixCSV',\n",
    "                        'temp/all_merged_segments.csv': 'TableCSV',\n",
    "                        'temp/README': 'Raw'},\n",
    "                      dataset_description=\n",
    "    \"\"\"\n",
    "    #Copy Number Omics:\n",
    "\n",
    "    for informations, see README\n",
    "\n",
    "    NEW LINES:\n",
    "    \"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "    BLACKLIST:\n",
    "    \"\"\"+str(blacklist))\n",
    "    # To add to a virtual dataset\n",
    "    AddToVirtual(virtual[val], taiga_copynumber[val], [('CCLE_gene_cn', 'all_merged_genes_cn'), ('CCLE_segment_cn','all_merged_segments')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add to a eternal dataset\n",
    "AddToVirtual('depmap-a0ab', taiga_copynumber['internal'], [('CCLE_gene_cn', 'all_merged_genes_cn'), ('CCLE_segment_cn', 'all_merged_segments')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_tpm = pd.read_csv('temp/expression_' + samplesetname + '_transcripts_tpm.csv',index_col=0)\n",
    "genes_tpm = pd.read_csv('temp/expression_' + samplesetname + '_genes_tpm.csv',index_col=0)\n",
    "genes_expected_count = pd.read_csv('temp/expression_' + samplesetname + '_genes_expected_count.csv',index_col=0)\n",
    "proteincoding_genes_expected_count = pd.read_csv('temp/expression_' + samplesetname + '_proteincoding_genes_expected_count.csv',index_col=0)\n",
    "proteincoding_genes_tpm = pd.read_csv('temp/expression_' + samplesetname + '_proteincoding_genes_tpm.csv',index_col=0)\n",
    "transcripts_expected_count = pd.read_csv('temp/expression_' + samplesetname + '_transcripts_expected_count.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting it back to what it was before\n",
    "\n",
    "# log transforming tpm data\n",
    "transcripts_tpm=transcripts_tpm.apply(lambda x: np.log2(x+1))\n",
    "genes_tpm=genes_tpm.apply(lambda x: np.log2(x+1))\n",
    "proteincoding_genes_tpm=proteincoding_genes_tpm.apply(lambda x: np.log2(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = set()\n",
    "for val in ['internal','ibm', 'dmc','public']:\n",
    "    print('_________________________________________________')\n",
    "    print(val)\n",
    "    print('not present')\n",
    "    removed = set(prev[val]) - set(genes_tpm.index)\n",
    "    print(removed)\n",
    "    print('removed for QC reasons')\n",
    "    print(failed)\n",
    "    print('removed')\n",
    "    removed = set(prevrna[val]) - set(genes_tpm.index)\n",
    "    #print(removed - set(rename.keys()))\n",
    "    missing = set(new[val]) - set(genes_tpm.index)\n",
    "    blacklist = (set(genes_tpm.index) - (prevrna[val] | set(new[val]))) | blacklist\n",
    "    print('missing')\n",
    "    print(missing)\n",
    "    newlines = set(new[val]) \n",
    "    print('blacklist')\n",
    "    print(len(blacklist), blacklist)\n",
    "\n",
    "    ## removing first blacklisted, then embargoed, to create two datasets\n",
    "    print(len(genes_expected_count))\n",
    "    a = genes_expected_count[~genes_expected_count.index.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/expression_genes_expected_count.csv')\n",
    "    print(len(genes_tpm))\n",
    "    a = genes_tpm[~genes_tpm.index.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/expression_genes_tpm.csv')\n",
    "    print(len(proteincoding_genes_tpm))\n",
    "    a = proteincoding_genes_tpm[~proteincoding_genes_tpm.index.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/expression_proteincoding_genes_tpm.csv')\n",
    "    print(len(transcripts_tpm))\n",
    "    a = transcripts_tpm[~transcripts_tpm.index.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/expression_transcripts_tpm.csv')\n",
    "    print(len(proteincoding_genes_expected_count))\n",
    "    a = proteincoding_genes_expected_count[~proteincoding_genes_expected_count.index.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/expression_proteincoding_genes_expected_count.csv')\n",
    "    print(len(transcripts_expected_count))\n",
    "    a = transcripts_expected_count[~transcripts_expected_count.index.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/expression_transcripts_expected_count.csv')\n",
    "    \n",
    "    os.popen('cp readmes/'+val+'-'+release+'.txt temp/README')\n",
    "\n",
    "    # adding to taiga\n",
    "    tc.update_dataset(dataset_permaname=taiga_expression[val],\n",
    "                     upload_file_path_dict={\n",
    "                       'temp/expression_genes_expected_count.csv': 'NumericMatrixCSV',\n",
    "                       'temp/expression_transcripts_tpm.csv': 'NumericMatrixCSV',\n",
    "                       'temp/expression_genes_tpm.csv': 'NumericMatrixCSV',\n",
    "                       'temp/expression_proteincoding_genes_tpm.csv': 'NumericMatrixCSV',\n",
    "                       'temp/expression_proteincoding_genes_expected_count.csv': 'NumericMatrixCSV',\n",
    "                       'temp/expression_transcripts_expected_count.csv': 'NumericMatrixCSV',\n",
    "                     \"temp/README\": \"Raw\"},\n",
    "                      dataset_description=\n",
    "    \"\"\"\n",
    "    # INTERNAL RNA\n",
    "\n",
    "    for information, see README\n",
    "\n",
    "    NEW LINES:\n",
    "    \"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "    REMOVED FOR QC REASONS:\n",
    "    \"\"\"+str(failed)+\"\"\"\n",
    "\n",
    "    BLACKLIST:\n",
    "    \"\"\"+str(blacklist))\n",
    "\n",
    "    # add to virtual \n",
    "    AddToVirtual(virtual[val], taiga_expression[val], files=[\n",
    "    ('CCLE_expression_full', 'expression_genes_tpm'), \n",
    "    ('CCLE_RNAseq_transcripts', 'expression_transcripts_tpm'),\n",
    "    ('CCLE_RNAseq_reads', 'expression_genes_expected_count'),\n",
    "    ('CCLE_expression', 'expression_proteincoding_genes_tpm'),\n",
    "    ('CCLE_expression_proteincoding_genes_expected_count', 'expression_proteincoding_genes_expected_count'),\n",
    "    ('CCLE_expression_transcripts_expected_count', 'expression_transcripts_expected_count')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AddToVirtual('depmap-a0ab', taiga_expression['internal'], files=[\n",
    "('CCLE_expression_full', 'expression_genes_tpm'), \n",
    "('CCLE_RNAseq_transcripts', 'expression_transcripts_tpm'),\n",
    "('CCLE_RNAseq_reads', 'expression_genes_expected_count'),\n",
    "('CCLE_expression', 'expression_proteincoding_genes_tpm'), ('CCLE_expression_proteincoding_genes_expected_count', 'expression_proteincoding_genes_expected_count'),('CCLE_expression_transcripts_expected_count', 'expression_transcripts_expected_count')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions = pd.read_csv('temp/fusions_'+samplesetname+'.csv')\n",
    "filtered = pd.read_csv('temp/filtered_fusions_'+samplesetname+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(fusions.DepMap_ID) - set(filtered.DepMap_ID))\n",
    "print(set(filtered.DepMap_ID) - set(fusions.DepMap_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = set()\n",
    "for val in ['internal', 'ibm', 'dmc', 'public']:\n",
    "    print('_________________________________________________')\n",
    "    print(val)\n",
    "    print('not present')\n",
    "    removed = set(prev[val]) - set(fusions.DepMap_ID)\n",
    "    print(removed)\n",
    "    print('removed for QC reasons')\n",
    "    print(failed)\n",
    "    print('removed')\n",
    "    removed = set(prevrna[val]) - set(fusions.DepMap_ID)\n",
    "    print(removed - set(rename.keys()))\n",
    "    missing = set(new[val]) - set(fusions.DepMap_ID)\n",
    "    blacklist = (set(fusions.DepMap_ID) - (prevrna[val] | set(new[val]))) | blacklist\n",
    "    print('missing')\n",
    "    print(missing)\n",
    "    newlines = set(new[val]) \n",
    "    print('blacklist')\n",
    "    print(len(blacklist), blacklist)\n",
    "    ## removing first blacklisted, then embargoed, to create two datasets\n",
    "    print(len(fusions))\n",
    "    a = fusions[~fusions.DepMap_ID.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/fusions.csv', index=False)\n",
    "    print(len(filtered))\n",
    "    a= filtered[~filtered.DepMap_ID.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/filtered_fusions.csv', index=False)\n",
    "\n",
    "    os.popen('cp readmes/'+val+'-'+release+'.txt temp/README')\n",
    "\n",
    "    # uploading to taiga\n",
    "    tc.update_dataset(dataset_permaname=taiga_fusion[val],\n",
    "                     upload_file_path_dict={\n",
    "                         'temp/fusions.csv': 'TableCSV',\n",
    "                         'temp/filtered_fusions.csv': 'TableCSV',\n",
    "                         'temp/README': 'Raw'},\n",
    "                      dataset_description=\n",
    "    \"\"\"\n",
    "    # Internal Fusions\n",
    "\n",
    "    for more information, see README\n",
    "\n",
    "    NEW LINES:\n",
    "    \"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "    REMOVED FOR QC REASONS:\n",
    "    \"\"\"+str(failed)+\"\"\"\n",
    "\n",
    "    BLACKLIST:\n",
    "    \"\"\"+str(blacklist))\n",
    "\n",
    "    # virtual datasets\n",
    "    AddToVirtual(virtual[val], taiga_fusion[val], files=[('CCLE_fusions_unfiltered', 'fusions'),('CCLE_fusions', 'filtered_fusions')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AddToVirtual('depmap-a0ab', \"gene-fusions-8b7a\", files=[('CCLE_fusions_unfiltered', 'fusions'),('CCLE_fusions', 'filtered_fusions')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "206px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
