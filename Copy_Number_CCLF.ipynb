{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Number Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import sys\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from src.CCLE_postp_function import *\n",
    "from JKBio import terra\n",
    "from JKBio.utils import helper as h\n",
    "from JKBio.google import gcp\n",
    "from gsheets import Sheets\n",
    "from taigapy import TaigaClient\n",
    "import dalmatian as dm\n",
    "from JKBio.google.google_sheet import dfToSheet\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "\n",
    "from bokeh.plotting import *\n",
    "from bokeh.models import HoverTool\n",
    "from collections import OrderedDict\n",
    "from IPython.display import Image,display\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext rpy2.ipython\n",
    "tc = TaigaClient()\n",
    "output_notebook()\n",
    "\n",
    "my_id = '~/.client_secret.json'\n",
    "mystorage_id = \"~/.storage.json\"\n",
    "# do the first steps of https://medium.com/craftsmenltd/from-csv-to-google-sheet-using-python-ef097cb014f9\n",
    "creds = '../.credentials.json'\n",
    "\n",
    "sheets = Sheets.from_files(my_id, mystorage_id)\n",
    "replace = {'T': 'Tumor', 'N': 'Normal', 'm': 'Unknown', 'L': 'Unknown'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace1=\"nci-mimoun-bi-org/CCLF_WES\"\n",
    "# refworkspace=\"nci-mimoun-bi-org/CCLF_WES_CN_HG38_tmp\"\n",
    "refworkspace=\"cclf-core/CCLF_WES_CN_HG38\"\n",
    "source1=\"cclf\"\n",
    "sample_set_id = \"CCLF_WES_august\"\n",
    "release = sample_set_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm1 = dm.WorkspaceManager(workspace1)\n",
    "cnwm = dm.WorkspaceManager(refworkspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = cnwm.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refwm.delete_sample(cnwm.get_samples().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toprocess = pd.read_csv('data/CCLF_august/toprocess.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toprocess = [i.CCLE_Name+\"-Tumor-\" + i.CCLF_ID for p, i in toprocess.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = dm.WorkspaceManager(\"cclf-core/CCLF_WES_CN_HG38\").get_samples()\n",
    "# samples = samples[['participant']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs = dm.WorkspaceManager(\"cclf-core/CCLF_WES_CN_HG38\").get_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair_sets = dm.WorkspaceManager(\"cclf-core/CCLF_WES_CN_HG38\").get_pair_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_sets = dm.WorkspaceManager(\"cclf-core/CCLF_WES_CN_HG38\").get_sample_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and CN\n",
    "cnwm = cnwm.disable_hound()\n",
    "cnwm.upload_samples(samples)\n",
    "cnwm.upload_entities('pairs', pairs)\n",
    "# cnwm.update_pair_set(pair_set_id=samplesetname, pair_ids=pairs.index)\n",
    "sam = cnwm.get_samples()\n",
    "\n",
    "# pair = cnwm.get_pairs()\n",
    "# cnwm.update_pair_set(pair_set_id='all',pair_ids=pair.index)\n",
    "# cnwm.update_pair_set(pair_set_id='all_agilent',pair_ids=pair[pair[\"case_sample\"].isin(sam[sam['baits']==\"AGILENT\"].index.tolist())].index)\n",
    "# cnwm.update_pair_set(pair_set_id='all_ice',pair_ids=pair[pair[\"case_sample\"].isin([i for i in sam[(sam['baits'] == \"ICE\") |(sam['baits'].isna())].index.tolist() if i != 'nan'])].index)\n",
    "#creating a sample set\n",
    "# cnwm.update_sample_set(sample_set_id=samplesetname, sample_ids=samples.index)\n",
    "cnwm.update_sample_set(sample_set_id='all', sample_ids=sample_sets.loc['all', 'samples'])\n",
    "cnwm.update_sample_set(sample_set_id='all_agilent', sample_ids = sample_sets.loc['all_agilent', 'samples'])\n",
    "cnwm.update_sample_set(sample_set_id='all_ice', sample_ids=sample_sets.loc['all_ice', 'samples'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the pipeline\n",
    "\n",
    "We are using Dalmatian to send request to Terra, we are running a set of 5 functions To generate the copy number dataset:\n",
    "\n",
    "*   **BamToUnmappedRGBams_MC** vdauwera/BamToUnmappedRGBamsSnapshot ID: 3\n",
    "*   **Generate_uBAM_File_List** gkugener/ArrayOfFilesToTxtSnapshot ID: 1\n",
    "*   **Realign_WES_GATK4** gatk/PreProcessingForVariantDiscovery_GATK4Snapshot ID: 7\n",
    "*   **CNV_sample_XX** gatk/CNV_Somatic_Pair_WorkflowSnapshot ID: 9\n",
    "*   **Aggregate_CN_seg_files** gkugener/Aggregate_CN_seg_filesSnapshot ID: 2\n",
    "\n",
    "This output file for download will be saved under the sample set under the combined_seg_file attribute.\n",
    "\n",
    "There are several other tasks in this workspace. In brief:\n",
    "\n",
    "*   **CNV_Somatic_Panel_Workflow_Agilent_XX** gatk/CNV_Somatic_Panel_WorkflowSnapshot ID: 11. This task was used in this workspace to generate the Sanger PON. In the Sanger dataset, there is a set of 40 normal cell lines samples (cell lines derived from matched normal tissue). We can use these to generate a PON to normalize to rather than using the Agilent PON we use for the other CCLE cell lines. This leads to less noisy results. HOWEVER, results using the PON from this workflow should not use the X chromosome, as the sanger normals are not exclusively female or male (it is likely a mix).\n",
    "*   **SANGER_PON_CNV_sample_XX** gatk/CNV_Somatic_Pair_WorkflowSnapshot ID: 9. Same as the CNV_sample_XX_gatk, except that is uses the Sanger based PON. Should be used only for the Sanger cell lines.\n",
    "*   **Sanger_PON_Aggregate_CN_seg_files** gkugener/Aggregate_CN_seg_filesSnapshot ID: 2. Aggregates the segment files for the samples that were run using the Sanger PON based CNV workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torm = terra.deleteHeavyFiles(refworkspace)\n",
    "h.parrun(['gsutil rm '+i for i in torm], cores=8)\n",
    "terra.removeFromFailedWorkflows(refworkspace, dryrun=False, everythingFor=['Realign_WES_GATK4','Generate_uBAM_File_List','BamToUnmappedRGBams_MC','CGA_WES_CCLE_ICE','CGA_WES_CCLE_AGILENT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Terra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of Terra workflows that are in the workspace and that we will call sequentially\n",
    "bamtoubam= \"BamToUnmappedRGBams_MC\"\n",
    "ubamtofilelist = \"Generate_uBAM_File_List\"\n",
    "realign=\"Realign_WES_GATK4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see dalmatian\n",
    "subid = refwm.create_submission(bamtoubam, samplesetname,\"sample_set\",\"this.samples\")\n",
    "terra.waitForSubmission(refworkspace, subid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subid = refwm.create_submission(ubamtofilelist,samplesetname,\"sample_set\",\"this.samples\")\n",
    "terra.waitForSubmission(refworkspace, subid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subid = refwm.create_submission(realign,samplesetname,\"sample_set\",\"this.samples\")\n",
    "terra.waitForSubmission(refworkspace, subid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing out the XY PoN for CN characterization. Will test by producing an output in a different column from usual so it's easy to delete the column attribute later\n",
    "# Also, need to make a split between Agilent and ICE samples..\n",
    "submission_id= refwm.create_submission(\"CNV_sample_XY_ice\",etype='sample_set',entity='all_ice', expression='this.samples')\n",
    "terra.waitForSubmission(refworkspace,submission_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id= refwm.create_submission(\"CNV_sample_XY_agilent\",etype='sample_set',entity='all_agilent', expression='this.samples')\n",
    "terra.waitForSubmission(refworkspace,submission_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy pairs data to sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = refwm.get_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairs[~pairs['called_copy_ratio_segments_tumor'].isna()]\n",
    "pairs = pairs.drop(columns=['case_sample','control_sample','participant'])\n",
    "pairs.index = [i.split('_')[0] for i in pairs.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refwm.update_sample_attributes(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id = cnwm.create_submission(\"Aggregate_CN_seg_files\", entity=\"all\")\n",
    "terra.waitForSubmission(refworkspace, submission_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.waitForSubmission(refworkspace, submission_id)\n",
    "aggregated = cnwm.get_entities('sample_set').loc['all'][\"combined_seg_file\"]\n",
    "aggregated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We then save the workflow configurations used__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.saveConfigs(refworkspace, 'data/'+sample_set_id+'/CNVconfig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__delete unmapped bams generated during the process__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toremove = [\"readgroup_ubams\",]\n",
    "res = refwm.get_samples()\n",
    "for val in toremove:\n",
    "    refwm.disable_hound().delete_entity_attributes('sample', res[val], delete_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes the previous step does not work and you need to do it manually (you can run this to check it worked)\n",
    "for val in samplesinset.readgroup_ubams:\n",
    "    ubams = ''\n",
    "    if not type(val) is list:\n",
    "        continue \n",
    "    for v in val:\n",
    "        ubams+=' '+v\n",
    "    os.system('gsutil -m rm'+ubams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = 'gs://fc-secure-d8458bee-4f7e-4de1-b9d0-17df5cbe9477/7e944d7a-960a-4a1f-995a-55801d02fdc1/aggregate_CN_segments_wrkflw/d17c98f0-6754-490c-9b32-69c5f63314fe/call-aggregate_CN_segments/cacheCopy/all.called.seg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = pd.read_csv(\"temp/cnv_ccle.called.seg.tsv\", sep='\\t')\n",
    "segments.to_csv(\"temp/cnv_ccle.called.seg\", index)\n",
    "# TODO: copy allelic calls as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(segments.Sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = segments.rename(columns={'CONTIG':'Chromosome',\n",
    "'START':'Start',\n",
    "'END':'End',\n",
    "'Sample':\"DepMap_ID\",\n",
    "'NUM_POINTS_COPY_RATIO':'Num_Probes',\n",
    "'MEAN_LOG2_COPY_RATIO':'Segment_Mean',\n",
    "'CALL':'Status'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## post Procesing\n",
    "\n",
    "The post processing happens in R using guillaume's functions, in brief:\n",
    "\n",
    "- processSegments\n",
    "- filterForCCLE\n",
    "- interpolateGapsInSegmented\n",
    "- extendEndsOfSegments\n",
    "- reprioritizeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_mapping = pd.read_csv('data/genemapping_19Q1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments['Chromosome'] = [i[3:] for i in segments['Chromosome'].tolist()]\n",
    "# reverting logtransform of GTK\n",
    "segments.Segment_Mean = 2**segments.Segment_Mean\n",
    "segments.Start = segments.Start.astype(int)\n",
    "segments.End = segments.End.astype(int)\n",
    "# setting sex genes to half of their value for it to match relative concentration of other genes.\n",
    "segments.loc[segments[segments.Chromosome.isin(['X','Y'])].index,'Segment_Mean'] = segments[segments.Chromosome.isin(['X','Y'])]['Segment_Mean']/2\n",
    "segments = segments.sort_values(by=['DepMap_ID','Chromosome','Start','End'])\n",
    "gene_mapping = gene_mapping.sort_values(by=['Chromosome','start','end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check on IGV maxvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation step\n",
    "\n",
    "Once the files are saved, we load them back in python and do some validations, in brief:\n",
    "\n",
    "- mean,max,var...\n",
    "- to previous version: same mean,max,var...\n",
    "- checkAmountOfSegments: flag any samples with a very high number of segments\n",
    "- checkGeneChangeAccrossAll: flag any genes which stay at a similar value across all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(segments[segments.Segment_Mean>1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from JKBio.mutations import manageGapsInSegments, toGeneMatrix, checkGeneChangeAccrossAll, checkAmountOfSegments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapmergedsegs = manageGapsInSegments(segments)\n",
    "genecn = toGeneMatrix(gapmergedsegs, gene_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genecn.to_csv('temp/gene_cn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join(checkGeneChangeAccrossAll(genecn, thresh=0.025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genecn.values.min(), genecn.values.mean(), genecn.values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = checkAmountOfSegments(segments, thresh = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to taiga\n",
    "\n",
    "- we load the blacklisted/embargoed sample ids\n",
    "- we log2 transform and create a file for each release (and one containing everything)\n",
    "- we upload the files using taigapy in a corresponding taiga dataset with the corresponding description and also upload it to its virtual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taigapy import TaigaClient\n",
    "tc = TaigaClient()\n",
    "\n",
    "dataset_version_id = tc.update_dataset(\n",
    "    dataset_id='cclf-cn-f083',\n",
    "    changes_description='divide X values by half',\n",
    "    upload_files=[\n",
    "        {\"path\": 'temp/cnv_ccle.called.seg',\n",
    "        \"format\": 'TableCSV',\n",
    "        \"name\": 'wes_segment_cn_Xhalved'},\n",
    "        {\"path\": 'temp/gene_cn.csv',\n",
    "         'format': 'NumericMatrixCSV',\n",
    "         \"name\": 'wes_gene_cn_Xhalved'}\n",
    "    ],\n",
    "    add_all_existing_files=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "313px",
    "width": "588px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230.788px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
