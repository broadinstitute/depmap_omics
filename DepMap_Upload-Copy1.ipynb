{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro & Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "\n",
    "import os \n",
    "\n",
    "from genepy.utils import helper as h\n",
    "from depmapomics import terra as myterra\n",
    "from depmapomics.config import *\n",
    "from gsheets import Sheets\n",
    "from taigapy import TaigaClient\n",
    "from bokeh.plotting import output_notebook\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext rpy2.ipython\n",
    "tc = TaigaClient()\n",
    "output_notebook()\n",
    "\n",
    "sheets = Sheets.from_files('~/.client_secrets.json', '~/.storage.json')\n",
    "\n",
    "virtual = VIRTUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIRTUAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making the virtuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = {}\n",
    "gsheets = sheets.get(POTENTIAL_LIST).sheets[0].to_frame()\n",
    "new['internal'] = set([i for i in gsheets['Internal'].values.tolist() if str(i) != \"nan\"])\n",
    "new['dmc'] = set([i for i in gsheets['DMC'].values.tolist() if str(i) != \"nan\"])\n",
    "new['ibm'] = set([i for i in gsheets['IBM'].values.tolist() if str(i) != \"nan\"])\n",
    "new['public'] = set([i for i in gsheets['Public'].values.tolist() if str(i) != \"nan\"])\n",
    "\n",
    "\n",
    "new[\"internal\"] = new[\"internal\"] | new[\"ibm\"] | new[\"dmc\"] | new[\"public\"]\n",
    "new[\"ibm\"] = new[\"ibm\"] | new[\"dmc\"] | new[\"public\"]\n",
    "new[\"dmc\"] = new[\"dmc\"] | new[\"public\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting what was released before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevmut = {}\n",
    "prevrna = {}\n",
    "prevcn = {}\n",
    "prevwes = {}\n",
    "prev = {}\n",
    "for val in datasets:\n",
    "    print(val)\n",
    "    prevmut[val] = set(tc.get(name=PREV_VIRTUAL[val], file='CCLE_mutations').DepMap_ID)\n",
    "    prevrna[val] = set(tc.get(name=PREV_VIRTUAL[val], file='CCLE_expression').index)\n",
    "    prevcn[val] = set(tc.get(name=PREV_VIRTUAL[val], file='CCLE_segment_cn').DepMap_ID)\n",
    "    prev[val] = prevmut[val] | prevrna[val] | prevcn[val]\n",
    "    prevwes[val] = prevmut[val] | prevcn[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevmut[\"dmc\"] = prevmut[\"dmc\"] | prevmut[\"public\"]\n",
    "prevrna[\"dmc\"] = prevrna[\"dmc\"] | prevrna[\"public\"]\n",
    "prevcn[\"dmc\"] = prevcn[\"dmc\"] | prevcn[\"public\"]\n",
    "prev[\"dmc\"] = prev[\"dmc\"] | prev[\"public\"]\n",
    "prevwes[\"dmc\"] = prevwes[\"dmc\"] | prevwes[\"public\"]\n",
    "\n",
    "prevmut[\"ibm\"] = prevmut[\"ibm\"] | prevmut[\"dmc\"]\n",
    "prevrna[\"ibm\"] = prevrna[\"ibm\"] | prevrna[\"dmc\"]\n",
    "prevcn[\"ibm\"] = prevcn[\"ibm\"] | prevcn[\"dmc\"]\n",
    "prev[\"ibm\"] = prev[\"ibm\"] | prev[\"dmc\"]\n",
    "prevwes[\"ibm\"] = prevwes[\"ibm\"] | prevwes[\"dmc\"]\n",
    "\n",
    "prevmut[\"internal\"] = prevmut[\"internal\"] | prevmut[\"ibm\"]\n",
    "prevrna[\"internal\"] = prevrna[\"internal\"] | prevrna[\"ibm\"]\n",
    "prevcn[\"internal\"] = prevcn[\"internal\"] | prevcn[\"ibm\"]\n",
    "prev[\"internal\"] = prev[\"internal\"] | prev[\"ibm\"]\n",
    "prevwes[\"internal\"] = prevwes[\"internal\"] | prevwes[\"ibm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentcn = pd.read_csv('temp/'+SAMPLESETNAME+'/achilles_segment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFO = {}\n",
    "blacklist = set()\n",
    "\n",
    "for val in datasets:\n",
    "    removed = set(prevcn[val]) - set(segmentcn.DepMap_ID)\n",
    "    missing = set(new[val]) - set(segmentcn.DepMap_ID)\n",
    "    blacklist = (set(segmentcn.DepMap_ID) - (prevcn[val] | set(new[val]))) | blacklist\n",
    "    newlines = set(new[val]) \n",
    "\n",
    "    INFO[val] = \"# \" + val + \"\"\" dataset:\n",
    "                \n",
    "## DNAseq Omics:\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "BLACKLIST:\n",
    "\"\"\"+str(blacklist)+\"\"\"\n",
    "\n",
    "MISSING:\n",
    "\"\"\"+str(missing)+\"\"\"\n",
    "\n",
    "REMOVED:\n",
    "\"\"\"+str(removed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_tpm = pd.read_csv('temp/'+SAMPLESETNAME+'/genes_tpm_logp1.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnafailed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = {'ACH-000658'}\n",
    "for val in datasets:\n",
    "    removed = set(prev[val]) - set(genes_tpm.index)\n",
    "    removed = set(prevrna[val]) - set(genes_tpm.index)\n",
    "    missing = set(new[val]) - set(genes_tpm.index)\n",
    "    blacklist = (set(genes_tpm.index) - (prevrna[val] | set(new[val]))) | blacklist\n",
    "    newlines = set(new[val]) \n",
    "    \n",
    "    INFO[val] += \"\"\"\n",
    "\n",
    "\n",
    "## RNAseq Omics:\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+str(newlines)+\"\"\"\n",
    "\n",
    "BLACKLIST:\n",
    "\"\"\"+str(blacklist)+\"\"\"\n",
    "\n",
    "MISSING:\n",
    "\"\"\"+str(missing)+\"\"\"\n",
    "\n",
    "REMOVED:\n",
    "\"\"\"+str(removed)+\"\"\"\n",
    "                \n",
    "REMOVED FOR QC REASONS:\n",
    "\"\"\"+str(rnafailed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions = pd.read_csv('temp/'+SAMPLESETNAME+'/fusions_latest.csv')\n",
    "filtered = pd.read_csv('temp/'+SAMPLESETNAME+'/filteredfusions_latest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = {'ACH-000658'}\n",
    "for val in datasets:\n",
    "    print('_________________________________________________')\n",
    "    print(val)\n",
    "    print('not present')\n",
    "    removed = set(prev[val]) - set(fusions.DepMap_ID)\n",
    "    print(removed)\n",
    "    print('removed for QC reasons')\n",
    "    print(failed)\n",
    "    print('removed')\n",
    "    removed = set(prevrna[val]) - set(fusions.DepMap_ID)\n",
    "    print(removed)\n",
    "    missing = set(new[val]) - set(fusions.DepMap_ID)\n",
    "    blacklist = (set(fusions.DepMap_ID) - (prevrna[val] | set(new[val]))) | blacklist\n",
    "    print('missing')\n",
    "    print(missing)\n",
    "    newlines = set(new[val]) \n",
    "    print('blacklist')\n",
    "    print(len(blacklist), blacklist)\n",
    "    ## removing first blacklisted, then embargoed, to create two datasets\n",
    "    print(len(fusions))\n",
    "    a = fusions[~fusions.DepMap_ID.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/fusions.csv', index=False)\n",
    "    print(len(filtered))\n",
    "    a= filtered[~filtered.DepMap_ID.isin(blacklist)]\n",
    "    print(len(a))\n",
    "    a.to_csv('temp/filtered_fusions.csv', index=False)\n",
    "\n",
    "    # uploading to taiga\n",
    "    tc.update_dataset(virtual[val],\n",
    "                      changes_description='adding fusions',\n",
    "                      upload_files=[\n",
    "                        {\n",
    "                            \"path\": \"temp/fusions.csv\",\n",
    "                            \"name\": \"CCLE_fusions_unfiltered\",\n",
    "                            \"format\": \"TableCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"path\": \"temp/filtered_fusions.csv\",\n",
    "                            \"name\": \"CCLE_fusions\",\n",
    "                            \"format\": \"TableCSV\",\n",
    "                            \"encoding\": \"utf-8\"\n",
    "                        },\n",
    "                      ],\n",
    "                      dataset_description=INFO[val],\n",
    "                      add_all_existing_files=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating eternal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLatestVersion(dataset, approved_only=True):\n",
    "    highest = 0\n",
    "    latest_version = 0\n",
    "    data = tc.get_dataset_metadata(dataset)\n",
    "    for val in data['versions']:\n",
    "        if val['state']==\"approved\" or not approved_only:\n",
    "            if int(val['name'])>highest:\n",
    "                highest = int(val['name'])\n",
    "                latest_version = highest\n",
    "    if latest_version==0:\n",
    "        raise ValueError('could not find a version')\n",
    "    return data['permanames'][0]+'.'+str(latest_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add to a eternal dataset\n",
    "latest_version = findLatestVersion(virtual['internal'])\n",
    "\n",
    "files = [\"CCLE_gene_cn\", \"CCLE_segment_cn\", \n",
    "         \n",
    "         \"CCLE_mutations\", \"CCLE_mutations_bool_damaging\", \"CCLE_mutations_bool_nonconserving\", \"CCLE_mutations_bool_otherconserving\", \"CCLE_mutations_bool_hotspot\", \n",
    "         \n",
    "         \"CCLE_expression_full\", \"CCLE_RNAseq_transcripts\", \"CCLE_RNAseq_reads\", \"CCLE_expression\", \"CCLE_expression_proteincoding_genes_expected_count\", \"CCLE_expression_transcripts_expected_count\",\n",
    "\n",
    "         \"CCLE_fusions_unfiltered\", \"CCLE_fusions\"]\n",
    "\n",
    "tc.update_dataset(eternal_dataset,\n",
    "                changes_description='new '+SAMPLESETNAME+\" omics dataset.\",\n",
    "                add_taiga_ids=[{\"taiga_id\": latest_version +\"/\"+ file, \"name\": file} for file in files],\n",
    "                add_all_existing_files=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving the current release version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd ../ccle_processing && git add . && git commit -m \"depmap omics $samplesetname final\" && git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bba30bad6dc2abd483aef1526473acfc7356ef9fe6d481727d10a1c0a97ae5c6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
