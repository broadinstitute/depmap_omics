{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebd33b02",
   "metadata": {},
   "source": [
    "Read sample table from Terra workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7adf35ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dalmatian\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "namespace = \"broad-firecloud-ccle\"\n",
    "workspaces = [\"DepMap_WES_CN_hg38\", \"DepMap_WGS_CN\"]\n",
    "dest_dataset = \"depmap-omics.maf_staging_0916\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac52eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class Transfer:\n",
    "    srcs : str\n",
    "    dest_table : str\n",
    "    cds_id : str\n",
    "\n",
    "def get_transfers(workspace):\n",
    "    wm = dalmatian.WorkspaceManager(f\"{namespace}/{workspace}\")\n",
    "\n",
    "    sample = wm.get_entities(\"sample\")\n",
    "    sample = sample.reset_index()\n",
    "\n",
    "    transfers = []\n",
    "    for rec in sample.to_dict(\"records\"):\n",
    "        if isinstance(rec['full_file'], list):\n",
    "            dest_table = f\"{dest_dataset}.stage_maf_{rec['sample_id'].replace('-', '_')}\"\n",
    "            transfers.append(Transfer(rec['full_file'], dest_table, rec[\"sample_id\"]))\n",
    "\n",
    "    return transfers\n",
    "\n",
    "transfers = []\n",
    "for workspace in workspaces:\n",
    "    transfers.extend(get_transfers(workspace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00899f91-644e-446a-a20e-f9665a7f1bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2395"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transfers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7060ef69",
   "metadata": {},
   "source": [
    "Create \"external\" tables, one per cds_id from the associated uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254a6070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "import re\n",
    "\n",
    "from google.api_core.exceptions import Conflict\n",
    "\n",
    "def create_ext_table(srcs, dest_table, job_prefix):\n",
    "    table = bigquery.Table(dest_table)\n",
    "\n",
    "    external_config = bigquery.ExternalConfig(bigquery.external_config.ExternalSourceFormat.PARQUET)\n",
    "    external_config.source_uris = srcs\n",
    "    table.external_data_configuration = external_config\n",
    "\n",
    "    client.create_table(table, exists_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53533c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd635b019a81401f86ca6b4362221f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def cleanup_uris(uris):\n",
    "    result = []\n",
    "    for uri in uris:\n",
    "        result.extend([x.strip() for x in uri.split(\",\")])\n",
    "    return list(set(result))\n",
    "\n",
    "#transfers = transfers[:10]\n",
    "\n",
    "# create a bunch of tables which correspond to CDS_IDs, because we want to add CDS_ID as a column\n",
    "for transfer in tqdm(transfers):\n",
    "    uris = cleanup_uris(transfer.srcs) # at least one row has a entry which looks like a string containing a comma seperated list instead of a real list\n",
    "    create_ext_table(uris, transfer.dest_table, \"t2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a64de8e-fe81-4be0-92ef-905c1f093019",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = client.get_table(table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ae9b4d-654d-409e-b5c3-858c18b363cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transfer(srcs=['gs://fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/submissions/745d8e9e-5651-453e-842a-7add2f3c16b5/run_vcf_to_depmap/15616287-c648-4836-8a34-3296d3fe2638/call-vcf_to_depmap/glob-5efb9cd35734f694b162198c2ed1e6ac/238d247a228040148d3a63ab161ad46e-0.parquet', 'gs://fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/submissions/745d8e9e-5651-453e-842a-7add2f3c16b5/run_vcf_to_depmap/15616287-c648-4836-8a34-3296d3fe2638/call-vcf_to_depmap/glob-5efb9cd35734f694b162198c2ed1e6ac/89cb21285167491e98a7aa0267a2256d-0.parquet', 'gs://fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/submissions/745d8e9e-5651-453e-842a-7add2f3c16b5/run_vcf_to_depmap/15616287-c648-4836-8a34-3296d3fe2638/call-vcf_to_depmap/glob-5efb9cd35734f694b162198c2ed1e6ac/935cda2204e547d9a00128a5cf086676-0.parquet', 'gs://fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/submissions/745d8e9e-5651-453e-842a-7add2f3c16b5/run_vcf_to_depmap/15616287-c648-4836-8a34-3296d3fe2638/call-vcf_to_depmap/glob-5efb9cd35734f694b162198c2ed1e6ac/961daae3052f47598d20801a3bfc020a-0.parquet', 'gs://fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/submissions/745d8e9e-5651-453e-842a-7add2f3c16b5/run_vcf_to_depmap/15616287-c648-4836-8a34-3296d3fe2638/call-vcf_to_depmap/glob-5efb9cd35734f694b162198c2ed1e6ac/d4864d841c5f46c388eebb8d6abe3aed-0.parquet', 'gs://fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/submissions/745d8e9e-5651-453e-842a-7add2f3c16b5/run_vcf_to_depmap/15616287-c648-4836-8a34-3296d3fe2638/call-vcf_to_depmap/glob-5efb9cd35734f694b162198c2ed1e6ac/ddfa88a34e9d4508b8dafe06cf132d33-0.parquet', 'gs://fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/submissions/745d8e9e-5651-453e-842a-7add2f3c16b5/run_vcf_to_depmap/15616287-c648-4836-8a34-3296d3fe2638/call-vcf_to_depmap/glob-5efb9cd35734f694b162198c2ed1e6ac/f765931477544456a9ff212c2d93e729-0.parquet', 'gs://fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/submissions/745d8e9e-5651-453e-842a-7add2f3c16b5/run_vcf_to_depmap/15616287-c648-4836-8a34-3296d3fe2638/call-vcf_to_depmap/glob-5efb9cd35734f694b162198c2ed1e6ac/f8882fa214d3419e9097d31b23dfb7fa-0.parquet', 'gs://fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/submissions/745d8e9e-5651-453e-842a-7add2f3c16b5/run_vcf_to_depmap/15616287-c648-4836-8a34-3296d3fe2638/call-vcf_to_depmap/glob-5efb9cd35734f694b162198c2ed1e6ac/fbe3b1c47edc40409aaf9c5905e2519a-0.parquet'], dest_table='depmap-omics.maf_staging_0916.stage_maf_CDS_ztD4Zl', cds_id='CDS-ztD4Zl')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7609ecde",
   "metadata": {},
   "source": [
    "Copy from the external table into a single table adding the cds_id to each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c502fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def create_batches(data, batch_size):\n",
    "    return [data[x:x+batch_size] for x in range(0, len(data), batch_size)]\n",
    "\n",
    "# Concatenate table adding CDS_ID to the dest table\n",
    "def concatenate_tables(dest_table, transfers, job_prefix, parallelism):\n",
    "    create_table_stmt = f\"create table if not exists {dest_table} as select 'invalid' CDS_ID, * from `{transfers[0].dest_table}` limit 0\"\n",
    "    job = client.query(create_table_stmt)\n",
    "    job.result() # wait for completion\n",
    "\n",
    "    # figure out which cds_ids have already been loaded\n",
    "    already_loaded = set(pd.read_gbq(f\"\"\"select distinct cds_id from `{dest_dataset}.merged_maf` \"\"\")[\"cds_id\"])\n",
    "    \n",
    "    # drop transfers already loaded\n",
    "    remaining_transfers = [x for x in transfers if x.cds_id not in already_loaded]\n",
    "    print(f\"{len(already_loaded)} CDS IDs already loaded. {len(remaining_transfers)} of {len(transfers)} tables need to be loaded\")\n",
    "    transfers = remaining_transfers\n",
    "          \n",
    "    batches = create_batches(transfers, parallelism)\n",
    "    #return\n",
    "    \n",
    "    for batch in tqdm(batches, desc=\"batch\", position=0):\n",
    "        jobs = []\n",
    "\n",
    "        # submit a batch to run in parallel\n",
    "        for transfer in tqdm(batch, desc=\" submit\", position=1, leave=False):\n",
    "            append_stmt = f\"insert into {dest_table} select '{transfer.cds_id}' CDS_ID, * from {transfer.dest_table} where hugo_symbol != '' and hugo_symbol is not NULL\"\n",
    "\n",
    "            job = client.query(append_stmt)            \n",
    "            jobs.append(job)\n",
    "        \n",
    "        # wait for batch to complete\n",
    "        for job in tqdm(jobs, desc=\" wait\", position=1, leave=False):            \n",
    "            job.result() # wait for completion\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d34dca77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 CDS IDs already loaded. 2395 of 2395 tables need to be loaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9667ced6b8b4b1dbda3ae54d89f8e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batch:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " submit:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3caf6cda2b4549b62ace9e4b9f1696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " wait:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "BadRequest",
     "evalue": "400 Query column 6 has type INT64 which cannot be inserted into column civic_description, which has type STRING at [1:54]\n\nLocation: US\nJob ID: 0c018b91-a1cd-49c2-b624-bfd798c57878\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconcatenate_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdest_dataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.merged_maf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransfers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mt5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallelism\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mconcatenate_tables\u001b[0;34m(dest_table, transfers, job_prefix, parallelism)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# wait for batch to complete\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m tqdm(jobs, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m wait\u001b[39m\u001b[38;5;124m\"\u001b[39m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):            \n\u001b[0;32m---> 36\u001b[0m     \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/jupyter/lib/python3.9/site-packages/google/cloud/bigquery/job/query.py:1499\u001b[0m, in \u001b[0;36mQueryJob.result\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retry_do_query \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m job_retry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1497\u001b[0m         do_get_result \u001b[38;5;241m=\u001b[39m job_retry(do_get_result)\n\u001b[0;32m-> 1499\u001b[0m     \u001b[43mdo_get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mGoogleAPICallError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1502\u001b[0m     exc\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m=\u001b[39m _EXCEPTION_FOOTER_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1503\u001b[0m         message\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39mmessage, location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation, job_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\n\u001b[1;32m   1504\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/jupyter/lib/python3.9/site-packages/google/api_core/retry.py:283\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    280\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    282\u001b[0m )\n\u001b[0;32m--> 283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/jupyter/lib/python3.9/site-packages/google/api_core/retry.py:190\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/jupyter/lib/python3.9/site-packages/google/cloud/bigquery/job/query.py:1489\u001b[0m, in \u001b[0;36mQueryJob.result.<locals>.do_get_result\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_do_query \u001b[38;5;241m=\u001b[39m retry_do_query\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_job_retry \u001b[38;5;241m=\u001b[39m job_retry\n\u001b[0;32m-> 1489\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mQueryJob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;66;03m# Since the job could already be \"done\" (e.g. got a finished job\u001b[39;00m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;66;03m# via client.get_job), the superclass call to done() might not\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;66;03m# set the self._query_results cache.\u001b[39;00m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reload_query_results(retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/jupyter/lib/python3.9/site-packages/google/cloud/bigquery/job/base.py:728\u001b[0m, in \u001b[0;36m_AsyncJob.result\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_begin(retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    727\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;129;01mis\u001b[39;00m DEFAULT_RETRY \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretry\u001b[39m\u001b[38;5;124m\"\u001b[39m: retry}\n\u001b[0;32m--> 728\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_AsyncJob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/jupyter/lib/python3.9/site-packages/google/api_core/future/polling.py:137\u001b[0m, in \u001b[0;36mPollingFuture.result\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking_poll(timeout\u001b[38;5;241m=\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# Pylint doesn't recognize that this is valid in this case.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 Query column 6 has type INT64 which cannot be inserted into column civic_description, which has type STRING at [1:54]\n\nLocation: US\nJob ID: 0c018b91-a1cd-49c2-b624-bfd798c57878\n"
     ]
    }
   ],
   "source": [
    "concatenate_tables(f\"{dest_dataset}.merged_maf\", transfers, \"t5\", parallelism=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "125a8904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "q = client.query(f\"\"\"select * from (\n",
    "  SELECT chrom, pos, variant_type, count(1) mut_count FROM `{dest_dataset}.merged_maf` \n",
    "  where hugo_symbol='BRAF'\n",
    "  group by chrom, pos, variant_type) where mut_count > 10\n",
    "  LIMIT 1000\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e016b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = q.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "267d61df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cabc9208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x17ded4640>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c0dfbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_gbq(f\"\"\"select * from (\n",
    "  SELECT chrom, pos, variant_type, count(1) mut_count FROM `{dest_dataset}.merged_maf` \n",
    "  group by chrom, pos, variant_type)\n",
    "  LIMIT 1000\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b607cbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>variant_type</th>\n",
       "      <th>mut_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>144412187</td>\n",
       "      <td>SNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr22</td>\n",
       "      <td>22690933</td>\n",
       "      <td>DNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>177976318</td>\n",
       "      <td>DNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr3</td>\n",
       "      <td>159842127</td>\n",
       "      <td>DNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr7</td>\n",
       "      <td>5030546</td>\n",
       "      <td>SNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>chr3</td>\n",
       "      <td>167868549</td>\n",
       "      <td>SNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>chr2</td>\n",
       "      <td>239529175</td>\n",
       "      <td>SNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>chr8</td>\n",
       "      <td>12036530</td>\n",
       "      <td>SNP</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>chr8</td>\n",
       "      <td>43247356</td>\n",
       "      <td>SNP</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>chr2</td>\n",
       "      <td>176783423</td>\n",
       "      <td>SNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chrom        pos variant_type  mut_count\n",
       "0     chr1  144412187          SNP          1\n",
       "1    chr22   22690933          DNP          2\n",
       "2     chr1  177976318          DNP          1\n",
       "3     chr3  159842127          DNP          1\n",
       "4     chr7    5030546          SNP          1\n",
       "..     ...        ...          ...        ...\n",
       "995   chr3  167868549          SNP          1\n",
       "996   chr2  239529175          SNP          1\n",
       "997   chr8   12036530          SNP          4\n",
       "998   chr8   43247356          SNP          6\n",
       "999   chr2  176783423          SNP          1\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a3e7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "import re\n",
    "\n",
    "from google.api_core.exceptions import Conflict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60c7d292-c8c0-4bc9-a0ac-60a28f8d0f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = list(client.list_tables(\"depmap-omics.maf_staging_0916\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42041c63-3a60-4287-a8dd-25c3fe17bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_mafs = [x.table_id[len(\"stage_maf_\"):].replace(\"_\", \"-\") for x in tables if x.table_id.startswith(\"stage_maf_CDS\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3abe32f-820f-4e62-97bb-e274271b4c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_gbq(f\"\"\"select distinct cds_id from `{dest_dataset}.merged_maf` \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5461a3fe-f75e-43d2-994a-a6b0c2dc7ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CDS-dhBHhw'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stage_mafs).difference(set(df[\"cds_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d891873-30b3-454f-8e20-55138ce3ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = list(client.list_jobs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd9983eb-27dc-4da1-b7ff-3e479267d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = [x for x in jobs if \"CDS_dhBHhw\" in x.job_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23167b7c-fe5f-464a-b16d-4378623f2cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'reason': 'internalError',\n",
       "  'message': 'An internal error occurred and the request could not be completed. This is usually caused by a transient issue. Retrying the job with back-off as described in the BigQuery SLA should solve the problem: https://cloud.google.com/bigquery/sla. If the error continues to occur please contact support at https://cloud.google.com/support.'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing[0].errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31824496-264c-4a6c-804f-bd20a6b98e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QueryJob<project=broad-achilles, location=US, id=concat_t5_stage_maf_CDS_dhBHhw>,\n",
       " QueryJob<project=broad-achilles, location=US, id=concat_t3_stage_maf_CDS_dhBHhw>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f71c0d0a-ce5d-41d8-8a35-4d4bfbce41f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "just_one_transfer = [x for x in transfers if \"CDS_dhBHhw\" in x.dest_table]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bb0d5615-21dc-4913-8c59-0fea6ff43bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2514 CDS IDs already loaded. 0 of 1 tables need to be loaded\n"
     ]
    }
   ],
   "source": [
    "concatenate_tables(f\"{dest_dataset}.merged_maf\", just_one_transfer, \"t6\", parallelism=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9d697e9-df86-4b80-8184-16071f81414a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryJob<project=broad-achilles, location=US, id=160ccb99-d142-4fc9-9687-8362f1a286f6>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3ef8b81-4b31-49ab-a337-6ebbb141f293",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "500 An internal error occurred and the request could not be completed. This is usually caused by a transient issue. Retrying the job with back-off as described in the BigQuery SLA should solve the problem: https://cloud.google.com/bigquery/sla. If the error continues to occur please contact support at https://cloud.google.com/support.\n\nLocation: US\nJob ID: concat_t5_stage_maf_CDS_dhBHhw\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmissing\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/jupyter/lib/python3.9/site-packages/google/cloud/bigquery/job/query.py:1499\u001b[0m, in \u001b[0;36mQueryJob.result\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retry_do_query \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m job_retry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1497\u001b[0m         do_get_result \u001b[38;5;241m=\u001b[39m job_retry(do_get_result)\n\u001b[0;32m-> 1499\u001b[0m     \u001b[43mdo_get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mGoogleAPICallError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1502\u001b[0m     exc\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m=\u001b[39m _EXCEPTION_FOOTER_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1503\u001b[0m         message\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39mmessage, location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation, job_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\n\u001b[1;32m   1504\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/jupyter/lib/python3.9/site-packages/google/cloud/bigquery/job/query.py:1489\u001b[0m, in \u001b[0;36mQueryJob.result.<locals>.do_get_result\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_do_query \u001b[38;5;241m=\u001b[39m retry_do_query\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_job_retry \u001b[38;5;241m=\u001b[39m job_retry\n\u001b[0;32m-> 1489\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mQueryJob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;66;03m# Since the job could already be \"done\" (e.g. got a finished job\u001b[39;00m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;66;03m# via client.get_job), the superclass call to done() might not\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;66;03m# set the self._query_results cache.\u001b[39;00m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reload_query_results(retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/jupyter/lib/python3.9/site-packages/google/cloud/bigquery/job/base.py:728\u001b[0m, in \u001b[0;36m_AsyncJob.result\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_begin(retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    727\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;129;01mis\u001b[39;00m DEFAULT_RETRY \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretry\u001b[39m\u001b[38;5;124m\"\u001b[39m: retry}\n\u001b[0;32m--> 728\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_AsyncJob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/jupyter/lib/python3.9/site-packages/google/api_core/future/polling.py:137\u001b[0m, in \u001b[0;36mPollingFuture.result\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking_poll(timeout\u001b[38;5;241m=\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# Pylint doesn't recognize that this is valid in this case.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "\u001b[0;31mInternalServerError\u001b[0m: 500 An internal error occurred and the request could not be completed. This is usually caused by a transient issue. Retrying the job with back-off as described in the BigQuery SLA should solve the problem: https://cloud.google.com/bigquery/sla. If the error continues to occur please contact support at https://cloud.google.com/support.\n\nLocation: US\nJob ID: concat_t5_stage_maf_CDS_dhBHhw\n"
     ]
    }
   ],
   "source": [
    "missing[0].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b43a2db7-b6e4-4fdd-9f81-17b9235f6ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transfer(srcs=['gs://fc-secure-d2a2d895-a7af-4117-bdc7-652d7d268324/submissions/c46ec126-d6b9-4664-b7b7-536ce97d9d0e/run_vcf_to_depmap/ac80bb6b-40aa-491d-9cbe-cccdb9b3e42a/call-vcf_to_depmap/glob-233ae0abbeccb769e7426b0faeb6b946/b953a6d9f73d4464bcb7a4a64a09bd31-0.parquet'], dest_table='depmap-omics.maf_staging_0916.stage_maf_CDS_00rz9N', cds_id='CDS-00rz9N')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a370a-2002-4de7-8732-c77976b206da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
