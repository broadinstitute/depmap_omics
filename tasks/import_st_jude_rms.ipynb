{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dalmatian as dm\n",
    "import pdb\n",
    "import math\n",
    "import TerraFunction as terra\n",
    "import sys\n",
    "sys.path.insert(0, '../ccle_processing/')\n",
    "import CCLE_postp_function as ccle\n",
    "import rpy2\n",
    "%load_ext rpy2.ipython\n",
    "from taigapy import TaigaClient\n",
    "from IPython.display import Image,display\n",
    "from IPython.core.display import HTML \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = TaigaClient()\n",
    "dm.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initializing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maleintervals = \"gs://fc-secure-fd4c24cf-6bfd-410a-9bca-e02642da12f8/immediate/intervalsXY.list\"\n",
    "femaleintervals = \"gs://fc-secure-fd4c24cf-6bfd-410a-9bca-e02642da12f8/immediate/intervalsXX.list\"\n",
    "sample_values_todrop = [\"sj_diseases\",\"sj_datasets\",\"attr_age_at_diagnosis\",\"attr_sex\",\"attr_race\",\"attr_ethnicity\",\"attr_diagnosis\"]\n",
    "outpath = \"sample.tsv\"\n",
    "spamplepath = \"SAMPLE_INFO.txt\"\n",
    "bucketname= \"gs://fc-secure-fd4c24cf-6bfd-410a-9bca-e02642da12f8/\"\n",
    "samplesetname = \"WGS_CNV_stjude\"\n",
    "namespace=\"rmc-rnaseq\"\n",
    "workspace=\"St_Jude_RMS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uploading the required interval list of chromosomes for the PON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"chr1\\nchr2\\nchr3\\nchr4\\nchr5\\nchr6\\nchr7\\nchr8\\nchr9\\nchr10\\nchr11\\nchr12\\nchr13\\nchr14\\nchr15\\nchr16\\nchr17\\nchr18\\nchr19\\nchr20\\nchr21\\nchr22\\nchrX\\nchrY\" > intervalsXY.list\n",
    "! echo \"chr1\\nchr2\\nchr3\\nchr4\\nchr5\\nchr6\\nchr7\\nchr8\\nchr9\\nchr10\\nchr11\\nchr12\\nchr13\\nchr14\\nchr15\\nchr16\\nchr17\\nchr18\\nchr19\\nchr20\\nchr21\\nchr22\\nchrX\\nchrX\" > intervalsXX.list\n",
    "! gsutil cp intervalsXY.list $maleintervals\n",
    "! gsutil cp intervalsXX.list $femaleintervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading and Displaying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsample = pd.read_csv(spamplepath,sep='\\t')\n",
    "newsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keeping whole genome\n",
    "for i,val in enumerate(newsample[\"file_path\"]):\n",
    "    if val.split('/')[-1].split('.')[1] != \"WholeGenome\" or val.split('/')[-2]!= \"bam\":\n",
    "        newsample = newsample.drop(i)\n",
    "    elif val.split('/')[1] != 'gs:':\n",
    "        newsample[\"file_path\"][i]=\"gs://fc-secure-fd4c24cf-6bfd-410a-9bca-e02642da12f8/immediate/bam_wg/\"+newsample[\"file_path\"][i].split('/')[-1]\n",
    "newsample = newsample.reset_index(drop=True)\n",
    "newsample = newsample.rename(index=str, columns={\"sample_name\": \"sample_id\", \"subject_name\": \"participant_id\",\"file_path\":\"WGS_bam\"})\n",
    "currfile=\"\"\n",
    "bai = ['']*int(newsample.shape[0])\n",
    "#creating an array of bai and adding it to their coresponding bams\n",
    "for i in newsample.index:\n",
    "    currfile=newsample[\"WGS_bam\"][i]\n",
    "    if currfile.split('/')[-1].split('.')[-1] == \"bai\":\n",
    "        bai[int(newsample[newsample[\"WGS_bam\"]==currfile[:-4]].index.values[0])] = currfile\n",
    "newsample[\"WGS_bam_index\"]=pd.Series(bai,index=newsample.index)\n",
    "#removing original bai rows\n",
    "for i in newsample.index: \n",
    "    currfile=newsample[\"WGS_bam\"][i]\n",
    "    if currfile.split('/')[-1].split('.')[-1] == \"bai\":\n",
    "        newsample = newsample.drop(i)\n",
    "newsample = newsample.reset_index(drop=True)\n",
    "newsample[\"sample_set\"]=pd.Series([samplesetname]*int(newsample.shape[0]),index=newsample.index)\n",
    "newsample.set_index(\"sample_id\",inplace=True,drop=True)\n",
    "newsample = newsample[newsample.columns.tolist()[1:]+[newsample.columns.tolist()[0]]]\n",
    "newsample = newsample.loc[~newsample.index.duplicated(keep='first')]\n",
    "newsample.to_csv(outpath,sep=\"\\t\")\n",
    "newsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing a corrupted sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsample=newsample.drop(\"SJRHB007_G\")\n",
    "newsample=newsample.drop(\"SJRHB010_D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating set for each samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm = dm.WorkspaceManager(namespace, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "samplesetname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm.upload_samples(newsample)\n",
    "wm.update_sample_set(samplesetname,newsample.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating the sample set for normal cells with m/f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalsXX = newsample[(newsample[\"sample_type\"]==\"Germline\") & (newsample[\"sj_datasets\"]!=\"Clinical Pilot\") &(newsample[\"attr_sex\"]==\"Female\")].index.values\n",
    "normalsXY = newsample[(newsample[\"sample_type\"]==\"Germline\") & (newsample[\"sj_datasets\"]!=\"Clinical Pilot\") &(newsample[\"attr_sex\"]==\"Male\")].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalsXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm.update_sample_set(samplesetname+\"_normals_XY\",normalsXY.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm.update_sample_set(samplesetname+\"_normals_XX1\",normalsXX.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating the sample set for cancer patients with/without germline cells sequenced\n",
    "\n",
    "I am quite positive that the clinical pilot are not germline and have been misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnosis samples\n",
    "diagnosis = newsample[(newsample[\"sample_type\"]!=\"Germline\") | (newsample[\"sj_datasets\"]==\"Clinical Pilot\")]['participant_id'].values.tolist()\n",
    "# germline samples\n",
    "germline = newsample[(newsample[\"sample_type\"]==\"Germline\") & (newsample[\"sj_datasets\"]!=\"Clinical Pilot\")]['participant_id'].values.tolist()\n",
    "# assert that we have them all in total\n",
    "assert(len(diagnosis)+len(germline)==newsample.shape[0]) \n",
    "# people without a matching germline\n",
    "patientswithout = set(diagnosis) - set(germline)\n",
    "# samples from patients without a matching germline\n",
    "toprocessPON = newsample[newsample[\"participant_id\"].isin(patientswithout)].index.values.tolist()\n",
    "# samples from patients with a matching germline\n",
    "not_toprocessPON = newsample[~newsample[\"participant_id\"].isin(patientswithout)][newsample[\"sample_type\"]==\"Germline\"].index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm.update_sample_set(samplesetname+\"_not_toprocessPON\",not_toprocessPON)\n",
    "wm.update_sample_set(samplesetname+\"_toprocessPON\",toprocessPON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnv_pon = wm.get_config(\"CNV_Somatic_Panel_Workflow\")\n",
    "cnv_pon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnv_pon['inputs']['CNVSomaticPanelWorkflow.normal_bams'] = 'this.samples.WGS_bam'\n",
    "cnv_pon['inputs']['CNVSomaticPanelWorkflow.normal_bais'] = 'this.samples.WGS_bam_index'\n",
    "\n",
    "## runing male PON\n",
    "#a['inputs']['CNVSomaticPanelWorkflow.intervals'] = '\"'+maleintervals+'\"'\n",
    "\n",
    "\n",
    "#wm.create_submission(a, setname+\"_normals_XY\", 'sample_set', use_callcache=True)\n",
    "\n",
    "## running female PON\n",
    "cnv_pon['inputs']['CNVSomaticPanelWorkflow.intervals'] = '\"'+femaleintervals+'\"'\n",
    "wm.update_config(cnv_pon)\n",
    "wm.create_submission(cnv_pon['name'], samplesetname+\"_normals_XX1\", 'sample_set', use_callcache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## running specific PON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = newsample[~newsample[\"participant_id\"].isin(patientswithout)][newsample[\"sample_type\"]!=\"Germline\"].index.values.tolist()\n",
    "nomatched = newsample[newsample[\"participant_id\"].isin(patientswithout)].index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleset = wm.get_sample_sets()\n",
    "samples = wm.get_samples()\n",
    "new_dataset = pd.DataFrame(columns=[samplesetname+\"_id\",\"read_count_pon\",\"WGS_bam_tumor\",\"WGS_bam_normal\",\"WGS_bam_normal_index\",\"WGS_bam_tumor_index\",\"intervals\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=samples.drop(labels=\"SJRHB007_G\")\n",
    "samples=samples.drop(labels=\"SJRHB010_D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in nomatched:\n",
    "    sex = \"_normals_XY\" if newsample[\"attr_sex\"][val]!=\"Female\" else \"_normals_XX1\" \n",
    "    intervals = maleintervals if samples[\"attr_sex\"][val]!=\"Female\" else femaleintervals \n",
    "    new_dataset = new_dataset.append({\n",
    "        samplesetname+\"_id\": val,\n",
    "        \"read_count_pon\": sampleset[\"read_count_pon\"][samplesetname+sex],\n",
    "        \"WGS_bam_tumor\": samples[\"WGS_bam\"][val],\n",
    "        \"WGS_bam_normal\": \"\",\n",
    "        \"WGS_bam_normal_index\": \"\",\n",
    "        \"WGS_bam_tumor_index\": samples[\"WGS_bam_index\"][val],\n",
    "        \"intervals\": intervals\n",
    "    },ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in pairs:\n",
    "    paired_germline = samples[samples[\"participant\"]==samples[\"participant\"][val]][samples[\"sample_type\"]==\"Germline\"]\n",
    "    sex = \"_normals_XY\" if samples[\"attr_sex\"][val]!=\"Female\" else \"_normals_XX\" \n",
    "    read_count_pon = sampleset[\"read_count_pon\"][samplesetname+sex]\n",
    "    intervals = maleintervals if samples[\"attr_sex\"][val]!=\"Female\" else femaleintervals \n",
    "    new_dataset = new_dataset.append({\n",
    "        samplesetname+\"_id\": val,\n",
    "        \"read_count_pon\": read_count_pon,\n",
    "        \"WGS_bam_tumor\": samples[\"WGS_bam\"][val],\n",
    "        \"WGS_bam_normal\": paired_germline[\"WGS_bam\"].values[0],\n",
    "        \"WGS_bam_normal_index\": paired_germline[\"WGS_bam_index\"].values[0],\n",
    "        \"WGS_bam_tumor_index\": samples[\"WGS_bam_index\"][val],\n",
    "        \"intervals\": intervals\n",
    "    },ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset.set_index(samplesetname+\"_id\",inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm.upload_entities(samplesetname,new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm.update_sample_set(sample_ids=new_dataset.index.values.tolist(),sample_set_id=samplesetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNVpipeline = wm.get_config('CNV_Somatic_Pair_Workflow')\n",
    "CNVpipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNVpipeline['inputs']['CNVSomaticPairWorkflow.tumor_bam'] = 'this.WGS_bam_tumor'\n",
    "CNVpipeline['inputs']['CNVSomaticPairWorkflow.tumor_bam_idx'] = 'this.WGS_bam_tumor_index'\n",
    "CNVpipeline['inputs']['CNVSomaticPairWorkflow.normal_bam'] = 'this.WGS_bam_normal'\n",
    "CNVpipeline['inputs']['CNVSomaticPairWorkflow.normal_bam_idx'] = 'this.WGS_bam_normal_index'\n",
    "CNVpipeline['inputs']['CNVSomaticPairWorkflow.padding'] = 250\n",
    "CNVpipeline['rootEntityType']= 'pair'\n",
    "CNVpipeline['inputs']['CNVSomaticPairWorkflow.common_sites'] = 'workspace.common_sites_hg38'\n",
    "## runing male PON\n",
    "CNVpipeline['inputs']['CNVSomaticPairWorkflow.intervals'] = 'workspace.interval_list'\n",
    "CNVpipeline['inputs']['CNVSomaticPairWorkflow.read_count_pon'] = 'this.read_count_pon'\n",
    "CNVpipeline['inputs']['CNVSomaticPairWorkflow.bin_length'] = 1000\n",
    "wm.update_config(CNVpipeline)\n",
    "submission_id = wm.create_submission(CNVpipeline['name'],etype='sample_set',entity=samplesetname,expression='this.samples')\n",
    "terra.wait_for_submission(submission_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate = wm.get_config('Aggregate_CN_seg_files')\n",
    "aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm.update_pair_set(samplesetname,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate['inputs']['aggregate_CN_segments_wrkflw.aggregate_CN_segments.sample_seg_files'] = 'this.pair.called_copy_ratio_segments_tumor'\n",
    "wm.update_config(aggregate)\n",
    "submission_id = wm.create_submission(config = aggregate['name'], entity=samplesetname)\n",
    "terra.wait_for_submission(submission_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = wm.get_entities(etype=\"pair_CNV_set\")[\"combined_seg_file\"].values[1]\n",
    "aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil cp $aggregated temp/cn.aggregated.called.seg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can even add `-i df -w 5 -h 5 --units in -r 200`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "source(\"gkugener/RScripts/load_libraries_and_annotations.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "source(\"../ccle_processing/CCLE_postp_function.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "a <- interpolate_gaps_in_segmented(process_segments(\n",
    "    \"temp/cn.aggregated.called.seg\"))\n",
    "segments <- extend_ends_of_segments(a$segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "segments[170:200,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "segments %<>% dplyr::mutate(Source='st_jude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "write.table(segments, file = \"temp/wgs.st.jude.segmented.cn\", sep = ',', quote = F, row.names = F) \n",
    "# What we upload to taiga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "allENTREZG <- generate_entrez_genes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "segments %<>% mutate(seqnames=gsub('chr', '', seqnames)) \n",
    "head(segments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "data <- generate_gene_level_matrix_from_segments(allENTREZG, segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "head(data$gene_level_data_hg38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "write.table(data$gene_level_data_hg38, file = \"temp/wgs.st.jude.gene.cn\", sep = ',', quote = F, row.names = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genecn = pd.read_csv(\"temp/wgs.st.jude.gene.cn\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentcn_wes = tc.get(name='copy-number-d4d9', version=5, file='wes.st.jude.segmented.cn')\n",
    "segmentcn_wgs = pd.read_csv(\"temp/wgs.st.jude.segmented.cn\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle.checkAmountOfSegments(segmentcn_wgs,thresh = 850)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle.checkGeneChangeAccrossAll(genecn, thresh=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentcn_wgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle.checkDifferencesWESWGS(segmentcn_wes, segmentcn_wgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = wm.get_entities(etype=\"pair_CNV\")[\"modeled_segments_plot_tumor\"].values\n",
    "for plot in plots:\n",
    "    ! gsutil cp $plot temp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plot in plots:\n",
    "    display(Image('temp/'+plot.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in seeing if there is 18q/VPS4B loss in RMS. We previously attempted to look at CN loss in an RMS dataset that used SOLID sequencing. However, our results were inconclusive due to problems with the quality of the data. We expected the data from St Jude's to be of much higher quality and that we should get a better sense of the CN profile of these tumors from this dataset.\n",
    "\n",
    "### TODOS:\n",
    "\n",
    "* Check the seg files in IGV look for hypo diploid samples with large gains/losses\n",
    "* Before plotting - check on the sample metadata and remove some samples that are PDXs etc...\n",
    "* Possibly run ABSOLUTE to get ploidy and whole genome doubling calls\n",
    "* Summary figure of heatmap on 18q/SMAD4 sorted by deepest deletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "st.jude.sample.info <- load.from.taiga(data.name='sample-annotations-7ca1', data.version=2, data.file='sample.info')\n",
    "\n",
    "# Load the St Jude WES and WGS copy number data\n",
    "st.jude.provided.bed.gene.cn <- load.from.taiga(data.name='copy-number-d4d9', data.version=6, data.file='st.jude.provided.bed.gene.cn')\n",
    "st.jude.provided.bed.segmented.cn <- load.from.taiga(data.name='copy-number-d4d9', data.version=6, data.file='st.jude.provided.bed.segmented.cn')\n",
    "wes.st.jude.gene.cn <- load.from.taiga(data.name='copy-number-d4d9', data.version=6, data.file='wes.st.jude.gene.cn')\n",
    "wes.st.jude.segmented.cn <- load.from.taiga(data.name='copy-number-d4d9', data.version=6, data.file='wes.st.jude.segmented.cn')\n",
    "wgs.st.jude.gene <- load.from.taiga(data.name='copy-number-d4d9', data.version=6, data.file='wgs.st.jude.gene')\n",
    "wgs.st.jude.segmented <- load.from.taiga(data.name='copy-number-d4d9', data.version=6, data.file='wgs.st.jude.segmented')\n",
    "\n",
    "cyto_band_file <- '~/Documents/Analysis/RScripts/Common_annotations/hg38_cytoband.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "total_segments_per_sample <- rbind(\n",
    "  wgs.st.jude.segmented %>%\n",
    "    dplyr::rename(Sample=DepMap_ID) %>%\n",
    "    group_by(Sample) %>%\n",
    "    dplyr::summarise(count=n()) %>%\n",
    "    mutate(Source='WGS'),\n",
    "  wes.st.jude.segmented.cn %>%\n",
    "    group_by(Sample) %>%\n",
    "    dplyr::summarise(count=n()) %>%\n",
    "    mutate(Source='WES'),\n",
    "  st.jude.provided.bed.segmented.cn %>%\n",
    "    group_by(Sample) %>%\n",
    "    dplyr::summarise(count=n()) %>%\n",
    "    mutate(Source='BED')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "chr_cutoffs <- generate_chromosome_cutoffs_list(cyto_band_file = cyto_band_file)\n",
    "columns_for_segment_plotting <- c('Sample', 'Chromosome', 'Start', 'End', 'Segment_Mean', 'Source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# The plots below give us a sense of the copy number profile of the samples \n",
    "continuous.wes.st.jude.segmented.cn <- wes.st.jude.segmented.cn %>%\n",
    "  mutate(Start=Start+chr_cutoffs[paste0('chr', gsub('^chr', '', Chromosome))], End=End+chr_cutoffs[paste0('chr', gsub('^chr', '', Chromosome))]) %>%\n",
    "  mutate(Source='WES') %>%\n",
    "  dplyr::select(columns_for_segment_plotting)\n",
    "continuous.wgs.st.jude.segmented.cn <- wgs.st.jude.segmented %>%\n",
    "  mutate(Start=start+chr_cutoffs[paste0('chr', gsub('^chr', '', seqnames))], End=end+chr_cutoffs[paste0('chr', gsub('^chr', '', seqnames))]) %>%\n",
    "  mutate(Source='WGS') %>%\n",
    "  dplyr::rename(Sample=DepMap_ID, Chromosome=seqnames) %>%\n",
    "  dplyr::select(columns_for_segment_plotting)\n",
    "continuous.provided.bed.st.jude.segmented.cn <- st.jude.provided.bed.segmented.cn %>%\n",
    "  mutate(Start=Start+chr_cutoffs[paste0('chr', gsub('^chr', '', Chromosome))], End=End+chr_cutoffs[paste0('chr', gsub('^chr', '', Chromosome))]) %>%\n",
    "  dplyr::select(columns_for_segment_plotting)\n",
    "\n",
    "combined_segments_all_sources <- rbind(continuous.wes.st.jude.segmented.cn, continuous.wgs.st.jude.segmented.cn, continuous.provided.bed.st.jude.segmented.cn)\n",
    "\n",
    "# Plot the data\n",
    "# (1) Filter out all the germline samples\n",
    "tumor_samples_only <- st.jude.sample.info %>% filter(sample_type != 'Germline') %$% sample_name\n",
    "tumor_segments_only <- combined_segments_all_sources %>% filter(Sample %in% tumor_samples_only)\n",
    "\n",
    "sample_order_for_plot <- unique(tumor_segments_only$Sample)\n",
    "\n",
    "# Plot\n",
    "tumor_segments_only %<>% mutate(CN_capped=ifelse(log2(Segment_Mean) > 1, 1, ifelse(log2(Segment_Mean) < -1, -1, log2(Segment_Mean))))\n",
    "tumor_segments_only %<>% mutate(Sample=factor(Sample, levels=sample_order_for_plot))\n",
    "sample_labels <- setNames(seq(1, length(sample_order_for_plot)), sample_order_for_plot)\n",
    "\n",
    "continuous_chromosome_plots_all <- ggplot(tumor_segments_only) +\n",
    "  geom_rect(aes(xmin=Start, xmax=End, ymin=as.integer(Sample)-0.5, ymax=as.integer(Sample)+0.5, fill=CN_capped)) +\n",
    "  scale_fill_gradient2(low='blue', high='red', mid='white', midpoint=0) +\n",
    "  scale_x_continuous(breaks=chr_cutoffs, labels=names(chr_cutoffs)) +\n",
    "  scale_y_continuous(breaks=sample_labels, labels=names(sample_labels)) +\n",
    "  facet_wrap(~Source, ncol = 1) +\n",
    "  theme(\n",
    "    axis.text.x = element_text(angle=90, hjust=1, vjust=0.5, size=10),\n",
    "    axis.text.y = element_text(size=10)\n",
    "  )\n",
    "ggsave(continuous_chromosome_plots_all, filename = file.path(plot_saving_directory, 'temp/continuous_segments_complete_all_source.pdf'), width=10, height = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload the validated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tc = TaigaClient()\n",
    "tc.update_dataset(dataset_permaname=\"copy-number-d4d9\", \n",
    "                  upload_file_path_dict={'temp/wgs.st.jude.gene.cn': 'NumericMatrixCSV',\n",
    "                                        'temp/wgs.st.jude.segmented.cn': 'TableCSV'},\n",
    "                 dataset_description=\"updating to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
