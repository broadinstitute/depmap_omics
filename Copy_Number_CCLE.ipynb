{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Number Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you need to have installed JKBio in the same folder as ccle_processing\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image,display\n",
    "import dalmatian as dm\n",
    "from IPython.core.display import HTML \n",
    "import sys\n",
    "#loading package in another path\n",
    "sys.path.insert(0, '..')\n",
    "from src.CCLE_postp_function import *\n",
    "from JKBio import TerraFunction as terra\n",
    "# we will run some python functions directly in the notebook\n",
    "import rpy2\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext rpy2.ipython\n",
    "from taigapy import TaigaClient\n",
    "tc = TaigaClient()\n",
    "# we will use google sheets (you need to have your storage and client files for your google account with an access to the required google sheets)- see sheeturl below\n",
    "from gsheets import Sheets\n",
    "sheets = Sheets.from_files('~/.client_secret.json', '~/.storage.json')\n",
    "replace = {'T': 'Tumor', 'N': 'Normal', 'm': 'Unknown', 'L': 'Unknown'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boot up\n",
    "\n",
    "- you first need to go to [taiga](https://cds.team/taiga/dataset) and create some new datasets for the virtual release\n",
    "- the easiest way to create a new dataset is to upload an empty file (since at least one file is required). This empty file can be deleted when you update the dataset with a new version\n",
    "\n",
    "we are instanciating all the parameters needed for this pipeline to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesetname = \"20Q3\"\n",
    "prevname=\"20Q2\"\n",
    "prevversion=42\n",
    "prevprevname ='20Q1'\n",
    "prevprevversion= 40\n",
    "virtual_public='public-20q3-3d35'\n",
    "virtual_dmc='dmc-20q3-033d'\n",
    "virtual_internal='internal-20q3-00d0'\n",
    "\n",
    "workspace1=\"broad-genomics-delivery/Getz_IBM_CellLines_Exomes\"\n",
    "workspace2=\"broad-firecloud-ccle/CCLE_DepMap_WES\"\n",
    "workspace3=\"broad-genomics-delivery/CCLE_DepMap_WES\"\n",
    "\n",
    "workspace6=\"terra-broad-cancer-prod/CCLE_DepMap_WES\"\n",
    "\n",
    "refworkspace=\"broad-firecloud-ccle/DepMap_WES_CN_hg38\"\n",
    "source1=\"ibm\"\n",
    "source2=\"ccle\"\n",
    "source3=\"ccle\"\n",
    "source6=\"ccle\"\n",
    "source7=\"ibm\"\n",
    "\n",
    "refsheet_url = \"https://docs.google.com/spreadsheets/d/1XkZypRuOEXzNLxVk9EOHeWRE98Z8_DBvL4PovyM01FE\"\n",
    "sheeturl = \"https://docs.google.com/spreadsheets/d/115TUgA1t_mD32SnWAGpW9OKmJ2W5WYAOs3SuSdedpX4\"\n",
    "release = samplesetname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# same thing for R\n",
    "release <- '20Q2'\n",
    "prevname <- '20Q1'\n",
    "version<-37\n",
    "prevversion <- 40\n",
    "prevprevversion<- 38\n",
    "prevprevname <- '19Q4'\n",
    "genome_version <- 'hg38'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we initialize the workspaces manager from dalmatian\n",
    "wm1 = dm.WorkspaceManager(workspace1)\n",
    "wm2 = dm.WorkspaceManager(workspace2)\n",
    "wm3 = dm.WorkspaceManager(workspace3)\n",
    "\n",
    "wm6 = dm.WorkspaceManager(workspace6)\n",
    "\n",
    "refwm = dm.WorkspaceManager(refworkspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes the bam files live under a different column in the workspace data\n",
    "extract_to_change = {'from_arxspan_id': 'participant'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new data\n",
    "\n",
    "We are looking for new samples in a range of workspaces.\n",
    "\n",
    "They are quite messy and might contains duplicates, contain broken file paths...\n",
    "\n",
    "- We are thus looking at the bam files one by one and comparing them with our own bams. \n",
    "- We remove broken files, duplicates and add new version of a cell line's bam if we find some."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, pairs, noarxspan = GetNewCellLinesFromWorkspaces(refworkspace, stype='wes', refurl=refsheet_url, wmfroms = [workspace1, workspace2, workspace3, workspace6], sources=[source1, source2, source3, source6], match=['ACH-','CDS-'], participantslicepos=10, accept_unknowntypes=True, extract=extract_to_change, recomputedate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsample[1][newsample[1].index.isin(newsample[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporary renaming\n",
    "rename = {'ACH-002446_2':'ACH-003000_1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids, refsamples, ccle_name = createDatasetWithNewCellLines(refworkspace, samplesetname, wmfroms = [workspace1, workspace2, workspace3], sources=[source1, source2, source3], gsfolderto='gs://ccle_bams/wes/', match='ACH', participantslicepos=10, accept_unknowntypes=True, extract = extract_to_change, dry_run = False, rename=rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refsamples[refsamples.index.isin(sample_ids)].WES_bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that we have all the cell lines we expect for this release\n",
    "\n",
    "This involves comparing to the list in the Google sheet \"Cell Line Profiling Status.\"\n",
    "\n",
    "_As the list cannot be parsed, we are not comparing it for now_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function may not work - it hasn't been tested\n",
    "url = 'https://docs.google.com/spreadsheets/d/1qus-9TKzqzwUMNWp8S1QP4s4-3SsMo2vuQRZrNXf7ag/edit?ts=5db85e27#gid=0&fvid=1627883727'\n",
    "\n",
    "compareToCuratedGS(url, sample = newsample[0], samplesetname = samplesetname, colname = 'CN New to internal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the pipeline\n",
    "\n",
    "We are using Dalmatian to send request to Terra, we are running a set of 5 functions To generate the copy number dataset:\n",
    "\n",
    "*   **BamToUnmappedRGBams_MC** vdauwera/BamToUnmappedRGBamsSnapshot ID: 3\n",
    "*   **Generate_uBAM_File_List** gkugener/ArrayOfFilesToTxtSnapshot ID: 1\n",
    "*   **Realign_WES_GATK4** gatk/PreProcessingForVariantDiscovery_GATK4Snapshot ID: 7\n",
    "*   **CNV_sample_XX** gatk/CNV_Somatic_Pair_WorkflowSnapshot ID: 9\n",
    "*   **Aggregate_CN_seg_files** gkugener/Aggregate_CN_seg_filesSnapshot ID: 2\n",
    "\n",
    "This output file for download will be saved under the sample set under the combined_seg_file attribute.\n",
    "\n",
    "There are several other tasks in this workspace. In brief:\n",
    "\n",
    "*   **CNV_Somatic_Panel_Workflow_Agilent_XX** gatk/CNV_Somatic_Panel_WorkflowSnapshot ID: 11. This task was used in this workspace to generate the Sanger PON. In the Sanger dataset, there is a set of 40 normal cell lines samples (cell lines derived from matched normal tissue). We can use these to generate a PON to normalize to rather than using the Agilent PON we use for the other CCLE cell lines. This leads to less noisy results. HOWEVER, results using the PON from this workflow should not use the X chromosome, as the sanger normals are not exclusively female or male (it is likely a mix).\n",
    "*   **SANGER_PON_CNV_sample_XX** gatk/CNV_Somatic_Pair_WorkflowSnapshot ID: 9. Same as the CNV_sample_XX_gatk, except that is uses the Sanger based PON. Should be used only for the Sanger cell lines.\n",
    "*   **Sanger_PON_Aggregate_CN_seg_files** gkugener/Aggregate_CN_seg_filesSnapshot ID: 2. Aggregates the segment files for the samples that were run using the Sanger PON based CNV workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Terra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of Terra workflows that are in the workspace and that we will call sequentially\n",
    "bamtoubam= \"BamToUnmappedRGBams_MC\"\n",
    "ubamtofilelist = \"Generate_uBAM_File_List\"\n",
    "realign=\"Realign_WES_GATK4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see dalmatian\n",
    "subid = refwm.create_submission(bamtoubam,samplesetname,\"sample_set\",\"this.samples\")\n",
    "terra.waitForSubmission(refworkspace, subid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subid = refwm.create_submission(ubamtofilelist,samplesetname,\"sample_set\",\"this.samples\")\n",
    "terra.waitForSubmission(refworkspace, subid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subid = refwm.create_submission(realign,samplesetname,\"sample_set\",\"this.samples\")\n",
    "terra.waitForSubmission(refworkspace, subid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing out the XY PoN for CN characterization. Will test by producing an output in a different column from usual so it's easy to delete the column attribute later\n",
    "# Also, need to make a split between Agilent and ICE samples..\n",
    "samplesetname = '19Q4'\n",
    "submission_id= refwm.create_submission(\"CNV_sample_XX\",etype='sample_set',entity=samplesetname,expression='this.samples')\n",
    "terra.waitForSubmission(refworkspace,submission_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id= refwm.create_submission(\"CNV_sample_XX\",etype='sample_set',entity=samplesetname,expression='this.samples')\n",
    "terra.waitForSubmission(refworkspace,submission_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy pairs data to sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = refwm.get_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairs[pairs.index.isin(tokeep)]\n",
    "pairs = pairs[~pairs['called_copy_ratio_segments_tumor'].isna()]\n",
    "pairs = pairs.drop(columns=['case_sample','control_sample','participant_id'])\n",
    "pairs.index = [i.split('_')[0] for i in pairs.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refwm.update_sample_attributes(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id = refwm.create_submission(\"Aggregate_CN_seg_files\",entity=samplesetname)\n",
    "terra.waitForSubmission(refworkspace,submission_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__we are getting the results file path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = refwm.get_entities('sample_set').loc[samplesetname][\"combined_seg_file\"]\n",
    "aggregated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We then save the workflow configurations used__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.saveConfigs(refworkspace,'data/'+samplesetname+'/CNVconfig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__delete unmapped bams generated during the process__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toremove = [\"readgroup_ubams\",]\n",
    "for val in toremove:\n",
    "    refwm.disable_hound().delete_entity_attributes('sample', res[val], delete_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes the previous step does not work and you need to do it manually (you can run this to check it worked)\n",
    "for val in samplesinset.readgroup_ubams:\n",
    "    ubams = ''\n",
    "    if not type(val) is list:\n",
    "        continue \n",
    "    for v in val:\n",
    "        ubams+=' '+v\n",
    "    os.system('gsutil -m rm'+ubams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__and move the hg38 aligned bams to our own datastorage bucket__\n",
    "\n",
    "Note that we may encounter some WGS files, which need to go to a different folder from the WES bam files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlycol = ['hg38_analysis_ready_bam', 'hg38_analysis_ready_bam_index', 'hg38_analysis_ready_bam_md5']\n",
    "\n",
    "wes_newgs = 'gs://cclebams/hg38_wes/'\n",
    "wgs_newgs = 'gs://cclebams/hg38_wgs/'\n",
    "\n",
    "wes_samples = samplesinset[samplesinset.datatype == 'wes']\n",
    "wes_res = terra.changeGSlocation(refworkspace, newgs=wes_newgs, data=wes_samples, onlycol=onlycol, entity='samples', keeppath=False, dry_run = True)\n",
    "\n",
    "wgs_samples = samplesinset[samplesinset.datatype == 'wgs']\n",
    "wgs_res = terra.changeGSlocation(refworkspace, data=wgs_samples , newgs=wgs_newgs, onlycol=onlycol, entity='samples', keeppath=False, dry_run = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil cp $aggregated \"temp/cnv_ccle.called.seg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We download and reprocess removing the appended version and keeping only the newest versions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"temp/cnv_ccle.called.seg\", sep='\\t')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(a.Sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get QC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataBam = getWESQC(workspace=refworkspace ,only=[], qcname=[\"hg38_duplication_metrics\",\"hg38_bqsr_report\"])\n",
    "dataCN = getWESQC(workspace=refworkspace ,only=[], qcname=[\"allelic_counts_tumor\",\"delta_MAD_tumor\",\"denoised_MAD_tumor\",\"scaled_delta_MAD_tumor\",\"denoised_copy_ratios_lim_4_plot_tumor\",\"denoised_copy_ratios_plot_tumor\",\"modeled_segments_plot_tumor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = ccle_refsamples.set_index('cds_sample_id',drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataBam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dataCN.items():\n",
    "    if k =='nan':\n",
    "        continue\n",
    "    ccle_refsamples.loc[k,'processing_qc'] = str(v)\n",
    "for k,v in dataBam.items():\n",
    "    if k =='nan':\n",
    "        continue\n",
    "    ccle_refsamples.loc[k,'bam_qc'] = str(v)\n",
    "ccle_refsamples.to_csv('temp/newrefCN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priorization\n",
    "\n",
    "add columns to seg file with arxspan ID, version. only keep the newest version for any given arxspan ID.\n",
    "The process to keep the newest version of any given line is a little different from 20Q2 onwards, because don't have any dataset that uses the CDS-IDs for the data from 20Q1 or earlier.\n",
    "\n",
    "We have to download the Taiga datasets from the previous quarter, see if we have any arxspan IDs with new data, and then replace with that data. We use the function called \"removeOlderVersions\" to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_indexed = a.set_index('Sample')\n",
    "a_indexed.index.names = ['sample_id']\n",
    "a_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming = removeOlderVersions(names=a_indexed.index.tolist(), refsamples=refwm.get_samples(), arxspan_id=\"arxspan_id\", version=\"version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_indexed[a_indexed.index.isin(renaming.keys())].rename(renaming).to_csv(\"temp/cnv_ccle.called.seg\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saving samples used for 20Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples.loc[renaming.keys(),version]=1\n",
    "ccle_refsamples.to_csv('temp/newrefCN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__If want to reprocess something__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%R\n",
    "#segments_unfiltered <- readr::read_csv('temp/wes.19Q3.segmented.cn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Absolute data from the mutation PiPeline and ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## post Procesing\n",
    "\n",
    "The post processing happens in R using guillaume's functions, in brief:\n",
    "\n",
    "- processSegments\n",
    "- filterForCCLE\n",
    "- interpolateGapsInSegmented\n",
    "- extendEndsOfSegments\n",
    "- reprioritizeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "source('src/load_libraries_and_annotations.R')\n",
    "source(\"src/CCLE_postp_function.R\")\n",
    "library('celllinemapr')\n",
    "library('magrittr')\n",
    "library('taigr')\n",
    "library('cdsomics')\n",
    "library('readr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Previous release copy number profiles. This line will need to be updated as well\n",
    "wes.priority.cn.seg.profiles <- taigr::load.from.taiga(data.name='segmented-cn-wes-prioritzed-7fe1', data.file=paste0(\"wes.\",prevname,\".segmented\"),data.version=prevversion) %>%\n",
    "  dplyr::select(DepMap_ID, Chromosome, Start, End, Num_Probes, Segment_Mean, Source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "print(mean(wes.priority.cn.seg.profiles$Segment_Mean))\n",
    "print(max(wes.priority.cn.seg.profiles$Segment_Mean))\n",
    "print(min(wes.priority.cn.seg.profiles$Segment_Mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### debugging interpolateGapsInSegmented(segments)$segs\n",
    "**TODO:** getting error when call interpolateGapsInSegmented for the 20Q2 data. In particular, the mutate call at line 275 in the CCLE_postp_function.R file yields the error: \"Error: must be a double vector, not an integer vector\". The solution was changing `TRUE ~ as.integer(1))` to `TRUE ~ as.numeric(1))` in the interpolateGapsInSegmented function. I've pushed this to the Git repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "segments <- processSegments(\"temp/cnv_ccle.called.seg\")\n",
    "segments <- filterForCCLE(segments)\n",
    "segments <- interpolateGapsInSegmented(segments)$segs\n",
    "segments <- extendEndsOfSegments(segments,'../JKBio/data/hg38_cytoband.gz')\n",
    "print(segments)\n",
    "print(head(wes.priority.cn.seg.profiles))\n",
    "# reprioritize also undo logtransform\n",
    "print('all sources need to be named \"Broad WES\"')\n",
    "print(wes.priority.cn.seg.profiles$Source)\n",
    "segments_unfiltered <- reprioritizeData(segments, wes.priority.cn.seg.profiles)\n",
    "# Fill in the gaps on the entire dataset\n",
    "# Extend start sites to 1, end sites to the end of the chromosome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "print(mean(segments_unfiltered$Segment_Mean))\n",
    "print(max(segments_unfiltered$Segment_Mean))\n",
    "print(min(segments_unfiltered$Segment_Mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "write.table(segments_unfiltered, file = paste0(\"temp/wes.\",release,\".segment.cn\"), sep = ',', quote = F, row.names = F) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating gene copy number\n",
    "\n",
    "- generateEntrezGenes\n",
    "- generateGeneLevelMatrixFromSegments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "entrezgenes <- generateEntrezGenes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "head(corner(entrezgenes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "res <- generateGeneLevelMatrixFromSegments(entrezgenes, segments_unfiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "genematrix_unfiltered <- res$gene_level_data_hg38\n",
    "corner(genematrix_unfiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "print(mean(genematrix_unfiltered))\n",
    "print(max(genematrix_unfiltered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# we save this table to be validated in python (quicker way to do it by passing it in cells)\n",
    "write.table(genematrix_unfiltered, file = paste0('temp/wes.',release,'.gene.cn'), \n",
    "sep = ',', quote = F, row.names = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation step\n",
    "\n",
    "Once the files are saved, we load them back in python and do some validations, in brief:\n",
    "\n",
    "- mean,max,var...\n",
    "- to previous version: same mean,max,var...\n",
    "- checkAmountOfSegments: flag any samples with a very high number of segments\n",
    "- checkGeneChangeAccrossAll: flag any genes which stay at a similar value across all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "genecn = pd.read_csv('temp/wes.'+release+'.gene.cn', sep = ',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##################]100% |  33.6 MiB/s | 373.6 MiB / 373.6 MiB | Time:  0:00:11\n"
     ]
    }
   ],
   "source": [
    "prevgenecn = tc.get(name='depmap-wes-cn-data-81a7', version=22, file='internal_20Q2_gene_cn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACH-002462',\n",
       " 'ACH-002463',\n",
       " 'ACH-002464',\n",
       " 'ACH-002465',\n",
       " 'ACH-002466',\n",
       " 'ACH-002467',\n",
       " 'ACH-002475'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(prevgenecn.index) & set(blacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(prevgenecn.index) - set(genecn.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentcn = pd.read_csv('temp/wes.'+release+'.segment.cn', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: This version is deprecated. Please use with caution, and see the reason below:\n",
      "\tmissing cell lines\n"
     ]
    }
   ],
   "source": [
    "# getting the previous versions to check that we have everything we should\n",
    "prev = set(tc.get(name='segmented-cn-wes-prioritzed-7fe1', file='wes.'+prevname+'.gene', version=prevversion).index.tolist())\n",
    "prevprev= set(tc.get(name='segmented-cn-wes-prioritzed-7fe1', file='wes.'+prevprevname+'.gene', version=prevprevversion).index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1760 1760 1767 1767\n"
     ]
    }
   ],
   "source": [
    "new1 = set(genecn.index.values.tolist())\n",
    "new2 = set(segmentcn['DepMap_ID'].values.tolist())\n",
    "print(len(prev), len(prev & new1), len(new1), len(new1 & new2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DepMap_ID</th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Num_Probes</th>\n",
       "      <th>Segment_Mean</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [DepMap_ID, Chromosome, Start, End, Num_Probes, Segment_Mean, Source]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentcn[segmentcn.DepMap_ID==\"ACH-001546\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ACH-001546\" in segmentcn.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACH-000044 1202\n",
      "ACH-001230 947\n",
      "ACH-000836 1001\n",
      "ACH-000216 925\n",
      "ACH-000593 764\n",
      "ACH-000090 1024\n",
      "ACH-001955 1296\n",
      "ACH-002204 1318\n",
      "ACH-000327 819\n",
      "ACH-000842 929\n",
      "ACH-001045 822\n",
      "ACH-000258 872\n",
      "ACH-000659 1129\n",
      "ACH-000118 794\n",
      "ACH-000064 1203\n",
      "ACH-000868 1422\n",
      "ACH-001150 782\n",
      "ACH-000941 813\n",
      "ACH-000600 939\n",
      "ACH-000870 1557\n",
      "ACH-000068 812\n",
      "ACH-000128 767\n",
      "ACH-001101 1005\n",
      "ACH-000028 868\n",
      "ACH-000658 927\n",
      "ACH-000690 771\n",
      "ACH-000444 974\n",
      "ACH-000167 838\n",
      "ACH-001043 825\n",
      "ACH-000901 816\n",
      "ACH-000071 1287\n",
      "ACH-001249 1756\n",
      "ACH-001956 1368\n",
      "ACH-000774 953\n",
      "ACH-000419 826\n",
      "ACH-000887 1408\n",
      "ACH-000710 968\n",
      "ACH-000578 869\n",
      "ACH-001036 858\n",
      "ACH-000550 974\n",
      "ACH-000923 1469\n",
      "ACH-001017 1223\n",
      "ACH-001000 980\n",
      "ACH-000300 1431\n",
      "ACH-001079 2586\n",
      "ACH-001234 819\n",
      "ACH-001679 1227\n",
      "ACH-001239 851\n",
      "ACH-001094 1036\n",
      "ACH-001225 792\n",
      "ACH-002335 1312\n",
      "ACH-000837 1015\n",
      "ACH-000960 913\n",
      "ACH-000452 816\n",
      "ACH-000961 763\n",
      "ACH-000635 1368\n",
      "ACH-000848 1171\n",
      "ACH-000356 1294\n",
      "ACH-000454 1051\n",
      "ACH-000458 762\n",
      "ACH-001088 1337\n",
      "ACH-001113 1072\n",
      "ACH-001171 792\n",
      "ACH-001071 1175\n",
      "ACH-000854 899\n",
      "ACH-000509 873\n",
      "ACH-000488 954\n",
      "ACH-000904 868\n",
      "ACH-000195 2029\n",
      "ACH-000738 1064\n",
      "ACH-001957 1426\n",
      "ACH-001214 889\n",
      "ACH-000865 1358\n"
     ]
    }
   ],
   "source": [
    "checkAmountOfSegments(segmentcn,thresh = 750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkGeneChangeAccrossAll(genecn, thresh=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentcn.Start = segmentcn.Start.astype(int)\n",
    "segmentcn.End = segmentcn.End.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.780513339939832e-10, 1.0050513176124436, 7.220474335775503)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genecn.values.min(), genecn.values.mean(), genecn.values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(genecn.values.max() > 100):\n",
    "    print(\"\\n\\n\\nTOO HIGH, not LOG2 transformed!\")\n",
    "if(len(genecn.index.tolist()) > len(set(genecn.index))):\n",
    "    print(\"Duplicate CL, not reprioritized well!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, val in samplesinset.iterrows():\n",
    "    plot = val[\"modeled_segments_plot_tumor\"]\n",
    "    ! gsutil cp $plot temp/\n",
    "    print(k)\n",
    "    print(val['arxspan_id'])\n",
    "    display(Image('temp/'+plot.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look bad in 20Q1: \n",
    "ACH-002511 (M140325), ACH-001370 (OCIP5X)\n",
    "\n",
    "These CN plots subjectively appear to have too many segments in new 20Q2 samples: \n",
    "ACH-002399 (CDS-sukIAT, 21NT_1), ACH-002401 (CDS-tVy3GF, 21MT2_1), ACH-002400 (CDS-VUHMHG, 21MT1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ACH-001547',\n",
       "  'ACH-001679',\n",
       "  'ACH-001970',\n",
       "  'ACH-001973',\n",
       "  'ACH-002399',\n",
       "  'ACH-002400',\n",
       "  'ACH-002401',\n",
       "  'ACH-002462',\n",
       "  'ACH-002463',\n",
       "  'ACH-002464',\n",
       "  'ACH-002465',\n",
       "  'ACH-002466',\n",
       "  'ACH-002467'],\n",
       " [],\n",
       " ['ACH-001006',\n",
       "  'ACH-001007',\n",
       "  'ACH-001008',\n",
       "  'ACH-001009',\n",
       "  'ACH-001010',\n",
       "  'ACH-001062',\n",
       "  'ACH-001082',\n",
       "  'ACH-001083',\n",
       "  'ACH-001153',\n",
       "  'ACH-001154',\n",
       "  'ACH-001155',\n",
       "  'ACH-001156',\n",
       "  'ACH-001157',\n",
       "  'ACH-001158',\n",
       "  'ACH-001159',\n",
       "  'ACH-001160',\n",
       "  'ACH-001161',\n",
       "  'ACH-001178',\n",
       "  'ACH-001179',\n",
       "  'ACH-001181',\n",
       "  'ACH-001204',\n",
       "  'ACH-001218',\n",
       "  'ACH-001219',\n",
       "  'ACH-001220',\n",
       "  'ACH-001221',\n",
       "  'ACH-001222',\n",
       "  'ACH-001223',\n",
       "  'ACH-001251',\n",
       "  'ACH-001252',\n",
       "  'ACH-001253',\n",
       "  'ACH-001254',\n",
       "  'ACH-001255',\n",
       "  'ACH-001256',\n",
       "  'ACH-001257',\n",
       "  'ACH-001258',\n",
       "  'ACH-001259',\n",
       "  'ACH-001269',\n",
       "  'ACH-001434',\n",
       "  'ACH-001752',\n",
       "  'ACH-001753',\n",
       "  'ACH-001754',\n",
       "  'ACH-001755',\n",
       "  'ACH-001756',\n",
       "  'ACH-001757',\n",
       "  'ACH-001758',\n",
       "  'ACH-001759',\n",
       "  'ACH-001760',\n",
       "  'ACH-001780',\n",
       "  'ACH-001781',\n",
       "  'ACH-001782',\n",
       "  'ACH-001783',\n",
       "  'ACH-001784',\n",
       "  'ACH-001785',\n",
       "  'ACH-002446-311cas9',\n",
       "  'ACH-002476',\n",
       "  'ACH-003000',\n",
       "  'ACH-002874',\n",
       "  'ACH-002875',\n",
       "  'ACH-001140',\n",
       "  'ACH-001546'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsheets = sheets.get(sheeturl).sheets[6].to_frame()\n",
    "wes_embargo = [i for i in gsheets['WES_embargo'].values.tolist() if str(i) != 'nan']\n",
    "wes_dmc_embargo = [i for i in gsheets['WES_DMC_embargo'].values.tolist() if str(i) != 'nan']\n",
    "blacklist = [i for i in gsheets['blacklist'].values.tolist() if str(i) != 'nan']\n",
    "\n",
    "wes_embargo, wes_dmc_embargo, blacklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to taiga\n",
    "\n",
    "- we load the blacklisted/embargoed sample ids\n",
    "- we log2 transform and create a file for each release (and one containing everything)\n",
    "- we upload the files using taigapy in a corresponding taiga dataset with the corresponding description and also upload it to its virtual dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we push full dataset version in depmap taiga CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148.134924260474 1.068830521805282 1.92730498227434e-10\n",
      "7.220474335775503 1.0050513176124436 2.780513339939832e-10\n"
     ]
    }
   ],
   "source": [
    "print(segmentcn.Segment_Mean.max(), segmentcn.Segment_Mean.mean(), segmentcn.Segment_Mean.min())\n",
    "print(genecn.values.max(), genecn.values.mean(),genecn.values.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for genecn removing first blacklisted, then embargoed, to create two datasets\n",
    "genecn = genecn.apply(lambda x: np.log2(1+x))\n",
    "genecn.to_csv('temp/wes.'+release+'.gene.cn', index=True)\n",
    "segmentcn.to_csv('temp/wes.'+release+'.segment.cn', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(genecn.values.max() > 100):\n",
    "    print(\"\\n\\n\\nTOO HIGH, not LOG2 transformed!\")\n",
    "if(len(genecn.index.tolist()) > len(set(genecn.index))):\n",
    "    print(\"Duplicate CL, not reprioritized well!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Old genecn shape:\", genecn.shape)\n",
    "print(\"Old segmentcn shape:\", segmentcn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.update_dataset(dataset_permaname=\"segmented-cn-wes-prioritzed-7fe1\", \n",
    "                  upload_file_path_dict={\n",
    "                    'temp/wes.'+release+'.gene.cn': 'NumericMatrixCSV',\n",
    "                    'temp/wes.'+release+'.segment.cn': 'TableCSV'},\n",
    "                  changes_description=\n",
    "\"\"\"\n",
    "Removing duplication of ACH-000219 from segmentcn file to prevent issues in future releases, which use this Taiga dataset in the process of determining which new lines to release. Now both the genecn file and the segmentcn file have 1767 unique DepMap IDs.\n",
    "\"\"\",\n",
    "                  dataset_description=\n",
    "\"\"\"\n",
    "# Copy Number\n",
    "\n",
    "Combined segment and gene-level CN calls from Broad WES, Sanger WES, and Broad SNP. Relative CN, log2(x+1) transformed.\n",
    "\n",
    "PORTAL TEAM SHOULD NOT USE THIS: There are lines here that should not make it even to internal. Must use subsetted dataset instead. These data will not make it on the portal starting 19Q1. With the DMC portal, there is new cell line release prioritization as to which lines can be included, so a new taiga dataset will be created containing CN for the portal.\n",
    "\n",
    "These data are generated for Achilles to pull from to run CERES.\n",
    "\n",
    "Versions to use:\n",
    "\n",
    "v45 for 20Q2 (For Achilles QC, use v44 of segmentcn)\n",
    "v40 for 20Q1\n",
    "v38 for 19Q4\n",
    "v33 for 19Q4\n",
    "v25 for 19Q2 (hg38 aligned, Broad WES and Sanger WES based calls were generated from bam realignment. SNP based calls are still from liftover). The gene mapping script was updated to improve the gene level matrix (to remove NAs). The segment level matrix is untransformed relative CN. Gene level matrix is log2(CN + 1).\n",
    "v20 for 19Q1 (version 21 is hg19)\n",
    "v18: for 18Q4\n",
    "v15: for 18Q3\n",
    "v11: for 18Q2\n",
    "Gene-level matrix in versions below 10 were using hg38 and not hg19. Version 11 is corrected and should be used instead\n",
    "\n",
    "Calls on X, Y chromosome for profiles should not be used.\n",
    "\n",
    "Prioritization is as follows:\n",
    "\n",
    "Broad WES kept over everything\n",
    "Sanger WES kept if:\n",
    "This cell line did not fail fingerprinting\n",
    "This cell line has no other CN data\n",
    "This cell lines does not have CRISPR LFC data from the Achilles screen\n",
    "This CN profile correlates better with Achilles CRISPR LFC data than Broad SNP CN OR the % gene-level difference between this cell lines CN profile from Sanger WES and Broad SNP < 2.5%\n",
    "Broad SNP used for remaining lines with no Broad WES or with Sanger WES that does not pass the criteria above\n",
    "The 'Source' column indicates which CN profile was used for that cell line.\n",
    "\n",
    "version 6: renamed Sample column to CCLE_name for consistency for the Achilles pipeline\n",
    "\n",
    "version 7: missing chordoma lines\n",
    "\n",
    "version 8: fixed to names of two chordoma lines (changed suffix from CHORDOMA -> BONE) and removed renamed \n",
    "cell lines that were duplicated (with different names). Reran comparison using 18q2 LFC results. Gene level matrix will be generated for version 9\n",
    "\n",
    "version 11: corrected error in gene-level matrix calculation (previously had been aligned to hg38 however alignment should be hg19). Segment level calls are unaffected.\n",
    "\n",
    "versions 12-14: Sanger WES were multiplied by 2 so should not be used\n",
    "\n",
    "version 15: internal segments and gene level matrices for 18q3 release including public version (removed black list lines and Broad WES < 6 months old). Gene level matrices are indexed using Broad IDs.\n",
    "\n",
    "version 16: internal segments and gene level matrices for 18q4 release including public version (uses all SNP and only WES if those lines are present in the 18Q4 public Achilles dataset)\n",
    "\n",
    "version 17: same as version 16 but with two additional line in the internal version\n",
    "\n",
    "version 18: same as version 17 but switched one line in public to use SNP instead of WES because not in public Avana\n",
    "\n",
    "version 20: two major changes occurred (1) we are using a FireCloud based pipeline for CN calling now for Broad WES data (2) we have moved to use hg38. This is accomplished by lifting over coordinates from hg19 to hg38 after processed by the CN pipeline.\n",
    "v21 same as version 20, but we are using the original hg19 coordinates, not hg38\n",
    "\n",
    "version 25: Broad WES and Sanger WES were realigned to hg38. SNP still uses liftover from hg19 to hg38\n",
    "\n",
    "version 35: Seeing what went wrong with the upload.\n",
    "\n",
    "version 36: problem with not log2 transforming the data\n",
    "\n",
    "version 37: resolving the problem with log2 transforming the segment data\n",
    "\n",
    "version 38: resolving the problem with log2 transforming the segment data\n",
    "\n",
    "version 39: 20Q1. Samples ACH-002511 (M140325) and ACH-001370 (OCIP5X) appear to have too many segments looking at the CN profile.\n",
    "\n",
    "version 40: unlog2 transforming segmentcn\n",
    "\n",
    "version 41: 20Q2 (segmentcn is just relative copy number, whereas the genecn is log2(x+1) transformed). Added 7 new samples.\n",
    "These CN plots subjectively appear to have too many segments in new 20Q2 samples: ACH-002399 (CDS-sukIAT, 21NT\\_1), ACH-002401 (CDS-tVy3GF, 21MT2\\_1), ACH-002400 (CDS-VUHMHG, 21MT1\\_1)\n",
    "\n",
    "version 42: **note: version 42 is missing some of the cell lines. Do not use** \n",
    "\n",
    "version 43: Resolving issue of no DepMap ID index in the genecn file. Duplicating the CN data in genecn and segmentcn for ACH-000219 so we have CN data for ACH-002874, the same cell line grown in different media. This step is required for Achilles / CERES.\n",
    "\n",
    "version 44: Removing duplication of ACH-000219 from genecn file. The Achilles QC only needs the duplication in the segmentcn file. This change results in 1767 unique DepMap IDs in the genecn file, and 1768 unique DepMap IDs in the segmentcn file.\n",
    "\n",
    "version 45: Removing duplication of ACH-000219 from segmentcn file to prevent issues in future releases, which use this Taiga dataset in the process of determining which lines should be released to Public. Now both the genecn file and the segmentcn file have 1767 unique DepMap IDs.\n",
    "\n",
    "version 46: removing two weird undefined lines \n",
    "\n",
    "Gene level CN data:\n",
    "\n",
    "__Rows__: DepMap cell line IDs\n",
    "\n",
    "__Columns__: gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "\n",
    "Segment level data:\n",
    "\n",
    "__Columns__: DepMap\\_ID, Chromosome, Start, End, Num\\_Probes, Segment\\_Mean\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We push internal dataset with blacklisted removed\n",
    "\n",
    "and we add it to eternal dataset and to virtual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341529\n",
      "341053\n",
      "1767\n",
      "1765\n"
     ]
    }
   ],
   "source": [
    "## for segment removing first blacklisted, then embargoed, to create two datasets\n",
    "print(len(segmentcn))\n",
    "segmentcn = segmentcn[~segmentcn.DepMap_ID.isin(blacklist)]\n",
    "print(len(segmentcn))\n",
    "segmentcn.to_csv('temp/internal_'+release+'_segs_cn', index=False)\n",
    "print(len(genecn))\n",
    "genecn = genecn[~genecn.index.isin(blacklist)]\n",
    "print(len(genecn))\n",
    "genecn.to_csv('temp/internal_'+release+'_gene_cn', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevcn = tc.get(name='depmap-cn-data-81a7', version=24, file='unfiltered_fusions_'+prevname)\n",
    "print('shoud be None')\n",
    "print(set(prevcn.DepMap_ID) - set(genecn.DepMap_ID))\n",
    "print(\"new lines\")\n",
    "newlines = set(genecn.DepMap_ID) - set(prevcn.DepMap_ID) \n",
    "newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading internal_20Q3_gene_cn...\n",
      "hitting https://cds.team/taiga/api/datafile/cb5e4c48b1904f25ac1ccb8aef424184\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1750\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: internal_20Q3_gene_cn properly converted and uploaded\n",
      "Uploading internal_20Q3_segs_cn...\n",
      "hitting https://cds.team/taiga/api/datafile/cb5e4c48b1904f25ac1ccb8aef424184\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: internal_20Q3_segs_cn properly converted and uploaded\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id e31e5206fe674ae9aee8b2129cba7599 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/e31e5206fe674ae9aee8b2129cba7599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'e31e5206fe674ae9aee8b2129cba7599'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.update_dataset(dataset_permaname=\"depmap-wes-cn-data-81a7\", \n",
    "                  upload_file_path_dict={\n",
    "                    'temp/internal_'+release+'_gene_cn': 'NumericMatrixCSV',\n",
    "                    'temp/internal_'+release+'_segs_cn': 'TableCSV'},\n",
    "                  dataset_description=\n",
    "\"\"\"\n",
    "# Copy Number\n",
    "\n",
    "\n",
    "## ** Version 1 Internal 18Q1****\n",
    "\n",
    "Generated with the following script:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='gene-level-cn-87aa', \n",
    "                                  data.version=5, \n",
    "                                  data.file='gene_CN_WES_priority')\n",
    "source_info <- data.frame(ccle_name=gsub(\"snp_|sangerWES_|ccleWES_|achillesWES_\", \n",
    "                                         \"\", row.names(wes_pri)), \n",
    "                          source=gsub(\"_.*\", \"\", row.names(wes_pri)))\n",
    "wes_pri %<>% magrittr::set_rownames(source_info$ccle_name)\n",
    "\n",
    "```\n",
    "\n",
    "## ** Version 2 Internal 18Q2****\n",
    "\n",
    "Generated with the following script:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='segmented-cn-wes-prioritzed-7fe1', data.version=9, data.file='wes_priority_cn_gene_matrix') %>% log2()\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "## ** Version 3 Internal 18Q2****\n",
    "\n",
    "Generated with the following script:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='segmented-cn-wes-prioritzed-7fe1', data.version=11, data.file='wes_priority_cn_gene_matrix') %>% log2()\n",
    "\n",
    "\n",
    "```\n",
    "## ** Version 4-6 Internal 18Q3****\n",
    "\n",
    "__Description__: log2 gene level copy number data\n",
    "\n",
    "Generated with the following script:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='segmented-cn-wes-prioritzed-7fe1', data.version=15, data.file='wes_priority_cn_gene_matrix') %>% log2()\n",
    "\n",
    "\n",
    "```\n",
    "__Rows__: Broad (arxspan) cell line IDs\n",
    "\n",
    "__Columns__: gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "\n",
    "Version 5 has updated cell line name mapping\n",
    "\n",
    "Version 4 and 5 the segment level CN for Sanger's data is off by a factor of 2, version 6 corrects this\n",
    "\n",
    "**** Version 7 Internal 18Q4****\n",
    "\n",
    "__Description__: log2 gene level copy number data\n",
    "\n",
    "Generated with the following script:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='segmented-cn-wes-prioritzed-7fe1', data.version=17, data.file='wes_priority_cn_gene_matrix') %>% log2()\n",
    "\n",
    "\n",
    "```\n",
    "__Rows__: DepMap (arxspan) cell line IDs\n",
    "\n",
    "__Columns__: gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "\n",
    "## ** Version 8-9 Internal 19Q1****\n",
    "\n",
    "version 9 has the correct data for 19Q1\n",
    "\n",
    "## ** Version 10-11 Internal 19Q2****\n",
    "\n",
    "__version 11 added an additional 13 cell lines and adds the segment level copy number data__\n",
    "\n",
    "## ** Version 12 Internal 19Q3****\n",
    "\n",
    "__Description__: log2(X + 1) gene level copy number data (data is now log2 transformed with a __pseudocount of 1__ added). CN data is generated using __hg38__. \n",
    "\n",
    "\n",
    "## ** Version 15 Internal 19Q4****\n",
    "\n",
    "Adding 35 new cell lines\n",
    "\n",
    "## ** Version 16 Internal 19Q4****\n",
    "resolving problem with not having log2 transform \n",
    "\n",
    "## ** Version 17 Internal 19Q4****\n",
    "resolving problem with having log2 transform on segments\n",
    "\n",
    "## ** Version 18 Internal 20Q1****\n",
    "adding 8 new cell lines\n",
    "\n",
    "## ** Version 19 Internal 20Q1****\n",
    "unlog2 transforming segmentcn\n",
    "\n",
    "## ** Version 20 Internal 20Q1****\n",
    "adding new cell lines\n",
    "\n",
    "## ** Version 21 Internal 20Q1****\n",
    "reparing some missing lines\n",
    "\n",
    "## ** Version 22 Internal 20Q2****\n",
    "adding new lines\n",
    "\n",
    "## ** Version 23 Internal 20Q3****\n",
    "nothing changed from 20Q2 updating the blacklist\n",
    "\n",
    "## ** Version 24 Internal 20Q3****\n",
    "updating the blacklists\n",
    "\n",
    "\n",
    "Some cells lines have been flagged as:\n",
    "\n",
    " - having bad looking copy ration plots = ACH-002511 (M140325) and ACH-001370 (OCIP5X)\n",
    " - having too many segments (format: sample seg_count) = ACH-001079 2586, ACH-000044 1202, ACH-000258 872, ACH-001230 947, ACH-000068 812, ACH-000454 1051, ACH-000216 925, ACH-001150 782, ACH-001214 889, ACH-002335 1312, ACH-000836 1001, ACH-001957 1426, ACH-000960 913, ACH-000458 762, ACH-000578 869, ACH-000327 819, ACH-000090 1024, ACH-000488 954, ACH-000848 1171, ACH-000923 1469, ACH-000904 868, ACH-000452 816, ACH-000600 939, ACH-001656 902, ACH-000854 899, ACH-000774 953, ACH-001000 980, ACH-000941 813, ACH-000887 1408, ACH-001017 1223, ACH-001171 792, ACH-001071 1175, ACH-000593 764, ACH-001239 851, ACH-000071 1287, ACH-001956 1368, ACH-000509 873, ACH-002204 1318, ACH-000550 974, ACH-000738 1064, ACH-000870 1557, ACH-001036 858, ACH-001043 825, ACH-000028 868, ACH-001955 1296, ACH-000419 826, ACH-001234 819, ACH-001094 1036, ACH-001225 792, ACH-000118 794, ACH-000300 1431, ACH-001113 1072, ACH-001045 822, ACH-000444 974, ACH-000901 816, ACH-000865 1358, ACH-000961 763, ACH-001249 1756, ACH-000167 838, ACH-001101 1005, ACH-000842 929, ACH-000837 1015, ACH-000710 968, ACH-000195 2029, ACH-000064 1203, ACH-000690 771, ACH-000635 1368, ACH-000356 1294, ACH-000659 1129, ACH-000868 1422, ACH-000128 767, ACH-000658 927, ACH-001088 1337\n",
    " - Genes having a similar CN value accross all: []\n",
    " \n",
    "## ** Version 20 Internal 20Q2****\n",
    "Added 7 samples.\n",
    "\n",
    "Some cells lines have been flagged as:\n",
    "\n",
    " - having bad looking copy ratio plots (appear to have too many segments): ACH-002399 (CDS-sukIAT, 21NT\\_1), ACH-002401 (CDS-tVy3GF, 21MT2\\_1), ACH-002400 (CDS-VUHMHG, 21MT1\\_1)\n",
    " - having too many segments (format: sample seg_count): same as for 20Q1\n",
    " - Genes having a similar CN value accross all samples: []\n",
    " \n",
    " \n",
    "## ** Version 21 Internal 20Q2****\n",
    " \n",
    "Duplicating the CN data in genecn and segmentcn for ACH-000219 so we have CN data for ACH-002874, the same cell line grown in different media. This step is required for Achilles / CERES.\n",
    "\n",
    "Version 22: removing two weird undefined lines \n",
    "\n",
    "## ** Version 23 Internal 20Q3****\n",
    "\n",
    "same  as  20Q2 for this release. no new lines\n",
    "\n",
    "Gene level CN data:\n",
    "\n",
    "__Rows__: DepMap cell line IDs\n",
    "\n",
    "__Columns__: gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "\n",
    "Segment level data:\n",
    "\n",
    "__Columns__: DepMap\\_ID, Chromosome, Start, End, Num\\_Probes, Segment\\_Mean\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+newlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CCLE_gene_cn', 'depmap-wes-cn-data-81a7.24/internal_20Q3_gene_cn'), ('CCLE_segment_cn', 'depmap-wes-cn-data-81a7.24/internal_20Q3_segs_cn'), ('CCLE_RNAseq_reads', 'depmap-rnaseq-expression-data-363a.25/internal_20Q3_counts'), ('CCLE_expression', 'depmap-rnaseq-expression-data-363a.25/internal_20Q3_proteincoding_tpm'), ('CCLE_mutations', 'depmap-mutation-calls-9be3.23/depmap_20q3_mutation_calls'), ('CCLE_RNAseq_transcripts', 'depmap-rnaseq-expression-data-363a.25/internal_20Q3_transcripts_tpm'), ('CCLE_expression_full', 'depmap-rnaseq-expression-data-363a.25/internal_20Q3_tpm')]\n",
      "hitting https://cds.team/taiga/api/datafile/cda244e63bde446da7a1507d74f8a431\n",
      "hitting https://cds.team/taiga/api/datafile/cda244e63bde446da7a1507d74f8a431\n",
      "hitting https://cds.team/taiga/api/datafile/cda244e63bde446da7a1507d74f8a431\n",
      "hitting https://cds.team/taiga/api/datafile/cda244e63bde446da7a1507d74f8a431\n",
      "hitting https://cds.team/taiga/api/datafile/cda244e63bde446da7a1507d74f8a431\n",
      "hitting https://cds.team/taiga/api/datafile/cda244e63bde446da7a1507d74f8a431\n",
      "hitting https://cds.team/taiga/api/datafile/cda244e63bde446da7a1507d74f8a431\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 0cc043aaf39444119d17a2a2f593cda1 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/0cc043aaf39444119d17a2a2f593cda1\n",
      "[('CCLE_gene_cn', 'depmap-wes-cn-data-81a7.24/internal_20Q3_gene_cn'), ('CCLE_segment_cn', 'depmap-wes-cn-data-81a7.24/internal_20Q3_segs_cn'), ('CCLE_expression_full', 'depmap-rnaseq-expression-data-363a.25/internal_20Q3_tpm'), ('TD_summary_table', 'master-table-26f2.3/summary_table'), ('SCORE_replicate_map', 'sanger-crispr-project-score--e20b.4/replicate_map'), ('SCORE_gene_dependency', 'sanger-crispr-project-score--e20b.4/gene_dependency'), ('D2_common_essentials', 'demeter2-combined-dc9c.16/pan_dependent_genes'), ('SCORE_gene_effect', 'sanger-crispr-project-score--e20b.4/gene_effect'), ('CCLE_README', 'ccle-readmes-b1a1.4/Internal_CCLE_README'), ('CCLE_fusions', 'gene-fusions-8b7a.12/filtered_fusions_20Q2'), ('CCLE_expression', 'depmap-rnaseq-expression-data-363a.25/internal_20Q3_proteincoding_tpm'), ('sample_info', 'depmap-a0ab.6/sample_info'), ('Achilles_common_essentials', 'avana-internal-20q2-3b07.1/pan_dependent_genes'), ('SCORE_gene_effect_unscaled', 'sanger-crispr-project-score--e20b.4/gene_effect_unscaled'), ('SCORE_guide_efficacy', 'sanger-crispr-project-score--e20b.4/guide_efficacy'), ('common_essentials', 'avana-internal-20q2-3b07.1/essential_genes'), ('Achilles_high_variance_genes', 'avana-internal-20q2-3b07.1/high_variance_genes'), ('Achilles_gene_dependency', 'avana-internal-20q2-3b07.1/gene_dependency'), ('Achilles_guide_efficacy', 'avana-internal-20q2-3b07.1/guide_efficacy'), ('D2_gene_dependency', 'demeter2-combined-dc9c.16/gene_dependency'), ('CCLE_mutations', 'depmap-mutation-calls-9be3.23/depmap_20q3_mutation_calls'), ('Achilles_replicate_map', 'avana-internal-20q2-3b07.1/replicate_map'), ('D2_hairpin_parameters', 'demeter2-combined-dc9c.16/hp_data_comb'), ('Achilles_README', 'avana-internal-19q3-67a9.3/README'), ('Achilles_logfold_change_failures', 'avana-internal-20q2-3b07.1/logfold_change_failures'), ('Achilles_raw_readcounts_failures', 'avana-internal-20q2-3b07.1/raw_readcounts_failing'), ('Achilles_gene_effect_unscaled', 'avana-internal-20q2-3b07.1/gene_effect_unscaled'), ('Achilles_dropped_guides', 'avana-internal-20q2-3b07.1/dropped_guides'), ('SCORE_essential_genes', 'sanger-crispr-project-score--e20b.4/pan_dependent_genes'), ('CCLE_fusions_unfiltered', 'gene-fusions-8b7a.12/unfiltered_fusions_20Q2'), ('CCLE_RNAseq_transcripts', 'depmap-rnaseq-expression-data-363a.25/internal_20Q3_transcripts_tpm'), ('D2_gene_effect', 'demeter2-combined-dc9c.16/gene_effect'), ('Achilles_guide_map', 'avana-internal-20q2-3b07.1/guide_gene_map'), ('Achilles_logfold_change', 'avana-internal-20q2-3b07.1/logfold_change'), ('nonessentials', 'avana-internal-20q2-3b07.1/nonessential_genes'), ('SCORE_logfold_change', 'sanger-crispr-project-score--e20b.4/logfold_change'), ('SCORE_raw_readcounts', 'sanger-crispr-readcounts-2fa9.1/SangerRawReadcounts_filtered'), ('SCORE_guide_map', 'sanger-crispr-project-score--e20b.4/guide_gene_map'), ('CCLE_RNAseq_reads', 'depmap-rnaseq-expression-data-363a.25/internal_20Q3_counts'), ('Achilles_replicate_QC_report_failing', 'avana-internal-19q4-4c36.4/replicate_QC_report_failing'), ('D2_cell_parameters', 'demeter2-combined-dc9c.16/CL_data_comb'), ('Achilles_gene_effect', 'avana-internal-20q2-3b07.1/gene_effect'), ('Achilles_raw_readcounts', 'avana-internal-20q2-3b07.1/raw_readcounts')]\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datafile/f353508990cf46adab595ce1f4def659\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 8baba7f5f8584352a380946b1ec9a1c1 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/8baba7f5f8584352a380946b1ec9a1c1\n"
     ]
    }
   ],
   "source": [
    "# To add to a virtual dataset\n",
    "AddToVirtual(virtual_internal, 'depmap-wes-cn-data-81a7', [('CCLE_gene_cn', 'internal_'+release+'_gene_cn'),('CCLE_segment_cn', 'internal_'+release+'_segs_cn')])\n",
    "# To add to a eternal dataset\n",
    "AddToVirtual('depmap-a0ab', 'depmap-wes-cn-data-81a7', [('CCLE_gene_cn', 'internal_'+release+'_gene_cn'),('CCLE_segment_cn', 'internal_'+release+'_segs_cn')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We add to dmc as in internal*\n",
    "\n",
    "* **NOTE: change as of 20Q2 onwards**. We need to remove lines in WES_DMC_embargo from the Internal version of the CN datasets before we upload the `genecn` and `segmentcn` files to DMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341053\n",
      "341053\n",
      "1765\n",
      "1765\n"
     ]
    }
   ],
   "source": [
    "## for segment removing first blacklisted, then embargoed, to create two datasets\n",
    "print(len(segmentcn))\n",
    "segmentcn = segmentcn[~segmentcn.DepMap_ID.isin(wes_dmc_embargo)]\n",
    "print(len(segmentcn))\n",
    "segmentcn.to_csv('temp/dmc_'+release+'_segs_cn', index=False)\n",
    "print(len(genecn))\n",
    "genecn = genecn[~genecn.index.isin(wes_dmc_embargo)]\n",
    "print(len(genecn))\n",
    "genecn.to_csv('temp/dmc_'+release+'_gene_cn', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevcn = tc.get(name='depmap-cn-data-9b9d', version=11, file='unfiltered_fusions_'+prevname)\n",
    "print('shoud be None')\n",
    "print(set(prevcn.DepMap_ID) - set(genecn.DepMap_ID))\n",
    "print(\"new lines\")\n",
    "newlines = set(genecn.DepMap_ID) - set(prevcn.DepMap_ID) \n",
    "newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading dmc_20Q3_gene_cn...\n",
      "hitting https://cds.team/taiga/api/datafile/dba99a9f1615439ea8e5f4ba3c39bc8c\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1750\n",
      "\t Conversion in progress, line 1750\n",
      "\t Conversion in progress, line 1750\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: dmc_20Q3_gene_cn properly converted and uploaded\n",
      "Uploading dmc_20Q3_segs_cn...\n",
      "hitting https://cds.team/taiga/api/datafile/dba99a9f1615439ea8e5f4ba3c39bc8c\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: dmc_20Q3_segs_cn properly converted and uploaded\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 72688a3cd3474a86ae553b11c1c03025 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/72688a3cd3474a86ae553b11c1c03025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'72688a3cd3474a86ae553b11c1c03025'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.update_dataset(dataset_permaname=\"depmap-cn-data-9b9d\",\n",
    "                upload_file_path_dict={\n",
    "                    'temp/dmc_'+release+'_gene_cn':'NumericMatrixCSV',\n",
    "                    'temp/dmc_'+release+'_segs_cn': 'TableCSV',\n",
    "                   },\n",
    "                  changes_description=\n",
    "\"\"\"\n",
    "Adding 20Q2 samples.\n",
    "\"\"\",\n",
    "                \n",
    "                  dataset_description=\"\"\"\n",
    "**** Version 1-2 DMC 19Q1****\n",
    "\n",
    "version 2 contains the correct data for 19Q1\n",
    "\n",
    "**** Version 3-4 DMC 19Q2****\n",
    "\n",
    "__version 4 added an additional 13 cell lines and adds the segment level copy number data__\n",
    "\n",
    "**** Version 5 DMC 19Q3***\n",
    "\n",
    "**** Version 7 DMC 19Q4***\n",
    "adding 35 new cell lines\n",
    "\n",
    "**** Version 8 DMC 19Q4****\n",
    "resolving problem with not having log2 transform \n",
    "\n",
    "**** Version 9 DMC 19Q4****\n",
    "resolving problem with having log2 transformed the segments\n",
    "\n",
    "**** Version 10 DMC 20Q1****\n",
    "adding new samples\n",
    "\n",
    "**** Version 11 DMC 20Q1****\n",
    "unlog2 transforming segmentcn\n",
    "\n",
    "**** Version 12 DMC 20Q2****\n",
    "Adding samples to be included in 20Q2\n",
    "\n",
    "**** Version 13 DMC 20Q2****\n",
    "unknown changes\n",
    "\n",
    "**** Version 14 DMC 20Q3****\n",
    "updated blacklists\n",
    "\n",
    "**** Version 15 DMC 20Q3****\n",
    "issues with blacklists\n",
    "\n",
    "__Description__: log2(X + 1) gene level copy number data (data is now log2 transformed with a __pseudocount of 1__ added). CN data is generated using __hg38__.  The segment copy number data includes the mean segment copy number segments.\n",
    "\n",
    "Gene level CN data:\n",
    "\n",
    "__Rows__: DepMap cell line IDs\n",
    "\n",
    "__Columns__: gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "\n",
    "Segment level data:\n",
    "\n",
    "__Columns__: DepMap\\_ID, Chromosome, Start, End, Num\\_Probes, Segment\\_Mean\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+newlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CCLE_gene_cn', 'depmap-cn-data-9b9d.15/dmc_20Q3_gene_cn'), ('CCLE_segment_cn', 'depmap-cn-data-9b9d.15/dmc_20Q3_segs_cn'), ('Achilles_gene_effect_unscaled', 'avana-consortium-20q3-902b.1/gene_effect_unscaled'), ('CCLE_RNAseq_transcripts', 'depmap-rnaseq-expression-data-80ef.15/dmc_20Q3_transcripts_tpm'), ('Achilles_raw_readcounts_failures', 'avana-consortium-20q3-902b.1/raw_readcounts_failing'), ('Achilles_gene_effect', 'avana-consortium-20q3-902b.1/gene_effect'), ('CCLE_mutations', 'depmap-mutation-calls-dfce.16/depmap_20q3_mutation_calls'), ('Achilles_gene_dependency', 'avana-consortium-20q3-902b.1/gene_dependency'), ('nonessentials', 'avana-consortium-20q3-902b.1/nonessential_genes'), ('Achilles_common_essentials', 'avana-consortium-20q3-902b.1/pan_dependent_genes'), ('CCLE_RNAseq_reads', 'depmap-rnaseq-expression-data-80ef.15/dmc_20Q3_counts'), ('Achilles_dropped_guides', 'avana-consortium-20q3-902b.1/dropped_guides'), ('common_essentials', 'avana-consortium-20q3-902b.1/essential_genes'), ('Achilles_logfold_change', 'avana-consortium-20q3-902b.1/logfold_change'), ('Achilles_guide_efficacy', 'avana-consortium-20q3-902b.1/guide_efficacy'), ('Achilles_guide_map', 'avana-consortium-20q3-902b.1/guide_gene_map'), ('CCLE_expression_full', 'depmap-rnaseq-expression-data-80ef.15/dmc_20Q3_tpm'), ('Achilles_raw_readcounts', 'avana-consortium-20q3-902b.1/raw_readcounts'), ('CCLE_expression', 'depmap-rnaseq-expression-data-80ef.15/dmc_20Q3_proteincoding_tpm'), ('Achilles_logfold_change_failures', 'avana-consortium-20q3-902b.1/logfold_change_failures'), ('Achilles_replicate_map', 'avana-consortium-20q3-902b.1/replicate_map'), ('Achilles_high_variance_genes', 'avana-consortium-20q3-902b.1/high_variance_genes')]\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datafile/fcb64761800a40ac838d60a114609f88\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id c95b221f40684797a554fa4b648ef9ba created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/c95b221f40684797a554fa4b648ef9ba\n"
     ]
    }
   ],
   "source": [
    "AddToVirtual(virtual_dmc, \"depmap-cn-data-9b9d\", files=[('CCLE_gene_cn', 'dmc_'+release+'_gene_cn'),('CCLE_segment_cn', 'dmc_'+release+'_segs_cn')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We add to public as internal minus dmc embargoed and only cell lines from previous previous release (6 month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341053\n",
      "337818\n",
      "1765\n",
      "1752\n"
     ]
    }
   ],
   "source": [
    "print(len(segmentcn))\n",
    "segmentcn = segmentcn[segmentcn.DepMap_ID.isin(prevprev)]\n",
    "segmentcn = segmentcn[~segmentcn.DepMap_ID.isin(set(wes_embargo))]\n",
    "print(len(segmentcn))\n",
    "segmentcn.to_csv('temp/public_' + release + '_segs_cn', index=False)\n",
    "print(len(genecn))\n",
    "genecn = genecn[genecn.index.isin(prevprev)]\n",
    "genecn = genecn[~genecn.index.isin(set(wes_embargo))]\n",
    "print(len(genecn))\n",
    "genecn.to_csv('temp/public_'+release+'_gene_cn', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevcn = tc.get(name='depmap-cn-data-97cc', version=33, file='unfiltered_fusions_'+prevname)\n",
    "print('shoud be None')\n",
    "print(set(prevcn.DepMap_ID) - set(genecn.DepMap_ID))\n",
    "print(\"new lines\")\n",
    "newlines = set(genecn.DepMap_ID) - set(prevcn.DepMap_ID) \n",
    "newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading public_20Q3_gene_cn...\n",
      "hitting https://cds.team/taiga/api/datafile/bcbe83ee64c94aba90c814a849d73146\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Scanning through file to determine size (line 1001)\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 250\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 500\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 750\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1000\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1250\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1500\n",
      "\t Conversion in progress, line 1750\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: public_20Q3_gene_cn properly converted and uploaded\n",
      "Uploading public_20Q3_segs_cn...\n",
      "hitting https://cds.team/taiga/api/datafile/bcbe83ee64c94aba90c814a849d73146\n",
      "Conversion and upload...:\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Downloading the file from S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\t Uploading to S3\n",
      "\n",
      "\t Done: public_20Q3_segs_cn properly converted and uploaded\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 1516e31ba2da4c8b93b5d221a0533026 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/1516e31ba2da4c8b93b5d221a0533026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1516e31ba2da4c8b93b5d221a0533026'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.update_dataset(dataset_permaname='depmap-wes-cn-data-97cc',\n",
    "                    upload_file_path_dict={\n",
    "                    'temp/public_'+release+'_gene_cn':'NumericMatrixCSV',\n",
    "                    'temp/public_'+release+'_segs_cn': 'TableCSV',\n",
    "                   },\n",
    "                  changes_description=\n",
    "\"\"\"\n",
    "Adding 20Q2 samples.\n",
    "\"\"\",\n",
    "                  dataset_description=\"\"\"\n",
    "**** Versions 1-5 Public 18Q1****\n",
    "\n",
    "Gene-level WES copy-number data for publicly accessible CCLE data. \n",
    "\n",
    "```\n",
    "\n",
    "internal_lines <- readr::read_csv(\"~/Downloads/avana-broad-18q1_v2-sample-info.csv\")$cell_line\n",
    "public_lines <- readr::read_csv(\"~/Downloads/avana-public-tentative-18q1_v5-sample-info.csv\")$cell_line\n",
    "non_public_lines <- setdiff(internal_lines, public_lines)\n",
    "\n",
    "full_cn_set <- taigr::load.from.taiga(data.name='gene-level-cn-87aa', data.version=5, data.file='full_gene_CN')\n",
    "source_info <- data.frame(source=gsub(\"_.*\", \"\", row.names(full_cn_set)),\n",
    "                          ccle_name=gsub(\"snp_|achillesWES_|ccleWES_|sangerWES_\", \"\",\n",
    "                                         row.names(full_cn_set)),\n",
    "                          row_idx=1:nrow(full_cn_set))\n",
    "to_remove <- source_info %>%\n",
    "  dplyr::filter(ccle_name %in% non_public_lines,\n",
    "                source %in% c(\"ccleWES\", \"achillesWES\"))\n",
    "also_to_remove <- source_info %>%\n",
    "                    dplyr::filter(source == \"sangerWES\")\n",
    "indices_to_remove <- c(to_remove$row_idx, also_to_remove$row_idx) %>% unique()\n",
    "indices_to_keep <- source_info %>%\n",
    "  dplyr::filter(!(row_idx %in% indices_to_remove)) %>%\n",
    "  dplyr::group_by(ccle_name) %>%\n",
    "  dplyr::mutate(priority=ifelse(source == \"snp\", 4,\n",
    "                                ifelse(source == \"sangerWES\", 3,\n",
    "                                       ifelse(source == \"ccleWES\", 2, 1)))) %>%\n",
    "  dplyr::filter(priority == min(priority)) %>%\n",
    "  dplyr::ungroup()\n",
    "\n",
    "public_cn <- full_cn_set[indices_to_keep$row_idx,]\n",
    "source_info <- data.frame(source=gsub(\"_.*\", \"\", row.names(public_cn)),\n",
    "                          ccle_name=gsub(\"snp_|achillesWES_|ccleWES_|sangerWES_\", \"\",\n",
    "                                         row.names(public_cn)))\n",
    "public_cn %<>% magrittr::set_rownames(source_info$ccle_name)\n",
    "```\n",
    "\n",
    "CN data are on a log2 scale.\n",
    "\n",
    "`WES_source_info` tracks the source data for each cell line. Sources are `snp`, `achillesWES`, `ccleWES`, and `sangerWES`\n",
    "\n",
    "NOTE: Version 1 contained WES data from cell lines not available in the 18Q1 Public release. Versions 2-4 contained Sanger's WES CN data\n",
    "\n",
    "**** Version 6 Public 18Q2****\n",
    "\n",
    "Generated by running:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='segmented-cn-wes-prioritzed-7fe1', data.version=10, data.file='public_wes_priority_cn_gene_matrix') %>% log2()\n",
    "```\n",
    "\n",
    "**** Version 7 Public 18Q2****\n",
    "\n",
    "Generated by running:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='segmented-cn-wes-prioritzed-7fe1', data.version=11, data.file='public_wes_priority_cn_gene_matrix') %>% log2()\n",
    "```\n",
    "\n",
    "\n",
    "**** Version 8-9 Public 18Q3****\n",
    "\n",
    "Generated by running:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='segmented-cn-wes-prioritzed-7fe1', data.version=15, data.file='public_wes_priority_cn_gene_matrix') %>% log2()\n",
    "```\n",
    "Version 8 the segment level CN for Sanger's data is off by a factor of 2, version 9 corrects this\n",
    "\n",
    "includes cell lines that should not be public\n",
    "\n",
    "**** Version 10 Public 18Q1, 18Q2, 18Q3****\n",
    "\n",
    "__use version 10 for 18Q1, 18Q2 and 18Q3 datasets__ \n",
    "\n",
    "Version 10 is the most up-to-date version of \"public\\_18Q3\\_gene\\_cn.csv\". The three datasets have been updated to remove cell lines that should not have been made public. They are named in the portal and google bucket for portal downloads as v2, e.g. public\\_18Q3\\_gene\\_cn\\_v2.csv.\n",
    "\n",
    "__Rows__: Broad (arxspan) cell line IDs\n",
    "\n",
    "__Columns__: gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "\n",
    "**** Version 11 Public 18Q4****\n",
    "\n",
    "Generated by running:\n",
    "\n",
    "```\n",
    "wes_pri <- taigr::load.from.taiga(data.name='segmented-cn-wes-prioritzed-7fe1', data.version=17, data.file='public_wes_priority_cn_gene_matrix') %>% log2()\n",
    "```\n",
    "\n",
    "__Rows__: DepMap (arxspan) cell line IDs\n",
    "\n",
    "__Columns__: gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "\n",
    "**** Version 12-14 Public 19Q1****\n",
    "\n",
    "version 14 contains the correct data for 19Q1\n",
    "\n",
    "version 13 is the same as v12 except that it uses the original hg19 coordinates not hg38. The Achilles public data set uses the hg19 coordinates. \n",
    "\n",
    "**** Version 15-16 Public 19Q2****\n",
    "\n",
    "__version 16 also adds the segment level copy number data__\n",
    "\n",
    "**** Version 17-18 Public 19Q3****\n",
    "\n",
    "\n",
    "**** Version 23 Public 19Q4****\n",
    "adding new cell lines\n",
    "\n",
    "**** Version 24 Internal 19Q4****\n",
    "resolving problem with not having log2 transform \n",
    "\n",
    "**** Version 25 Internal 19Q4****\n",
    "another issue in log transform\n",
    "\n",
    "**** Version 26 Internal 19Q4****\n",
    "unlog2 transforming segmentcn FINAL\n",
    "\n",
    "**** Version 27 Internal 20Q1****\n",
    "adding new samples\n",
    "\n",
    "**** Version 28 Internal 20Q1****\n",
    "log 2 transform issues\n",
    "\n",
    "**** Version 29 Internal 20Q1****\n",
    "readding one missing column in segments\n",
    "\n",
    "**** Version 30 Internal 20Q2****\n",
    "Adding new samples\n",
    "\n",
    "**** Version 31 Internal 20Q2****\n",
    "unknown changes\n",
    "\n",
    "**** Version 32 Internal 20Q3****\n",
    "same  as  20Q2 for this release. no new lines\n",
    "\n",
    "**** Version 33 Internal 20Q3****\n",
    "updated blacklist\n",
    "\n",
    "## Gene level CN data:\n",
    "\n",
    "__data is hg38 liftover__\n",
    "\n",
    "__Description__: log2 + 1 gene level copy number data (data is log2 transformed with a __pseudocount of 1__ added). It uses hg19 coordinates. Also the segment level copy number data.\n",
    "\n",
    "__Rows__: DepMap cell line IDs\n",
    "\n",
    "__Columns__: gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "\n",
    "Segment level data:\n",
    "\n",
    "__Columns__: DepMap\\_ID, Chromosome, Start, End, Num\\_Probes, Segment\\_Mean, CCLE\\_name\n",
    "\n",
    "NEW LINES:\n",
    "\"\"\"+newlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CCLE_gene_cn', 'depmap-wes-cn-data-97cc.33/public_20Q3_gene_cn'), ('CCLE_segment_cn', 'depmap-wes-cn-data-97cc.33/public_20Q3_segs_cn'), ('CCLE_expression', 'depmap-rnaseq-expression-data-ccd0.22/public_20Q3_proteincoding_tpm'), ('CCLE_expression_full', 'depmap-rnaseq-expression-data-ccd0.22/public_20Q3_tpm'), ('CCLE_RNAseq_reads', 'depmap-rnaseq-expression-data-ccd0.22/public_20Q3_counts'), ('CCLE_mutations', 'depmap-mutation-calls-9a1a.19/depmap_20q3_mutation_calls'), ('CCLE_RNAseq_transcripts', 'depmap-rnaseq-expression-data-ccd0.22/public_20Q3_transcripts_tpm')]\n",
      "hitting https://cds.team/taiga/api/datafile/77c75977a31d42f68527c72b84e2f609\n",
      "hitting https://cds.team/taiga/api/datafile/77c75977a31d42f68527c72b84e2f609\n",
      "hitting https://cds.team/taiga/api/datafile/77c75977a31d42f68527c72b84e2f609\n",
      "hitting https://cds.team/taiga/api/datafile/77c75977a31d42f68527c72b84e2f609\n",
      "hitting https://cds.team/taiga/api/datafile/77c75977a31d42f68527c72b84e2f609\n",
      "hitting https://cds.team/taiga/api/datafile/77c75977a31d42f68527c72b84e2f609\n",
      "hitting https://cds.team/taiga/api/datafile/77c75977a31d42f68527c72b84e2f609\n",
      "hitting https://cds.team/taiga/api/datasetVersion\n",
      "\n",
      "Dataset version with id 0387a4ca28774411aa8c3ee274763579 created. You can access to this dataset version directly with this url: https://cds.team/taiga/dataset_version/0387a4ca28774411aa8c3ee274763579\n"
     ]
    }
   ],
   "source": [
    "# To add to a virtual dataset\n",
    "AddToVirtual(virtual_public, \"depmap-wes-cn-data-97cc\", files=[('CCLE_gene_cn', 'public_'+release+'_gene_cn'),('CCLE_segment_cn', 'public_'+release+'_segs_cn')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "313px",
    "width": "588px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230.788px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
