{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Number Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls gs://cclebams/wgs/G16427/Hep_G2/v1/Hep_G2.bam*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.CCLE_postp_function import *\n",
    "from genepy import terra\n",
    "from genepy.utils import helper as h\n",
    "from genepy.google import gcp\n",
    "from gsheets import Sheets\n",
    "from taigapy import TaigaClient\n",
    "import dalmatian as dm\n",
    "from genepy.google.google_sheet import dfToSheet\n",
    "\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "\n",
    "from bokeh.plotting import *\n",
    "from IPython.display import Image,display\n",
    "import seaborn as sns\n",
    "\n",
    "from biomart import BiomartServer\n",
    "import io\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext rpy2.ipython\n",
    "tc = TaigaClient()\n",
    "output_notebook()\n",
    "\n",
    "my_id = '~/.client_secret.json'\n",
    "mystorage_id = \"~/.storage.json\"\n",
    "# do the first steps of https://medium.com/craftsmenltd/from-csv-to-google-sheet-using-python-ef097cb014f9\n",
    "creds = '../.credentials.json'\n",
    "\n",
    "sheets = Sheets.from_files(my_id, mystorage_id)\n",
    "replace = {'T': 'Tumor', 'N': 'Normal', 'm': 'Unknown', 'L': 'Unknown'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boot up\n",
    "\n",
    "- you first need to go to [taiga](https://cds.team/taiga/dataset) and create some new datasets for the virtual release\n",
    "- the easiest way to create a new dataset is to upload an empty file (since at least one file is required). This empty file can be deleted when you update the dataset with a new version\n",
    "\n",
    "we are instanciating all the parameters needed for this pipeline to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesetname = \"21Q2\"\n",
    "\n",
    "refworkspace=\"broad-firecloud-ccle/DepMap_WES_CN_hg38\"\n",
    "genelist_hg38 = 'ftp://ftp.ncbi.nlm.nih.gov/pub/CCDS/current_human/CCDS.20180614.txt'\n",
    "\n",
    "refsheet_url = \"https://docs.google.com/spreadsheets/d/1Pgb5fIClGnErEqzxpU7qqX6ULpGTDjvzWwDN8XUJKIY\"\n",
    "sheeturl = \"https://docs.google.com/spreadsheets/d/115TUgA1t_mD32SnWAGpW9OKmJ2W5WYAOs3SuSdedpX4\"\n",
    "potential_list_url = \"https://docs.google.com/spreadsheets/d/1BEgH03V4OmGhYeciLCZV00h6hp3WkO0basahS93akCE\"\n",
    "\n",
    "CNWESmethods = [\n",
    "    \"gatk/PreProcessingForVariantDiscovery_GATK4/8\",\n",
    "    \"GP-TAG/Manta_SomaticSV/9\",\n",
    "    \"gkugener/ArrayOfFilesToTxt/1\",\n",
    "    \"vdauwera/BamToUnmappedRGBams/4\",\n",
    "    \"gatk/CNV_Somatic_Pair_Workflow/9\",\n",
    "    \"gkugener/Aggregate_CN_seg_files/2\"\n",
    "]\n",
    "\n",
    "#version 102\n",
    "ensemblserver = \"http://nov2020.archive.ensembl.org/biomart\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "release = samplesetname\n",
    "# we initialize the workspaces manager from dalmatian\n",
    "refwm = dm.WorkspaceManager(refworkspace)\n",
    "\n",
    "potential_list = sheets.get(potential_list_url).sheets[0].to_frame().values.T[0].tolist()\n",
    "\n",
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame(index_col=0)\n",
    "\n",
    "len(ccle_refsamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that we have all the cell lines we expect for this release\n",
    "\n",
    "This involves comparing to the list in the Google sheet \"Cell Line Profiling Status.\"\n",
    "\n",
    "_As the list cannot be parsed, we are not comparing it for now_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function may not work - it hasn't been tested\n",
    "url = 'https://docs.google.com/spreadsheets/d/1qus-9TKzqzwUMNWp8S1QP4s4-3SsMo2vuQRZrNXf7ag/edit?ts=5db85e27#gid=0&fvid=1627883727'\n",
    "\n",
    "compareToCuratedGS(url, sample = newsample[0], samplesetname = samplesetname, colname = 'CN New to internal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the pipeline\n",
    "\n",
    "We are using Dalmatian to send request to Terra, we are running a set of 5 functions To generate the copy number dataset:\n",
    "\n",
    "*   **BamToUnmappedRGBams_MC** vdauwera/BamToUnmappedRGBamsSnapshot ID: 3\n",
    "*   **Generate_uBAM_File_List** gkugener/ArrayOfFilesToTxtSnapshot ID: 1\n",
    "*   **Realign_WES_GATK4** gatk/PreProcessingForVariantDiscovery_GATK4Snapshot ID: 7\n",
    "*   **CNV_sample_XX** gatk/CNV_Somatic_Pair_WorkflowSnapshot ID: 9\n",
    "*   **Aggregate_CN_seg_files** gkugener/Aggregate_CN_seg_filesSnapshot ID: 2\n",
    "\n",
    "This output file for download will be saved under the sample set under the combined_seg_file attribute.\n",
    "\n",
    "There are several other tasks in this workspace. In brief:\n",
    "\n",
    "*   **CNV_Somatic_Panel_Workflow_Agilent_XX** gatk/CNV_Somatic_Panel_WorkflowSnapshot ID: 11. This task was used in this workspace to generate the Sanger PON. In the Sanger dataset, there is a set of 40 normal cell lines samples (cell lines derived from matched normal tissue). We can use these to generate a PON to normalize to rather than using the Agilent PON we use for the other CCLE cell lines. This leads to less noisy results. HOWEVER, results using the PON from this workflow should not use the X chromosome, as the sanger normals are not exclusively female or male (it is likely a mix).\n",
    "*   **SANGER_PON_CNV_sample_XX** gatk/CNV_Somatic_Pair_WorkflowSnapshot ID: 9. Same as the CNV_sample_XX_gatk, except that is uses the Sanger based PON. Should be used only for the Sanger cell lines.\n",
    "*   **Sanger_PON_Aggregate_CN_seg_files** gkugener/Aggregate_CN_seg_filesSnapshot ID: 2. Aggregates the segment files for the samples that were run using the Sanger PON based CNV workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torm = terra.listHeavyFiles(refworkspace)\n",
    "h.parrun(['gsutil rm '+i for i in torm], cores=8)\n",
    "terra.removeFromFailedWorkflows(refworkspace, dryrun=False, everythingFor=['Realign_WES_GATK4','Generate_uBAM_File_List','BamToUnmappedRGBams_MC','CGA_WES_CCLE_ICE','CGA_WES_CCLE_AGILENT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Terra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of Terra workflows that are in the workspace and that we will call sequentially\n",
    "bamtoubam= \"BamToUnmappedRGBams_MC\"\n",
    "ubamtofilelist = \"Generate_uBAM_File_List\"\n",
    "realign=\"Realign_WES_GATK4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see dalmatian\n",
    "subid = refwm.create_submission(bamtoubam,samplesetname,\"sample_set\",\"this.samples\")\n",
    "terra.waitForSubmission(refworkspace, subid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subid = refwm.create_submission(ubamtofilelist,samplesetname,\"sample_set\",\"this.samples\")\n",
    "terra.waitForSubmission(refworkspace, subid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subid = refwm.create_submission(realign,samplesetname,\"sample_set\",\"this.samples\")\n",
    "terra.waitForSubmission(refworkspace, subid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing out the XY PoN for CN characterization. Will test by producing an output in a different column from usual so it's easy to delete the column attribute later\n",
    "# Also, need to make a split between Agilent and ICE samples..\n",
    "submission_id= refwm.create_submission(\"CNV_sample_XY_ice\",etype='sample_set',entity=samplesetname, expression='this.samples')\n",
    "terra.waitForSubmission(refworkspace,submission_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy pairs data to sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = refwm.get_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairs[~pairs['called_copy_ratio_segments_tumor'].isna()]\n",
    "pairs = pairs.drop(columns=['case_sample','control_sample','participant'])\n",
    "pairs.index = [i.split('_')[0] for i in pairs.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refwm.update_sample_attributes(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id = refwm.create_submission(\"Aggregate_CN_seg_files\",entity=\"all\")\n",
    "terra.waitForSubmission(refworkspace,submission_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__we are getting the results file path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.waitForSubmission(refworkspace,submission_id)\n",
    "aggregated = refwm.get_entities('sample_set').loc['all'][\"combined_seg_file\"]\n",
    "aggregated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We then save the workflow configurations used__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.saveConfigs(refworkspace,'data/'+samplesetname+'/CNVconfig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__delete unmapped bams generated during the process__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toremove = [\"readgroup_ubams\",]\n",
    "res = refwm.get_samples()\n",
    "for val in toremove:\n",
    "    refwm.disable_hound().delete_entity_attributes('sample', res[val], delete_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes the previous step does not work and you need to do it manually (you can run this to check it worked)\n",
    "for val in samplesinset.readgroup_ubams:\n",
    "    ubams = ''\n",
    "    if not type(val) is list:\n",
    "        continue \n",
    "    for v in val:\n",
    "        ubams+=' '+v\n",
    "    os.system('gsutil -m rm'+ubams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__and move the hg38 aligned bams to our own datastorage bucket__\n",
    "\n",
    "Note that we may encounter some WGS files, which need to go to a different folder from the WES bam files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesetname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samplesinset = samples.index.tolist()\n",
    "samplesinset= [i['entityName'] for i in refwm.get_entities('sample_set').loc[samplesetname].samples]\n",
    "samplesinset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlycol = ['hg38_analysis_ready_bam', 'hg38_analysis_ready_bam_index', 'hg38_analysis_ready_bam_md5']\n",
    "wes_newgs = 'gs://cclebams/hg38_wes/'\n",
    "wes_res, flagged = terra.changeGSlocation(refworkspace, newgs=wes_newgs, onlysamples=samplesinset, onlycol=onlycol, entity='sample', keeppath=False, dry_run = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set it this way in our sample tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame(index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples.loc[samplesinset,['legacy_bam_filepath','legacy_bai_filepath', 'legacy_size', 'legacy_crc32c_hash']] = ccle_refsamples.loc[samplesinset][['internal_bam_filepath', 'internal_bai_filepath', 'size', 'crc32c_hash']].values\n",
    "\n",
    "ccle_refsamples.loc[samplesinset,'internal_bam_filepath'] = wes_res['hg38_analysis_ready_bam'].values\n",
    "\n",
    "ccle_refsamples.loc[samplesinset,'internal_bai_filepath'] = wes_res['hg38_analysis_ready_bam_index'].values\n",
    "\n",
    "ccle_refsamples.loc[wes_res.index.tolist(),'size'] = [gcp.extractSize(i)[1] for i in gcp.lsFiles(wes_res['hg38_analysis_ready_bam'].tolist(),'-l')]\n",
    "\n",
    "ccle_refsamples.loc[wes_res.index.tolist(),'crc32c_hash'] = [gcp.extractHash(i) for i in gcp.lsFiles(wes_res['hg38_analysis_ready_bam'].tolist(),'-L')]\n",
    "\n",
    "ccle_refsamples.loc[wes_res.index.tolist(),'md5_hash'] = gcp.catFiles(wes_res['hg38_analysis_ready_bam_md5'].tolist(), cut=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToSheet(ccle_refsamples,'ccle sample tracker', secret=creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get QC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataBam = getQC(workspace=refworkspace ,only=samplesinset, qcname=[\"hg38_duplication_metrics\",\"hg38_bqsr_report\"])\n",
    "dataCN = getQC(workspace=refworkspace ,only=samplesinset, qcname=[\"allelic_counts_tumor\",\"delta_MAD_tumor\",\"denoised_MAD_tumor\",\"scaled_delta_MAD_tumor\",\"denoised_copy_ratios_lim_4_plot_tumor\",\"denoised_copy_ratios_plot_tumor\",\"modeled_segments_plot_tumor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dataCN.items():\n",
    "    if k =='nan':\n",
    "        continue\n",
    "    ccle_refsamples.loc[k,'processing_qc'] = str(v)\n",
    "for k,v in dataBam.items():\n",
    "    if k =='nan':\n",
    "        continue\n",
    "    ccle_refsamples.loc[k,'bam_qc'] = str(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToSheet(ccle_refsamples,'ccle sample tracker', secret=creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We download and reprocess removing the appended version and keeping only the newest versions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil cp $aggregated \"temp/cnv_ccle.called.seg\"\n",
    "segments = pd.read_csv(\"temp/cnv_ccle.called.seg\", sep='\\t')\n",
    "segments = segments.rename(columns={'CONTIG':'Chromosome',\n",
    "'START':'Start',\n",
    "'END':'End',\n",
    "'Sample':\"DepMap_ID\",\n",
    "'NUM_POINTS_COPY_RATIO':'Num_Probes',\n",
    "'MEAN_LOG2_COPY_RATIO':'Segment_Mean',\n",
    "'CALL':'Status'})\n",
    "# TODO: copy allelic calls as well\n",
    "len(set(segments.Sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = segments[~segments.DepMap_ID.isin(wrongswes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrongswes = {'CDS-8Ut3sT','CDS-Ip02tY','CDS-Rd4nMx','CDS-TGTiB8','CDS-VnMBYD','CDS-YSRYLi','CDS-ZJh6UN','CDS-dgxjAa','CDS-0aJ4Yh','CDS-0lfqVz','CDS-0pZb0j','CDS-1b1Hxk','CDS-1djAlo','CDS-1p2nnc','CDS-34hKv3','CDS-3EBt51','CDS-3M6Pq9','CDS-3WygAj','CDS-49azaP','CDS-4sr6RL','CDS-5rD8XC','CDS-5wYxZS','CDS-6Yy3Yj','CDS-6da3hu','CDS-6l3V79','CDS-7PFldq','CDS-9XPgHB','CDS-9qDPiX','CDS-B0qAaq','CDS-CMenCH','CDS-CuJ0f8','CDS-Dkl8OF','CDS-Eq9UNX','CDS-FRxdcH','CDS-HNytLD','CDS-Hj3xAa','CDS-IJnjkY','CDS-Ig6N9S','CDS-KQDgIV','CDS-KYkMDa','CDS-KbbgMb','CDS-KgRznV','CDS-L0pDPl','CDS-M8xDMS','CDS-MLJbT2','CDS-MnF3x8','CDS-OCkOqy','CDS-ODmXrP','CDS-OgPf0h','CDS-PYw8ID','CDS-PdUZxY','CDS-QHp4h4','CDS-QU7ftt','CDS-QVhVDT','CDS-QXBhht','CDS-SJq3p4','CDS-Sp18uD','CDS-TpDBjm','CDS-TyWjJs','CDS-UV1pVE','CDS-UnDaBI','CDS-UtrDTK','CDS-W80jkV','CDS-WedVJA','CDS-WfjTcJ','CDS-X3c4UY','CDS-XQkXf4','CDS-XevQNc','CDS-YMIv9D','CDS-YYLKZ0','CDS-agZcmk','CDS-bntBUl','CDS-cAEii6','CDS-cYWYp7','CDS-cyuMYb','CDS-d18Xie','CDS-dpub1O','CDS-eUqT7L','CDS-eowEZF','CDS-fXMRF9','CDS-gIMBax','CDS-gRA4SM','CDS-iEULQm','CDS-ihI7Dp','CDS-iqPqOr','CDS-jqOvtj','CDS-kxNZ5S','CDS-leGxSD','CDS-nby0QM','CDS-no7ysz','CDS-o4dXGr','CDS-oHu1Ik','CDS-pXMN9C','CDS-picEuX','CDS-qZsCuJ','CDS-rLRUbG','CDS-txTRwz','CDS-uQ8nnX','CDS-yPSmxb''CDS-0qPmaJ','CDS-1PXzlf','CDS-1uWUTi','CDS-294bk6','CDS-2JxT1P','CDS-2LFZYm','CDS-2Q2Kia','CDS-2hGt1N','CDS-2lAFkD','CDS-2xSJmZ','CDS-3DHwSX','CDS-3FueNQ','CDS-3VNhFC','CDS-3jIdRa','CDS-3mvYnW','CDS-3pZIvU','CDS-49xzNU','CDS-4BrJr7','CDS-4S6juQ','CDS-4ZOQQF','CDS-4l9BUT','CDS-5H2go6','CDS-5IcijG','CDS-5LNjjI','CDS-5PXB9Y','CDS-5ViPeM','CDS-5bQzF2','CDS-5hbofu','CDS-6EyvRQ','CDS-6Fc0S5','CDS-6PZKz8','CDS-6mq2Or','CDS-6xyqy9','CDS-75psAH','CDS-7JWzyA','CDS-7nEZFG','CDS-7rcFYn','CDS-83LhEq','CDS-8aHSii','CDS-8mpXJa','CDS-8sQWae','CDS-8yHnJv','CDS-8z476r','CDS-96DdrP','CDS-9JpX07','CDS-9M8GNS','CDS-9sg0Pm','CDS-9u5DMn','CDS-9zidMf','CDS-AJMYsd','CDS-AOWMF3','CDS-AjRIMt','CDS-Awmxa5','CDS-BRxHbu','CDS-BnszE4','CDS-Bojgi7','CDS-C3hSav','CDS-C7o0op','CDS-CRPZeK','CDS-CZstO2','CDS-D6mIfI','CDS-DIckeT','CDS-DZMoWW','CDS-Eh7ost','CDS-Eo5oAR','CDS-EpURcL','CDS-EzZEgz','CDS-Fz0HXE','CDS-G1sVsw','CDS-GINQfy','CDS-GnBdHN','CDS-H1oKTL','CDS-H4hPhD','CDS-HEoDm7','CDS-HOVBCg','CDS-HjGCvC','CDS-HkZUmY','CDS-HoW111','CDS-Hv0i3y','CDS-Hw6KuA','CDS-Hx6zuD','CDS-I7bMcd','CDS-I97Uzq','CDS-IGOgCK','CDS-Iu8c04','CDS-IzeN7a','CDS-J3jfZW','CDS-J6kDsZ','CDS-JMfP1M','CDS-JvOeJK','CDS-K2tTmq','CDS-Kswf83','CDS-LCfY0q','CDS-LNTGnh','CDS-LOW19e','CDS-LUm1Vn','CDS-LVeuLY','CDS-LifesX','CDS-LnV7QY','CDS-M1sAGX','CDS-M8aV3P','CDS-MOOIHL','CDS-Md89va','CDS-MhXQX3','CDS-N83rwD','CDS-NBnCDl','CDS-NPG23x','CDS-NXnWiI','CDS-NZsio7','CDS-NjunRu','CDS-O1ShTQ','CDS-O8dfj7','CDS-OLgoE4','CDS-OWJaXi','CDS-OjLMVy','CDS-OnIxUL','CDS-OxQgBw','CDS-P79y6z','CDS-PHI8VT','CDS-PYWxsh','CDS-Pkk9e2','CDS-Pku96X','CDS-PyELSk','CDS-QE7bdY','CDS-Qbfoau','CDS-Ql8GJZ','CDS-QtTdY6','CDS-QxeMJW','CDS-R3txwY','CDS-R6ehaT','CDS-RFBAY6','CDS-RWYJ02','CDS-RnsUHX','CDS-RxQhcq','CDS-SO3AhH','CDS-SvzhGj','CDS-T10Uph','CDS-TCqSJW','CDS-TDblpN','CDS-TSDUCK','CDS-Twv1kD','CDS-Ty3mgt','CDS-UL1jLm','CDS-UVxUrF','CDS-UfC2Dz','CDS-Uru0Mh','CDS-UvBswk','CDS-UxKEaK','CDS-V2ZEuP','CDS-V6Kk5q','CDS-VBr00g','CDS-VCuHjJ','CDS-WAPQGk','CDS-WHZolj','CDS-WP95Oi','CDS-Ww1LC7','CDS-XJDBDj','CDS-Xgu4mi','CDS-XqaEOX','CDS-Y27yfi','CDS-YYd4ww','CDS-YnodyM','CDS-ZGlgTf','CDS-ZMsoXe','CDS-aDUHcI','CDS-aGMcvr','CDS-aXqwpM','CDS-allHxr','CDS-awunD8','CDS-b9sdh9','CDS-bPT1F0','CDS-bdb5iE','CDS-bons31','CDS-c2Sowd','CDS-cBOy2Z','CDS-cKMeDY','CDS-cMvnjL','CDS-ck9vpG','CDS-cmV75B','CDS-ctVpqU','CDS-dJqQ4g','CDS-dNVjOc','CDS-dPlJzz','CDS-dWHWU3','CDS-eGQYXr','CDS-eZg4P8','CDS-fLsYaB','CDS-fRpNQH','CDS-frzvLf','CDS-fs8moU','CDS-g0KUGN','CDS-gCSYjV','CDS-gKIdjs','CDS-gsqqAz','CDS-h4mOdz','CDS-hOI086','CDS-iKXYuH','CDS-iRstNJ','CDS-iX8vqU','CDS-ik526H','CDS-jHqXGP','CDS-kAARUi','CDS-kFiHZk','CDS-kt2Gne','CDS-ktRRkc','CDS-l1OClV','CDS-lSpYo6','CDS-lTogDX','CDS-ldrQm3','CDS-leyYAD','CDS-loy9vi','CDS-m49nRz','CDS-mGHY2S','CDS-mazUYU','CDS-mtMTts','CDS-n7Fqfe','CDS-nOKbmw','CDS-nTW67d','CDS-nYIBWR','CDS-ocw0rP','CDS-ogUnWk','CDS-ohjYlg','CDS-opnGD7','CDS-qIc5x3','CDS-qP2MBQ','CDS-qUtkjN','CDS-qaOoHQ','CDS-qeIIoY','CDS-qv2bpJ','CDS-r5Ym7C','CDS-rLadW7','CDS-rQIdNN','CDS-rQMY3G','CDS-rUs3FP','CDS-rVAuin','CDS-ragHOy','CDS-s7pOQR','CDS-sCWLGL','CDS-sbwn0P','CDS-sieIuO','CDS-soTPPi','CDS-tORJC8','CDS-tPR3fn','CDS-tYXity','CDS-tgnRyK','CDS-u1AlUI','CDS-uGZguG','CDS-w7i5l7','CDS-w8wJvh','CDS-wSV3OM','CDS-wWwBMZ','CDS-wbPtTZ','CDS-wlTAAF','CDS-wpXVQk','CDS-x21VqU','CDS-x7srFK','CDS-xCyamv','CDS-xI8ZAZ','CDS-xIv1KJ','CDS-xKNh7Q','CDS-yCSYHi','CDS-ycD9px','CDS-ydPJEM','CDS-z8Bvmk','CDS-ziEOXJ','CDS-zwAn7G'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priorization\n",
    "\n",
    "add columns to seg file with arxspan ID, version. only keep the newest version for any given arxspan ID.\n",
    "The process to keep the newest version of any given line is a little different from 20Q2 onwards, because don't have any dataset that uses the CDS-IDs for the data from 20Q1 or earlier.\n",
    "\n",
    "We have to download the Taiga datasets from the previous quarter, see if we have any arxspan IDs with new data, and then replace with that data. We use the function called \"removeOlderVersions\" to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming = removeOlderVersions(names=set(segments.DepMap_ID.tolist()), refsamples=ccle_refsamples[ccle_refsamples.datatype==\"wes\"], arxspan_id=\"arxspan_id\", version=\"version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## post Procesing\n",
    "\n",
    "The post processing happens in R using guillaume's functions, in brief:\n",
    "\n",
    "- processSegments\n",
    "- filterForCCLE\n",
    "- interpolateGapsInSegmented\n",
    "- extendEndsOfSegments\n",
    "- reprioritizeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notWESnotlegacy = notWES - set(legacy_segments.DepMap_ID)\n",
    "%store notWESnotlegacy\n",
    "notWESnotlegacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = BiomartServer(ensemblserver)\n",
    "ensmbl = server.datasets['hsapiens_gene_ensembl']\n",
    "server.show_databases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = BiomartServer( \"http://www.nov2020.archive.ensembl.org/biomart\" )\n",
    "ensmbl = server.datasets['hsapiens_gene_ensembl']\n",
    "server.show_databases()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genemapping[genemapping.gene_biotype==\"protein_coding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments['Chromosome'] = [i[3:] for i in segments['Chromosome'].tolist()]\n",
    "# reverting logtransform of GTK\n",
    "segments.Segment_Mean = 2**segments.Segment_Mean\n",
    "segments.Start = segments.Start.astype(int)\n",
    "segments.End = segments.End.astype(int)\n",
    "# setting sex genes to half of their value for it to match relative concentration of other genes.\n",
    "segments.loc[segments[segments.Chromosome.isin(['X','Y'])].index,'Segment_Mean'] = segments[segments.Chromosome.isin(['X','Y'])]['Segment_Mean']/2\n",
    "segments = segments.sort_values(by=['DepMap_ID','Chromosome','Start','End'])\n",
    "genemapping = genemapping.sort_values(by=['Chromosome','start','end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check on IGV maxvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation step\n",
    "\n",
    "Once the files are saved, we load them back in python and do some validations, in brief:\n",
    "\n",
    "- mean,max,var...\n",
    "- to previous version: same mean,max,var...\n",
    "- checkAmountOfSegments: flag any samples with a very high number of segments\n",
    "- checkGeneChangeAccrossAll: flag any genes which stay at a similar value across all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(segments[segments.Segment_Mean>1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapmergedsegs = manageGapsInSegments(segments)\n",
    "genecn = toGeneMatrix(gapmergedsegs, gene_mapping)\n",
    "checkGeneChangeAccrossAll(genecn, thresh=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genecn.values.min(), genecn.values.mean(), genecn.values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = checkAmountOfSegments(segments,thresh = 2000)\n",
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reparing QC when we have a better duplicate\n",
    "ref=pd.DataFrame(ccle_refsamples[ccle_refsamples.datatype==\"wes\"]['arxspan_id'])\n",
    "replace={}\n",
    "for val in failed:\n",
    "    if val in list(renaming.keys()):\n",
    "        a = ref[ref.arxspan_id==ref.loc[val].arxspan_id].index\n",
    "        for v in a:\n",
    "            if v not in failed:\n",
    "                replace.update({val:v})\n",
    "                break\n",
    "print(len(replace), len(failed))\n",
    "for k, val in replace.items():\n",
    "    renaming[val] = renaming.pop(k)\n",
    "wesfailed = set(failed) - set(replace.keys())\n",
    "%store wesfailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r wesfailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (k, val) in enumerate(refwm.get_samples().loc[refwm.get_sample_sets().loc[\"all\"].samples].iterrows()):\n",
    "    if i>100:\n",
    "        continue\n",
    "    plot = val[\"modeled_segments_plot_tumor\"]\n",
    "    ! gsutil cp $plot temp/\n",
    "    print(k)\n",
    "    print(val['arxspan_id'], val['sex'])\n",
    "    display(Image('temp/'+plot.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look bad in 20Q1: \n",
    "ACH-002511 (M140325), ACH-001370 (OCIP5X)\n",
    "\n",
    "These CN plots subjectively appear to have too many segments in new 20Q2 samples: \n",
    "ACH-002399 (CDS-sukIAT, 21NT_1), ACH-002401 (CDS-tVy3GF, 21MT2_1), ACH-002400 (CDS-VUHMHG, 21MT1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevgenecn = tc.get(name='internal-20q3-00d0', file='CCLE_gene_cn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the previous versions to check that we have everything we should\n",
    "#prevgenecn = tc.get(name='depmap-a0ab', file='CCLE_gene_cn')\n",
    "prevgenecn = tc.get(name='internal-20q3-00d0', file='CCLE_gene_cn')\n",
    "\n",
    "prevsegments = tc.get(name='depmap-a0ab', file='CCLE_segment_cn')\n",
    "prev = set(prevgenecn.index.tolist())\n",
    "prevgenecn.max().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to replicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding missmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest = findClosestMatching(genecn, CCLE_gene_cn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each replicats, if it is not what it is supposed to be, will print other replicates that exist for this cell lines, and print what it seems to be vs what it is supposed to be\n",
    "issues = []\n",
    "for k,v in closest.items():\n",
    "    if ccle_refsamples.loc[k,'arxspan_id'] != v:\n",
    "        print(k)\n",
    "        print(ccle_refsamples[(ccle_refsamples.index!=k) & (ccle_refsamples.arxspan_id==v) & (ccle_refsamples.datatype=='wes')].index)\n",
    "        print(v,ccle_refsamples.loc[k,'arxspan_id'])\n",
    "        issues.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match, corr =findClosestMatching(genecn, prevgenecn.loc[['ACH-000123',]], True, returncorr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = changeCellLineName(ccle_refsamples, datatype = \"wes\", dupdict={\n",
    "'CDS-b5ElTm': \"ACH-000157\", \n",
    "\"CDS-up4Vo5\": \"ACH-000662\",\n",
    "\"CDS-CWA37D\": \"ACH-000825\", \n",
    "\"CDS-CCAK2f\": \"ACH-001328\",\n",
    "\"CDS-2jBQ8n\": \"ACH-000757\",\n",
    "\"CDS-T8W6P4\": \"ACH-000398\",\n",
    "\"CDS-9TDVpH\": \"ACH-000685\",\n",
    "\"CDS-dQKiht\": \"ACH-000375\",\n",
    "\"CDS-Ckptje\": \"ACH-002291\",\n",
    "\"CDS-ljFuDX\": \"ACH-001339\",\n",
    "\"CDS-5x4qLj\": \"ACH-000608\",\n",
    "\"CDS-UxJcOY\": \"ACH-000561\",\n",
    "\"CDS-TUYedU\": \"ACH-000261\",\n",
    "\"CDS-RLVrVE\": \"ACH-001523\",\n",
    "\"CDS-6liik0\": \"ACH-000561\",\n",
    "\"CDS-b5ElTm\": \"ACH-000157\",\n",
    "\"CDS-u9hZ60\": \"ACH-000077\",\n",
    "\"CDS-NUlX3d\": \"ACH-000458\",\n",
    "\"CDS-2HO10g\": \"ACH-000278\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = cleanVersions(ccle_refsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iss=[]\n",
    "for k,v in corr.iterrows():\n",
    "    print(k, v.mean())\n",
    "    try:\n",
    "        if v[ccle_refsamples.loc[k,'arxspan_id']] < 0.75:\n",
    "            print(v[[closest[k],ccle_refsamples.loc[k,'arxspan_id']]])\n",
    "            continue\n",
    "    except:\n",
    "        a = np.argsort(v.values)[-5:]   \n",
    "        if  v.values[a[-1]]>0.8:\n",
    "            print(ccle_refsamples.loc[k,'arxspan_id'], corr.columns[a], v.values[a])\n",
    "            continue\n",
    "    iss.append(k)\n",
    "issues = iss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iss=[]\n",
    "for val in issues:\n",
    "    if val in renaming:\n",
    "        v = ccle_refsamples.loc[val,'arxspan_id']\n",
    "        a = ccle_refsamples[(ccle_refsamples.index!=val) & (ccle_refsamples.arxspan_id==v) & (ccle_refsamples.datatype=='wes')].index.tolist()\n",
    "        a = [e for e in a if e not in issues]\n",
    "        if len(a)>0:\n",
    "            a[0] = renaming.pop(val)\n",
    "        else:\n",
    "            iss.append(val)\n",
    "issues = iss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store issues\n",
    "issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevgenecn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = {k: v for k,v in ccle_refsamples[ccle_refsamples.index.isin(set(genecn.index))]['arxspan_id'].iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge = np.log2(1+genecn[cols])\n",
    "ce = CCLE_gene_cn[cols]\n",
    "prev = ce.index.tolist()\n",
    "corr={val: {} for val in set(prev) & set(CCLE_gene_cn.index)}\n",
    "for k,v in lis.items():\n",
    "    if v in prev:\n",
    "        corr[v][k] = spearmanr(ge.loc[k],ce.loc[v])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomerge=[]\n",
    "for k,v in corr.items():\n",
    "    a = []\n",
    "    for i in h.dups(v.values()):\n",
    "        for l,w in v.items():\n",
    "            if w == i:\n",
    "                a.append(l)\n",
    "    if len(a)>1:\n",
    "        tomerge.append(a)\n",
    "len(tomerge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments[segments.DepMap_ID==\"CDS-A7rsOJ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerenaming['ACH-002359']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in corr.items():\n",
    "    if v<0.7:\n",
    "        print(k)\n",
    "        print(set(priosegments[priosegments.DepMap_ID==k].Source), set(prevsegments[prevsegments.DepMap_ID==k].Source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wesdup= np.array(tomerge)\n",
    "%store wesdup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp.rmFiles(ccle_refsamples[ccle_refsamples.index.isin(np.array(tomerge)[:,1])][['internal_bam_filepath', 'internal_bai_filepath', 'legacy_bam_filepath', 'legacy_bai_filepath']].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace in the renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame(index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = ccle_refsamples.drop(np.array(tomerge)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = cleanVersions(ccle_refsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfToSheet(ccle_refsamples,'ccle sample tracker', secret=creds)\n",
    "copyToWorkspace(\"broad-firecloud-ccle/DepMap_WES_CN_hg38\", ccle_refsamples, deleteUnmatched=True)\n",
    "copyToWorkspace(\"broad-firecloud-ccle/DepMap_Mutation_Calling_CGA_pipeline\", ccle_refsamples, deleteUnmatched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wesfailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = segments[~segments.DepMap_ID.isin(set(wesfailed) | set(wesdup[:,1]))]\n",
    "genecn = genecn[~genecn.index.isin(set(wesfailed) | set(wesdup[:,1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in set(segments.DepMap_ID):\n",
    "    segments.loc[segments[segments.DepMap_ID==v].index,'Source']= ccle_refsamples[ccle_refsamples.index==v].source.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments.Source = segments.Source.replace({'CCLF':'Broad WES', 'CHORDOMA':'Chordoma WES', 'SANGER':'Sanger WES', 'IBM':'Broad WES', np.nan:'Broad WES', 'DEPMAP':'Broad WES', 'IBM WES': \"Broad WES\", 'Broad CCLF':\"Broad WES\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments.to_csv('temp/segments_allWES_withreplicates_'+samplesetname+'.csv', index=False)\n",
    "genecn.to_csv('temp/gene_cn_allWES_withreplicates_'+samplesetname+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(set(renaming.keys()) - set(segments.DepMap_ID)) - wesfailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = pd.read_csv('temp/segments_allWES_withreplicates_'+samplesetname+'.csv')\n",
    "genecn = pd.read_csv('temp/gene_cn_allWES_withreplicates_'+samplesetname+\".csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to prioritized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the other version if necessary, because the other on needs to be removed\n",
    "for val in wesdup:\n",
    "    if val[1] in renaming:\n",
    "        renaming[val[0]] = renaming.pop(val[1])\n",
    "        \n",
    "# getting another version that did not fail\n",
    "for val in wesfailed:\n",
    "    v = ccle_refsamples[(ccle_refsamples.arxspan_id == ccle_refsamples.loc[val].arxspan_id[0]) & (ccle_refsamples.datatype=='wes')].index\n",
    "    if len(v)>1:\n",
    "        for k in v:\n",
    "            if k != val:\n",
    "                renaming[k] = renaming.pop(val)\n",
    "    else:\n",
    "        try:\n",
    "            renaming.pop(val)\n",
    "        except:\n",
    "            print('already removed')\n",
    "%store renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([\"ACH-000274\",\n",
    "\"ACH-002446\",\n",
    "\"ACH-000833\",\n",
    "\"ACH-001151\",\n",
    "\"ACH-001955\",\n",
    "\"ACH-000757\",\n",
    "\"ACH-000511\",\n",
    "\"ACH-001321\",\n",
    "\"ACH-000473\",\n",
    "\"ACH-001605\",\n",
    "\"ACH-001957\"]) - set(priosegments.DepMap_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming.update({\"CDS-Ckptje\": \"ACH-001672\",\n",
    "\"CDS-pgDmZb\": \"ACH-002291\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priosegments = segments[segments.DepMap_ID.isin(set(renaming.keys()))].replace(renaming)\n",
    "priogenecn = genecn[genecn.index.isin(set(renaming.keys()))].rename(index=renaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = set(priogenecn.columns) & set(CCLE_gene_cn.columns)\n",
    "ge = np.log2(1+priogenecn[cols])\n",
    "ce = CCLE_gene_cn[cols]\n",
    "ind = set(priogenecn.index) & set(CCLE_gene_cn.index)\n",
    "corr={}\n",
    "for val in ind:\n",
    "    corr[val] = pearsonr(ge.loc[val],ce.loc[val])[0]\n",
    "for k,v in corr.items():\n",
    "    if v<0.3:\n",
    "        print(k)\n",
    "        print(set(priosegments[priosegments.DepMap_ID==k].Source), set(prevsegments[prevsegments.DepMap_ID==k].Source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in corr.items():\n",
    "    if v<0.3:\n",
    "        print(k)\n",
    "        print(set(priosegments[priosegments.DepMap_ID==k].Source), set(CCLE_segment_cn[CCLE_segment_cn.DepMap_ID==k].Source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(list(corr.values()))\n",
    "sns.kdeplot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=ge.loc[ind].values.ravel()[:100000],y=ce.loc[ind].values.ravel()[:100000],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=np.array([ge.loc[ind].values.ravel()[:100000], ce.loc[ind].values.ravel()[:100000]]).T, fill=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving prioritizd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame(index_col=0)\n",
    "normals = ccle_refsamples[ccle_refsamples['primary_disease']=='normal'].index.tolist()\n",
    "#priosegments = priosegments[~priosegments.DepMap_ID.isin(normals)]\n",
    "#priogenecn = priogenecn.drop(index=normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h.compareDfs(priosegments, tc.get(name='depmap-a0ab', file='CCLE_segment_cn'))\n",
    "h.compareDfs(priogenecn, tc.get(name='depmap-a0ab', file='CCLE_gene_cn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priosegments.to_csv(\"temp/segments_allWES_latest_\"+samplesetname+\".csv\", index=False)\n",
    "priogenecn.to_csv('temp/gene_cn_allWES_latest_'+samplesetname+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priosegments= pd.read_csv(\"temp/segments_allWES_latest_\"+samplesetname+\".csv\")\n",
    "priogenecn = pd.read_csv('temp/gene_cn_allWES_latest_'+samplesetname+\".csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking for correlation issues to previous releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(priogenecn.columns) & set(prevgenecn.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.corrcoef(priogenecn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = priogenecn.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [(ind[val[0]], ind[val[1]]) for val in np.argwhere(corr>0.96) if val[0]!=val[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['ACH-000131','ACH-000125','ACH-001093','ACH-000284','ACH-000340', 'ACH-000214', 'ACH-001767','ACH-000240','ACH-000154','ACH-000063','ACH-000165']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[val for val in a if val[1] not in ['ACH-000131','ACH-000125','ACH-001093','ACH-000284','ACH-000340', 'ACH-000214', 'ACH-001767','ACH-000240','ACH-000154','ACH-000063','ACH-000165']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving samples version used for the release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame(index_col=0)\n",
    "loc = set(wes_res.index) & set(ccle_refsamples.index)\n",
    "for i in ccle_refsamples.columns[-14:-1]:\n",
    "    ccle_refsamples.loc[loc,i] = 0\n",
    "ccle_refsamples[samplesetname]=0\n",
    "ccle_refsamples.loc[renaming.keys(),samplesetname]=1\n",
    "ccle_refsamples.loc[failed,'low_quality']=1\n",
    "dfToSheet(ccle_refsamples,'ccle sample tracker', secret=creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to taiga\n",
    "\n",
    "- we load the blacklisted/embargoed sample ids\n",
    "- we log2 transform and create a file for each release (and one containing everything)\n",
    "- we upload the files using taigapy in a corresponding taiga dataset with the corresponding description and also upload it to its virtual dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we push full dataset version in depmap taiga CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.update_dataset(dataset_permaname=\"cn-latest-d8d4\", \n",
    "                  upload_file_path_dict={\n",
    "    'temp/segments_allWES_latest_'+samplesetname+'.csv': 'TableCSV',\n",
    "    'temp/gene_cn_allWES_latest_'+samplesetname+\".csv\": 'NumericMatrixCSV',\n",
    "    'temp/segments_allWES_withreplicates_'+samplesetname+'.csv': 'TableCSV',\n",
    "    'temp/gene_cn_allWES_withreplicates_'+samplesetname+\".csv\": 'NumericMatrixCSV',\n",
    "    'temp/gene_cn_all_merged_'+samplesetname+\".csv\":\"NumericMatrixCSV\",\n",
    "    'temp/segments_allWGS_withreplicates_'+samplesetname+\".csv\":\"TableCSV\",\n",
    "    'temp/gene_cn_allWGS_withreplicates_'+samplesetname+\".csv\":\"NumericMatrixCSV\"},\n",
    "                  changes_description=\n",
    "\"\"\"\n",
    "\"\"\",\n",
    "#\"adding:\"+len(new)+\"lines and removed\"+str(removed)+\" and adding WGS data! with 29 new lines\",\n",
    "                  dataset_description=\"\"\"\n",
    "# Copy Number\n",
    "\n",
    "PORTAL TEAM SHOULD NOT USE THIS: There are lines here that should not make it even to internal.\n",
    "\n",
    "/!\\ This is the most up to date version of the CCLE CN data.\n",
    "\n",
    "# Notations:\n",
    "\n",
    "all: everything\n",
    "\n",
    "allWES: all data comes from the WExomeS samples we posses\n",
    "\n",
    "allWGS: all data comes from the WGenomeS samples we posses\n",
    "\n",
    "withreplicates: if we have two different sequencing from a sample, we kept both, see the depmap sample tracker for annotations [https://docs.google.com/spreadsheets/d/1XkZypRuOEXzNLxVk9EOHeWRE98Z8_DBvL4PovyM01FE](https://docs.google.com/spreadsheets/d/1XkZypRuOEXzNLxVk9EOHeWRE98Z8_DBvL4PovyM01FE). this dataset is more geared toward QC or in-depth analysis of a particular cell line.\n",
    "\n",
    "merged: everything from both WGS and WES\n",
    "\n",
    "latest: only the latest sequencing versions of the samples were kept\n",
    "\n",
    "\n",
    "Gene level CN data:\n",
    "\n",
    "__Rows__: cell line IDs\n",
    "\n",
    "__Columns__: gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "\n",
    "Segment level data:\n",
    "\n",
    "__Columns__: DepMap\\_ID, Chromosome, Start, End, Segment\\_Mean, Num\\_Probes, Calls\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "313px",
    "width": "588px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230.788px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
