{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T14:11:36.220106Z",
     "start_time": "2021-03-15T14:11:36.175873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1002\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.4.min.js\"];\n",
       "  var css_urls = [];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1002\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.4.min.js\"];\n  var css_urls = [];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src import tracker, rna, terra, loading\n",
    "\n",
    "from genepy import terra\n",
    "from genepy.utils import helper as h\n",
    "from genepy.google import gcp\n",
    "from genepy import rna\n",
    "\n",
    "from genepy.google.google_sheet import dfToSheet\n",
    "from gsheets import Sheets\n",
    "\n",
    "from taigapy import TaigaClient\n",
    "import dalmatian as dm\n",
    "\n",
    "from bokeh.plotting import output_notebook\n",
    "\n",
    "from biomart import BiomartServer\n",
    "import io\n",
    "\n",
    "from IPython.display import Image,display\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "tc = TaigaClient()\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "immutable parameters (user specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:27:10.018737Z",
     "start_time": "2021-03-17T14:27:09.989726Z"
    }
   },
   "outputs": [],
   "source": [
    "samplesetname=\"21Q2\"\n",
    "# current age at which to consider the sample already loaded in previous release\n",
    "maxage='2020-11-01'\n",
    "\n",
    "my_id = '~/.client_secret.json'\n",
    "mystorage_id = \"~/.storage.json\"\n",
    "# do the first steps of https://medium.com/craftsmenltd/from-csv-to-google-sheet-using-python-ef097cb014f9\n",
    "creds = '../.credentials.json'\n",
    "\n",
    "sheets = Sheets.from_files(my_id, mystorage_id)\n",
    "\n",
    "\n",
    "# GP storage buckets\n",
    "#workspace2=\"broad-firecloud-ccle/CCLE_DepMap_RNAseq\"\n",
    "#workspace4=\"broad-genomics-delivery/Cancer_Cell_Line_Factory_CCLF_RNAseq\"\n",
    "#workspace5=\"nci-mimoun-bi-org/CCLF_RNA_2_0\"\n",
    "\n",
    "#workspace3=\"broad-genomics-delivery/CCLE_DepMap_RNAseq\"\n",
    "#workspace1=\"broad-genomics-delivery/Getz_IBM_CellLines_RNASeqData\"\n",
    "\n",
    "workspace6=\"terra-broad-cancer-prod/CCLE_DepMap_RNAseq\"\n",
    "workspace7=\"terra-broad-cancer-prod/Getz_IBM_CellLines_RNASeqData\"\n",
    "\n",
    "# and their correesponding sample source\n",
    "source1=\"ibm\"\n",
    "source2=\"ccle\"\n",
    "source3=\"ccle\"\n",
    "source4=\"cclf\"\n",
    "source5=\"cclf\"\n",
    "source6=\"ccle\"\n",
    "source7=\"ibm\"\n",
    "\n",
    "release = samplesetname\n",
    "\n",
    "# our working workspace (reference)\n",
    "refworkspace=\"broad-firecloud-ccle/DepMap_hg38_RNAseq\"\n",
    "\n",
    "# info/metadata google spreadsheets (info about cell lines)\n",
    "refsheet_url = \"https://docs.google.com/spreadsheets/d/1Pgb5fIClGnErEqzxpU7qqX6ULpGTDjvzWwDN8XUJKIY\"\n",
    "privacy_release_url = \"https://docs.google.com/spreadsheets/d/115TUgA1t_mD32SnWAGpW9OKmJ2W5WYAOs3SuSdedpX4\"\n",
    "depmap_pv = \"https://docs.google.com/spreadsheets/d/1uqCOos-T9EMQU7y2ZUw4Nm84opU5fIT1y7jet1vnScE\"\n",
    "depmap_taiga = \"arxspan-cell-line-export-f808\"\n",
    "\n",
    "# genomic annotations (v35)\n",
    "gencode = 'ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/gencode.v35.annotation.gff3.gz'\n",
    "\n",
    "RNAmethods = ['']\n",
    "\n",
    "\n",
    "replace = {'T': 'Tumor', 'N': 'Normal', 'm': 'Unknown', 'L': 'Unknown'}\n",
    "extract_to_change = {'from_arxspan_id': 'participant'}\n",
    "\n",
    "#version 102\n",
    "ensemblserver = \"http://nov2020.archive.ensembl.org/biomart\" \n",
    "\n",
    "datatype = 'rna'\n",
    "match = ['ACH-','CDS-']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate sample set from new samples\n",
    "\n",
    "we retrieve all the samples we can find from the GP workspaces\n",
    "\n",
    "__CCLE specific__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T15:54:35.742306Z",
     "start_time": "2021-03-19T15:54:35.616345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arxspan_id</th>\n",
       "      <th>version</th>\n",
       "      <th>sm_id</th>\n",
       "      <th>PDO</th>\n",
       "      <th>datatype</th>\n",
       "      <th>size</th>\n",
       "      <th>ccle_name</th>\n",
       "      <th>stripped_cell_line_name</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>cellosaurus_id</th>\n",
       "      <th>...</th>\n",
       "      <th>19q2</th>\n",
       "      <th>19q3</th>\n",
       "      <th>19q4</th>\n",
       "      <th>20q1</th>\n",
       "      <th>20q2</th>\n",
       "      <th>20q4</th>\n",
       "      <th>20q</th>\n",
       "      <th>21Q1</th>\n",
       "      <th>low_quality</th>\n",
       "      <th>legacy_crc32_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CDS-ABH0uZ</th>\n",
       "      <td>ACH-001767</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rna</td>\n",
       "      <td>311757376.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CCLFPEDS0018T</td>\n",
       "      <td>PT-pmZkEqFb</td>\n",
       "      <td>U</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            arxspan_id  version  sm_id  PDO datatype         size  ccle_name  \\\n",
       "CDS-ABH0uZ  ACH-001767        1    NaN  NaN      rna  311757376.0        NaN   \n",
       "\n",
       "           stripped_cell_line_name participant_id cellosaurus_id  ...  19q2  \\\n",
       "CDS-ABH0uZ           CCLFPEDS0018T    PT-pmZkEqFb              U  ...   NaN   \n",
       "\n",
       "           19q3 19q4 20q1 20q2 20q4 20q 21Q1 low_quality legacy_crc32_hash  \n",
       "CDS-ABH0uZ  NaN  NaN  NaN  NaN  NaN NaN  0.0         0.0               NaN  \n",
       "\n",
       "[1 rows x 54 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker.(ccle_refsamples.loc[['CDS-ABH0uZ']],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T15:52:16.521529Z",
     "start_time": "2021-03-19T15:52:15.086504Z"
    }
   },
   "outputs": [
    {
     "ename": "APIException",
     "evalue": "Sample set import failed.: (400) : {\n  \"causes\": [{\n    \"causes\": [],\n    \"message\": \"sample CDS-ABH0uZ not found\",\n    \"source\": \"rawls\",\n    \"stackTrace\": []\n  }],\n  \"message\": \"Could not resolve some entity references\",\n  \"source\": \"rawls\",\n  \"stackTrace\": [],\n  \"statusCode\": 400,\n  \"timestamp\": 1616169136473\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIException\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-3c82a1da26f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m'CDS-kU30H5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m'CDS-G0F5f5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m 'CDS-ABH0uZ'])\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/dalmatian/wmanager.py\u001b[0m in \u001b[0;36mupdate_sample_set\u001b[0;34m(self, sample_set_id, sample_ids)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_sample_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_set_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \u001b[0;34m\"\"\"Update or create a sample set\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_entity_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_set_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/dalmatian/wmanager.py\u001b[0m in \u001b[0;36mupdate_entity_set\u001b[0;34m(self, etype, set_id, entity_ids)\u001b[0m\n\u001b[1;32m   1524\u001b[0m             )\n\u001b[1;32m   1525\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1526\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}_set'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1527\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m                 \u001b[0;31m# Upload empty set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/dalmatian/wmanager.py\u001b[0m in \u001b[0;36mupload_entities\u001b[0;34m(self, etype, df, index)\u001b[0m\n\u001b[1;32m    344\u001b[0m                                         )\n\u001b[1;32m    345\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAPIException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} import failed.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0met\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAPIException\u001b[0m: Sample set import failed.: (400) : {\n  \"causes\": [{\n    \"causes\": [],\n    \"message\": \"sample CDS-ABH0uZ not found\",\n    \"source\": \"rawls\",\n    \"stackTrace\": []\n  }],\n  \"message\": \"Could not resolve some entity references\",\n  \"source\": \"rawls\",\n  \"stackTrace\": [],\n  \"statusCode\": 400,\n  \"timestamp\": 1616169136473\n}"
     ]
    }
   ],
   "source": [
    "refwm.update_sample_set('re_rsem_21Q2', ['CDS-fk564T',\n",
    "'CDS-kU30H5',\n",
    "'CDS-G0F5f5',\n",
    "'CDS-ABH0uZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = loading.loadRNA(samplesetname,workspaces=[\"terra-broad-cancer-prod/CCLE_DepMap_WES\", \"terra-broad-cancer-prod/Getz_IBM_CellLines_Exomes\"],sources=[\"ccle\", \"ibm\"],maxage='2020-09-10', baits='polyA',stype=\"rna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading.update(samples, samplesetname, stype=\"rna\", bucket=\"\", refworkspace,\n",
    "          name_col=\"index\", values=['legacy_bam_filepath', 'legacy_bai_filepath'],\n",
    "          filetypes=['bam', 'bai'],\n",
    "          my_id='~/.client_secret.json',\n",
    "          mystorage_id=\"~/.storage.json\",\n",
    "          creds='../.credentials.json',\n",
    "          sampletrackername='ccle sample tracker', refsheet_url=\"https://docs.google.com/spreadsheets/d/1Pgb5fIClGnErEqzxpU7qqX6ULpGTDjvzWwDN8XUJKIY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the pipeline\n",
    "\n",
    "We are using Dalmatian to send request to Terra, we are running a set of 6 functions To generate the expression/fusion dataset:\n",
    "\n",
    "We use the GTEx pipeline ([https://github.com/broadinstitute/gtex-pipeline/blob/v9/TOPMed_RNAseq_pipeline.md](https://github.com/broadinstitute/gtex-pipeline/blob/v9/TOPMed_RNAseq_pipeline.md)).\n",
    "\n",
    "To generate the expression dataset, run the following tasks on all samples that you need, in this order:\n",
    "\n",
    "\n",
    "\n",
    "*   samtofastq_v1-0_BETA_cfg \n",
    "\n",
    "    (broadinstitute_gtex/samtofastq_v1-0_BETA Snapshot ID: 5)\n",
    "\n",
    "*   star_v1-0_BETA_cfg\n",
    "\n",
    "(broadinstitute_gtex/star_v1-0_BETA Snapshot ID: 7)\n",
    "\n",
    "\n",
    "\n",
    "*   rsem_v1-0_BETA_cfg \n",
    "\n",
    "    (broadinstitute_gtex/rsem_v1-0_BETA Snapshot ID: 4)\n",
    "\n",
    "*   rsem_aggregate_results_v1-0_BETA_cfg (broadinstitute_gtex/rsem_aggregate_results_v1-0_BETA Snapshot ID: 3)\n",
    "\n",
    "The outputs to be downloaded will be saved under the sample set that you ran. The outputs we use for the release are:\n",
    "\n",
    "\n",
    "\n",
    "*   rsem_genes_expected_count\n",
    "*   rsem_genes_tpm\n",
    "*   rsem_transcripts_tpm\n",
    "\n",
    "****Make sure that you delete the intermediate files. These files are quite large so cost a lot to store. To delete, you can either write a task that deletes them or use gsutil rm*****\n",
    "\n",
    "\n",
    "##### Fusions {#fusions}\n",
    "\n",
    "We use STAR-Fusion [https://github.com/STAR-Fusion/STAR-Fusion/wiki](https://github.com/STAR-Fusion/STAR-Fusion/wiki). The fusions are generated by running the following tasks\n",
    "\n",
    "\n",
    "\n",
    "*   hg38_STAR_fusion (gkugener/STAR_fusion Snapshot ID: 14)\n",
    "*   Aggregate_Fusion_Calls (gkugener/Aggregate_files_set Snapshot ID: 2)\n",
    "\n",
    "The outputs to be downloaded will be saved under the sample set you ran. The outputs we use for the release are: \n",
    "\n",
    "\n",
    "\n",
    "*   fusions_star\n",
    "\n",
    "This task uses the same samtofastq_v1-0_BETA_cfg task as in the expression pipeline, although in the current implementation, this task will be run twice. It might be worth combing the expression/fusion calling into a single workflow. This task also contains a flag that lets you specify if you want to delete the intermediates (fastqs). \n",
    "\n",
    "There are several other tasks in this workspace. In brief:\n",
    "\n",
    "\n",
    "\n",
    "*   Tasks prefixed with **EXPENSIVE** or **CHEAP** are identical to their non-prefixed version, except that they specify different memory, disk space, etc. parameters. These versions can be used when samples fail the normal version of the task due to memory errors.\n",
    "*   The following tasks are part of the GTEx pipeline but we do not use them (we use RSEM exclusively): markduplicates_v1-0_BETA_cfg (broadinstitute_gtex/markduplicates_v1-0_BETA Snapshot ID: 2), rnaseqc2_v1-0_BETA_cfg (broadinstitute_gtex/rnaseqc2_v1-0_BETA Snapshot ID: 2)\n",
    "*   **ExonUsage_hg38_fixed** (gkugener/ExonUsage_fixed Snapshot ID: 1): this task calculates exon usage ratios. The non-fixed version contains a bug in the script that is not able to handle chromosome values prefixed with ‘chr’. The ‘fixed’ version resolves this issue.\n",
    "*   **AggregateExonUsageRObj_hg38** (ccle_mg/AggregateExonUsageRObj Snapshot ID: 2): combines the exon usage ratios into a matrices that are saved in an R object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torm = terra.listHeavyFiles(refworkspace)\n",
    "h.parrun(['gsutil rm '+i for i in torm], cores=8)\n",
    "terra.removeFromFailedWorkflows(refworkspace, dryrun=False, everythingFor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Terra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update with latest workspace parameters from our repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T16:17:24.432228Z",
     "start_time": "2021-03-17T14:28:34.618305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 of jobs Succeeded in submission 0.sion 0. 106 mn elapsed..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_id = refwm.create_submission(\"RNA_pipeline\", samplesetname,'sample_set',expression='this.samples')\n",
    "await terra.waitForSubmission(refworkspace, submission_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T18:46:42.273132Z",
     "start_time": "2021-03-17T16:17:27.509883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created submission 4e5d24b2-5b48-453e-9d49-4617028b31f3.\n",
      "1.0 of jobs Succeeded in submission 0.sion 0. 145 mn elapsed..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_id = refwm.create_submission(\"RNA_aggregate\", 'all')\n",
    "await terra.waitForSubmission(refworkspace, submission_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the workflow configurations used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.saveWorkspace(refworkspace,'data/'+samplesetname+'/RNAconfig/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load QC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starlogs = getQC(workspace=refworkspace ,only=samples.index.tolist(), qcname=\"star_logs\",match=\".Log.final.out\")\n",
    "rnaqc = getQC(workspace=refworkspace ,only=samples.index.tolist(), qcname=\"rnaseqc2_metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,val in rnaqc.items():\n",
    "    if type(val[0]) is not str:\n",
    "        print(\"QC was not done for: \"+k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcs = pd.DataFrame()\n",
    "for k,val in rnaqc.items():\n",
    "    if val[0] is not np.nan:\n",
    "        qcs = pd.concat([qcs, pd.read_csv(val[0],sep='\\t',index_col=0)],axis=1)\n",
    "qcs = qcs[~((qcs.mean(1)==1.0) | (qcs.mean(1)==0.0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowqual = rna.filterRNAfromQC(qcs, thresholds={'minmapping': 0.85,\n",
    "                                          'minendmapping': 0.75,\n",
    "                                          'minefficiency': 0.75,\n",
    "                                          'maxendmismatch': 0.02,\n",
    "                                          'maxmismatch': 0.02,\n",
    "                                          'minhighqual': 0.8,\n",
    "                                          'minexon': 0.7,\n",
    "                                          \"maxambiguous\": 0.05,\n",
    "                                          \"maxsplits\": 0.1,\n",
    "                                          \"maxalt\": 0.2,\n",
    "                                          \"maxchim\": 0.05,\n",
    "                                          \"minreads\": 20000000,\n",
    "                                          \"minlength\": 80,\n",
    "                                          \"maxgenes\": 35000,\n",
    "                                          \"mingenes\": 12000,\n",
    "                                          }, folder='data/rna_qc_plots/lowqual_'+samplesetname+\"/\", plot=True, qant1=0.1, qant3=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = rna.filterRNAfromQC(qcs, thresholds={'minmapping': 0.7,\n",
    "                                          'minendmapping': 0.66,\n",
    "                                          'minefficiency': 0.6,\n",
    "                                          'maxendmismatch': 0.02,\n",
    "                                          'maxmismatch': 0.02,\n",
    "                                          'minhighqual': 0.7,\n",
    "                                          'minexon': 0.66,\n",
    "                                          \"maxambiguous\": 0.1,\n",
    "                                          \"maxsplits\": 0.1,\n",
    "                                          \"maxalt\": 0.5,\n",
    "                                          \"maxchim\": 0.2,\n",
    "                                          \"minreads\": 20000000,\n",
    "                                          \"minlength\": 80,\n",
    "                                          \"maxgenes\": 35000,\n",
    "                                          \"mingenes\": 10000,\n",
    "                                          }, folder='data/rna_qc_plots/'+samplesetname+\"/\", plot=True, qant1=0.07, qant3=0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = failed.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed.extend(['CDS-12DTEw', 'CDS-9hv1zM', 'CDS-A6GSeQ', 'CDS-aWlMRt', 'CDS-B1ywOH', 'CDS-BixxtG', 'CDS-DRM3l2', 'CDS-jOlYT4', 'CDS-KMhiT9', 'CDS-M6mnMA', 'CDS-pYwECX', 'CDS-v6E624', 'CDS-vxTqNJ', 'CDS-YxtmkI'])\n",
    "print('you want to copy that up top, to save it for next time',failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame(index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in starlogs.items():\n",
    "    if k =='nan':\n",
    "        continue\n",
    "    if ccle_refsamples.loc[k,'bam_qc']!=v[0]:\n",
    "        ccle_refsamples.loc[k,'bam_qc']=v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToSheet(ccle_refsamples,'ccle sample tracker', secret=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newfail = []\n",
    "# finding other replicates to solve failed ones\n",
    "for val in failed:\n",
    "    a = ccle_refsamples.loc[val].arxspan_id\n",
    "    res = ccle_refsamples[(ccle_refsamples.datatype == 'rna') &(ccle_refsamples.arxspan_id == a)]\n",
    "    if len(res)>1:\n",
    "        for k in res.index:\n",
    "            if k not in failed:\n",
    "                renaming[k] = renaming.pop(val)\n",
    "    else:\n",
    "        newfail.append(renaming.pop(val))\n",
    "failed = newfail\n",
    "newfail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove some datafile to save money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = refwm.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colstoremove = ['fastq1', 'fastq2','recalibrated_bam','recalibrated_bam_index']\n",
    "for val in colstoremove:\n",
    "    refwm.disable_hound().delete_entity_attributes('sample', res[val], delete_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesinset = samples.index.tolist()\n",
    "#samplesinset= [i['entityName'] for i in refwm.get_entities('sample_set').loc[samplesetname].samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## copy star bam file to our cclebams/rnasq_hg38/ bucket\n",
    "renamed, _ = terra.changeGSlocation(workspacefrom=refworkspace, newgs=\"gs://cclebams/rnasq_hg38/\", onlysamples=samplesinset, onlycol=[\"star_bam_file\",'star_bam_index'], entity=\"sample\", keeppath=False,dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame(index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples.loc[samplesinset,['legacy_bam_filepath','legacy_bai_filepath','legacy_size','legacy_crc32c_hash']] = ccle_refsamples.loc[samplesinset][['internal_bam_filepath','internal_bai_filepath','size','crc32c_hash']].values\n",
    "\n",
    "ccle_refsamples.loc[samplesinset,'internal_bam_filepath'] = renamed['star_bam_file'].values\n",
    "\n",
    "ccle_refsamples.loc[samplesinset,'internal_bai_filepath'] = renamed['star_bam_index'].values\n",
    "\n",
    "ccle_refsamples.loc[samplesinset,'size'] = [gcp.extractSize(i)[1] for i in gcp.lsFiles(renamed['star_bam_file'].tolist(),'-l')]\n",
    "ccle_refsamples.loc[samplesinset,'crc32c_hash'] = [gcp.extractHash(i) for i in gcp.lsFiles(renamed['star_bam_file'].tolist(),'-L')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToSheet(ccle_refsamples,'ccle sample tracker', secret=creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expression post processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = refwm.get_sample_sets().loc['all']\n",
    "rsem_genes_expected_count = res['rsem_genes_expected_count']\n",
    "rsem_genes_tpm = res['rsem_genes_tpm']\n",
    "rsem_transcripts_tpm = res['rsem_transcripts_tpm']\n",
    "rsem_transcripts_expected_count = res['rsem_transcripts_expected_count']\n",
    "! gsutil cp $rsem_genes_expected_count \"temp/rsem_genes_expected_count\" & gsutil cp $rsem_genes_tpm \"temp/rsem_genes_tpm\" & gsutil cp $rsem_transcripts_tpm \"temp/rsem_transcripts_tpm\" & gsutil cp $rsem_transcripts_expected_count \"temp/rsem_transcripts_expected_count\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {}\n",
    "renaming = {}\n",
    "for val in [\"temp/rsem_transcripts_tpm\",\"temp/rsem_genes_tpm\", \"temp/rsem_genes_expected_count\",\"temp/rsem_transcripts_expected_count\"]:\n",
    "    file = pd.read_csv(val, compression='gzip', header=0, sep='\\t', quotechar='\"', error_bad_lines=False)\n",
    "    print(file.columns[:10])\n",
    "    if len(renaming) == 0:\n",
    "        # removing failed version\n",
    "        renaming  = removeOlderVersions(names=file.columns[2:], refsamples=refwm.get_samples(), arxspan_id=\"arxspan_id\", version=\"version\")\n",
    "        renaming.update({'transcript_id(s)':'transcript'})\n",
    "        # if we have a replaceable failed version in our dataset\n",
    "        for k, v in renaming.items():\n",
    "            if k in rename:\n",
    "                renaming[rename[k]] = renaming.pop(k)\n",
    "    if val==\"temp/rsem_genes_expected_count\":\n",
    "        replevel = file.drop(columns = 'transcript_id(s)').set_index('gene_id', drop=True)\n",
    "        replevel = replevel[(replevel.sum(1) != 0) & (replevel.var(1) != 0)]\n",
    "    # we remove the failed samples where we did not found anything else to replace them with\n",
    "    files[val.split('/')[-1]] = file[file.columns[:2].tolist()+[i for i in file.columns[2:] if i in set(renaming.keys())]].rename(columns=renaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generating gene names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = BiomartServer(ensemblserver)\n",
    "ensmbl = server.datasets['hsapiens_gene_ensembl']\n",
    "ensembltohgnc = pd.read_csv(io.StringIO(ensmbl.search({\n",
    "  'attributes': ['ensembl_gene_id','clone_based_ensembl_gene','hgnc_symbol','gene_biotype','entrezgene_id']\n",
    "}, header=1).content.decode()), sep='\\t')\n",
    "\n",
    "ensembltohgnc.columns = ['ensembl_gene_id','clone_based_ensembl_gene','hgnc_symbol','gene_biotype','entrezgene_id']\n",
    "ensembltohgnc = ensembltohgnc[~(ensembltohgnc['clone_based_ensembl_gene'].isna() & ensembltohgnc['hgnc_symbol'].isna())]\n",
    "ensembltohgnc.loc[ensembltohgnc[ensembltohgnc.hgnc_symbol.isna()].index,\"hgnc_symbol\"] = ensembltohgnc[ensembltohgnc.hgnc_symbol.isna()]['clone_based_ensembl_gene']\n",
    "\n",
    "gene_rename =  {i.ensembl_gene_id: i.hgnc_symbol+' ('+i.ensembl_gene_id+')' for k,i in ensembltohgnc.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protcod_rename = {i.ensembl_gene_id: i.hgnc_symbol+' ('+str(int(i.entrezgene_id))+')' for _,i in ensembltohgnc[(~ensembltohgnc.entrezgene_id.isna()) & (ensembltohgnc.gene_biotype=='protein_coding')].iterrows()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### renaming the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene level\n",
    "for val in ['rsem_genes_expected_count','rsem_genes_tpm']:\n",
    "    file = files[val].drop(columns='transcript').set_index('gene_id')\n",
    "    file = file[(file.sum(1) != 0) & (file.var(1) != 0)]\n",
    "    r = [i.split('.')[0] for i in file.index]\n",
    "    dup = h.dups(r)\n",
    "    if len(dup)>0:\n",
    "        print(dup)\n",
    "        raise ValueError('duplicate genes')\n",
    "    file.index = r\n",
    "    files[val.replace('genes','proteincoding_genes')] = file[file.index.isin(set(ensembltohgnc[ensembltohgnc.gene_biotype == 'protein_coding'].ensembl_gene_id))]\n",
    "    files[val] = file.rename(index=gene_rename).T\n",
    "    files[val.replace('genes','proteincoding_genes')] = files[val.replace('genes','proteincoding_genes')].rename(index=protcod_rename).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript level\n",
    "rename_transcript = {}\n",
    "missing = []\n",
    "for val in ['rsem_transcripts_expected_count','rsem_transcripts_tpm']:\n",
    "    file = files[val]\n",
    "    file = file[(file[file.columns[2:]].sum(1) != 0) & (file[file.columns[2:]].var(1) != 0)]\n",
    "    r = [i.split('.')[0] for i in file.transcript_id]\n",
    "    dup = h.dups(r)\n",
    "    if len(dup)>0:\n",
    "        print(dup)\n",
    "        raise ValueError('duplicate genes')    \n",
    "    file.transcript_id = r\n",
    "    if len(rename_transcript)==0:\n",
    "        for _,v in file.iterrows():\n",
    "            if v.gene_id.split('.')[0] in gene_rename:\n",
    "                rename_transcript[v.transcript_id] = gene_rename[v.gene_id.split('.')[0]].split(' (')[0] + ' (' + v.transcript_id + ')'\n",
    "            else:\n",
    "                missing.append(v.gene_id.split('.')[0])\n",
    "        print('missing: '+str(len(missing))+' genes')\n",
    "    files[val] = file.set_index('transcript_id').drop(columns = 'gene_id').rename(index = rename_transcript).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing genes that did not match.. pretty unfortunate \n",
    "files['rsem_proteincoding_genes_expected_count'] = files['rsem_proteincoding_genes_expected_count'][[i for i in files['rsem_proteincoding_genes_expected_count'].columns if ' (' in i]]\n",
    "files['rsem_proteincoding_genes_tpm'] = files['rsem_proteincoding_genes_tpm'][[i for i in files['rsem_proteincoding_genes_tpm'].columns if ' (' in i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check: do we have any duplicates?\n",
    "h.dups(files['rsem_proteincoding_genes_expected_count'].columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we do, managing duplicates\n",
    "for val in ['rsem_proteincoding_genes_expected_count', 'rsem_proteincoding_genes_tpm']:\n",
    "    for dup in h.dups(files[val].columns):\n",
    "        a = files[val][dup].sum()\n",
    "        files[val].drop(columns=dup)\n",
    "        files[val][dup] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saving samples used for the release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame(index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples.loc[set(renaming.keys())-set(['transcript_id(s)']),release]=1\n",
    "ccle_refsamples.loc[ccle_refsamples[ccle_refsamples.datatype=='rna'].index,'low_quality']=0\n",
    "ccle_refsamples.loc[lowqual[lowqual.sum(1)>3].index.tolist(),'low_quality']=1\n",
    "ccle_refsamples.to_csv('temp/updated_ref_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToSheet(ccle_refsamples,'ccle sample tracker', secret=creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevcounts = tc.get(name='depmap-a0ab', file='CCLE_RNAseq_reads')\n",
    "overlap = set(prevcounts.columns) & set(files['rsem_genes_expected_count'].columns)\n",
    "len(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have we lost any files compared to last release?\n",
    "lost = set(prevcounts.index) - set(files['rsem_proteincoding_genes_tpm'].index)\n",
    "%store failed\n",
    "lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we have samples that are missanotated compared to previous releases (replicate level)\n",
    "notindataset, missannotated, unmatched = findMissAnnotatedReplicates(replevel, prevcounts, renaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in unmatched.items():\n",
    "    if ccle_refsamples.loc[k].arxspan_id!=v:\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame(index_col=0)\n",
    "normals = ccle_refsamples[ccle_refsamples['primary_disease']=='normal'].index.tolist()\n",
    "normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for k,val in files.items():\n",
    "    #files[k] = val.drop(index=normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we have samples that are missanotated compared to previous releases (sample level)\n",
    "unmatched = rna.getDifferencesFromCorrelations(files['rsem_genes_expected_count'] ,prevcounts, minsimi=0.95)\n",
    "unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is it because of  duplicate version?\n",
    "rnasamples = ccle_refsamples[ccle_refsamples.datatype=='rna']\n",
    "for i,val in unmatched:\n",
    "    print(len(rnasamples[rnasamples.arxspan_id==i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ssGSEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_genes = files['rsem_genes_expected_count'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in counts_genes.columns if 'MYC' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_genes.columns = [i.split(' (')[0] for i in counts_genes.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in h.dups(counts_genes.columns):\n",
    "    val = counts_genes[i].sum(1)\n",
    "    counts_genes=counts_genes.drop(columns=i)\n",
    "    counts_genes[i]=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set([val for val in counts_genes.columns if '.' not in val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAYBE NOT NEEDED\n",
    "#### merging splicing variants into the same gene\n",
    "#counts_genes_merged, _, _= h.mergeSplicingVariants(counts_genes.T, defined='.')\n",
    "counts_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with R ssGSEA on the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichments= rna.gsva(counts_genes.T, pathtoJKBio=\"../JKBio/\", geneset_file = \"data/genesets/msigdb.v7.2.symbols.gmt\", method='ssgsea').T\n",
    "enrichments.index = [i.replace('.','-') for i in enrichments.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = tc.get(name='depmap-a0ab', file='sample_info')\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding train and test set\n",
    "trainame = [val for val in new1&prev if val[:3] == 'ACH']\n",
    "testname = [val for val in new1-prev if val[:3] == 'ACH']\n",
    "\n",
    "#looking at the 2000 most variable genes in the two sets\n",
    "genetolookfor = 2000\n",
    "gene_var = counts_genes[trainame].var(1).values\n",
    "print(len(gene_var))\n",
    "sorting = np.argsort(gene_var)[-genetolookfor:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unregistered = set(testname) - set(metadata[\"DepMap_ID\"].values.tolist())\n",
    "unregistered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(counts_genes['ACH-001767']) - np.count_nonzero(counts_genes['ACH-001767'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and reodering train and test sets\n",
    "traindata = counts_genes[set(trainame)-unregistered].values[sorting].T\n",
    "trainlabels = [metadata[metadata[\"DepMap_ID\"]==val][\"disease\"].values[0] for val in counts_genes[set(trainame)-unregistered].columns.tolist() if val not in unregistered]\n",
    "\n",
    "testdata = counts_genes[set(testname)-unregistered].values[sorting].T\n",
    "testlabels = [metadata[metadata[\"DepMap_ID\"]==val][\"disease\"].values[0] for val in counts_genes[set(testname)-unregistered].columns.tolist() if val not in unregistered]\n",
    "traindata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn KNN classifier to the metadata diseases\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(traindata, trainlabels) \n",
    "predicted = neigh.predict(testdata)\n",
    "predicted[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = trainlabels + testlabels\n",
    "colors=[0]*len(trainlabels)\n",
    "colors.extend([1,2,2,2,2,1,2,2,2,1,2])\n",
    "data = np.vstack([traindata,testdata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot them with TSNE, highlight the points that failed and show colors for diseases\n",
    "dimred = TSNE(2,10).fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(dimred, labels=labels,colors=colors, radi=1.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save files for taiga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls temp/gene_sets_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h.compareDfs(enrichments, tc.get(name='depmap-a0ab', file='CCLE_fusions_unfiltered'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(ccle_refsamples[ccle_refsamples.datatype=='rna'].arxspan_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichments.to_csv('temp/gene_sets_'+release+'_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CCLE_expression, CCLE_expression_full, , \n",
    "#h.compareDfs(files[\"rsem_transcripts_tpm\"], tc.get(name='depmap-a0ab', file='CCLE_RNAseq_transcripts'))\n",
    "#h.compareDfs(files[\"rsem_transcripts_expected_count\"], tc.get(name='depmap-a0ab', file='CCLE_expression_transcripts_expected_count'))\n",
    "h.compareDfs(files[\"rsem_genes_expected_count\"], tc.get(name='depmap-a0ab', file='CCLE_RNAseq_reads'))\n",
    "h.compareDfs(files[\"rsem_genes_tpm\"], tc.get(name='depmap-a0ab', file='CCLE_expression_full'))\n",
    "h.compareDfs(files[\"rsem_proteincoding_genes_tpm\"], tc.get(name='depmap-a0ab', file='CCLE_expression'))\n",
    "h.compareDfs(files[\"rsem_proteincoding_genes_expected_count\"], tc.get(name='depmap-a0ab', file = 'CCLE_expression_proteincoding_genes_expected_count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,val in files.items():\n",
    "    #h.compareDfs(val, tc.get(name='depmap-a0ab', file=k))\n",
    "    val.to_csv('temp/'+k.replace('rsem','expression_'+release)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.update_dataset(dataset_permaname=\"expression-d035\",\n",
    "                 upload_file_path_dict={\n",
    "    'temp/expression_'+release+'_transcripts_tpm.csv': 'NumericMatrixCSV',\n",
    "    'temp/expression_'+release+'_genes_tpm.csv': 'NumericMatrixCSV',\n",
    "    'temp/expression_'+release+'_genes_expected_count.csv': 'NumericMatrixCSV',\n",
    "    'temp/expression_'+release+'_proteincoding_genes_expected_count.csv': 'NumericMatrixCSV',\n",
    "    'temp/expression_'+release+'_proteincoding_genes_tpm.csv': 'NumericMatrixCSV',\n",
    "    'temp/expression_'+release+'_transcripts_expected_count.csv': 'NumericMatrixCSV',\n",
    "    'temp/gene_sets_'+release+'_all.csv': 'NumericMatrixCSV'\n",
    "                },\n",
    "                  dataset_description=\n",
    "\"\"\"\n",
    "# RNAseq\n",
    "\n",
    "PORTAL TEAM SHOULD NOT USE THIS: There are lines here that should not make it even to internal.\n",
    "\n",
    "/!\\ This is the most up to date version of the CCLE RNA data.\n",
    "\n",
    "## Annotations:\n",
    "\n",
    "transcriptions (Transcripts rpkm):\n",
    "\n",
    "genes (gene rpkm):\n",
    "__Rows__:\n",
    "__Columns__:\n",
    "Counts (gene counts):\n",
    "__Rows__:\n",
    "__Columns__:\n",
    "Gene level CN data:\n",
    "__Rows__:\n",
    "__Columns__:\n",
    " DepMap cell line IDs\n",
    " gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "DepMap\\_ID, Chromosome, Start, End, Num\\_Probes, Segment\\_Mean\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.saveConfigs(refworkspace,'data/'+samplesetname+'/RNAconfig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.waitForSubmission(refworkspace, submission_id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = refwm.get_sample_sets().loc['all']['fusions_star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil cp $aggregated \"temp/expression.fusion.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions = pd.read_csv('temp/expression.fusion.tsv', names=['DepMap_ID', 'FusionName', 'JunctionReadCount', 'SpanningFragCount', 'SpliceType', 'LeftGene', 'LeftBreakpoint', 'RightGene', 'RightBreakpoint', 'LargeAnchorSupport', 'FFPM', 'LeftBreakDinuc', 'LeftBreakEntropy', 'RightBreakDinuc', 'RightBreakEntropy','annots'], skiprows=1, sep='\\t')\n",
    "fusions[\"DepMap_ID\"] = [i.split('.')[0] for i in fusions['DepMap_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fusions))\n",
    "renaming = removeOlderVersions(names=set(fusions['DepMap_ID']), refsamples=refwm.get_samples(), arxspan_id=\"arxspan_id\", version=\"version\")\n",
    "print(len(fusions))\n",
    "print(fusions['DepMap_ID'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions['CCLE_count'] = [i.LeftBreakpoint+'_'+i.RightBreakpoint for k, i in fusions.iterrows()]\n",
    "counts = Counter(list(fusions['CCLE_count']))\n",
    "fusions['CCLE_count'] = [counts[val] for val in fusions['CCLE_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(fusions['CCLE_count'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions.RightGene = renameFusionGene(fusions.RightGene)\n",
    "fusions.LeftGene = renameFusionGene(fusions.LeftGene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions[['LeftGene', 'RightGene']] = fusions[['LeftGene', 'RightGene']].applymap(lambda x: re.sub(r'([^\\^]+)\\^(.*)$', r'\\1 (\\2)', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions.to_csv('temp/fusions_withReplicates_'+release+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions = pd.read_csv('temp/fusions_withReplicates_'+release+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate filtered fusion table\n",
    "\n",
    "We want to apply filters to the fusion table to reduce the number of artifacts in the dataset. Specifically, we filter the following:\n",
    "\n",
    "* Remove fusions involving mitochondrial chromosomes, or HLA genes, or immunoglobulin genes\n",
    "* Remove red herring fusions (from STAR-Fusion annotations column)\n",
    "* Remove recurrent in CCLE (>= 25 samples)\n",
    "* Remove fusion with (SpliceType=\" INCL_NON_REF_SPLICE\" and LargeAnchorSupport=\"No\" and FFPM < 0.1)\n",
    "* Remove fusions with FFPM < 0.05 (STAR-Fusion suggests using 0.1, but looking at the translocation data, this looks like it might be too aggressive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions = fusions[fusions['DepMap_ID'].isin(renaming.keys())].replace({'DepMap_ID':renaming}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions['CCLE_count'] = [i.LeftBreakpoint+'_'+i.RightBreakpoint for k, i in fusions.iterrows()]\n",
    "counts = Counter(list(fusions['CCLE_count']))\n",
    "fusions['CCLE_count'] = [counts[val] for val in fusions['CCLE_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = filterFusions(fusions, maxfreq=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(fusions.DepMap_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame(index_col=0)\n",
    "normals = ccle_refsamples[ccle_refsamples['primary_disease']=='normal'].index.tolist()\n",
    "normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fusions = fusions[~fusions.DepMap_ID.isin(normals)]\n",
    "#filtered = filtered[~filtered.DepMap_ID.isin(normals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tc.get(name='depmap-a0ab', file='CCLE_fusions_unfiltered')\n",
    "print('new')\n",
    "print(set(fusions.DepMap_ID) - set(a.DepMap_ID))\n",
    "print('removed')\n",
    "print(set(a.DepMap_ID) - set(fusions.DepMap_ID))\n",
    "print(\"in fusion, not in rna\")\n",
    "print(set(fusions.DepMap_ID) - set(files['rsem_proteincoding_genes_tpm'].index))\n",
    "print('in depmap, not in fusions')\n",
    "print(set(files['rsem_proteincoding_genes_tpm'].index) - set(fusions.DepMap_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions.to_csv('temp/fusions_'+release+'.csv',index=False)\n",
    "filtered.to_csv('temp/filtered_fusions_'+release+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions = pd.read_csv('temp/fusions_'+release+'.csv')\n",
    "filtered = pd.read_csv('temp/filtered_fusions_'+release+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading to Taiga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.update_dataset(dataset_permaname=\"fusions-95c9\",\n",
    "                     upload_file_path_dict={\n",
    "                'temp/fusions_'+release+'.csv': 'TableCSV',\n",
    "                'temp/filtered_fusions_'+release+'.csv': 'TableCSV',\n",
    "                'temp/fusions_withReplicates_'+release+'.csv': \"TableCSV\"},\n",
    "                 dataset_description=\"\"\"\n",
    "# Fusions\n",
    "\n",
    "PORTAL TEAM SHOULD NOT USE THIS: There are lines here that should not make it even to internal.\n",
    "\n",
    "/!\\ This is the most up to date version of the CCLE CN data.\n",
    "\n",
    "## Annotations\n",
    "\n",
    "Description: Gene fusions derived from RNAseq data.\n",
    "\n",
    "Rows: cell lines, IDs contained in the column DepMap_ID\n",
    "\n",
    "Unfiltered data contains all output fusions, while the filtered data uses the filters suggested by the star fusion docs. These filters are:\n",
    "- FFPM > 0.1 -  a cutoff of 0.1 means&nbsp;at least 1 fusion-supporting RNAseq fragment per 10M total reads\n",
    "- Remove known false positives, such as GTEx recurrent fusions and certain paralogs\n",
    "- Genes that are next to each other\n",
    "- Fusions with mitochondrial breakpoints\n",
    "- Removing fusion involving mitochondrial chromosomes or HLA genes\n",
    "- Removed common false positive fusions (red herring annotations as described in the STAR-Fusion docs)\n",
    "- Recurrent fusions observed in CCLE across cell lines (in more than 10% of our samples)\n",
    "- Removed fusions where SpliceType='INCL_NON_REF_SPLICE' and LargeAnchorSupport='NO_LDAS' and FFPM < 0.1\n",
    "- FFPM < 0.05\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "222.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
