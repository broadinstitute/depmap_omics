{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from depmapomics import tracker, loading, fusion\n",
    "from depmapomics import postprocess_expression as postrna\n",
    "from depmapomics.qc import utils as myQC\n",
    "from genepy import terra\n",
    "from genepy.utils import helper as h\n",
    "from genepy import rna\n",
    "\n",
    "from gsheets import Sheets\n",
    "\n",
    "from taigapy import TaigaClient\n",
    "import dalmatian as dm\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from bokeh.plotting import output_notebook\n",
    "\n",
    "import re\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "tc = TaigaClient()\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "immutable parameters (user specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERAL PARAMS\n",
    "\n",
    "isCCLE = True\n",
    "doCleanup = True\n",
    "samplesetname=\"21Q2\"\n",
    "release = samplesetname\n",
    "\n",
    "## current age at which to consider the sample already loaded in previous release\n",
    "maxage = '2020-11-01'\n",
    "\n",
    "## genomic annotations (v35)\n",
    "gencode = 'ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/gencode.v35.annotation.gff3.gz'\n",
    "replace = {'T': 'Tumor', 'N': 'Normal', 'm': 'Unknown', 'L': 'Unknown'}\n",
    "\n",
    "# Terra workflow names\n",
    "RNAmethods = ['']\n",
    "\n",
    "#fusion data\n",
    "fusionSamplecol = \"DepMap_ID\"\n",
    "fusionCountCol = \"CCLE_count\"\n",
    "\n",
    "## version 102\n",
    "ensemblserver = \"http://nov2020.archive.ensembl.org/biomart\" \n",
    "datatype = 'rna'\n",
    "\n",
    "# USER SPECIFIC\n",
    "\n",
    "my_id = '~/.client_secret.json'\n",
    "mystorage_id = \"~/.storage.json\"\n",
    "\n",
    "## do the first steps of https://medium.com/craftsmenltd/from-csv-to-google-sheet-using-python-ef097cb014f9\n",
    "creds = '../.credentials.json'\n",
    "sheets = Sheets.from_files(my_id, mystorage_id)\n",
    "\n",
    "## lines that have issues\n",
    "toraise = [\"ACH-001195\"]\n",
    "previousQCfail = ['CDS-12DTEw', 'CDS-9hv1zM', 'CDS-A6GSeQ', 'CDS-aWlMRt', 'CDS-B1ywOH', 'CDS-BixxtG', 'CDS-DRM3l2', 'CDS-jOlYT4', 'CDS-KMhiT9', 'CDS-M6mnMA', 'CDS-pYwECX', 'CDS-v6E624', 'CDS-vxTqNJ', 'CDS-YxtmkI',\"CDS-fk564T\",\"CDS-kU30H5\",\"CDS-G0F5f5\",\"CDS-ABH0uZ\"]\n",
    "\n",
    "colstoclean = ['fastq1', 'fastq2','recalibrated_bam','recalibrated_bam_index']\n",
    "\n",
    "# CCLE SPECIFIC\n",
    "\n",
    "## old GP storage buckets\n",
    "workspace2=\"broad-firecloud-ccle/CCLE_DepMap_RNAseq\"\n",
    "workspace4=\"broad-genomics-delivery/Cancer_Cell_Line_Factory_CCLF_RNAseq\"\n",
    "workspace5=\"nci-mimoun-bi-org/CCLF_RNA_2_0\"\n",
    "workspace3=\"broad-genomics-delivery/CCLE_DepMap_RNAseq\"\n",
    "workspace1=\"broad-genomics-delivery/Getz_IBM_CellLines_RNASeqData\"\n",
    "\n",
    "## curent GP buckets\n",
    "workspace6=\"terra-broad-cancer-prod/CCLE_DepMap_RNAseq\"\n",
    "workspace7=\"terra-broad-cancer-prod/Getz_IBM_CellLines_RNASeqData\"\n",
    "\n",
    "## and their correesponding sample source\n",
    "source1=\"ibm\"\n",
    "source2=\"ccle\"\n",
    "source3=\"ccle\"\n",
    "source4=\"cclf\"\n",
    "source5=\"cclf\"\n",
    "\n",
    "source6=\"ccle\"\n",
    "source7=\"ibm\"\n",
    "\n",
    "## our working workspace (reference)\n",
    "refworkspace=\"broad-firecloud-ccle/DepMap_hg38_RNAseq\"\n",
    "\n",
    "## info/metadata google spreadsheets (info about cell lines)\n",
    "refsheet_url = \"https://docs.google.com/spreadsheets/d/1Pgb5fIClGnErEqzxpU7qqX6ULpGTDjvzWwDN8XUJKIY\"\n",
    "privacy_release_url = \"https://docs.google.com/spreadsheets/d/115TUgA1t_mD32SnWAGpW9OKmJ2W5WYAOs3SuSdedpX4\"\n",
    "depmap_pv = \"https://docs.google.com/spreadsheets/d/1uqCOos-T9EMQU7y2ZUw4Nm84opU5fIT1y7jet1vnScE\"\n",
    "depmap_taiga = \"arxspan-cell-line-export-f808\"\n",
    "\n",
    "sampletrackername='ccle sample tracker'\n",
    "## values we need to rename from the GP workspaces\n",
    "extract_to_change = {'from_arxspan_id': 'participant'}\n",
    "\n",
    "## things to match to from the GP workspaces\n",
    "match = ['ACH-','CDS-']\n",
    "\n",
    "## taiga to test\n",
    "tocompare = {\"genes_expected_count\":\"CCLE_RNAseq_reads\", \"genes_tpm\":\"CCLE_expression_full\", \"proteincoding_genes_tpm\":\"CCLE_expression\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate sample set from new samples\n",
    "\n",
    "we retrieve all the samples we can find from the GP workspaces\n",
    "\n",
    "__CCLE specific__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isCCLE:\n",
    "    print(\"loading new RNAseq data\")\n",
    "    samples = loading.loadRNA(samplesetname,workspaces=[workspace6, workspace7],sources=[\"ccle\", \"ibm\"],maxage=maxage, baits='polyA', stype=\"rna\", toraise=toraise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isCCLE:\n",
    "    print(\"uploading samples to the tracker and Terra\")\n",
    "    loading.update(samples, samplesetname, stype=\"rna\", bucket=\"\", refworkspace,\n",
    "          name_col=\"index\", values=['legacy_bam_filepath', 'legacy_bai_filepath'],\n",
    "          filetypes=['bam', 'bai'],\n",
    "          my_id=my_id,\n",
    "          mystorage_id=mystorage_id,\n",
    "          creds=creds,\n",
    "          sampletrackername=sampletrackername, refsheet_url=refsheet_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the pipeline\n",
    "\n",
    "We are using Dalmatian to send request to Terra, we are running a set of 6 functions To generate the expression/fusion dataset:\n",
    "\n",
    "We use the GTEx pipeline ([https://github.com/broadinstitute/gtex-pipeline/blob/v9/TOPMed_RNAseq_pipeline.md](https://github.com/broadinstitute/gtex-pipeline/blob/v9/TOPMed_RNAseq_pipeline.md)).\n",
    "\n",
    "To generate the expression dataset, run the following tasks on all samples that you need, in this order:\n",
    "\n",
    "\n",
    "\n",
    "*   samtofastq_v1-0_BETA_cfg \n",
    "\n",
    "    (broadinstitute_gtex/samtofastq_v1-0_BETA Snapshot ID: 5)\n",
    "\n",
    "*   star_v1-0_BETA_cfg\n",
    "\n",
    "(broadinstitute_gtex/star_v1-0_BETA Snapshot ID: 7)\n",
    "\n",
    "\n",
    "\n",
    "*   rsem_v1-0_BETA_cfg \n",
    "\n",
    "    (broadinstitute_gtex/rsem_v1-0_BETA Snapshot ID: 4)\n",
    "\n",
    "*   rsem_aggregate_results_v1-0_BETA_cfg (broadinstitute_gtex/rsem_aggregate_results_v1-0_BETA Snapshot ID: 3)\n",
    "\n",
    "The outputs to be downloaded will be saved under the sample set that you ran. The outputs we use for the release are:\n",
    "\n",
    "\n",
    "\n",
    "*   rsem_genes_expected_count\n",
    "*   rsem_genes_tpm\n",
    "*   rsem_transcripts_tpm\n",
    "\n",
    "****Make sure that you delete the intermediate files. These files are quite large so cost a lot to store. To delete, you can either write a task that deletes them or use gsutil rm*****\n",
    "\n",
    "\n",
    "##### Fusions {#fusions}\n",
    "\n",
    "We use STAR-Fusion [https://github.com/STAR-Fusion/STAR-Fusion/wiki](https://github.com/STAR-Fusion/STAR-Fusion/wiki). The fusions are generated by running the following tasks\n",
    "\n",
    "\n",
    "\n",
    "*   hg38_STAR_fusion (gkugener/STAR_fusion Snapshot ID: 14)\n",
    "*   Aggregate_Fusion_Calls (gkugener/Aggregate_files_set Snapshot ID: 2)\n",
    "\n",
    "The outputs to be downloaded will be saved under the sample set you ran. The outputs we use for the release are: \n",
    "\n",
    "\n",
    "\n",
    "*   fusions_star\n",
    "\n",
    "This task uses the same samtofastq_v1-0_BETA_cfg task as in the expression pipeline, although in the current implementation, this task will be run twice. It might be worth combing the expression/fusion calling into a single workflow. This task also contains a flag that lets you specify if you want to delete the intermediates (fastqs). \n",
    "\n",
    "There are several other tasks in this workspace. In brief:\n",
    "\n",
    "\n",
    "\n",
    "*   Tasks prefixed with **EXPENSIVE** or **CHEAP** are identical to their non-prefixed version, except that they specify different memory, disk space, etc. parameters. These versions can be used when samples fail the normal version of the task due to memory errors.\n",
    "*   The following tasks are part of the GTEx pipeline but we do not use them (we use RSEM exclusively): markduplicates_v1-0_BETA_cfg (broadinstitute_gtex/markduplicates_v1-0_BETA Snapshot ID: 2), rnaseqc2_v1-0_BETA_cfg (broadinstitute_gtex/rnaseqc2_v1-0_BETA Snapshot ID: 2)\n",
    "*   **ExonUsage_hg38_fixed** (gkugener/ExonUsage_fixed Snapshot ID: 1): this task calculates exon usage ratios. The non-fixed version contains a bug in the script that is not able to handle chromosome values prefixed with ‘chr’. The ‘fixed’ version resolves this issue.\n",
    "*   **AggregateExonUsageRObj_hg38** (ccle_mg/AggregateExonUsageRObj Snapshot ID: 2): combines the exon usage ratios into a matrices that are saved in an R object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doCleanup:\n",
    "    print(\"cleaning workspaces\")\n",
    "    torm = asyncio.run(terra.deleteHeavyFiles(refworkspace))\n",
    "    h.parrun(['gsutil rm '+i for i in torm], cores=8)\n",
    "    terra.removeFromFailedWorkflows(refworkspace, dryrun=False, everythingFor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Terra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update with latest workspace parameters from our repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"running Terra pipeline\")\n",
    "\n",
    "submission_id = refwm.create_submission(\"RNA_pipeline\", samplesetname,'sample_set',expression='this.samples')\n",
    "asyncio.run(terra.waitForSubmission(refworkspace, submission_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id = refwm.create_submission(\"RNA_aggregate\", 'all')\n",
    "asyncio.run(terra.waitForSubmission(refworkspace, submission_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the workflow configurations used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.saveWorkspace(refworkspace,'data/'+samplesetname+'/RNAconfig/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load QC files and generate a QC report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"load QC and generate QC report\")\n",
    "samplesinset= [i['entityName'] for i in refwm.get_entities('sample_set').loc[samplesetname].samples]\n",
    "\n",
    "qcs, lowqual, failed = myQC.plot_rnaseqc_results(refworkspace, samplesinset, output_path=\"data/\"+samplesetname+\"rna_qcs/\")\n",
    "\n",
    "failed = failed.index.tolist()\n",
    "print('you want to copy that up top, to save it for next time',failed)\n",
    "failed.extend(previousQCfail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solve QC fails when possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = postrna.solveQC(ccle_refsamples, failed)\n",
    "%store rnafailed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove some datafile to save money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doCleanup:\n",
    "    print(\"cleaninp up data\")\n",
    "    res = refwm.get_samples()\n",
    "    for val in colstoclean:\n",
    "        refwm.disable_hound().delete_entity_attributes('sample', res[val], delete_files=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expression post processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generating gene names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"generating gene names\")\n",
    "gene_rename, protcod_rename, ensembltohgnc = postrna.generateGeneNames(ensemble_server=ensemblserver, cached=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loading files\")\n",
    "def rn(r):\n",
    "    renaming = tracker.removeOlderVersions(names=r, refsamples=refwm.get_samples(), arxspan_id=\"arxspan_id\", version=\"version\")\n",
    "    # if we have a replaceable failed version in our dataset\n",
    "    for k, v in renaming.items():\n",
    "        if k in rename:\n",
    "            renaming[rename[k]] = renaming.pop(k)\n",
    "    return renaming\n",
    "files, renaming = postrna.loadFromRSEMaggregate(refwm, ccle_refsamples, renameFunc=rn, filenames=[\"transcripts_tpm\", \"genes_tpm\", \"genes_expected_count\", \"transcripts_expected_count\"],  sampleset=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### renaming the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"renaming files\")\n",
    "# gene level\n",
    "files = postrna.subsetGenes(files, gene_rename, filenames = ['rsem_genes_expected_count', 'rsem_genes_tpm'], drop=\"transcript_id\", index=\"gene_id\")\n",
    "\n",
    "files = postrna.extractProtCod(files, ensembltohgnc[ensembltohgnc.gene_biotype == 'protein_coding'], protcod_rename, filenames=['rsem_genes_expected_count', 'rsem_genes_tpm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript level\n",
    "files = postrna.subsetGenes(files, gene_rename, filenames = ['rsem_transcripts_expected_count', 'rsem_transcripts_tpm'], drop=\"gene_id\", index=\"transcript_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isCCLE:\n",
    "    print(\"doing validation\")\n",
    "    prevcounts = tc.get(name='depmap-a0ab', file='CCLE_RNAseq_reads')\n",
    "    nonoverlap = set(prevcounts.columns) ^ set(files['genes_expected_count'].columns)\n",
    "    print(\"number of non overlaping genes:\")\n",
    "    print(len(nonoverlap))\n",
    "    # have we lost any samples compared to last release?\n",
    "    lost = set(prevcounts.index) - set(files['genes_expected_count'].index)\n",
    "    print(\"of which, lost genes:\")\n",
    "    print(lost)\n",
    "    # do we have samples that are missanotated compared to previous releases (replicate level)\n",
    "    #notindataset, missannotated, unmatched = findMissAnnotatedReplicates(replevel, prevcounts, renaming)\n",
    "    #for k,v in unmatched.items():\n",
    "    #    if ccle_refsamples.loc[k].arxspan_id!=v:\n",
    "    #        print(k,v)\n",
    "    # do we have samples that are missanotated compared to previous releases (sample level)\n",
    "    unmatched = rna.getDifferencesFromCorrelations(files['genes_expected_count'] ,prevcounts, minsimi=0.95)\n",
    "    print(\"differences in correlations against the previous release\")\n",
    "    print(unmatched)\n",
    "    # Is it because of  duplicate version?\n",
    "    print('do we see it as a duplicate in the tracker?')\n",
    "    rnasamples = ccle_refsamples[ccle_refsamples.datatype=='rna']\n",
    "    for i,val in unmatched:\n",
    "        print(len(rnasamples[rnasamples.arxspan_id==i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ssGSEA using R's console and GSVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"doing ssGSEA\")\n",
    "enrichments = asyncio.run(postrna.ssGSEA(files['genes_tpm']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save files for taiga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isCCLE:    \n",
    "    #CCLE_expression, CCLE_expression_full, , \n",
    "    print(\"comparing to previous release\")\n",
    "    #h.compareDfs(files[\"rsem_transcripts_tpm\"], tc.get(name='depmap-a0ab', file='CCLE_RNAseq_transcripts'))\n",
    "    #h.compareDfs(files[\"rsem_transcripts_expected_count\"], tc.get(name='depmap-a0ab', file='CCLE_expression_transcripts_expected_count'))\n",
    "    # h.compareDfs(enrichments, tc.get(name='depmap-a0ab', file='CCLE_fusions_unfiltered'))\n",
    "    for key, val in tocompare.items():\n",
    "        _, omissmatchCols, _,omissmatchInds, newNAs, new0s = h.compareDfs(files[key], tc.get(name='depmap-a0ab', file=val))\n",
    "        print(key)\n",
    "        assert omissmatchCols==0\n",
    "        assert omissmatchInds==0\n",
    "        assert newNAs==0\n",
    "        assert new0s==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"saving files\")\n",
    "enrichments.to_csv('temp/gene_sets_'+samplesetname+'_all.csv')\n",
    "postrna.saveFiles(files, release)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isCCLE:\n",
    "    print(\"updating the tracker\")\n",
    "    ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame(index_col=0)\n",
    "    postrna.updateTracker(refworkspace, \n",
    "                          selected=set(renaming.keys())-set(['transcript_id(s)']),\n",
    "                          lowqual=lowqual[lowqual.sum(1)>3].index.tolist()\n",
    "                          ccle_refsamples, samplesinset, sheetname=sampletrackername, sheetcreds=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filenames = os.listdir(\"temp/expression_$release*\n",
    "#files = {}\n",
    "#for val in filenames:\n",
    "#    #h.compareDfs(val, tc.get(name='depmap-a0ab', file=k))\n",
    "#    files[val.replace('temp/expression_'+release, 'rsem')\n",
    "#          [:-4]] = pd.read_csv(val, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refwm = dm.WorkspaceManager(refworkspace)\n",
    "fusions = pd.read_csv(refwm.get_sample_sets().loc['all']['fusions_star'], names=[fusionSamplecol, 'FusionName', 'JunctionReadCount', 'SpanningFragCount', 'SpliceType', 'LeftGene', 'LeftBreakpoint', 'RightGene', 'RightBreakpoint', 'LargeAnchorSupport', 'FFPM', 'LeftBreakDinuc', 'LeftBreakEntropy', 'RightBreakDinuc', 'RightBreakEntropy','annots'], skiprows=1, sep='\\t')\n",
    "fusions[fusionSamplecol] = [i.split('.')[0] for i in fusions[fusionSamplecol]]\n",
    "print(len(fusions))\n",
    "print(fusions[fusionSamplecol][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions.RightGene = fusion.renameFusionGene(fusions.RightGene)\n",
    "fusions.LeftGene = fusion.renameFusionGene(fusions.LeftGene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions[['LeftGene', 'RightGene']] = fusions[['LeftGene', 'RightGene']].applymap(lambda x: re.sub(r'([^\\^]+)\\^(.*)$', r'\\1 (\\2)', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions.to_csv('temp/fusions_withReplicates_'+release+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fusions = pd.read_csv('temp/fusions_withReplicates_'+release+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate filtered fusion table\n",
    "\n",
    "We want to apply filters to the fusion table to reduce the number of artifacts in the dataset. Specifically, we filter the following:\n",
    "\n",
    "* Remove fusions involving mitochondrial chromosomes, or HLA genes, or immunoglobulin genes\n",
    "* Remove red herring fusions (from STAR-Fusion annotations column)\n",
    "* Remove recurrent in CCLE (>= 25 samples)\n",
    "* Remove fusion with (SpliceType=\" INCL_NON_REF_SPLICE\" and LargeAnchorSupport=\"No\" and FFPM < 0.1)\n",
    "* Remove fusions with FFPM < 0.05 (STAR-Fusion suggests using 0.1, but looking at the translocation data, this looks like it might be too aggressive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isCCLE:\n",
    "    renaming = tracker.removeOlderVersions(names=set(fusions[fusionSamplecol]), refsamples=refwm.get_samples(), arxspan_id=\"arxspan_id\", version=\"version\")\n",
    "    fusions = fusions[fusions[fusionSamplecol].isin(renaming.keys())].replace({fusionSamplecol:renaming}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions[fusionCountCol] = [i.LeftBreakpoint+'_'+i.RightBreakpoint for k, i in fusions.iterrows()]\n",
    "counts = Counter(list(fusions[fusionCountCol]))\n",
    "fusions[fusionCountCol] = [counts[val] for val in fusions[fusionCountCol]]\n",
    "sns.kdeplot(fusions[fusionCountCol] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = fusion.filterFusions(fusions, maxfreq=0.1)\n",
    "len(set(fusions['fusionSamplecol']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame(index_col=0)\n",
    "normals = ccle_refsamples[ccle_refsamples['primary_disease']=='normal'].index.tolist()\n",
    "#fusions = fusions[~fusions['fusionSamplecol']isin(normals)]\n",
    "#filtered = filtered[~filtered['fusionSamplecol']isin(normals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = tc.get(name='depmap-a0ab', file='CCLE_fusions_unfiltered')\n",
    "print('new')\n",
    "print(set(fusions[fusionSamplecol]) - set(prev[fusionSamplecol]))\n",
    "\n",
    "print('removed')\n",
    "print(set(prev[fusionSamplecol]) - set(fusions[fusionSamplecol]))\n",
    "\n",
    "print(\"changes in fusion names\")\n",
    "pf = prev.copy()\n",
    "pf[\"id\"] = pf[fusionSamplecol]+\"_\"+pf[\"FusionName\"]\n",
    "f = fusions.copy()\n",
    "f[\"id\"] = f[fusionSamplecol]+\"_\"+f[\"FusionName\"]\n",
    "print(len(set(pf[~pf.id.isin(f.id.tolist())][fusionSamplecol])))\n",
    "\n",
    "print(\"changes in junction readd counts\")\n",
    "f[\"sid\"] = f[fusionSamplecol]+\"_\"+f[\"FusionName\"] + \"_\"+ f[\"JunctionReadCount\"].astype(str)\n",
    "pf[\"sid\"] = pf[fusionSamplecol]+\"_\"+pf[\"FusionName\"] + \"_\"+ pf[\"JunctionReadCount\"].astype(str)\n",
    "print(len(set(pf[~pf.sid.isin(f.sid.tolist())][fusionSamplecol])))\n",
    "\n",
    "print(\"in fusion, not in rna\")\n",
    "print(set(fusions[fusionSamplecol]) - set(files['proteincoding_genes_tpm'].index))\n",
    "print('in depmap, not in fusions')\n",
    "print(set(files['proteincoding_genes_tpm'].index) - set(fusions[fusionSamplecol]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = filtered.drop(columns=\"id\")\n",
    "fusions = fusions.drop(columns=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions.to_csv('temp/fusions_'+release+'.csv',index=False)\n",
    "filtered.to_csv('temp/filtered_fusions_'+release+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions = pd.read_csv('temp/fusions_'+release+'.csv')\n",
    "filtered = pd.read_csv('temp/filtered_fusions_'+release+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading to Taiga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.update_dataset(dataset_permaname=\"fusions-95c9\",\n",
    "                  changes_description=\"new \"+samplesetname+\" release!\",\n",
    "                  upload_files=[\n",
    "                    {\n",
    "                        \"path\": 'temp/fusions_'+release+'.csv',\n",
    "                        \"format\": \"TableCSV\",\n",
    "                        \"encoding\": \"utf-8\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"path\": 'temp/filtered_fusions_'+release+'.csv',\n",
    "                        \"format\": \"TableCSV\",\n",
    "                        \"encoding\": \"utf-8\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"path\": \"temp/fusions_withReplicates_\"+release+\".csv\",\n",
    "                        \"format\": \"TableCSV\",\n",
    "                        \"encoding\": \"utf-8\"\n",
    "                    },\n",
    "                 ],\n",
    "                 dataset_description=\"\"\"\n",
    "# Fusions\n",
    "\n",
    "PORTAL TEAM SHOULD NOT USE THIS: There are lines here that should not make it even to internal.\n",
    "\n",
    "/!\\ This is the most up to date version of the CCLE CN data.\n",
    "\n",
    "## Annotations\n",
    "\n",
    "Description: Gene fusions derived from RNAseq data.\n",
    "\n",
    "Rows: cell lines, IDs contained in the column DepMap_ID\n",
    "\n",
    "Unfiltered data contains all output fusions, while the filtered data uses the filters suggested by the star fusion docs. These filters are:\n",
    "- FFPM > 0.1 -  a cutoff of 0.1 means&nbsp;at least 1 fusion-supporting RNAseq fragment per 10M total reads\n",
    "- Remove known false positives, such as GTEx recurrent fusions and certain paralogs\n",
    "- Genes that are next to each other\n",
    "- Fusions with mitochondrial breakpoints\n",
    "- Removing fusion involving mitochondrial chromosomes or HLA genes\n",
    "- Removed common false positive fusions (red herring annotations as described in the STAR-Fusion docs)\n",
    "- Recurrent fusions observed in CCLE across cell lines (in more than 10% of our samples)\n",
    "- Removed fusions where SpliceType='INCL_NON_REF_SPLICE' and LargeAnchorSupport='NO_LDAS' and FFPM < 0.1\n",
    "- FFPM < 0.05\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.update_dataset(changes_description=\"new \"+samplesetname+\" release!\",\n",
    "                dataset_permaname=\"expression-d035\",\n",
    "                upload_files=[\n",
    "                    {\n",
    "                        \"path\": \"temp/expression_\"+samplesetname+\"_proteincoding_tpm_logp1.csv\",\n",
    "                        \"format\": \"NumericMatrixCSV\",\n",
    "                        \"encoding\": \"utf-8\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"path\": \"temp/expression_\"+samplesetname+\"_transcripts_tpm_logp1.csv\",\n",
    "                        \"format\": \"NumericMatrixCSV\",\n",
    "                        \"encoding\": \"utf-8\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"path\": \"temp/expression_\"+samplesetname+\"_genes_tpm_logp1.csv\",\n",
    "                        \"format\": \"NumericMatrixCSV\",\n",
    "                        \"encoding\": \"utf-8\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"path\": \"temp/expression_\"+samplesetname+\"_genes_tpm.csv\",\n",
    "                        \"format\": \"NumericMatrixCSV\",\n",
    "                        \"encoding\": \"utf-8\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"path\": \"temp/expression_\"+samplesetname+\"_transcripts_tpm.csv\",\n",
    "                        \"format\": \"NumericMatrixCSV\",\n",
    "                        \"encoding\": \"utf-8\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"path\": \"temp/expression_\"+samplesetname+\"_proteincoding_tpm.csv\",\n",
    "                        \"format\": \"NumericMatrixCSV\",\n",
    "                        \"encoding\": \"utf-8\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"path\": \"temp/expression_\"+samplesetname+\"_transcripts_expectedcount.csv\",\n",
    "                        \"format\": \"NumericMatrixCSV\",\n",
    "                        \"encoding\": \"utf-8\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"path\": \"temp/expression_\"+samplesetname+\"_proteincoding_expectedcount.csv\",\n",
    "                        \"format\": \"NumericMatrixCSV\",\n",
    "                        \"encoding\": \"utf-8\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"path\": \"temp/expression_\"+samplesetname+\"_genes_expectedcount.csv\",\n",
    "                        \"format\": \"NumericMatrixCSV\",\n",
    "                        \"encoding\": \"utf-8\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"path\": 'temp/gene_sets_'+samplesetname+'_all.csv',\n",
    "                        \"format\": \"NumericMatrixCSV\",\n",
    "                        \"encoding\": \"utf-8\"\n",
    "                    },\n",
    "                 ],\n",
    "                upload_async=False,\n",
    "                add_all_existing_files=True,\n",
    "                dataset_description=\n",
    "\"\"\"\n",
    "# RNAseq\n",
    "\n",
    "PORTAL TEAM SHOULD NOT USE THIS: There are lines here that should not make it even to internal.\n",
    "\n",
    "/!\\ This is the most up to date version of the CCLE RNA data.\n",
    "\n",
    "## Annotations:\n",
    "\n",
    "transcriptions (Transcripts rpkm):\n",
    "\n",
    "genes (gene rpkm):\n",
    "__Rows__:\n",
    "__Columns__:\n",
    "Counts (gene counts):\n",
    "__Rows__:\n",
    "__Columns__:\n",
    "Gene level CN data:\n",
    "__Rows__:\n",
    "__Columns__:\n",
    " DepMap cell line IDs\n",
    " gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "DepMap\\_ID, Chromosome, Start, End, Num\\_Probes, Segment\\_Mean\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "222.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
