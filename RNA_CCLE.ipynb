{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from src.CCLE_postp_function import *\n",
    "from JKBio import Datanalytics as da \n",
    "from JKBio import TerraFunction as terra\n",
    "from JKBio import Helper as h\n",
    "from JKBio.helper.google_sheet import GSheet\n",
    "from gsheets import Sheets\n",
    "from taigapy import TaigaClient\n",
    "import dalmatian as dm\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from bokeh.plotting import *\n",
    "from bokeh.models import HoverTool\n",
    "from collections import OrderedDict\n",
    "from IPython.display import Image,display\n",
    "import seaborn as sns\n",
    "\n",
    "from biomart import BiomartServer\n",
    "import io\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext rpy2.ipython\n",
    "tc = TaigaClient()\n",
    "output_notebook()\n",
    "\n",
    "my_id = '~/.client_secret.json'\n",
    "mystorage_id = \"~/.storage.json\"\n",
    "sheets = Sheets.from_files(my_id, mystorage_id)\n",
    "replace = {'T': 'Tumor', 'N': 'Normal', 'm': 'Unknown', 'L': 'Unknown'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesetname=\"20Q4\"\n",
    "prevname=\"20Q3\"\n",
    "prevversion=14 #TOTAL\n",
    "prevprevname = \"20Q2\"\n",
    "prevprevversion=22 #INTERNAL\n",
    "virtual_public='public-20q3-3d35'\n",
    "virtual_dmc='dmc-20q3-033d'\n",
    "virtual_internal='internal-20q3-00d0'\n",
    "\n",
    "workspace2=\"broad-firecloud-ccle/CCLE_DepMap_RNAseq\"\n",
    "workspace4=\"broad-genomics-delivery/Cancer_Cell_Line_Factory_CCLF_RNAseq\"\n",
    "workspace5=\"nci-mimoun-bi-org/CCLF_RNA_2_0\"\n",
    "\n",
    "workspace3=\"broad-genomics-delivery/CCLE_DepMap_RNAseq\"\n",
    "workspace1=\"broad-genomics-delivery/Getz_IBM_CellLines_RNASeqData\"\n",
    "\n",
    "workspace6=\"terra-broad-cancer-prod/CCLE_DepMap_RNAseq\"\n",
    "workspace7=\"terra-broad-cancer-prod/Getz_IBM_CellLines_RNASeqData\"\n",
    "\n",
    "refworkspace=\"broad-firecloud-ccle/DepMap_hg38_RNAseq\"\n",
    "source1=\"ibm\"\n",
    "source2=\"ccle\"\n",
    "source3=\"ccle\"\n",
    "source4=\"cclf\"\n",
    "source5=\"cclf\"\n",
    "source6=\"ccle\"\n",
    "source7=\"ibm\"\n",
    "release = samplesetname\n",
    "\n",
    "refsheet_url = \"https://docs.google.com/spreadsheets/d/1XkZypRuOEXzNLxVk9EOHeWRE98Z8_DBvL4PovyM01FE\"\n",
    "privacy_release_url = \"https://docs.google.com/spreadsheets/d/115TUgA1t_mD32SnWAGpW9OKmJ2W5WYAOs3SuSdedpX4\"\n",
    "\n",
    "gencode = 'ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/gencode.v35.annotation.gff3.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "genome_version <- 'hg38'\n",
    "release <- '20Q2'\n",
    "hg38_cyto_band_reference <- '../JKBio/data/hg38_cytoband.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate sample set from new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_to_change = {'from_arxspan_id': 'participant',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm1 = dm.WorkspaceManager(workspace1)\n",
    "#wm2 = dm.WorkspaceManager(workspace2)\n",
    "#wm3 = dm.WorkspaceManager(workspace3)\n",
    "#wm4 = dm.WorkspaceManager(workspace4)\n",
    "#wm5 = dm.WorkspaceManager(workspace5)\n",
    "wm6 = dm.WorkspaceManager(workspace6)\n",
    "wm7 = dm.WorkspaceManager(workspace7)\n",
    "refwm = dm.WorkspaceManager(refworkspace).disable_hound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = sheets.get(refsheet_url).sheets[0].to_frame().set_index('cds_sample_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be missing \"primary disease\",\"sm_id\", \"cellosaurus_id\", \"gender, \"age\", \"primary_site\", \"primary_disease\", \"subtype\", \"subsubtype\", \"origin\", \"comments\"\n",
    "#when SMid: match==\n",
    "samples, pairs, noarxspan = GetNewCellLinesFromWorkspaces(refworkspace, stype='rna', refurl=refsheet_url, wmfroms = [workspace1, workspace6, workspace7], sources=[source1,source6, source7], match=['ACH-','CDS-'], participantslicepos=10, accept_unknowntypes=True, extract=extract_to_change, recomputedate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noarxspan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noarxspan.to_csv('temp/noarxspan_rna_'+release+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noarxspan.arxspan_id = [ccle_refsamples[ccle_refsamples.stripped_cell_line_name==i].arxspan_id[0] if i in ccle_refsamples.stripped_cell_line_name.tolist() else 0 for i in noarxspan.arxspan_id]\n",
    "a = [ccle_refsamples[ccle_refsamples.stripped_cell_line_name==i].arxspan_id[0] if i in ccle_refsamples.stripped_cell_line_name.tolist() else 0 for i in noarxspan.stripped_cell_line_name] \n",
    "noarxspan.arxspan_id = [i if i!=0 else a[e] for e,i in enumerate(noarxspan.arxspan_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depmap_pv = depmap_pv.drop(depmap_pv.iloc[:2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depmap_pv = sheets.get(\"https://docs.google.com/spreadsheets/d/1uqCOos-T9EMQU7y2ZUw4Nm84opU5fIT1y7jet1vnScE\").sheets[0].to_frame(header=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,val in noarxspan[noarxspan.arxspan_id==0].iterrows():\n",
    "    val = ''.join(''.join(''.join(val.stripped_cell_line_name.split('-')).split('_')[:-1]).split('.')).upper()\n",
    "    a = depmap_pv[depmap_pv.CCLE_name.str.contains(val) | depmap_pv['Stripped Cell Line Name'].str.contains(val) | depmap_pv.Aliases.str.contains(val)] \n",
    "    if len(a)>0:\n",
    "        noarxspan.loc[k,'arxspan_id'] = a.DepMap_ID[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noarxspan    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noarxspan.loc[noarxspan[noarxspan.arxspan_id==0].index,'arxspan_id']= ['ACH-001394']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noarxspan.loc[noarxspan[noarxspan.arxspan_id==0].index,'stripped_cell_line_name']= ['SUM229PE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noarxspan[noarxspan.arxspan_id==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noarxspan = resolveFromWorkspace(noarxspan, refsamples = ccle_refsamples[ccle_refsamples['datatype'] == 'rna'], match = ['ACH','CDS'], participantslicepos = 10, accept_unknowntypes = True, extract = extract_to_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noarxspan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.concat([samples, noarxspan], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = assessAllSamples(samples, ccle_refsamples, stype='rna', rename={}, extract={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting the addtional data and writing it here in the right order 'as shown above'\n",
    "- use the stripped_cell_line_name to find the samples on https://docs.google.com/spreadsheets/d/1uqCOos-T9EMQU7y2ZUw4Nm84opU5fIT1y7jet1vnScE/edit#gid=356471436. \n",
    "- Make sure that we don't have duplicate cell lines in there. Otherwise, use the duplicate renaming function\n",
    "- copy Primary Site, Primary Disease, Subtype, Comments, Disease Sub-subtype, if they exist. (sometimes subtype and subsubtype are the same.. don't use subsubtype then.\n",
    "- look for the cell line in cellosaurus, you might need to use one of the aliases given in master depmap pv..\n",
    "- copy  cellosaurus_id gender age info or write 'U' if they don't exist. 'can be a number or {Embryonic, Children, Adult, Fetus, U} \n",
    "- check that it does not say this cell line is not a duplicate from another cell line\n",
    "- check that if it says this cell line is derived/children/father/samepatient from other cell lines, and that if we have any of the other cell lines, that the patient id is changed to be the same one for all (be sure that you are updating everywhere these patient ids are used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If I have a previous samples I can update unknown data directly\n",
    "index=[]\n",
    "notfound=[]\n",
    "toupdate = {\"sex\":[],\n",
    "\"primary_disease\":[],\n",
    "\"cellosaurus_id\":[],\n",
    "\"age\":[],\n",
    "\"primary_site\":[],\n",
    "\"subtype\":[],\n",
    "\"subsubtype\":[],\n",
    "\"comments\":[],\n",
    "\"stripped_cell_line_name\":[],\n",
    "\"participant_id\":[]}\n",
    "for k, val in samples.iterrows():\n",
    "    dat = ccle_refsamples[ccle_refsamples['arxspan_id']==val['arxspan_id']]\n",
    "    if len(dat)>0:\n",
    "        index.append(k)\n",
    "        for k, v in toupdate.items():\n",
    "            toupdate[k].append(dat[k].tolist()[0])\n",
    "    else:\n",
    "        notfound.append(k)\n",
    "# doing so..\n",
    "for k, v in toupdate.items():\n",
    "    samples.loc[index,k] =v\n",
    "len(samples.loc[notfound].participant_id),samples.loc[notfound].participant_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for these samples I will need to check and manually add the data in the list \n",
    "samples.loc[notfound]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toupdate = {\n",
    "\"sex\":[\"Female\",\"Female\"],\n",
    "\"primary_disease\":[\"Lung Cancer\",\"Endometrial/Uterine Cancer\"],\n",
    "\"cellosaurus_id\":[\"CVCL_2410\",\"CVCL_E060\"],\n",
    "\"age\":['U',16],\n",
    "\"primary_site\":[\"bone_marrow\",\"haematopoietic_and_lymphoid_tissue\"],\n",
    "\"subtype\":[\"Small Cell Lung Cancer (SCLC)\",\"Mixed Uterine Adenocarcinoma and Rhabdomyosarcoma\"],\n",
    "\"subsubtype\":[\"\",''],\n",
    "\"comments\":[\"\",\"Mixed mesodermal tumor consists of adenocarcinoma and rhabdomyosarcoma. Cell growth is slow. fibroblast-like\"],\n",
    "\"participant_id\":[\"PT-Z2Fq3yte\",\"PT-OOZstzSA\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = pd.DataFrame(toupdate)\n",
    "a['name'] = samples.loc[notfound,\"stripped_cell_line_name\"].tolist()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating..\n",
    "for k, v in toupdate.items():\n",
    "    samples.loc[notfound,k] =v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploading to our bucket (now a new function)\n",
    "h.changeToBucket(samples,'gs://cclebams/rna/', name_col= \"index\" , values=['internal_bam_filepath','internal_bai_filepath'], filetypes=['bam', 'bai'], catchdup=True, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[]\n",
    "subccle_refsamples = ccle_refsamples[ccle_refsamples['datatype'] == \"rna\"]\n",
    "for k, val in samples.iterrows():\n",
    "    val = val[\"arxspan_id\"]\n",
    "    names.append(val)\n",
    "    samples.loc[k, 'version'] = len(subccle_refsamples[subccle_refsamples['arxspan_id'] == val]) + names.count(val)\n",
    "samples['version'] = samples['version'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that we have all the cell lines we expect for this release\n",
    "This involves comparing to the list in the Google sheet \"Cell Line Profiling Status.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function may not work - it hasn't been tested\n",
    "url = 'https://docs.google.com/spreadsheets/d/1qus-9TKzqzwUMNWp8S1QP4s4-3SsMo2vuQRZrNXf7ag'\n",
    "\n",
    "compareToCuratedGS(url, sample = samples, samplesetname = samplesetname, colname = 'RNA New to internal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = pd.read_csv('temp/updated_ref_samples.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if rsisks of older new samples::\n",
    "subccle_refsamples.sequencing_date = h.datetoint(subccle_refsamples.sequencing_date.values, split='/', order = \"asc\")\n",
    "for k, val in samples.iterrows():\n",
    "    loc = subccle_refsamples[subccle_refsamples.arxspan_id==val.arxspan_id]\n",
    "    if len(loc)>0:\n",
    "        if val.sequencing_date > 0:\n",
    "            for i, v in loc.iterrows():\n",
    "                if v.sequencing_date > val.sequencing_date:\n",
    "                    ccle_refsamples.loc[i,'version']+=1\n",
    "                    samples.loc[k, 'version']-=1\n",
    "        else:\n",
    "            if max(loc['size']) > val['size']:\n",
    "                samples.loc[k, 'version'] = 1\n",
    "                ccle_refsamples.loc[loc.index,'version'] = ccle_refsamples.loc[loc.index,'version'].values+1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = ccle_refsamples.append(samples, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'SHMAC4': ['CVCL_2722','Male']\n",
    "'C396':['CVCL_CW22','Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in samepatient:\n",
    "    sub = ccle_refsamples[ccle_refsamples.arxspan_id.isin(val)]\n",
    "    if len(set(sub.participant_id))>2:\n",
    "        print('we found a missig participant relationship')\n",
    "        # ccle_refsamples.loc[ccle_refsamples.index, \"participant_id\"]=sub.participant_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples.to_csv('temp/updated_ref_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uploading new samples\n",
    "refwm.upload_samples(samples)\n",
    "sam = refwm.get_samples()\n",
    "#creating a sample set\n",
    "refwm.update_sample_set(sample_set_id=samplesetname, sample_ids=samples.index)\n",
    "refwm.update_sample_set(sample_set_id='all', sample_ids=[i for i in sam.index.tolist() if i!='nan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the pipeline\n",
    "\n",
    "We are using Dalmatian to send request to Terra, we are running a set of 6 functions To generate the expression/fusion dataset:\n",
    "\n",
    "We use the GTEx pipeline ([https://github.com/broadinstitute/gtex-pipeline/blob/v9/TOPMed_RNAseq_pipeline.md](https://github.com/broadinstitute/gtex-pipeline/blob/v9/TOPMed_RNAseq_pipeline.md)).\n",
    "\n",
    "To generate the expression dataset, run the following tasks on all samples that you need, in this order:\n",
    "\n",
    "\n",
    "\n",
    "*   samtofastq_v1-0_BETA_cfg \n",
    "\n",
    "    (broadinstitute_gtex/samtofastq_v1-0_BETA Snapshot ID: 5)\n",
    "\n",
    "*   star_v1-0_BETA_cfg\n",
    "\n",
    "(broadinstitute_gtex/star_v1-0_BETA Snapshot ID: 7)\n",
    "\n",
    "\n",
    "\n",
    "*   rsem_v1-0_BETA_cfg \n",
    "\n",
    "    (broadinstitute_gtex/rsem_v1-0_BETA Snapshot ID: 4)\n",
    "\n",
    "*   rsem_aggregate_results_v1-0_BETA_cfg (broadinstitute_gtex/rsem_aggregate_results_v1-0_BETA Snapshot ID: 3)\n",
    "\n",
    "The outputs to be downloaded will be saved under the sample set that you ran. The outputs we use for the release are:\n",
    "\n",
    "\n",
    "\n",
    "*   rsem_genes_expected_count\n",
    "*   rsem_genes_tpm\n",
    "*   rsem_transcripts_tpm\n",
    "\n",
    "****Make sure that you delete the intermediate files. These files are quite large so cost a lot to store. To delete, you can either write a task that deletes them or use gsutil rm*****\n",
    "\n",
    "\n",
    "##### Fusions {#fusions}\n",
    "\n",
    "We use STAR-Fusion [https://github.com/STAR-Fusion/STAR-Fusion/wiki](https://github.com/STAR-Fusion/STAR-Fusion/wiki). The fusions are generated by running the following tasks\n",
    "\n",
    "\n",
    "\n",
    "*   hg38_STAR_fusion (gkugener/STAR_fusion Snapshot ID: 14)\n",
    "*   Aggregate_Fusion_Calls (gkugener/Aggregate_files_set Snapshot ID: 2)\n",
    "\n",
    "The outputs to be downloaded will be saved under the sample set you ran. The outputs we use for the release are: \n",
    "\n",
    "\n",
    "\n",
    "*   fusions_star\n",
    "\n",
    "This task uses the same samtofastq_v1-0_BETA_cfg task as in the expression pipeline, although in the current implementation, this task will be run twice. It might be worth combing the expression/fusion calling into a single workflow. This task also contains a flag that lets you specify if you want to delete the intermediates (fastqs). \n",
    "\n",
    "There are several other tasks in this workspace. In brief:\n",
    "\n",
    "\n",
    "\n",
    "*   Tasks prefixed with **EXPENSIVE** or **CHEAP** are identical to their non-prefixed version, except that they specify different memory, disk space, etc. parameters. These versions can be used when samples fail the normal version of the task due to memory errors.\n",
    "*   The following tasks are part of the GTEx pipeline but we do not use them (we use RSEM exclusively): markduplicates_v1-0_BETA_cfg (broadinstitute_gtex/markduplicates_v1-0_BETA Snapshot ID: 2), rnaseqc2_v1-0_BETA_cfg (broadinstitute_gtex/rnaseqc2_v1-0_BETA Snapshot ID: 2)\n",
    "*   **ExonUsage_hg38_fixed** (gkugener/ExonUsage_fixed Snapshot ID: 1): this task calculates exon usage ratios. The non-fixed version contains a bug in the script that is not able to handle chromosome values prefixed with ‘chr’. The ‘fixed’ version resolves this issue.\n",
    "*   **AggregateExonUsageRObj_hg38** (ccle_mg/AggregateExonUsageRObj Snapshot ID: 2): combines the exon usage ratios into a matrices that are saved in an R object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Terra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id = refwm.create_submission(\"samtofastq_v1-0_BETA_cfg\", samplesetname,'sample_set',expression='this.samples')\n",
    "terra.waitForSubmission(refworkspace, submission_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id = refwm.create_submission(\"star_v1-0_BETA_cfg\", samplesetname,'sample_set',expression='this.samples')\n",
    "terra.waitForSubmission(refworkspace, submission_id)\n",
    "submission_id = refwm.create_submission(\"markduplicates_v1-0_BETA_cfg\", samplesetname,'sample_set',expression='this.samples')\n",
    "terra.waitForSubmission(refworkspace, submission_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id3 = refwm.create_submission(\"hg38_STAR_fusion\", samplesetname,'sample_set',expression='this.samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.waitForSubmission(refworkspace, submission_id)\n",
    "submission_id2 = refwm.create_submission(\"rnaseqc2_v1-0_BETA_cfg\", samplesetname,'sample_set',expression='this.samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variant calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id4 = refwm.create_submission(\"rnaseq-germline-snps-indels\", samplesetname,'sample_set',expression='this.samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_id1 = refwm.create_submission(\"rsem_v1-0_BETA_cfg\", samplesetname,'sample_set',expression='this.samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#terra.waitForSubmission(refworkspace, [submission_id1])\n",
    "submission_id1 = refwm.create_submission(\"rsem_aggregate_results\", 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.waitForSubmission(refworkspace, [submission_id3])\n",
    "submission_id3 = refwm.create_submission(\"Aggregate_Fusion_Calls\", 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.waitForSubmission(refworkspace, [submission_id4])\n",
    "submission_id4 = refwm.create_submission(\"merge_vcfs\", 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.waitForSubmission(refworkspace, [submission_id4,submission_id3,submission_id2,submission_id1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = refwm.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the workflow configurations used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.saveConfigs(refworkspace,'data/'+samplesetname+'/RNAconfig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load QC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starlogs = getQC(workspace=refworkspace ,only=[], qcname=\"star_logs\",match=\".Log.final.out\")\n",
    "rnaqc = getQC(workspace=refworkspace ,only=[], qcname=\"rnaseqc2_metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,val in rnaqc.items():\n",
    "    if type(val[0]) is not str:\n",
    "        print(\"QC was not done for: \"+k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcs = pd.DataFrame()\n",
    "for k,val in rnaqc.items():\n",
    "    qcs = pd.concat([qcs, pd.read_csv(val[0],sep='\\t',index_col=0)],axis=1)\n",
    "qcs = qcs[~((qcs.mean(1)==1.0) | (qcs.mean(1)==0.0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowqual = h.filterRNAfromQC(qcs, thresholds={'minmapping': 0.85,\n",
    "                                          'minendmapping': 0.75,\n",
    "                                          'minefficiency': 0.75,\n",
    "                                          'maxendmismatch': 0.02,\n",
    "                                          'maxmismatch': 0.02,\n",
    "                                          'minhighqual': 0.8,\n",
    "                                          'minexon': 0.7,\n",
    "                                          \"maxambiguous\": 0.05,\n",
    "                                          \"maxsplits\": 0.1,\n",
    "                                          \"maxalt\": 0.2,\n",
    "                                          \"maxchim\": 0.05,\n",
    "                                          \"minreads\": 20000000,\n",
    "                                          \"minlength\": 80,\n",
    "                                          \"maxgenes\": 35000,\n",
    "                                          \"mingenes\": 12000,\n",
    "                                          }, folder='data/rna_qc_plots/lowqual_'+samplesetname+\"/\", plot=True, qant1=0.1, qant3=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = h.filterRNAfromQC(qcs, thresholds={'minmapping': 0.7,\n",
    "                                          'minendmapping': 0.66,\n",
    "                                          'minefficiency': 0.6,\n",
    "                                          'maxendmismatch': 0.02,\n",
    "                                          'maxmismatch': 0.02,\n",
    "                                          'minhighqual': 0.7,\n",
    "                                          'minexon': 0.66,\n",
    "                                          \"maxambiguous\": 0.1,\n",
    "                                          \"maxsplits\": 0.1,\n",
    "                                          \"maxalt\": 0.5,\n",
    "                                          \"maxchim\": 0.2,\n",
    "                                          \"minreads\": 20000000,\n",
    "                                          \"minlength\": 80,\n",
    "                                          \"maxgenes\": 35000,\n",
    "                                          \"mingenes\": 10000,\n",
    "                                          }, folder='data/rna_qc_plots/'+samplesetname+\"/\", plot=True, qant1=0.07, qant3=0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples = pd.read_csv('temp/updated_ref_samples.csv',index_col=\"cds_sample_id\")\n",
    "for k,v in starlogs.items():\n",
    "    if k =='nan':\n",
    "        continue\n",
    "    if ccle_refsamples.loc[k,'bam_qc']!=v[0]:\n",
    "        ccle_refsamples.loc[k,'bam_qc']=v[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove some datafile to save money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = refwm.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colstoremove = ['fastq1', 'fastq2','recalibrated_bam','recalibrated_bam_index']\n",
    "for val in colstoremove:\n",
    "    refwm.disable_hound().delete_entity_attributes('sample', res[val], delete_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesinset= [i['entityName'] for i in refwm.get_entities('sample_set').loc[samplesetname].samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## copy star bam file to our cclebams/rnasq_hg38/ bucket\n",
    "renamed, _ = terra.changeGSlocation(workspacefrom=refworkspace, newgs=\"gs://cclebams/rnasq_hg38/\", onlysamples=samplesinset, onlycol=[\"star_bam_file\",'star_bam_index'], entity=\"sample\", keeppath=False,dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples.loc[samplesinset,['legacy_bam_filepath','legacy_bai_filepath','legacy_size','legacy_crc32c_hash']] = ccle_refsamples.loc[samplesinset][['internal_bam_filepath','internal_bai_filepath','size','crc32c_hash']]\n",
    "ccle_refsamples.loc[samplesinset,'internal_bam_filepath'] = renamed['star_bam_file']\n",
    "ccle_refsamples.loc[samplesinset,'internal_bai_filepath'] = renamed['star_bam_index']\n",
    "ccle_refsamples.loc[samplesinset,'size'] = [gcp.extractSize(i)[1] for i in gcp.lsFiles(renamed['star_bam_file'].tolist(),'-l')]\n",
    "ccle_refsamples.loc[samplesinset,'crc32c_hash'] = [gcp.extractHash(i) for i in gcp.lsFiles(renamed['star_bam_file'].tolist(),'-L')]\n",
    "#ccle_refsamples.loc[samplesinset,'md5_hash'] = gcp.catFiles(renamed['hg38_analysis_ready_bam_md5'].tolist(), cut=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expression post processing\n",
    "\n",
    "Here we get all data and remove the duplicates directly with the function `removeDuplicates`\n",
    "\n",
    "we then run:\n",
    "\n",
    "- readTranscripts\n",
    "- readCounts\n",
    "- readTPM\n",
    "- renameFunction\n",
    "\n",
    "- Allie's gene renaming / filtering and log transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = refwm.get_sample_sets().loc['all']\n",
    "rsem_genes_expected_count = res['rsem_genes_expected_count']\n",
    "rsem_genes_tpm = res['rsem_genes_tpm']\n",
    "rsem_transcripts_tpm = res['rsem_transcripts_tpm']\n",
    "rsem_transcripts_expected_count = res['rsem_transcripts_expected_count']\n",
    "! gsutil cp $rsem_genes_expected_count \"temp/rsem_genes_expected_count\" & gsutil cp $rsem_genes_tpm \"temp/rsem_genes_tpm\" & gsutil cp $rsem_transcripts_tpm \"temp/rsem_transcripts_tpm\" & gsutil cp $rsem_transcripts_expected_count \"temp/rsem_transcripts_expected_count\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {}\n",
    "for val in [\"temp/rsem_transcripts_tpm\",\"temp/rsem_genes_tpm\", \"temp/rsem_genes_expected_count\",\"temp/rsem_transcripts_expected_count\"]:\n",
    "    file = pd.read_csv(val, compression='gzip', header=0, sep='\\t', quotechar='\"', error_bad_lines=False)\n",
    "    \n",
    "    print(file.columns[:10])\n",
    "    \n",
    "    file = file.drop(columns=set(failed.index))\n",
    "    renaming  = removeOlderVersions(names=file.columns[2:], refsamples=refwm.get_samples(), arxspan_id=\"arxspan_id\", version=\"version\")\n",
    "    renaming.update({'transcript_id(s)':'transcript'})\n",
    "    files[val.split('/')[-1]] = file[file.columns[:2].tolist()+[i for i in file.columns[2:] if i in renaming.keys()]].rename(columns=renaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = BiomartServer( \"http://www.ensembl.org/biomart\" )\n",
    "ensmbl = server.datasets['hsapiens_gene_ensembl']\n",
    "ensembltohgnc = pd.read_csv(io.StringIO(ensmbl.search({\n",
    "  'attributes': ['ensembl_gene_id','clone_based_ensembl_gene','hgnc_symbol','gene_biotype','entrezgene_id']\n",
    "}, header=1).content.decode()), sep='\\t')\n",
    "\n",
    "ensembltohgnc.columns = ['ensembl_gene_id','clone_based_ensembl_gene','hgnc_symbol','gene_biotype','entrezgene_id']\n",
    "ensembltohgnc = ensembltohgnc[~(ensembltohgnc['clone_based_ensembl_gene'].isna() & ensembltohgnc['hgnc_symbol'].isna())]\n",
    "ensembltohgnc.loc[ensembltohgnc[ensembltohgnc.hgnc_symbol.isna()].index,\"hgnc_symbol\"] = ensembltohgnc[ensembltohgnc.hgnc_symbol.isna()]['clone_based_ensembl_gene']\n",
    "\n",
    "gene_rename =  {i.ensembl_gene_id: i.hgnc_symbol+' ('+i.ensembl_gene_id+')' for k,i in ensembltohgnc.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protcod_rename = {i.ensembl_gene_id: i.hgnc_symbol+' ('+str(int(i.entrezgene_id))+')' for _,i in ensembltohgnc[(~ensembltohgnc.entrezgene_id.isna()) & (ensembltohgnc.gene_biotype=='protein_coding')].iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in ['rsem_genes_expected_count','rsem_genes_tpm']:\n",
    "    file = files[val].drop(columns='transcript').set_index('gene_id')\n",
    "    file = file[(file.sum(1) != 0) & (file.var(1) != 0)]\n",
    "    r = [i.split('.')[0] for i in file.index]\n",
    "    dup = h.dups(r)\n",
    "    if len(dup)>0:\n",
    "        print(dup)\n",
    "        raise ValueError('duplicate genes')\n",
    "    file.index = r\n",
    "    files[val.replace('genes','proteincoding_genes')] = file[file.index.isin(set(ensembltohgnc[ensembltohgnc.gene_biotype == 'protein_coding'].ensembl_gene_id))]\n",
    "    files[val] = file.rename(index=gene_rename).T\n",
    "    files[val.replace('genes','proteincoding_genes')] = files[val.replace('genes','proteincoding_genes')].rename(index=protcod_rename).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_transcript = {}\n",
    "missing = []\n",
    "for val in ['rsem_transcripts_expected_count','rsem_transcripts_tpm']:\n",
    "    file = files[val]\n",
    "    file = file[(file[file.columns[2:]].sum(1) != 0) & (file[file.columns[2:]].var(1) != 0)]\n",
    "    r = [i.split('.')[0] for i in file.transcript_id]\n",
    "    dup = h.dups(r)\n",
    "    if len(dup)>0:\n",
    "        print(dup)\n",
    "        raise ValueError('duplicate genes')    \n",
    "    file.transcript_id = r\n",
    "    if len(rename_transcript)==0:\n",
    "        for _,v in file.iterrows():\n",
    "            if v.gene_id.split('.')[0] in gene_rename:\n",
    "                rename_transcript[v.transcript_id] = gene_rename[v.gene_id.split('.')[0]].split(' (')[0] + ' (' + v.transcript_id + ')'\n",
    "            else:\n",
    "                missing.append(v.gene_id.split('.')[0])\n",
    "        print('missing: '+str(len(missing))+' genes')\n",
    "    files[val] = file.set_index('transcript_id').drop(columns = 'gene_id').rename(index = rename_transcript).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saving samples used for the release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_refsamples.loc[set(renaming.keys())-set(['transcript_id(s)']),release]=1\n",
    "ccle_refsamples.loc[ccle_refsamples[ccle_refsamples.datatype=='rna'].index,'low_quality']=0\n",
    "ccle_refsamples.loc[lowqual.index,'low_quality']=1\n",
    "ccle_refsamples.to_csv('temp/updated_ref_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevcounts = tc.get(name='depmap-rnaseq-expression-data-363a', version=26, file=\"internal_\"+prevname+'_counts')\n",
    "prevgenes = tc.get(name='depmap-rnaseq-expression-data-363a', version=26, file=\"internal_\"+prevname+'_tpm')\n",
    "prevtranscripts = tc.get(name='depmap-rnaseq-expression-data-363a', version=26, file=\"internal_\"+prevname+'_transcripts_tpm')\n",
    "prevproteincoding = tc.get(name='depmap-rnaseq-expression-data-363a', version=26, file=\"internal_\"+prevname+'_proteincoding_tpm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {}\n",
    "for k, val in failed.iterrows():\n",
    "    a = ccle_refsamples.loc[k].arxspan_id\n",
    "    if len(ccle_refsamples[(ccle_refsamples.datatype=='rna')&(ccle_refsamples.arxspan_id==a)])==1:\n",
    "        rename[a] = list(val[val].index)\n",
    "    else:\n",
    "        print(\"we had something else\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost = set(prevproteincoding.index) - set(files['rsem_proteincoding_genes_tpm'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost = lost - set(rename.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prevcounts), len(files['rsem_genes_expected_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store rename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do we have new duplicates that don't correlate well and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = set(files['rsem_genes_expected_count'].columns) & set(prevcounts.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched = h.getDifferencesFromCorrelations(files['rsem_genes_expected_count'][overlap] ,prevcounts[overlap], minsimi=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, _ in [('ACH-000561','')]:#+unmatched\n",
    "    files['rsem_genes_expected_count'].loc[k] = prevcounts.loc[k][overlap]\n",
    "    files['rsem_genes_tpm'].loc[k] = (2**prevgenes.loc[k][overlap])-1\n",
    "    \n",
    "    overlap = set(files['rsem_transcripts_tpm'].columns)&set(prevtranscripts.columns)\n",
    "    files['rsem_transcripts_tpm'].loc[k] = (2**prevtranscripts.loc[k][overlap])-1\n",
    "    \n",
    "    overlap = set(files['rsem_proteincoding_genes_tpm'].columns)&set(prevproteincoding.columns)\n",
    "    files['rsem_proteincoding_genes_tpm'].loc[k] = (2**prevproteincoding.loc[k][overlap])-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is it because of  duplicate version?\n",
    "rnasamples = ccle_refsamples[ccle_refsamples.datatype=='rna']\n",
    "for i,val in unmatched:\n",
    "    print(len(rnasamples[rnasamples.arxspan_id==i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ssGSEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_genes = files['rsem_genes_expected_count'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_genes.columns = [i.split(' (')[0] for i in counts_genes.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in h.dups(counts_genes.columns):\n",
    "    val = counts_genes[i].sum(1)\n",
    "    counts_genes=counts_genes.drop(columns=i)\n",
    "    counts_genes[i]=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set([val.split('.')[0] for val in counts_genes.columns if '.' in val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### merging splicing variants into the same gene\n",
    "counts_genes_merged, _, _= h.mergeSplicingVariants(counts_genes.T, defined='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_genes_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with R ssGSEA on the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichments= h.gsva(counts_genes_merged, pathtoJKBio=\"../JKBio/\", geneset_file = \"data/genesets/ALL.gmt\", method='ssgsea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = tc.get(name='depmap-a0ab', file='sample_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding train and test set\n",
    "trainame = [val for val in new1&prev if val[:3] == 'ACH']\n",
    "testname = [val for val in new1-prev if val[:3] == 'ACH']\n",
    "\n",
    "#looking at the 2000 most variable genes in the two sets\n",
    "genetolookfor = 2000\n",
    "gene_var = counts_genes[trainame].var(1).values\n",
    "print(len(gene_var))\n",
    "sorting = np.argsort(gene_var)[-genetolookfor:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unregistered = set(testname) - set(metadata[\"DepMap_ID\"].values.tolist())\n",
    "unregistered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(counts_genes['ACH-001767']) - np.count_nonzero(counts_genes['ACH-001767'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and reodering train and test sets\n",
    "traindata = counts_genes[set(trainame)-unregistered].values[sorting].T\n",
    "trainlabels = [metadata[metadata[\"DepMap_ID\"]==val][\"disease\"].values[0] for val in counts_genes[set(trainame)-unregistered].columns.tolist() if val not in unregistered]\n",
    "\n",
    "testdata = counts_genes[set(testname)-unregistered].values[sorting].T\n",
    "testlabels = [metadata[metadata[\"DepMap_ID\"]==val][\"disease\"].values[0] for val in counts_genes[set(testname)-unregistered].columns.tolist() if val not in unregistered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn KNN classifier to the metadata diseases\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(traindata, trainlabels) \n",
    "predicted = neigh.predict(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = trainlabels + testlabels\n",
    "colors=[0]*len(trainlabels)\n",
    "colors.extend([1,2,2,2,2,1,2,2,2,1,2])\n",
    "data = np.vstack([traindata,testdata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot them with TSNE, highlight the points that failed and show colors for diseases\n",
    "dimred = TSNE(2,10).fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(dimred, labels=labels,colors=colors, radi=1.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save files for taiga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls temp/gene_sets_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichments.to_csv('temp/gene_sets_'+release+'_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,val in files.items():\n",
    "    val.to_csv('temp/'+k.replace('rsem','expression_'+release)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.update_dataset(dataset_permaname=\"expression-d035\",\n",
    "                 upload_file_path_dict={\n",
    "    'temp/expression_'+release+'_transcripts_tpm.csv': 'NumericMatrixCSV',\n",
    "    'temp/expression_'+release+'_genes_tpm.csv': 'NumericMatrixCSV',\n",
    "    'temp/expression_'+release+'_genes_expected_count.csv': 'NumericMatrixCSV',\n",
    "    'temp/expression_'+release+'_proteincoding_genes_expected_count.csv': 'NumericMatrixCSV',\n",
    "    'temp/expression_'+release+'_proteincoding_genes_tpm.csv': 'NumericMatrixCSV',\n",
    "    'temp/expression_'+release+'_transcripts_expected_count.csv': 'NumericMatrixCSV',\n",
    "    'temp/gene_sets_'+release+'_all.csv': 'NumericMatrixCSV'\n",
    "                 },\n",
    "                  dataset_description=\n",
    "\"\"\"\n",
    "# RNAseq\n",
    "\n",
    "PORTAL TEAM SHOULD NOT USE THIS: There are lines here that should not make it even to internal.\n",
    "\n",
    "/!\\ This is the most up to date version of the CCLE CN data.\n",
    "The data is most likely of a better quality that what is on other folder. It is however in beta version as not all changes have either been confirmed or accepted by the DepMap Ops and the DepMap Portal Team.\n",
    "\n",
    "## Versions:\n",
    "\n",
    "v1: first version from 20Q4. with new gene cn compute, full reprocessing of the data, removal of non reproducible samples or samples that failed QC.\n",
    "\n",
    "## Annotations:\n",
    "\n",
    "transcriptions (Transcripts rpkm):\n",
    "\n",
    "genes (gene rpkm):\n",
    "__Rows__:\n",
    "__Columns__:\n",
    "Counts (gene counts):\n",
    "__Rows__:\n",
    "__Columns__:\n",
    "Gene level CN data:\n",
    "__Rows__:\n",
    "__Columns__:\n",
    " DepMap cell line IDs\n",
    " gene names in the format HGNC\\_symbol (Entrez\\_ID)\n",
    "DepMap\\_ID, Chromosome, Start, End, Num\\_Probes, Segment\\_Mean\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra.waitForSubmission(refworkspace, submission_id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = refwm.get_sample_sets().loc['All_samples']['fusions_star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil cp $aggregated \"temp/expression.fusion.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions = pd.read_csv('temp/expression.fusion.tsv', names=['DepMap_ID', 'FusionName', 'JunctionReadCount', 'SpanningFragCount', 'SpliceType', 'LeftGene', 'LeftBreakpoint', 'RightGene', 'RightBreakpoint', 'LargeAnchorSupport', 'FFPM', 'LeftBreakDinuc', 'LeftBreakEntropy', 'RightBreakDinuc', 'RightBreakEntropy','annots'], skiprows=1, sep='\\t')\n",
    "fusions[\"DepMap_ID\"] = [i.split('.')[0] for i in fusions['DepMap_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fusions))\n",
    "renaming = removeOlderVersions(names=set(fusions['DepMap_ID']), refsamples=refwm.get_samples(), arxspan_id=\"arxspan_id\", version=\"version\")\n",
    "fusions = fusions[fusions['DepMap_ID'].isin(renaming.keys())].replace({'DepMap_ID':renaming}).reset_index(drop=True)\n",
    "print(len(fusions))\n",
    "print(fusions['DepMap_ID'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions['CCLE_count'] = [i.LeftBreakpoint+'_'+i.RightBreakpoint for k, i in fusions.iterrows()]\n",
    "counts = Counter(list(fusions['CCLE_count']))\n",
    "fusions['CCLE_count'] = [counts[val] for val in fusions['CCLE_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions['FFPM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fusions[~(fusions['CCLE_count']>len(set(fusions['DepMap_ID']))*0.1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = filterFusions(fusions, maxfreq=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate filtered fusion table\n",
    "\n",
    "We want to apply filters to the fusion table to reduce the number of artifacts in the dataset. Specifically, we filter the following:\n",
    "\n",
    "* Remove fusions involving mitochondrial chromosomes, or HLA genes, or immunoglobulin genes\n",
    "* Remove red herring fusions (from STAR-Fusion annotations column)\n",
    "* Remove recurrent in CCLE (>= 25 samples)\n",
    "* Remove fusion with (SpliceType=\" INCL_NON_REF_SPLICE\" and LargeAnchorSupport=\"No\" and FFPM < 0.1)\n",
    "* Remove fusions with FFPM < 0.05 (STAR-Fusion suggests using 0.1, but looking at the translocation data, this looks like it might be too aggressive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions.RightGene = renameFusionGene(fusions.RightGene)\n",
    "fusions.LeftGene = renameFusionGene(fusions.LeftGene)\n",
    "filtered.RightGene = renameFusionGene(filtered.RightGene)\n",
    "filtered.LeftGene = renameFusionGene(filtered.LeftGene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(fusions.DepMap_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions = fusions[~fusions.DepMap_ID.isin(rename.keys())]\n",
    "filtered = filtered[~filtered.DepMap_ID.isin(rename.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls temp/un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions.to_csv('temp/unfiltered_fusions_'+release+'.csv',index=False)\n",
    "filtered.to_csv('temp/fusions_'+release+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading to Taiga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.update_dataset(dataset_permaname=\"fusions-95c9\",\n",
    "                     upload_file_path_dict={\n",
    "                'temp/fusions_'+release+'.csv': 'TableCSV',\n",
    "                'temp/unfiltered_fusions_'+release+'.csv': 'TableCSV'},\n",
    "                 dataset_description=\"\"\"\n",
    "# Fusions\n",
    "\n",
    "PORTAL TEAM SHOULD NOT USE THIS: There are lines here that should not make it even to internal.\n",
    "\n",
    "/!\\ This is the most up to date version of the CCLE CN data.\n",
    "The data is most likely of a better quality that what is on other folder. It is however in beta version as not all changes have either been confirmed or accepted by the DepMap Ops and the DepMap Portal Team.\n",
    "\n",
    "\n",
    "## Versions:\n",
    "\n",
    "version 1: new fusions dataset, renamed some columns. new reprocessing and sample filtering (should find back the same amounts of samples than in RNAseq), improved filtering on recurent fusions.\n",
    "\n",
    "\n",
    "## Annotations\n",
    "\n",
    "Description: Gene fusions derived from RNAseq data.\n",
    "\n",
    "Rows: cell lines, IDs contained in the column DepMap_ID\n",
    "\n",
    "Unfiltered data contains all output fusions, while the filtered data uses the filters suggested by the star fusion docs. These filters are:\n",
    "- FFPM > 0.1 -  a cutoff of 0.1 means&nbsp;at least 1 fusion-supporting RNAseq fragment per 10M total reads\n",
    "- Remove known false positives, such as GTEx recurrent fusions and certain paralogs\n",
    "- Genes that are next to each other\n",
    "- Fusions with mitochondrial breakpoints\n",
    "- Removing fusion involving mitochondrial chromosomes or HLA genes\n",
    "- Removed common false positive fusions (red herring annotations as described in the STAR-Fusion docs)\n",
    "- Recurrent fusions observed in CCLE across cell lines (in more than 10% of our samples)\n",
    "- Removed fusions where SpliceType='INCL_NON_REF_SPLICE' and LargeAnchorSupport='NO_LDAS' and FFPM < 0.1\n",
    "- FFPM < 0.05\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
