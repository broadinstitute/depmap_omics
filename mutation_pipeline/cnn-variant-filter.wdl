# This workflow takes an input CRAM to call variants with HaplotypeCaller
# Then filters the calls with the CNNVariant neural net tool
# The site-level scores are added to the INFO field of the VCF.
# The architecture arguments, info_key and tensor type arguments MUST be in agreement
# (e.g. 2D models must have tensor_type of read_tensor and info_key CNN_2D, 1D models have tensor_type reference and info_key CNN_1D)
# The INFO field key will be "1D_CNN" or "2D_CNN" depending on the neural net architecture used for inference.
# The architecture arguments specify pre-trained networks.
# New networks can be trained by the GATK tools: CNNVariantWriteTensors and CNNVariantTrain
# The CRAM could be generated by the single-sample pipeline
# (https://github.com/gatk-workflows/gatk4-data-processing/blob/master/processing-for-variant-discovery-gatk4.wdl)
# Also accepts a BAM as the input file in which case a BAM index is required as well.

import "https://api.firecloud.org/ga4gh/v1/tools/gatk:cnn-variant-common-tasks/versions/1/plain-WDL/descriptor" as CNNTasks

workflow Cram2FilteredVcf {
    File input_file                  # Aligned CRAM file or Aligned BAM files
    File? input_file_index           # Index for an aligned BAM file if that is the input, unneeded if input is a CRAM
    File reference_fasta 
    File reference_dict
    File reference_fasta_index
    File resource_fofn               # File of VCF file names of resources of known SNPs and INDELs, (e.g. mills, gnomAD)
    File resource_fofn_index         # File of VCF file indices of resources
    File? architecture_json          # Neural Net configuration for CNNScoreVariants
    File? architecture_hd5           # Pre-Trained weights and architecture for CNNScoreVariants
    Int? inference_batch_size        # Batch size for python in CNNScoreVariants
    Int? transfer_batch_size         # Batch size for java in CNNScoreVariants
    Int? intra_op_threads            # Tensorflow threading within nodes
    Int? inter_op_threads            # Tensorflow threading between nodes
    String output_prefix             # Identifying string for this run will be used to name all output files
    String? tensor_type              # What kind of tensors the Neural Net expects (e.g. reference, read_tensor)
    String info_key                  # The score key for the info field of the vcf (e.g. CNN_1D, CNN_2D)
    String snp_tranches              # Filtering threshold(s) for SNPs in terms of sensitivity to overlapping known variants in resources
    String indel_tranches            # Filtering threshold(s) for INDELs in terms of sensitivity to overlapping known variants in resources
    File? gatk_override              # GATK Jar file to over ride the one included in gatk_docker
    String gatk_docker
    File calling_intervals
    Int scatter_count                # Number of shards for parallelization of HaplotypeCaller and CNNScoreVariants
    String extra_args                # Extra arguments for HaplotypeCaller

    # Runtime parameters
    Int? mem_gb
    Int? preemptible_attempts
    Float? disk_space_gb
    Int? cpu

    Int? increase_disk_size
    Int additional_disk = select_first([increase_disk_size, 20])
    Float ref_size = size(reference_fasta, "GB") + size(reference_fasta_index, "GB") + size(reference_dict, "GB")

    # Clunky check to see if the input is a BAM or a CRAM
    if (basename(input_file) == basename(input_file, ".bam")){
        call CNNTasks.CramToBam {
            input:
              reference_fasta = reference_fasta,
              reference_dict = reference_dict,
              reference_fasta_index = reference_fasta_index,
              cram_file = input_file,
              output_prefix = output_prefix,
              disk_space_gb = round(4*size(input_file, "GB") + ref_size + additional_disk),
              preemptible_attempts = preemptible_attempts
        }
    }

    call SplitIntervals {
        input:
            gatk_override = gatk_override,
            scatter_count = scatter_count,
            intervals = calling_intervals,
            ref_fasta = reference_fasta,
            ref_dict = reference_dict,
            ref_fai = reference_fasta_index,
            gatk_docker = gatk_docker,
            disk_space = round(additional_disk + ref_size)
    }

    String input_bam = select_first([CramToBam.output_bam, input_file])
    Float bam_size = size(input_bam, "GB")

    scatter (calling_interval in SplitIntervals.interval_files) {
        call CNNTasks.RunHC4 {
            input:
                input_bam = input_bam,
                input_bam_index = select_first([CramToBam.output_bam_index, input_file_index]),
                reference_fasta = reference_fasta,
                reference_dict = reference_dict,
                reference_fasta_index = reference_fasta_index,
                output_prefix = output_prefix,
                interval_list = calling_interval,
                gatk_docker = gatk_docker,
                gatk_override = gatk_override,
                preemptible_attempts = preemptible_attempts,
                extra_args = extra_args,
                disk_space_gb = round(bam_size + ref_size + additional_disk)
        }

        call CNNTasks.CNNScoreVariants {
            input:
                input_vcf = RunHC4.raw_vcf,
                input_vcf_index = RunHC4.raw_vcf_index,
                bam_file = RunHC4.bamout,
                bam_file_index = RunHC4.bamout_index,
                architecture_json = architecture_json,
                architecture_hd5 = architecture_hd5,
                reference_fasta = reference_fasta,
                tensor_type = tensor_type,
                inference_batch_size = inference_batch_size,
                transfer_batch_size = transfer_batch_size,
                intra_op_threads = intra_op_threads,
                inter_op_threads = inter_op_threads,
                reference_dict = reference_dict,
                reference_fasta_index = reference_fasta_index,               
                output_prefix = output_prefix,
                interval_list = calling_interval,
                gatk_override = gatk_override,
                gatk_docker = gatk_docker,
                preemptible_attempts = preemptible_attempts,
                mem_gb = mem_gb,
                disk_space_gb = round((bam_size/scatter_count) + ref_size + additional_disk)
        }
    }

    call CNNTasks.MergeVCFs as MergeVCF_HC4 {
        input: 
            input_vcfs = CNNScoreVariants.cnn_annotated_vcf,
            output_prefix = output_prefix,
            gatk_override = gatk_override,
            preemptible_attempts = preemptible_attempts,
            gatk_docker = gatk_docker,
            disk_space_gb = additional_disk
    }

    call CNNTasks.FilterVariantTranches {
        input:
            input_vcf = MergeVCF_HC4.merged_vcf,
            input_vcf_index = MergeVCF_HC4.merged_vcf_index,
            resource_fofn = resource_fofn,
            resource_fofn_index = resource_fofn_index,
            output_prefix = output_prefix,
            snp_tranches = snp_tranches,
            indel_tranches = indel_tranches,
            info_key = info_key,
            gatk_override = gatk_override,
            preemptible_attempts = preemptible_attempts,
            gatk_docker = gatk_docker,
            disk_space_gb = additional_disk
    }

    call CNNTasks.SamtoolsMergeBAMs {
        input:
            input_bams = RunHC4.bamout,
            output_prefix = output_prefix,
            disk_space_gb = round(bam_size + ref_size + additional_disk)
    }
    
    # Oncotator is a tool for annotating human genomic point mutations and indels with data relevant to cancer researchers.
    call Oncotate_Task {
        input :            
            vcf=FilterVariantTranches.
            pairName=pairName,
            caseName=caseName,
            ctrlName=ctrlName,
    }
    
    # Detects and screens out OxoG artifacts from a set of SNV calls.
    # Oxidation of guanine to 8-oxoguanine is one of the most common pre-adapter artifacts associated with genomic library preparation,
    # arising from a combination of heat, shearing, and metal contaminates in a sample).
    # The 8-oxoguanine base can pair with either cytosine or adenine, ultimately leading to Gâ†’T transversion mutations during PCR amplification.   
    # CC. -> CA.
    # .GG -> .TG <= DNA F1R2 (Context - ".GG", REF Allele - "G", ALT Allele - "T")
    call OrientationBias_filter_Task as oxoGOBF {
        input:
            stub="oxog",
            tumorBam=input_bam,
            tumorBamIdx=select_first([CramToBam.output_bam_index, input_file_index]),
            pairName=pairName,
            detailMetrics=tumorMM_Task.pre_adapter_detail_metrics,
            MAF=Oncotate_Task.WXS_Mutation_M1_SNV_M2_INDEL_Strelka_INDEL_annotated_maf,
            GATK4_JAR=GATK4_JAR,
            refFasta=refFasta,
            refFasta_size=refFasta_size,
            tumorBam_size=tumorBam_size,
            gatk4_jar_size=gatk4_jar_size,
            diskGB_buffer=runtime_params["OrientationBias_filter_Task.diskGB_buffer"],
            diskGB_boot=runtime_params["OrientationBias_filter_Task.diskGB_boot"],
            preemptible=runtime_params["OrientationBias_filter_Task.preemptible"],
            memoryGB=runtime_params["OrientationBias_filter_Task.memoryGB"],
            cpu=runtime_params["OrientationBias_filter_Task.cpu"]
    }

    # Detects and screens out FFPE artifacts from a set of SNV calls.
    # FFPE introduces multiple types of DNA damage including deamination, which converts cytosine to uracil and leads to downstream mispairing
    # in PCR: C>T/G>A. Because deamination occurs prior to ligation of palindromic Illumina adapters, likely deamination artifacts will have
    # a read orientation bias. The FFPE Filter Task uses this read orientation to identify artifacts and calculate a Phred scaled Q-score for FFPE artifacts.
    # .CG -> .TG <= DNA F1R2 (Context - ".CG", REF Allele - "C", ALT Allele - "T")
    # CG. -> CA.
    call OrientationBias_filter_Task as ffpeOBF {
        input:
            stub="ffpe",
            tumorBam=select_first([tumorMM_Task.Bam,tumorBam]),
            tumorBamIdx=select_first([tumorMM_Task.Bai,tumorBamIdx]),
            pairName=pairName,
            detailMetrics=tumorMM_Task.pre_adapter_detail_metrics,
            MAF=Oncotate_Task.WXS_Mutation_M1_SNV_M2_INDEL_Strelka_INDEL_annotated_maf,
            GATK4_JAR=GATK4_JAR,
            refFasta=refFasta,
            refFasta_size=refFasta_size,
            tumorBam_size=tumorBam_size,
            gatk4_jar_size=gatk4_jar_size,
            diskGB_buffer=runtime_params["OrientationBias_filter_Task.diskGB_buffer"],
            diskGB_boot=runtime_params["OrientationBias_filter_Task.diskGB_boot"],
            preemptible=runtime_params["OrientationBias_filter_Task.preemptible"],
            memoryGB=runtime_params["OrientationBias_filter_Task.memoryGB"],
            cpu=runtime_params["OrientationBias_filter_Task.cpu"]
    }

    output {
        FilterVariantTranches.*
    }
}

task SplitIntervals {
    # inputs
    File? intervals
    File ref_fasta
    File ref_fai
    File ref_dict
    Int scatter_count
    String? split_intervals_extra_args

    File? gatk_override

    # runtime
    String gatk_docker
    Int? mem
    Int? preemptible_attempts
    Int? disk_space
    Int? cpu

    # Mem is in units of GB but our command and memory runtime values are in MB
    Int machine_mem = if defined(mem) then mem * 1000 else 3500
    Int command_mem = machine_mem - 500

    command {
        set -e
        export GATK_LOCAL_JAR=${default="/root/gatk.jar" gatk_override}

        gatk --java-options "-Xmx${command_mem}m" \
            SplitIntervals \
            -R ${ref_fasta} \
            ${"-L " + intervals} \
            -scatter ${scatter_count} \
            -O ./ \
            ${split_intervals_extra_args}
    }

    runtime {
        docker: "${gatk_docker}"
        memory: machine_mem + " MB"
        disks: "local-disk " + select_first([disk_space, 100]) + " HDD"
        preemptible: select_first([preemptible_attempts, 10])
        cpu: select_first([cpu, 1])
        bootDiskSizeGb: "16"
    }

    output {
        Array[File] interval_files = glob("*.interval_list")
    }
}

task VEP_Task {

    # TASK INPUT PARAMS
    File MUTECT1_CS
    File MUTECT2_VCF
    File STRELKA_VCF
    String pairName
    String caseName
    String ctrlName
    File VEP_File    
    File GNOMAD_FILE
    File GNOMAD_FILE_IDX
    File oncoDBTarBall_JustRef

    # RUNTIME INPUT PARAMS
    String preemptible
    String diskGB_boot
    String diskGB_buffer
    String memoryGB
    String cpu

    # DEFAULT VALUES
    String default_cpu = "1"
    String default_memoryGB = "10"
    String default_preemptible = "1"
    String default_diskGB_boot = "15"
    String default_diskGB_buffer = "50"

    # COMPUTE MEMORY SIZE
    Int machine_memoryGB = if memoryGB != "" then memoryGB else default_memoryGB
    Int command_memoryGB = machine_memoryGB - 1

    # COMPUTE DISK SIZE
    Int machine_diskGB_buffer = if diskGB_buffer != "" then diskGB_buffer else default_diskGB_buffer
    Int diskGB = ceil(size(MUTECT1_CS, "G") + size(MUTECT2_VCF, "G") + size(STRELKA_VCF, "G")
                + size(GNOMAD_FILE, "G")*5 + size(GNOMAD_FILE_IDX, "G") + size(VEP_File, "G") * 5 
                + machine_diskGB_buffer)

    parameter_meta {
        MUTECT1_CS : ""
        MUTECT2_VCF : ""
        STRELKA_VCF : ""
        pairName: "a string for the name of the pair under analysis used for naming output files"
        caseName : "tumor sample name, prefix for output"
        ctrlName : "normal sample name, prefix for output"
        VEP_File : ""
        GNOMAD_FILE : ""      
    }

    command <<<

        set -x

        ############## Pre-process MuTect1 call stats #################################
        # Running Oncotator to Convert MuTect1 callstats to VCF 

        MUTECT1_CS_PASSED="${pairName}.MuTect1.call_stats.passed.txt"
        MUTECT1_CS_REJECTED="${pairName}.MuTect1.call_stats.rejected.txt"
        MUTECT1_CS_MAFLITE="${pairName}.MuTect1.call_stats.maflite"
        MUTECT1_VCF="${pairName}.MuTect1.call_stats.maflite.annotated.vcf"

        # Filter MuTect1 mutation calls that passed filter
        python /usr/local/bin/filter_passed_mutations.py ${MUTECT1_CS} $MUTECT1_CS_PASSED $MUTECT1_CS_REJECTED "KEEP"
        # Convert MuTect1 call stats to MafLite
        python /usr/local/bin/callstats_to_maflite.py $MUTECT1_CS_PASSED $MUTECT1_CS_MAFLITE

        ########################### Unzip Oncotator database ###############################

        #find TARBALL type 
        # TODO Find better way to get extension
        TYPE=`echo 'if("${oncoDBTarBall_JustRef}"=~m/z$/) { print "GZ" ; } else { print "TAR" ; } '| perl` ;

        #obtain the name of the directory for oncodb and unpack based on the TYPE
        if [ "$TYPE" == "GZ" ] ; then
        # TODO Find better way to get name of the file
            ONCO_DB_DIR_NAME=`gunzip -c ${oncoDBTarBall_JustRef} |tar -tf /dev/stdin|head -1` ;
            tar -xzf ${oncoDBTarBall_JustRef}
        else
            ONCO_DB_DIR_NAME=`tar -tf ${oncoDBTarBall_JustRef} |head -1` ;
            tar -xf ${oncoDBTarBall_JustRef} ;
        fi ;

        ################## Annotate MuTect1, MuTect2, Strelka call stats ###########################

        # Annotate MuTect1 call stats (MAFLITE to VCF)
        # --infer-onps \        
        /root/oncotator_venv/bin/oncotator \
        -i MAFLITE \
        -o VCF \
        --db-dir `pwd`/$ONCO_DB_DIR_NAME \
        --infer_genotypes yes \
        -a normal_barcode:${ctrlName} \
        -a tumor_barcode:${caseName} \
        $MUTECT1_CS_PASSED $MUTECT1_VCF hg19

        ############### Run Variant Effector Predictor (VEP)  #########################

        #make a link from the home directory to the current directory to avoid running out of disk space on the boot disk
        mkdir -v vep_data_dir
        #delete the existing directory first to make a successful link
        rm -rf ~/.vep
        ln -vs `pwd`/vep_data_dir ~/.vep

        #In either case unpack the data into the home directory where VEP expects to find it
        IS_ZIP=`echo ${VEP_File}|grep -Pic '\.zip$'` ;
        if [ "$IS_ZIP" -eq "1" ] ;
        then
            #it's a zip file
            unzip -d ~ ${VEP_File} ;
        else
            #tar ball
            tar -C ~ -xvzf ${VEP_File}
        fi ;

        # VEP for MuTect1
        MUTECT1_VEP="${pairName}.mutect1.vep_annotated.vcf"
        MUTECT1_VEP_filtered="${pairName}.mutect1.vep_annotated.filtered.vcf"
        /ensembl-tools-release-83/ensembl-tools-release-83/scripts/variant_effect_predictor/variant_effect_predictor.pl \
        --custom ${GNOMAD_FILE},gnomADg,vcf,exact,0,GT,AC,AF,AN,AF_AFR,AF_AMR,AF_ASJ,AF_EAS,AF_FIN,AF_NFE,AF_OTH \
        --input_file $MUTECT1_VCF \
        --output_file $MUTECT1_VEP \
        --vcf \
        --symbol \
        --cache \
        --offline \
        --failed 1

        python /usr/local/bin/vep_filter_germline.py $MUTECT1_VEP $MUTECT1_VEP_filtered

        # VEP for MuTect2
        MUTECT2_VEP="${pairName}.mutect2.vep_annotated.vcf"
        MUTECT2_VEP_filtered="${pairName}.mutect2.vep_annotated.filtered.vcf"
        /ensembl-tools-release-83/ensembl-tools-release-83/scripts/variant_effect_predictor/variant_effect_predictor.pl \
        --custom ${GNOMAD_FILE},gnomADg,vcf,exact,0,GT,AC,AF,AN,AF_AFR,AF_AMR,AF_ASJ,AF_EAS,AF_FIN,AF_NFE,AF_OTH \
        --input_file ${MUTECT2_VCF} \
        --output_file $MUTECT2_VEP \
        --vcf \
        --symbol \
        --cache \
        --offline \
        --failed 1

        python /usr/local/bin/vep_filter_germline.py $MUTECT2_VEP $MUTECT2_VEP_filtered

        # VEP for Strelka
        STRELKA_VEP="${pairName}.strelka.vep_annotated.vcf"
        STRELKA_VEP_filtered="${pairName}.strelka.vep_annotated.filtered.vcf"
        /ensembl-tools-release-83/ensembl-tools-release-83/scripts/variant_effect_predictor/variant_effect_predictor.pl \
        --custom ${GNOMAD_FILE},gnomADg,vcf,exact,0,GT,AC,AF,AN,AF_AFR,AF_AMR,AF_ASJ,AF_EAS,AF_FIN,AF_NFE,AF_OTH \
        --input_file ${STRELKA_VCF} \
        --output_file $STRELKA_VEP \
        --vcf \
        --symbol \
        --cache \
        --offline \
        --failed 1

        python /usr/local/bin/vep_filter_germline.py $STRELKA_VEP $STRELKA_VEP_filtered

    >>>

    runtime {
        docker: "gcr.io/broad-getzlab-workflows/cga_production_pipeline:v0.2.ccle"
        bootDiskSizeGb: if diskGB_boot != "" then diskGB_boot else default_diskGB_boot
        preemptible: if preemptible != "" then preemptible else default_preemptible
        cpu: if cpu != "" then cpu else default_cpu
        disks: "local-disk ${diskGB} HDD"
        memory: machine_memoryGB + "GB"
    }

    output {
        File MUTECT1_VEP_annotated_vcf="${pairName}.mutect1.vep_annotated.vcf"
        File MUTECT2_VEP_annotated_vcf="${pairName}.mutect2.vep_annotated.vcf"
        File STRELKA_VEP_annotated_vcf="${pairName}.strelka.vep_annotated.vcf"  
        File MUTECT1_VEP_annotated_filtered_vcf="${pairName}.mutect1.vep_annotated.filtered.vcf"
        File MUTECT2_VEP_annotated_filtered_vcf="${pairName}.mutect2.vep_annotated.filtered.vcf"
        File STRELKA_VEP_annotated_filtered_vcf="${pairName}.strelka.vep_annotated.filtered.vcf"       
    }
}


task Oncotate_Task {

    # TASK INPUT PARAMS
    File MUTECT1_CS
    File MUTECT2_INDELS
    File STRELKA_INDELS
    String pairName
    String caseName
    String ctrlName
    File oncoDBTarBall

    # RUNTIME INPUT PARAMS
    String preemptible
    String diskGB_boot
    String diskGB_buffer
    String memoryGB
    String cpu

    # DEFAULT VALUES
    String default_cpu = "1"
    String default_memoryGB = "15"
    String default_preemptible = "1"
    String default_diskGB_boot = "15"
    String default_diskGB_buffer = "20"

    # COMPUTE MEMORY SIZE
    Int machine_memoryGB = if memoryGB != "" then memoryGB else default_memoryGB
   
    # COMPUTE DISK SIZE
    Int machine_diskGB_buffer = if diskGB_buffer != "" then diskGB_buffer else default_diskGB_buffer
    Int diskGB = ceil(size(oncoDBTarBall, "G") * 5 + machine_diskGB_buffer)

    parameter_meta {
        MUTECT1_CS : ""
        MUTECT2_INDELS : ""
        STRELKA_INDELS : ""
        pairName: "a string for the name of the pair under analysis used for naming output files"
        caseName : "tumor sample name, prefix for output"
        ctrlName : "normal sample name, prefix for output"
        oncoDBTarBall : ""
    }

    command <<<

        set -x

        ######## Files #################

        # MuTect1 files
        MUTECT1_CS_PASSED="${pairName}.MuTect1.call_stats.passed.txt"
        MUTECT1_CS_REJECTED="${pairName}.MuTect1.call_stats.rejected.txt"
        MUTECT1_CS_MAFLITE="${pairName}.MuTect1.call_stats.maflite"
        MUTECT1_CS_ANNOTATED_MAF="${pairName}.MuTect1.call_stats.annotated.maf"

        # MuTect2 files
        MUTECT2_INDELS_PASSED="${pairName}.MuTect2.call_stats.passed.vcf"
        MUTECT2_INDELS_REJECTED="${pairName}.MuTect2.call_stats.rejected.vcf"
        MUTECT2_INDELS_ANNOTATED_MAF="${pairName}.MuTect2.call_stats.indels.annotated.maf"
        
        # Strelka files
        STRELKA_REFORMATTED_VCF="${pairName}.Strelka.call_stats.re_formatted.vcf"
        STRELKA_ANNOTATED_MAF="${pairName}.Strelka.call_stats.annotated.maf"

        # Merged files
        MUTECT2_STRELKA_MERGED_MAF="${pairName}.MuTect2_INDEL.Strelka_INDEL.merged.maf" 
        MUTECT1_MUTECT2_STRELKA_MERGED_MAF="${pairName}.MuTect1_SNV.MuTect2_INDEL.Strelka_INDEL.annotated.maf"
        MUTECT1_MUTECT2_STRELKA_ANNOTATED_VCF="${pairName}.MuTect1_SNV.MuTect2_INDEL.Strelka_INDEL.annotated.vcf"

        ######## Processing call stats before annotation #################

        # Filter MuTect1 mutation calls that passed filter
        python /usr/local/bin/filter_passed_mutations.py ${MUTECT1_CS} $MUTECT1_CS_PASSED $MUTECT1_CS_REJECTED "PASS"
        # Convert MuTect1 call stats to MafLite
        #

        # Filter MuTect2 mutation calls that passed filter
        python /usr/local/bin/filter_passed_mutations.py ${MUTECT2_INDELS} $MUTECT2_INDELS_PASSED $MUTECT2_INDELS_REJECTED "PASS"

        # Edit Strelka VCF (adding AD and AF, replacing TUMOR/NORMAL with caseName/ctrlName)
        python /usr/local/bin/strelka_allelic_count.py ${STRELKA_INDELS} $STRELKA_REFORMATTED_VCF "${caseName}" "${ctrlName}"

        ########################### Unzip Oncotator database ###############################

        #find TARBALL type 
        # TODO Find better way to get extension
        TYPE=`echo 'if("${oncoDBTarBall}"=~m/z$/) { print "GZ" ; } else { print "TAR" ; } '| perl` ;

        #obtain the name of the directory for oncodb and unpack based on the TYPE
        if [ "$TYPE" == "GZ" ] ; then
        # TODO Find better way to get name of the file
            ONCO_DB_DIR_NAME=`gunzip -c ${oncoDBTarBall} |tar -tf /dev/stdin|head -1` ;
            tar -xzf ${oncoDBTarBall}
        else
            ONCO_DB_DIR_NAME=`tar -tf ${oncoDBTarBall} |head -1` ;
            tar -xf ${oncoDBTarBall} ;
        fi ;

        ################## Annotate MuTect1, MuTect2, Strelka call stats ###########################

        # Annotate MuTect1 call stats (VCF to TCGAMAF)
        # --infer-onps \        
        /root/oncotator_venv/bin/oncotator -i VCF --db-dir `pwd`/$ONCO_DB_DIR_NAME \
        --skip-no-alt \
        --longer-other-tx \
        -a normal_barcode:${ctrlName} \
        -a tumor_barcode:${caseName} \
        $MUTECT1_CS_PASSED $MUTECT1_CS_ANNOTATED_MAF hg19
        

        # Annotate MuTect2 call stats (VCF to TCGAMAF)
        /root/oncotator_venv/bin/oncotator -i VCF --db-dir `pwd`/$ONCO_DB_DIR_NAME \
        --longer-other-tx \
        --skip-no-alt \
        -a normal_barcode:${ctrlName} \
        -a tumor_barcode:${caseName} \
        $MUTECT2_INDELS_PASSED $MUTECT2_INDELS_ANNOTATED_MAF hg19

        # Annotate Strelka call stats (VCF to TCGAMAF)
        /root/oncotator_venv/bin/oncotator -i VCF --db-dir `pwd`/$ONCO_DB_DIR_NAME \
        --longer-other-tx \
        --skip-no-alt \
        -a normal_barcode:${ctrlName} \
        -a tumor_barcode:${caseName} \
        $STRELKA_REFORMATTED_VCF $STRELKA_ANNOTATED_MAF hg19

        ####################### Merge MuTect1, MuTect2, Strelka annotated TCGAMAFs into one file ####################

        # Merge Strelka and MuTect2 indels (only Strelka calls selected, MuTect2 and Strelka common calls are annotated)
        python /usr/local/bin/merge_strelka_mutect2.py $STRELKA_ANNOTATED_MAF $MUTECT2_INDELS_ANNOTATED_MAF $MUTECT2_STRELKA_MERGED_MAF
        # Merge MuTect1 SNVs and Strelka & MuTect2 indels into one MAF file
        python /usr/local/bin/maf_merge.py $MUTECT1_CS_ANNOTATED_MAF $MUTECT2_STRELKA_MERGED_MAF $MUTECT1_MUTECT2_STRELKA_MERGED_MAF

    >>>

    runtime {
        docker: "gcr.io/broad-getzlab-workflows/cga_production_pipeline:v0.2.ccle"
        bootDiskSizeGb: if diskGB_boot != "" then diskGB_boot else default_diskGB_boot
        preemptible: if preemptible != "" then preemptible else default_preemptible
        cpu: if cpu != "" then cpu else default_cpu
        disks: "local-disk ${diskGB} HDD"
        memory: machine_memoryGB + "GB"
    }

    output {
        File WXS_Mutation_M1_SNV_M2_INDEL_Strelka_INDEL_annotated_maf="${pairName}.MuTect1_SNV.MuTect2_INDEL.Strelka_INDEL.annotated.maf"               
    }
}


task OrientationBias_filter_Task {

    # TASK INPUT PARAMS
    File tumorBam
    File tumorBamIdx
    File? detailMetrics
    File MAF
    String pairName
    String stub
    File refFasta
    File GATK4_JAR

    # FILE SIZE
    Int tumorBam_size
    Int refFasta_size
    Int gatk4_jar_size

    # RUNTIME INPUT PARAMS
    String preemptible
    String diskGB_boot
    String diskGB_buffer
    String memoryGB
    String cpu

    # DEFAULT VALUES
    String default_cpu = "1"
    String default_memoryGB = "7"
    String default_preemptible = "1"
    String default_diskGB_boot = "15"
    String default_diskGB_buffer = "20"

    Boolean found_detailMetrics = defined(detailMetrics)

    # COMPUTE MEMORY SIZE
    Int machine_memoryGB = if memoryGB != "" then memoryGB else default_memoryGB
    Int command_memoryGB = machine_memoryGB - 1

    # COMPUTE DISK SIZE
    Int machine_diskGB_buffer = if diskGB_buffer != "" then diskGB_buffer else default_diskGB_buffer
    Int diskGB = ceil(tumorBam_size + refFasta_size + gatk4_jar_size + size(MAF, "G") 
                      + machine_diskGB_buffer)

    parameter_meta {        
        tumorBam: "sample tumor BAM file"
        tumorBamIdx : "sample tumor BAI file (indexed BAM)"
        MAF : "filename pointing to a mutation annotation format (MAF) file (data for somatic point mutations)"
        detailMetrics : "output from the Picard Multiple Metrics CollectSequencingArtifactMetrics run with the settings here; this allows for passthrough instead of recomputing"       
        refFasta : "Reference that was used to align BAM"
        stub : "string used to indicate in the output the effect name"
    }

    command <<<

        set -euxo pipefail

        SNV_MAF="${pairName}.snv.maf"
        INDEL_MAF="${pairName}.indel.maf"
        python /usr/local/bin/split_maf_indel_snp.py -i ${MAF} -o $SNV_MAF -f Variant_Type -v "SNP|DNP|TNP|MNP"
        python /usr/local/bin/split_maf_indel_snp.py -i ${MAF} -o $INDEL_MAF -f Variant_Type -v "INS|DEL"

        ################################

        python /usr/local/bin/get_context_ref_alt_alleles.py -s ${stub} -i ${pairName}

        CONTEXT=$( cat "${pairName}.context.${stub}.txt" )
        ARTIFACT_ALLELE=$( cat "${pairName}.artifact_allele.${stub}.txt" )

        if [ -s "${detailMetrics}" ] ;
        then
            DETAIL_METRICS_FILE=${detailMetrics}
        else
            /usr/local/jre1.8.0_73/bin/java "-Xmx${command_memoryGB}g" -jar ${GATK4_JAR} CollectSequencingArtifactMetrics \
            --INPUT ${tumorBam} \
            --OUTPUT ${pairName} \
            --REFERENCE_SEQUENCE ${refFasta}
            DETAIL_METRICS_FILE="${pairName}.pre_adapter_detail_metrics"  
        fi ;

        # Now parsing metrics for Q value
        python /usr/local/orientationBiasFilter/annotate_orientationBiasQ.py -i ${pairName} -m $DETAIL_METRICS_FILE -c $CONTEXT -a $ARTIFACT_ALLELE

        Q=$( cat "${pairName}.orientation_BiasQ.txt" )

        # Appending Q value to MAF
        python /usr/local/orientationBiasFilter/AppendAnnotation2MAF.py -i ${pairName} -m $SNV_MAF -f ${stub}_Q -v $Q

        OUTPUT_INTERVAL_FILE="${pairName}.intervals"
        OUTPUT_INFO_FILE="${pairName}.orientation_info.txt" 

        python /usr/local/orientationBiasFilter/write_interval_file.py "${pairName}.${stub}_Q.maf.annotated" $OUTPUT_INTERVAL_FILE       

        java "-Xmx${command_memoryGB}g" -jar /usr/local/orientationBiasFilter/GenomeAnalysisTK.jar \
        --analysis_type OxoGMetrics \
        -R ${refFasta} \
        -I ${tumorBam} \
        -L $OUTPUT_INTERVAL_FILE \
        -o $OUTPUT_INFO_FILE

        # Now appending orientation bias information to the MAF
        python /usr/local/orientationBiasFilter/AppendOrientationBiasFields2MAF.py \
        -i ${pairName} -m "${pairName}.${stub}_Q.maf.annotated" -b ${tumorBam} \
        -f $OUTPUT_INFO_FILE

        REF_ALLELE_COMP=$( cat "${pairName}.ref_allele_compliment.${stub}.txt" )
        ARTIFACT_ALLELE_COMP=$( cat "${pairName}.artifact_allele_compliment.${stub}.txt")

        bash -c "source /matlab_source_file_2012a.sh && /usr/local/orientationBiasFilter/orientationBiasFilter ${pairName}.OrientationBiasInfo.maf \
        ${pairName}.OrientationBiasFilter.maf . '0' '1' '0.96' '0.01' '-1' '30' '1.5' \
        $REF_ALLELE_COMP $ARTIFACT_ALLELE_COMP i_${stub}" ;

        #########################################

        #merge back indels into OBF output
        python /usr/local/bin/tsvConcatFiles.py $INDEL_MAF "${pairName}.OrientationBiasFilter.maf" \
        --outputFilename="${pairName}.OrientationBiasFilter.${stub}.indel_snp_merged.filtered.maf"

        python /usr/local/bin/tsvConcatFiles.py $INDEL_MAF "${pairName}.OrientationBiasFilter.unfiltered.maf" \
        --outputFilename="${pairName}.OrientationBiasFilter.${stub}.indel_snp_merged.unfiltered.maf"

        python /usr/local/bin/add_judgement_column.py \
        --input "${pairName}.OrientationBiasFilter.${stub}.indel_snp_merged.unfiltered.maf" \
        --output "${pairName}.OrientationBiasFilter.${stub}.indel_snp_merged.unfiltered.with_annotations.maf" \
        --column "i_${stub}_cut" \
        --pass_flag "0"
        
        zip -r ${pairName}.${stub}_OBF_figures.zip ./figures

    >>>

    runtime {
        docker: "gcr.io/broad-getzlab-workflows/cga_production_pipeline:v0.2.ccle"
        bootDiskSizeGb: if diskGB_boot != "" then diskGB_boot else default_diskGB_boot
        preemptible: if preemptible != "" then preemptible else default_preemptible
        cpu: if cpu != "" then cpu else default_cpu
        disks: "local-disk ${diskGB} HDD"
        memory: machine_memoryGB + "GB"
    }

    output {      
        Float q_val=read_float("${pairName}.orientation_BiasQ.txt")
        File OBF_figures="${pairName}.${stub}_OBF_figures.zip"
        Int num_passed_mutations=read_int("${pairName}.OrientationBiasFilter.maf.pass_count.txt")
        Int num_rejected_mutations=read_int("${pairName}.OrientationBiasFilter.maf.reject_count.txt")
        File WXS_Mutation_OBF_filtered_maf="${pairName}.OrientationBiasFilter.${stub}.indel_snp_merged.filtered.maf"
        File WXS_Mutation_OBF_unfiltered_maf="${pairName}.OrientationBiasFilter.${stub}.indel_snp_merged.unfiltered.maf"
        File WXS_Mutation_OBF_unfiltered_maf_with_annotations="${pairName}.OrientationBiasFilter.${stub}.indel_snp_merged.unfiltered.with_annotations.maf"
    }
}